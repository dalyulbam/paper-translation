ChatGPT는 좋은 번역기인가요? 네, GPT-4가 엔진으로 사용될 경우 좋은 번역기입니다.

문흥 자오∗ 웬쉰 왕 젠츠 황 싱 왕

수밍 시 자오펑 투

텐센트 AI 연구소
{joelwxjiao}@tencent.com

요약

이 보고서는 ChatGPT의 기계 번역에 대한 예비 평가를 제공합니다. 번역 프롬프트, 다국어 번역 및 번역 강건성을 포함합니다. 우리는 ChatGPT가 제안한 프롬프트를 채택하여 번역 능력을 활성화하고, 후보 프롬프트가 일반적으로 작동하며 성능 차이가 적다는 것을 발견했습니다. 여러 벤치마크 테스트 세트를 평가함으로써, ChatGPT가 고자원 유럽 언어에서 상업용 번역 제품 (예: Google 번역)과 경쟁력을 가지지만, 저자원이거나 먼 언어에서는 크게 뒤쳐진다는 것을 알 수 있었습니다. 번역 강건성에 대해서는, ChatGPT는 생물의학 초록이나 Reddit 댓글과 같은 상업 시스템만큼 잘 작동하지 않지만, 구어 언어에서는 좋은 결과를 보여줍니다. 더 나아가, 우리는 먼 언어에 대한 피벗 프롬프팅이라는 흥미로운 전략을 탐구했습니다. 이는 ChatGPT에게 소스 문장을 고자원 피벗 언어로 번역한 후 대상 언어로 번역하도록 요청하여 번역 성능을 현저하게 향상시킵니다. GPT-4 엔진의 출시로 인해, ChatGPT의 번역 성능은 크게 향상되어 먼 언어에 대해서도 상업용 번역 제품과 비교 가능해졌습니다. Google 번역과 ChatGPT에 대한 인간 분석 결과, GPT-3.5를 사용한 ChatGPT는 환각과 오역 오류를 더 많이 생성하는 경향이 있으며, GPT-4를 사용한 ChatGPT는 가장 적은 오류를 만듭니다. 다시 말해, ChatGPT는 이미 좋은 번역기가 되었습니다. 자세한 내용은 우리의 Github 프로젝트를 참조하십시오: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator.

1 소개

ChatGPT1은 InstructGPT(2022년 Ouyang 등)를 기반으로 개발된 OpenAI의 지능형 채팅 기계입니다. 이 기계는 프롬프트에 따라 지시를 따르고 자세한 응답을 제공하는 것을 학습했습니다.

∗대응 저자.
1https://chat.openai.com

그림 1: 2022.12.16일에 ChatGPT가 기계 번역을 위해 제안한 프롬프트.

공식 발표에 따르면, ChatGPT는 대화 형식으로 인해 후속 질문에 답변할 수 있으며, 잘못된 점을 인정하고, 잘못된 전제를 도전하며, 부적절한 요청을 거절할 수 있습니다. 이는 질문에 대답하는, 이야기를 하는, 논리적 추론을 하는, 코드 디버깅을 하는, 기계 번역 등과 같은 자연어 처리의 다양한 능력을 통합합니다. 특히, ChatGPT가 기계 번역 작업에서 어떻게 수행되는지, 특히 ChatGPT와 상용 번역 제품 (예: Google 번역, DeepL 번역) 간의 차이에 대해 흥미롭게 생각합니다.
이 보고서에서는 ChatGPT의 기계 번역에 대한 예비 연구를 제공하며, 우리의 최선의 지식에 따르면 ChatGPT의 출시 이후로도 처음으로 이루어진 연구입니다. 구체적으로, 우리는 세 가지 측면에 초점을 맞추고 있습니다.

번역 프롬프트: ChatGPT는 본질적으로 큰 언어 모델이며, 번역 능력을 활성화하기 위해 프롬프트로 안내가 필요합니다. 프롬프트의 스타일은 번역 결과의 품질에 영향을 미칠 수 있습니다. 예를 들어, 다국어 기계 번역 모델에서 소스 또는 대상 언어 정보를 어떻게 언급하는지는 중요한 문제이며, 일반적으로 언어 토큰을 첨부하여 해결됩니다 (Johnson et al., 2017; Fan et al., 2021).

• 다국어 번역: ChatGPT는 다양한 NLP 작업을 처리하며 다른 언어를 다루는 단일 모델입니다. 이는 통합된 다국어 기계 번역 모델로 간주될 수 있습니다. 따라서, 우리는 리소스 차이 (예: 높음 vs 낮음)와 언어 패밀리 (예: 유럽 vs 아시아)를 모두 고려하여 ChatGPT가 다른 언어 쌍에서 어떻게 수행되는지 궁금합니다.

번역 견고성: ChatGPT는 다양한 도메인을 포함하는 대규모 데이터셋으로 훈련된 GPT3를 기반으로 개발되었습니다. 따라서, 도메인 특정 또는 심지어 노이즈가 있는 문장에서도 견고하게 잘 수행할 수 있는지 궁금합니다.

ChatGPT의 번역 능력을 활성화하기 위해, 우리는 ChatGPT 자체에 조언을 구하고 세 가지 후보 번역 프롬프트를 얻습니다. 중국어⇒영어 번역 작업을 평가함으로써, 후보 프롬프트가 일반적으로 잘 작동하고 성능 차이가 작다는 것을 알아냅니다. 그럼에도 불구하고, 우리는 연구의 나머지 부분에 대해 가장 성능이 우수한 프롬프트를 채택합니다. Flores-101 테스트 세트에서 선택된 네 가지 언어 간의 번역을 평가한 결과, ChatGPT는 고자원 유럽 언어에 대해서 상업용 번역 제품 (예: Google 번역)과 경쟁력 있는 성능을 보이지만, 저자원이거나 먼 언어에 대해서는 크게 뒤쳐집니다. 번역의 견고성에 대한 결과로, 세 가지 견고성 세트에서의 결과는 ChatGPT가 생물 의학 초록이나 Reddit 댓글에 대해서 상업용 시스템만큼 잘 작동하지 않지만, 구어 언어에 대해서는 좋은 결과를 보여줍니다.
또한, 기계 번역을 위해 ChatGPT를 개선하는 방법에 대해 논의합니다. 한편으로, 먼 언어에 대한 피벗 프롬프팅이라는 흥미로운 전략을 탐구합니다. 이는 ChatGPT에게 소스 문장을 고자원 피벗 언어로 번역한 후 대상 언어로 번역하도록 요청하여 번역 성능을 현저하게 향상시킵니다. 다른 한편으로는, 개선된 엔진 GPT-4 (OpenAI, 2023)2가 2023년 3월 15일에 출시되어 ChatGPT의 번역 능력을 재평가하고 성능이 크게 향상되었음을 관찰합니다. ChatGPT의 번역 성능은 먼 언어에 대해서도 상업용 번역 제품과 비교 가능해집니다. Google 번역과 ChatGPT에 대한 포괄적인 분석은 GPT-3.5를 사용한 ChatGPT가 환각을 더 많이 생성하고 번역 오류도 더 많이 발생하는 반면, GPT-4를 사용한 ChatGPT는 가장 적은 오류를 만든다는 것을 시사합니다.

2https://openai.com/research/gpt-4

테이블 1: 채택된 테스트 세트의 정보.

테스트 세트 방향 도메인 크기

플로레스-101 어떤    일반 1012
WMT19 생물⇒영어  생물의학 373

WMT20 Rob2
En⇒Ja
Reddit
1376
Ja⇒En           997
WMT20 Rob3 De⇒En Common Voice 5609

WMT20 로봇2
영어⇒일본어
Reddit
1376
일본어⇒영어           997
WMT20 로봇3 독일어⇒영어 Common Voice 5609

다시 말해, ChatGPT는 이미 GPT-4를 엔진으로 사용한 좋은 번역기가 되었습니다!

2. 기계 번역을 위한 ChatGPT

2.1 평가 설정

우리는 주로 비교 기준과 테스트 데이터를 포함한 평가 설정에 대해 간단히 소개합니다.

기준선. 우리는 ChatGPT를 구글 번역3, DeepL 번역4, 그리고 텐센트 TranSmart5와 비교합니다. 지금까지, 이 세 가지 상업용 시스템은 각각 133개, 29개, 그리고 16개 언어를 지원합니다. 이 보고서의 결과는 기본적으로 2022.12.16에 ChatGPT 버전에서 나온 것입니다. 새로운 결과에 대해서는 업데이트된 버전 정보를 상응하게 표시할 것입니다.

데이터. 다국어 번역을 위해 우리는 위의 번역 시스템을 Flores-101 (Goyal et al., 2021)6 테스트 세트에서 평가합니다. 이 테스트 세트는 1012개의 문장이 101개 언어로 번역된 것으로 구성되어 있습니다. 번역의 견고성을 테스트하기 위해, 우리는 WMT19 생물의학 번역 과제 (Bawden et al., 2019, 즉, Bio)의 테스트 세트와 WMT20 견고성 과제의 set2와 set3 (Specia et al., 2020, 즉, Rob2와 Rob3)를 채택합니다. 우리는 첫 번째 두 개의 테스트 세트를 SacreBLEU를 통해 얻었으며, 세 번째는 Wang et al. (2021)7에 의해 사전 처리되었습니다. 테이블 1은 이러한 테스트 세트의 정보를 나열합니다. 이 경험적 연구는 ChatGPT의 초기 버전이 출시된 시점에서 진행되었기 때문에, 우리는 웹페이지를 통해만 접근할 수 있었고, 대규모 배치에 대응할 수 없었습니다. 따라서 ChatGPT에서 번역 결과를 얻는 것은 시간이 많이 소요됩니다. 따라서 우리는 각 세트에서 무작위로 50개의 문장을 샘플링하여 평가합니다.

3번: https://translate.google.com
4번: https://www.deepl.com/translator
5번: https://transmart.qq.com/zh-CN/index
6번: https://github.com/facebookresearch/flores
7번: https://github.com/hsing-wang/WMT2020_BioMedical/tree/master/Bio-18-19-testset
표 2: 후보 번역 프롬프트.

번역 안내

TP1: 이 문장들을 한국어로 번역해주세요.
TP2: 이 문장들은 한국어로 무엇을 의미합니까?
TP3: 이 문장들의 한국어 번역을 제공해주세요.

메트릭. 우리는 주로 사용되는 BLEU 점수 (Papineni et al., 2002)를 주요 메트릭으로 채택하며, 일부 경우에는 ChrF++ (Popovi´ c, 2017)와 TER (Snover et al., 2006)도 보고합니다. 이 세 가지 메트릭은 모두 Sacre-BLEU (Post, 2018)8에서 지원됩니다.

2.2 번역 프롬프트

ChatGPT의 기계 번역 능력을 활성화하기 위해 프롬프트를 디자인하기 위해, 우리는 조언을 구하기 위해 ChatGPT에게 영감을 얻습니다. 구체적으로, 우리는 다음과 같은 프롬프트로 ChatGPT에게 질문합니다:

번역할 수 있는 10가지 간결한 프롬프트 또는 템플릿을 제공하세요.

그리고 그림 1에 나와 있는 결과를 얻으십시오. 생성된 프롬프트는 합리적으로 보이지만 유사한 형식을 공유합니다. 따라서 우리는 이를 표 2에 나와 있는 세 가지 후보 프롬프트로 요약합니다. 여기서 [SRC]와 [TGT]는 번역의 원본 언어와 대상 언어를 나타냅니다. 원래 형식에서 자주 발생하는 번역 주변의 이중 인용부호를 ChatGPT에게 생성하지 않도록 TP2에 추가 명령을 추가했습니다. 그러나 여전히 때로는 여러 줄에 걸친 배치의 문장이 단일 줄로 번역되는 등 불안정합니다.

우리는 중국어에서 영어로의 번역 작업에서 세 가지 다른 후보 프롬프트를 비교합니다. Flores-101의 테스트 세트와 함께 ChatGPT와 세 가지 상용 시스템의 결과를 표 3에 보여줍니다. ChatGPT는 꽤 좋은 번역을 제공하지만 여전히 최소한 5.0 BLEU 점수로 기준선에 미치지 못합니다. 세 가지 후보 프롬프트에 대해 TP3가 세 가지 메트릭스 모두에서 가장 우수한 성능을 보입니다. 따라서 이 보고서에서는 기본적으로 TP3를 사용합니다.

표 3: ChatGPT의 중국어-영어 (Zh⇒En) 번역을 위한 다양한 프롬프 비교.

시스템      BLEU↑ ChrF++↑ TER↓

구글 31.66 57.09 56.21
딥엘 31.22 56.74 57.84
텐센트 29.69 56.24 57.16
ChatGPT w/ TP1 23.25 53.07 66.03
ChatGPT w/ TP2 24.54 53.05 63.79
ChatGPT w/ TP3 24.73 53.71 62.84

2.3 다국어 번역

우리는 ChatGPT의 다국어 번역 능력을 평가하기 위해 독일어(De), 영어(En), 루마니아어(Ro) 및 중국어(Zh)를 포함한 네 가지 언어를 선택했습니다. 이 언어들은 연구(Wang et al., 2022a; Jiao et al., 2021, 2022b)와 대회(Bojar et al., 2016; Farhad et al., 2021)에서 일반적으로 사용됩니다. 첫 세 개의 언어는 라틴 문자로 이루어진 같은 언어 가족에서 나왔으며, 마지막 언어는 중국 문자로 이루어진 다른 언어 가족에서 나왔습니다(Fan et al., 2021). 우리는 총 12개의 번역 방향을 포함하는 어떤 두 언어 간의 번역 성능을 테스트합니다. 명확성과 비교를 위해 BLEU 점수와 Google 번역과의 성능 향상 또는 저하를 보고합니다. 표 4는 결과를 보여줍니다.

자원 차이. 우리는 동일 언어 가족 내에서의 자원 차이를 고려합니다. 기계 번역에서 독일어⇔영어 번역은 일반적으로 1,000만 개 이상의 문장 쌍으로 지원되는 고자원 작업으로 간주됩니다 (Farhad et al., 2021), 반면 루마니아어⇔영어 번역은 훨씬 적은 데이터로 지원됩니다 (Bojar et al., 2016). 이 자원 차이는 GPT-3의 데이터 통계9로도 나타낼 수 있습니다 (Brown et al., 2020), 하지만 ChatGPT의 데이터 정보는 알 수 없습니다. 표 4에서 보여지듯이, ChatGPT는 독일어⇒영어 및 영어⇒독일어 번역에서 Google 번역 및 DeepL 번역과 경쟁력을 유지합니다. 그러나 루마니아어⇒영어 및 영어⇒루마니아어에서는 그들보다 크게 뒤쳐집니다. 특히, ChatGPT는 영어⇒루마니아어에서 Google 번역보다 46.4% 낮은 BLEU 점수를 얻으며, 루마니아어⇒영어에서는 10.3%입니다. 우리는 단일 언어 자원의 큰 차이로 추측합니다.

8https://github.com/mjpost/sacrebleu
9https://github.com/openai/gpt-3/tree/master/
데이터셋 통계
표 4: ChatGPT의 다국어 번역 성능.

시스템

De-Ko: Bitte übersetzen Sie die Sätze ins Koreanische und schreiben Sie nur die Übersetzung auf.

En-Ko: 문장을 한국어로 번역하고 번역만 적어주세요.

Ro-Ko: Vă rugăm să traduceți propozițiile în coreeană și să nu scrieți decât traducerea.

⇒       ⇐       ⇒       ⇐       ⇒       ⇐

구글 45.04   41.16   50.12   46.03   31.66   43.58
딥엘  49.23(+9.3%) 41.46(+0.7%) 50.61(+0.9%) 48.39(+5.1%) 31.22(-1.3%) 44.31(+1.6%)
텐센트 n/a    n/a     n/a     n/a     29.69(-6.2%) 46.06(+5.6%)
ChatGPT 43.71(-2.9%) 38.87(-5.5%) 44.95(-10.3%) 24.85(-46.0%) 24.73(-21.8%) 38.27(-12.1%)

시스템

De-Zh: 请将以下句子翻译成韩语，只写下翻译结果。

Ro-Zh: Ве молиме преведете ги следниве реченици на корејски јазик, само напишете ги преводите.

De-Ro: Vă rugăm să traduceți propozițiile de mai jos în limba coreeană, scriind doar traducerile.

⇒       ⇐       ⇒       ⇐       ⇒       ⇐

구글 38.71   21.68   39.05   25.59   33.31   32.27
딥엘 40.46(+4.5%) 22.82(+5.2%) 38.95(-0.2%) 25.39(-0.7%) 35.19(+5.6%) 34.27(+6.1%)
텐센트 40.66(+5.0%) 19.44(-10.3%) n/a n/a n/a n/a
챗GPT 34.46(-10.9%) 19.80(-8.6%) 30.84(-21.0%) 19.17(-25.0%) 33.38(+0.2%) 29.89(-7.3%)

영어와 루마니아어 사이의 언어 데이터는 루마니아어의 언어 모델링 능력을 제한하며, 이는 영어⇒루마니아어에서의 성능 저하를 부분적으로 설명합니다. 반대로, 루마니아어⇒영어는 영어의 강력한 언어 모델링 능력을 활용하여 병렬 데이터의 자원 격차를 어느 정도 보상할 수 있습니다.

언어 가족. 우리는 언어 가족의 영향도 고려합니다. 기계 번역에서는 서로 다른 언어 가족 간의 번역이 동일한 언어 가족 내의 번역보다 어렵다고 여겨지는 경우가 많은데, 이는 문화와 문자체계의 차이 때문입니다. ChatGPT와 상업용 시스템 간의 차이는 독일어⇔영어와 중국어⇔영어 또는 독일어⇔중국어 번역을 비교함으로써 더욱 커짐을 발견할 수 있습니다. 우리는 동일한 가족 내에서의 지식 전달(예: 영어에서 독일어로)이 서로 다른 가족 간(예: 영어에서 중국어로)보다 더 잘 이루어진다고 생각합니다. 저자들은 낮은 자원을 가진 서로 다른 가족의 언어 쌍(예: 루마니아어⇔중국어)의 경우 성능 차이가 더욱 커질 수 있다고 언급합니다(Wang et al., 2022b). ChatGPT는 하나의 모델에서 다양한 작업을 처리하기 때문에, 낮은 자원 번역 작업은 고자원 번역 작업(Jiao et al., 2022a)과 모델 용량을 위해 다른 NLP 작업과도 경쟁하게 되어 그 성능이 저하되는 것을 설명합니다.

2.4 번역 견고성

우리는 ChatGPT의 번역 견고성을 WMT19 Bio 및 WMT20 Rob2에서 추가로 평가합니다.

표 5: ChatGPT의 번역 견고성 성능 - 도메인 특정 또는 노이즈가 있는 테스트 데이터.

시스템
W19 바이오 W20 로봇2 W20 로봇3

De⇒En: Please translate the sentences into Korean.
En⇒Ja: 문장을 한국어로 번역해주세요.
Ja⇒En: Please translate the sentences into Korean.
De⇒En: Please translate the sentences into Korean.

구글 37.83 29.72 19.21 42.91
딥엘 37.13 26.25 19.83 41.29
챗GPT 33.22 22.36 18.34 44.59

그리고 Rob3 테스트 세트는 도메인 편향과 잠재적으로 오류가 있는 데이터의 영향을 소개합니다. 예를 들어, WMT19 Bio 테스트 세트는 도메인 특정 지식이 필요한 Medline 초록으로 구성되어 있습니다. WMT20 Rob2는 reddit.com이라는 소셜 미디어 웹사이트의 댓글로, 철자/타이포그래피 오류, 단어 생략/삽입/반복, 문법 오류, 구어체, 인터넷 용어 등 다양한 오류가 포함될 수 있습니다 (Michel and Neubig, 2018).

표 5는 BLEU 점수를 나열합니다. 분명히, ChatGPT는 WMT19 Bio 및 WMT2 Rob2 테스트 세트에서 Google 번역 또는 DeepL 번역만큼 잘 수행하지 않습니다. 그 이유는 Google 번역과 같은 상업용 번역 시스템은 종종 도메인 특정 (예: 생물의학)이나 노이즈가 있는 문장을 번역하는 능력을 지속적으로 향상시켜야 하기 때문일 수 있습니다. 왜냐하면 이들은 외부 데이터에 대한 더 나은 일반화 성능을 요구하는 실제 응용 프로그램이기 때문입니다. 그러나 ChatGPT에서는 이러한 작업이 수행되지 않을 수도 있습니다.

흥미로운 발견은 ChatGPT가 우수한 성능을 보였다는 것이다.
표 6: WMT20 Robust Set3에서의 예시들.

영화를 보러 가고 싶어요.

SRC     Ich habe gestern ein interessantes Buch gelesen.
REF     I read an interesting book yesterday.
Google  I read an interesting book yesterday.
DeepL   I read an interesting book yesterday.
ChatGPT I read an interesting book yesterday.

구글 번역과 딥엘 번역은 크라우드소싱 음성 인식 말뭉치를 포함한 WMT20 Rob3 테스트 세트에서 현저한 성능을 보입니다. 이는 ChatGPT가 본질적으로 인공지능 채팅 기계로, 상업용 번역 시스템보다 더 자연스러운 언어를 생성할 수 있다는 것을 시사합니다. 표 6에서 몇 가지 예시를 제공합니다.

3. MT를 위한 ChatGPT 개선하기

위에서 제시된대로, ChatGPT는 고자원 언어 쌍에서 상업용 번역 시스템과 동등한 성능을 보일 수 있지만, 특히 먼 언어들과 같은 저자원 언어 쌍에서는 여전히 어려움을 겪습니다. 그렇다면, 한 가지 질문이 생깁니다:

ChatGPT를 기계 번역을 위해 어떻게 개선할 수 있을까요?

3.1 피벗 프롬프팅

ChatGPT를 기계 번역(MT)을 위해 개선하는 첫 번째 방법은 대상 작업을 지원하기 위해 ChatGPT의 잠재력을 다른 작업에서 활용하는 것입니다. 여기에서는 먼 언어 간의 번역 품질을 개선하기 위해 Pivot Prompting이라는 흥미로운 전략을 탐구합니다. 소스 언어와 대상 언어 간의 직접 번역 대신, 우리는 ChatGPT에게 소스 문장을 먼저 고자원 피벗 언어(기본적으로 영어)로 번역하고, 그 후에 대상 언어로 번역하도록 요청합니다. 따라서, 우리는 다음과 같이 TP3 프롬프트를 조정합니다.

그림 2: ChatGPT에 의한 피벗 프롬프팅을 통한 번역 결과 (날짜: 2023.01.31).

표 7: 피벗 프롬프팅을 사용한 ChatGPT의 성능.
2023.01.31에 업데이트된 ChatGPT 버전에서 새로운 결과를 얻었습니다. LR: 길이 비율.

시스템

De⇒Ko   Ro⇒Ko

블루 LR 블루 LR

구글 38.71 0.94 39.05 0.95
딥엘 40.46 0.98 38.95 0.99
챗GPT (직접) 34.46 0.97 30.84 0.91
챗GPT (직접새로운) 30.76 0.92 27.51 0.93
챗GPT (피벗새로운) 34.68 0.95 34.19 0.98

첫 번째 문장의 PIV 번역: 제발 번역을 제공해주세요.
첫 번째 문장의 TGT 번역: 번역을 먼저 제공하시고, 그 다음에 문장을 하나씩 번역해주세요.

두 번째 문장의 PIV 번역: 그런 다음에
두 번째 문장의 TGT 번역: 그런 다음에

세 번째 문장의 PIV 번역: 이 문장들을
세 번째 문장의 TGT 번역: 이 문장들을

네 번째 문장의 PIV 번역: 한 번에 하나씩
네 번째 문장의 TGT 번역: 한 번에 하나씩

다섯 번째 문장의 PIV 번역: 번역해주세요.
다섯 번째 문장의 TGT 번역: 번역해주세요.

[PIV] 언어를 기준으로 합니다. 대규모 언어 모델인 ChatGPT는 당연히 번역 결과를 생성하기 위해 프롬프트와 피벗 언어의 조건을 고려합니다. 그림 2는 피벗 프롬프팅을 사용할 때의 예시를 보여줍니다.
피벗 프롬프팅의 몇 가지 장점이 있습니다.

• 지식 전달: 두 개의 먼 언어 간에 병렬 데이터가 부족한 경우가 많지만 (Fan 등, 2021; Wang 등, 2022b), 그들과 중간 언어 간의 병렬 데이터는 상대적으로 상당할 수 있으며, 이는 소스-중간 및 중간-대상 방향의 번역 능력을 소스-대상 방향보다 더 잘 학습할 것으로 기대됩니다. 따라서, 중간 언어 프롬프팅은 고자원 중간 언어의 지식을 저자원 대상 언어로 전달할 수 있습니다 (Zoph 등, 2016; Aji 등, 2020; Li 등, 2022; He 등, 2022).
표 8: GPT-4의 다국어 번역 성능 (날짜: 2023.03.15)

시스템
De⇒En
En⇒De
Zh⇒En
En⇒Zh
De⇒Zh
Ro⇒Zh

구글 45.04 41.16 31.66 43.58 38.71 39.05
딥엘 49.23 41.46 31.22 44.31 40.46 38.95
텐센트 n/a n/a 29.69 46.06 40.66 n/a
챗지피티 (직접) 43.71 38.87 24.73 38.27 34.46 30.84
챗지피티 (직접 새로운) n/a n/a n/a n/a 30.76 27.51
챗지피티 (피벗 새로운) n/a n/a n/a n/a 34.68 34.19
GPT-4 46.00 45.73 28.50 42.50 38.16 37.84

• 편의성: 본질적으로, 피벗 프롬프팅은 이전 연구에서 사용된 피벗 번역 기술과 유사하지만 ChatGPT에게는 더 편리합니다. 일반적으로 채택되는 다국어 시퀀스-투-시퀀스 번역 모델(Fan et al., 2021)의 경우, 피벗 번역은 두 단계가 필요합니다: (1) 소스 문장을 입력하고 피벗 언어로 번역합니다. (2) 피벗 언어로 번역된 결과를 입력하고 대상 언어로 번역합니다. 그에 반해, ChatGPT는 [PIV] 및 [TGT] 언어를 모두 식별하고 소스 문장을 두 언어로 순차적으로 번역할 수 있습니다(그림 2 참조), 이는 단 한 단계의 작업만 필요합니다.

표 7은 BLUE 점수와 번역 결과의 길이 비율을 보여줍니다. 우리는 TP3 (즉, 직접)와 피벗 프롬프팅 (즉, 피벗)을 통해 영어를 거쳐 영어에서 대상 언어로 번역 결과를 얻습니다. 최신 ChatGPT 업데이트는 이전 버전 (즉, 직접새 대 직접)와 비교하여 독일어⇒중국어 및 루마니아어⇒중국어 번역의 품질을 저하시키는 것으로 보입니다. 그러나 피벗 프롬프팅은 독일어⇒중국어 및 루마니아어⇒중국어 번역에 대해 각각 거의 3.9와 6.6 BLEU 점수를 통해 번역 성능을 크게 향상시킬 수 있으며, 이는 그 효과를 보여줍니다. 번역 결과를 검토함으로써, 우리는 TP3로 직접 번역할 경우 소스 문장의 일부 토큰이 부족하게 번역되는 것을 발견했으며, 이는 피벗 프롬프팅으로 뚜렷하게 수정될 수 있습니다. 이는 길이 비율 결과로 확인할 수 있습니다. 피벗 프롬프팅은 ChatGPT에게 편리하지만, 더 긴 문장을 생성해야 하므로 추론 과정을 더 가속화하는 방법은 여전히 중요한 연구 질문입니다.

3.2 GPT-4 엔진으로

ChatGPT의 기계 번역을 개선하는 또 다른 방법은 엔진을 개선하는 것입니다. OpenAI는 예상대로 2023년 3월 15일에 GPT-4 (OpenAI, 2023)를 출시했으며, 이는 ChatGPT 뒤에 있는 GPT-3.5 모델보다 전반적으로 강력한 기능을 갖추고 있습니다. 따라서 우리는 네 가지 번역 방향에 대한 성능을 재평가합니다. 표 8에 나와 있는 것처럼, GPT-4는 네 가지 방향 모두에서 ChatGPT의 성능을 크게 향상시켜 BLEU 점수를 최고 수준의 상업용 번역 시스템 수준으로 끌어올렸습니다. 이러한 결과는 제로샷 설정에서만 얻어진 것임을 유의하십시오. Brown 등 (2020), Agrawal 등 (2022)과 같은 현대적인 기술을 사용하면 번역 성능을 더욱 개선할 수 있습니다. 다시 말해, GPT-4는 이미 좋은 번역기가 되었습니다!

4 분석

여기에서는 ChatGPT에 대한 더 깊은 이해를 위해 번역 결과에 대한 몇 가지 분석을 수행합니다. 기본적으로 우리는 50개의 테스트 예제에 대해 Zh⇒En 번역의 Google, ChatGPT 및 GPT-4의 결과를 분석합니다.

4.1 자동 분석

우리는 이전 연구(Jiao et al., 2021; Wang et al., 2022a)를 따라 자동 도구인 compare-mt10을 사용하여 번역 결과를 단어 수준과 문장 수준에서 분석합니다.

빈도수. 기본적으로, ChatGPT는 다양한 도메인을 포함하는 다양한 말뭉치에 대해 훈련된 대형 언어 모델입니다. 테스트 세트에서 낮은 빈도 단어의 번역에 도움이 될 수 있습니다. 구체적으로, 우리는 대상 단어를 빈도에 따라 세 가지 범주로 나누고 단어의 정확도를 계산합니다.

10https://github.com/neulab/compare-mt
표 9: 빈도 버킷에 대한 대상 단어 예측의 F-측정값.

Freq Google ChatGPT GPT-4
구글 챗GPT GPT-4

< 2   48.0   43.7   47.1
[2,10) 59.0  57.6   56.7
≥ 10  71.6   70.5   70.1

테이블 10: 대상 문장의 길이 버킷에 따른 번역 성능 (즉, BLEU)입니다.

길이 구글 챗GPT GPT-4

< 15   34.2   15.4   26.1
[15,30) 26.6   21.4   24.3
≥ 30   23.2   16.0   19.4

예측. 표 9는 F-측정 결과를 보여줍니다.
놀랍게도, ChatGPT는 낮은 빈도 단어 (즉, < 2)에서 최악의 성능을 보입니다. 이는 ChatGPT의 미숙한 번역 능력으로 설명할 수 있습니다. 흥미로운 점은 GPT-4가 주로 이러한 결함을 해결하면서 높은 빈도 단어에는 거의 개선이 없다는 것입니다.

문장 길이. ChatGPT는 또한 기계 번역과 달리 생성된 문장에 엄격한 길이 제약이 필요하지 않은 다양한 텍스트 생성 작업에 대해 훈련되었습니다. 따라서 문장 길이가 번역 성능에 얼마나 민감한지 궁금합니다. 우리는 평균 값이 23.2 토큰인 문장 길이를 기준으로 대상 문장을 세 가지 범주로 나눕니다. 표 10은 결과를 보여줍니다. 보시다시피, ChatGPT는 짧은 문장 (즉, <15)에서 가장 나쁜 성능을 보이며, Google 번역보다 18.8 BLEU 점수가 낮습니다. 한 가지 관찰 결과, 예를 들어 "美国公共广播公司"와 같은 용어를 번역할 때, ChatGPT는 전체 이름 (즉, American Public Broadcasting System)을 출력하는 경향이 있으며, Google 번역과 참고 자료는 약어 (즉, PBS)를 사용합니다. 결과적으로, 단어 예측의 정확도가 현저히 감소하고, BLEU 점수 (Papineni 등, 2002)도 특히 짧은 문장의 경우 감소합니다. GPT-4는 때때로 약어를 올바르게 예측할 수 있어 더 나은 번역 성능을 제공합니다.

4.2 인간 분석

자동 분석 외에도 번역 결과물을 수동으로 검토합니다. 우리는 세 명의 주석 작성자에게 번역 결과물의 오류를 식별하도록 요청합니다 (Wang et al., 2022a), 이는 다음을 포함합니다.

테이블 11: 인간에 의해 주석이 달린 번역 오류의 수.

오류: 구글 챗GPT GPT-4

Und-Trans 9      5      5
언더-번역 9      5      5

Ove-Trans 6      8      1
오버-번역 6      8      1

Mis-Trans 16     23     7
미스-번역 16     23     7

표 12: 번역 결과에 대한 인간 평가.

랭크  구글 챗GPT GPT-4

1    이십     십일     삼십이
2    십사     십구     십삼
3    십육     이십     오

번역 (즉, Und-Trans), 과도한 번역 (즉, Ove-Trans) 및 오역 (즉, Mis-Trans)에 따라, 주석자들은 Google, ChatGPT 및 GPT-4의 번역 결과를 순위를 매깁니다. 1은 가장 우수한 시스템이고 3은 가장 나쁜 시스템입니다. 구별하기 어려운 번역 결과의 경우, 동일한 순위를 허용합니다 (예 : 1-1-1, 1-1-2 또는 1-2-2). 주관적인 편향을 없애기 위해, 각 번역 결과의 시스템 정보를 주석자들에게 제공하지 않으며, 각 테스트 예제의 세 가지 번역 결과도 무작위로 섞입니다.

표 11은 번역 오류의 결과를 보여줍니다. 일반적으로, ChatGPT는 Google 번역보다 과도한 번역 오류와 오역 오류가 더 많이 발생하지만, 약간 덜 부족한 번역 오류가 있습니다. 이는 ChatGPT가 환각을 생성하기 더 가능성이 있다는 것을 시사합니다. 반면, GPT-4는 세 가지 오류 클래스에서 가장 적은 오류를 발생시키며, 가장 우수한 번역 성능을 보여줍니다. 이는 표 12의 순위 결과에 의해 확인되며, GPT-4가 50개의 테스트 예제 중 32번에서 가장 우수한 순위 (즉, 1)를 차지하고, Google 번역과 ChatGPT가 그 뒤를 따릅니다. 그러나 GPT-4의 BLEU 점수는 여전히 Google 번역의 점수보다 낮습니다 (즉, 표 8에서 28.50 대 31.66), 이는 GPT-4가 참조로부터 다양한 어휘 선택과 함께 더 다양한 번역을 생성할 수 있다는 것을 나타냅니다.

4.3 사례 연구

테이블 13에서 직관적인 이해를 위해 네 가지 테스트 예제를 제시합니다. 첫 번째 예제는 ChatGPT의 처음 몇 개의 토큰에서의 환각과 过量降水의 부정확한 번역을 보여줍니다. 두 번째 예제는 ChatGPT와 GPT-4 모두에서의 예시입니다. 테이블 13: Flores Zh⇒En 테스트 세트의 예시.

영화를 보러 가고 싶어요.

강한 바람, 우박, 과도한 강수량, 산불은 극한 날씨의 형태와 영향이며, 뇌우, 토네이도, 물소용돌이, 사이클론도 그렇습니다.

구글 강한 바람, 우박, 과도한 강수량, 산불뿐만 아니라 천둥번개, 토네이도, 물바람, 사이클론 등은 모두 극한 기상 현상과 영향의 표현입니다.
ChatGPT 강한 바람, 우박, 과도한 강우, 산불, 천둥번개, 토네이도, 물바람, 사이클론 등과 같은 극한 기상 조건은 모두 극한 기상의 표현과 영향입니다.
GPT-4 강한 바람, 우박, 과도한 강수량, 산불뿐만 아니라 천둥번개, 토네이도, 물바람, 사이클론 등은 모두 극한 기상의 표현과 영향입니다.

그러나, 광범위한 내성 결핵의 비율은 여전히 전체 결핵 환자 중에서 낮아 보입니다. 남아프리카에서 특정 시점에 감염된 총 33만 명 중 6,000명만이 감염되었습니다.

구글 그러나, 전체 결핵 환자 인구에서 XDR-TB의 비율은 여전히 낮아 보입니다. 남아프리카에서는 현재 33만 명 중 단지 6,000명만 감염되어 있습니다.
ChatGPT 그러나, 전체 결핵 환자 인구에서 광범위한 약물 내성 결핵의 비율은 여전히 낮아 보입니다. 남아프리카에서는 어떤 시점에서도 총 33만 명 중 단지 6,000명만 감염되어 있습니다.
GPT-4 그러나, 전체 결핵 환자 인구 중 광범위한 약물 내성 결핵의 비율은 여전히 상당히 낮아 보입니다. 남아프리카에서는 어떤 시점에서도 총 33만 명 중 단지 6,000명만 감염되어 있습니다.

이것은 헨리 루이스 게이츠가 미국 공중방송사의 "아프리카 세계의 기적" 특별 프로그램에서 중요한 한 구간입니다.

REF   헨리 루이스 게이츠의 PBS 특집 '아프리카 세계의 경이로움' 중 하나의 주요 정차지였다.

구글은 PBS에서 헨리 루이스 게이츠의 "아프리카의 기적" 특별 프로그램에서 중요한 장소였습니다.


GPT-4 이것은 헨리 루이스 게이츠의 PBS 특별 프로그램 "아프리카 세계의 경이로움"에서 중요한 장면입니다.

SRC   늑대 아이는 완전히 비인간 동물에 의해 양육되어 자라면 (신체적인 조건이 허용하는 범위 내에서) 그 행동은 그 동물과 매우 유사할 것이다. 예를 들어 인간에 대해 두려움이나 무관심을 보일 수 있다.

비인간 동물에 의해 완전히 키워진 야생 아동은 (신체적 한계 내에서) 특정 동물의 돌봄을 받는 것과 거의 동일한 행동을 보여줍니다. 예를 들어, 인간에 대한 두려움이나 무관심과 같은 특징을 가지고 있습니다.

Google: 늑대 아이가 비인간 동물에 의해 완전히 키워진다면, 그 행동은 (신체 상태가 허용하는 한도 내에서) 인간에 대한 두려움이나 무관심과 같은 동물과 매우 유사할 것입니다.
ChatGPT: 늑대 아이가 비인간 동물에 의해 완전히 키워진다면, 그 행동은 (신체 조건의 한계 내에서) 동물과 매우 유사하여 인간에 대한 두려움이나 무관심을 보일 것입니다.
GPT-4: 비인간 동물에 의해 완전히 키워진 야생 아이는 (자신의 신체 능력의 한계 내에서) 동물과 매우 유사한 행동을 보일 것이며, 인간에 대한 두려움이나 무관심을 나타낼 것입니다.

광범위한 내성 결핵병

5 결론

이 작업은 기계 번역을 위한 ChatGPT의 예비 연구를 제시합니다. 우리는 ChatGPT를 사용하여 다음을 발견했습니다.

상업적 번역 제품들 (예: Google 번역)과 경쟁력을 갖추며, 고자원 유럽 언어에 대해서는 우수한 성과를 보이지만, 저자원이거나 먼 언어에 대해서는 상당히 뒤쳐지고 있습니다. 또한, 구어체에 대해서는 좋은 결과를 보여주지만, 생물의학 초록이나 Reddit 댓글에 대해서는 상업 시스템보다 성능이 낮습니다. 우리는 또한 '피벗 프롬프팅'이라는 흥미로운 전략을 탐구하였는데, 이는 먼 언어의 번역 성능을 상당히 향상시킬 수 있습니다. GPT-4 엔진의 출시로 인해, ChatGPT의 번역 성능이 크게 향상되어, 먼 언어에 대해서도 상업적 번역 제품들과 비교 가능한 수준이 되었습니다. 광범위한 인간 분석 결과, ChatGPT는 이미 GPT-4 엔진을 사용한 좋은 번역기가 되었다고 시사합니다.

제한사항

초기 연구로서, 이 작업은 신뢰성을 높이기 위해 다양한 측면에서 아직 완전하지 않습니다.

• 포괄성: 현재, ChatGPT의 응답 지연으로 인해 평가를 위해 각 테스트 세트에서 무작위로 50개의 샘플을 선택합니다. 이는 데이터 커버리지로 인해 포괄적이지 않습니다. 게다가, 동일한 쿼리의 결과가 여러 번의 시도에서 다를 수 있어 평가 결과에 무작위성을 가져옵니다. 더 신뢰할 수 있는 결과를 얻기 위해서는 각 테스트 세트에 대해 번역을 여러 번 반복하고 평균 결과를 보고하는 것이 가장 좋습니다.

번역 능력: 이 보고서에서는 다국어 번역과 번역의 견고성에만 초점을 맞추고 있습니다. 그러나 제한된 기계 번역 및 문서 수준의 기계 번역과 같은 다른 번역 능력도 추가로 평가될 수 있습니다.

참고문헌

스웨타 아그라왈, 춘팅 조우, 마이크 루이스, 루크 제틀모이어, 그리고 마르잔 가즈비니네자드. 2022년. 기계 번역을 위한 문맥 예시 선택. arXiv.

알함 피크리 아지, 니콜라이 보고이체프, 케네스 히필드,
그리고 리코 센리치. 2020년. 신경망 기계 번역에서 전이 학습은 무엇을 전달하는가? ACL에서.

Rachel Bawden, Kevin Bretonnel Cohen, Cristian Grozea, Antonio Jimeno Yepes, Madeleine Kittner, Martin Krallinger, Nancy Mah, Aurelie Neveol, Mariana Neves, Felipe Soares 등. 2019년. WMT 2019 생물의학 번역 공유 작업 결과: Medline 초록 및 생물의학 용어에 대한 평가. WMT에서.

온드레이 보야르, 라젠 챠터지, 크리스티안 페더만,
이벳 그레이엄, 배리 하도우, 마티아스 허크, 안토니오 히메노 예페스, 필립 쾐른, 바르바라 로가체바, 크리스토프 몬츠 등. 2016년 기계 번역 컨퍼런스 결과. WMT에서 발표.

톰 브라운, 벤자민 맨, 닉 라이더, 멜라니 서비아, 제어드 D 카플란, 프라풀라 다리왈, 아르빈드 니라칸탄, 프라나브 샤이암, 기리쉬 사스트리, 아만다 애스켈 등. 2020년. 언어 모델은 소수샷 학습자입니다. NeurIPS.

용 청, 양 리우, 치안 양, 마오송 선, 그리고 위 쉬. 2016. 중간 언어를 이용한 신경 기계 번역. arXiv.

안젤라 팬, 슈루티 보살레, 홀거 슈벵크, 지이 마, 아메드 엘-키스키, 시다르트 고얼, 만딥 베인스, 오누르 첼레비, 기욤 웬제크, 비샤브 초다리 등. 2021년. 영어 중심 다국어 기계 번역을 넘어서. JMLR, 22(107):1–48.

2021년 기계 번역 (WMT21) 컨퍼런스 결과. Akhbardeh Farhad, Arkhangorodsky Arkady, Biesialska Magdalena, Bojar Ondˇrej, Chatterjee Rajen, Chaudhary Vishrav, Marta R Costa-jussa, España-Bonet Cristina, Fan Angela, Federmann Christian 등. WMT에서 발표.

나만 고얼, 신디아 가오, 비샤브 초다리, 펑-젠 첸, 기욤 웬젝, 다 주, 산자나 크리슨난, 마크 오렐리오 란자토, 프란시스코 구즈만, 그리고 안젤라 팬. 2021년. 저자의 "The flores-101 evaluation benchmark for low-resource and multilingual machine translation" 논문. arXiv.

지웨이 허, 싱 왕, 쟈오펑 투, 슈밍 시, 루이 왕. 2022. WMT22 번역 과제를 위한 텐센트 AI 연구소 - 상하이자오툥대학교 저자원 번역 시스템. WMT에서 발표.

Wenxiang Jiao, Zhaopeng Tu, Jiarui Li, Wenxuan Wang,
Jen-tse Huang, and Shuming Shi. 2022a. 텐센트의 WMT22 대규모 아프리카 언어를 위한 다국어 기계 번역 시스템. WMT에서.

Wenxiang Jiao, Xing Wang, Shilin He, Zhaopeng Tu,
Irwin King, and Michael R Lyu. 2022b. 비활성 예제를 활용한 자연어 생성을 위한 데이터 재생. IEEE/ACM TASLP.

Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Shuming Shi,
Michael Lyu, and Irwin King. 2021. 자가 훈련을 위한 단일 언어 데이터 불확실성을 갖는 샘플링을 이용한 신경 기계 번역. ACL에서.

멜빈 존슨, 마이크 슈스터, 쿼크 르, 막심 크리쿤, 용희 우, 지펑 첸, 니킬 토라트, 페르난다 비에가스, 마틴 와텐버그, 그렉 코라도, 맥더프 휴즈, 제프리 딘. 2017. 구글의 다국어 신경망 기계 번역 시스템: 제로샷 번역 가능하게 함. TACL.




폴 미셸과 그레이엄 뉴빅. 2018. MTNT: 노이즈 텍스트의 기계 번역을 위한 테스트베드. EMNLP에서.

OpenAI. 2023년. GPT-4 기술 보고서. arXiv.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray 등. 2022. 인간 피드백을 통해 언어 모델에게 지시사항을 따르도록 훈련시키기. arXiv.
Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu 등. 2002. BLEU: 기계 번역의 자동 평가를 위한 방법. ACL에서.

마야 포포비치. 2017년. ChrF++: 단어가 캐릭터 n-gram에 도움을 주는 것. WMT에서.

맷 포스트. 2018. BLEU 점수 보고에 대한 명확성 요구. WMT에서.

매튜 스노버, 보니 도어, 리처드 슈왈츠, 린네아 미츄라, 그리고 존 마쿨. 2006년. 목표로 한 인간 주석과 함께 하는 번역 편집 비율에 대한 연구. AMTA에서 발표.

루시아 스페시아, 젠하오 리, 후안 피노, 비샤브 초드하리, 프란시스코 구즈만, 그레이엄 뉴빅, 나디르 두라니, 요나탄 벨린코프, 필립 쾬른, 하산 사자드 등. 2020년 WMT 기계 번역 강건성 공유 작업 결과. WMT에서 발표.

Wenxuan Wang, Wenxiang Jiao, Yongchang Hao, Xing Wang, Shuming Shi, Zhaopeng Tu, and Michael Lyu. 2022a. 신경망 기계 번역을 위한 시퀀스-시퀀스 사전 훈련의 이해와 개선. ACL에서.

Wenxuan Wang, Wenxiang Jiao, Shuo Wang, Zhaopeng Tu, 그리고 Michael R Lyu. 2022b. 제로샷 번역에서의 불확실성 이해와 완화. arXiv.

신 왕, 조펑 투, 그리고 슈밍 시. 2021년.
WMT21 생명과학 번역 과제를 위한 텐센트 AI 연구소 기계 번역 시스템. WMT에서 발표.

