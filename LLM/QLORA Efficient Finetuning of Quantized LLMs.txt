QLORA: 퀀타이즈된 LLMs의 효율적인 파인튜닝

팀 데트머스∗   아르티도로 파뇨니∗ 아리 홀츠만

루크 제틀모이어

워싱턴 대학교
{dettmers,artidoro,ahai,lsz}@cs.washington.edu

요약

우리는 QLORA를 제시합니다. 이는 메모리 사용량을 충분히 줄여 65B 파라미터 모델을 단일 48GB GPU에서 finetuning 할 수 있으며, 동시에 전체 16비트 finetuning 작업 성능을 유지합니다. QLORA는 얼어붙은 4비트 양자화된 사전 훈련 언어 모델의 그래디언트를 Low Rank Adapters (LoRA)로 역전파합니다. 우리가 Guanaco라고 명명한 최고의 모델 패밀리는 Vicuna 벤치마크에서 이전에 공개된 모든 모델을 능가하여, 단일 GPU에서 24시간의 finetuning만으로 ChatGPT의 성능 수준의 99.3%에 도달합니다. QLORA는 성능을 희생하지 않고 메모리를 절약하기 위해 다음과 같은 몇 가지 혁신을 도입합니다: (a) 정규 분포된 가중치에 대해 정보 이론적으로 최적인 새로운 데이터 유형인 4비트 NormalFloat (NF4), (b) 양자화 상수를 양자화하여 평균 메모리 풋프린트를 줄이는 Double Quantization, 그리고 (c) 메모리 스파이크를 관리하기 위한 Paged Optimizers. 우리는 QLORA를 사용하여 1,000개 이상의 모델을 finetuning하며, 8개의 지침 데이터셋, 여러 모델 유형 (LLaMA, T5) 및 일반적인 finetuning으로 실행하기에 불가능한 모델 규모에 걸쳐 지침 따르기와 챗봇 성능에 대한 상세한 분석을 제공합니다 (예: 33B 및 65B 파라미터 모델). 우리의 결과는 QLoRA가 작은 고품질 데이터셋에서 finetuning하는 것이 최첨단 결과를 낼 수 있음을 보여줍니다. 이전 SoTA보다 작은 모델을 사용할 때에도 GPT-4 평가를 사용하면 인간 평가에 대한 저렴하고 합리적인 대안임을 보여줍니다. 또한, 현재의 챗봇 벤치마크는 챗봇의 성능 수준을 정확하게 평가하기에 신뢰할 수 없음을 발견했습니다. Lemon-picked 분석은 Guanaco가 ChatGPT와 비교하여 어떻게 실패하는지를 보여줍니다. 우리는 4비트 훈련을 위한 CUDA 커널을 포함하여 모든 모델과 코드를 공개합니다.

1 소개

대형 언어 모델 (LLM)의 세밀 조정은 그들의 성능을 향상시키는 매우 효과적인 방법이며, 원하는 특성을 추가하거나 원하지 않는 행동을 제거하는 데 도움이 됩니다. 그러나 매우 큰 모델의 세밀 조정은 경제적으로 불가능합니다. LLaMA 65B 매개 변수 모델의 정규 16비트 세밀 조정은 780GB 이상의 GPU 메모리가 필요합니다. 최근 양자화 방법은 LLM의 메모리 풋프린트를 줄일 수 있지만, 이러한 기술은 추론에만 작동하며 훈련 중에는 실패합니다.

우리는 처음으로 4비트 양자화된 모델을 성능 저하 없이 세밀 조정할 수 있는 것을 보여줍니다. 우리의 방법인 QLORA는 고정밀도 기술을 사용하여 사전 훈련된 모델을 4비트로 양자화한 후, 일련의 학습 가능한 저차원 어댑터 가중치를 추가합니다. [28]

프리프린트. 심사 중.
a
r
X
i
v
:
2
3
0
5
.
1
4
3
1
4
v
1
[
c
s
.
L
G
]
2
3
M
a
y
2
0
2
3
표 1: 10,000개의 무작위 초기 순서에 대해 평균화된 모델 간의 Elo 등급. 경기의 승자는 GPT-4에 의해 결정되며, Vicuna 벤치마크의 특정 프롬프트에 대해 어떤 응답이 더 좋은지 선언합니다. 95% 신뢰 구간이 표시됩니다 (±). GPT-4 이후, Guanaco 33B와 65B가 가장 많은 경기에서 승리하며, Guanaco 13B는 Bard보다 더 좋은 점수를 얻습니다.

모델     사이즈  엘로

GPT-4 - 1348 ± 1
구아나코 65B 41 GB 1022 ± 1
구아나코 33B 21 GB 992 ± 1
비쿠냐 13B 26 GB 974 ± 1
ChatGPT - 966 ± 1
구아나코 13B 10 GB 916 ± 1
바드 - 902 ± 1
구아나코 7B 6 GB 879 ± 1
양자화된 가중치를 통해 역전파 기울기로 조정된 것입니다.

QLORA는 65B 파라미터 모델의 평균 메모리 요구량을 780GB 이상의 GPU 메모리에서 48GB 미만으로 줄여줍니다. 이는 16비트로 완전히 finetuned된 기준 모델과 비교하여 런타임이나 예측 성능을 저하시키지 않고 중요한 변화를 나타냅니다. 이제 QLORA를 사용하여 단일 GPU에서 finetuning이 가능한 현재까지 가장 큰 공개 가능한 모델들을 학습합니다. QLORA를 사용하여 우리는 Guanaco 모델 패밀리를 학습시키며, 두 번째로 좋은 모델은 Vicuna [10] 벤치마크에서 ChatGPT의 성능 수준의 97.8%에 도달하며, 단일 소비자 GPU에서 12시간 이내에 학습이 가능합니다. 단일 전문가 GPU를 사용하여 24시간 동안 우리의 가장 큰 모델로 99.3%의 성능을 달성하여 Vicuna 벤치마크에서 ChatGPT와 거의 동일한 수준까지 접근합니다. 배포될 때, 우리의 가장 작은 Guanaco 모델(7B 파라미터)은 메모리로 단지 5GB가 필요하며, Vicuna 벤치마크에서 26GB Alpaca 모델보다 20% 이상 우수한 성능을 발휘합니다 (표 6).

QLORA는 성능을 희생하지 않고 메모리 사용량을 줄이기 위해 여러 혁신을 도입합니다: (1) 4비트 NormalFloat, 일반적으로 분포된 데이터에 대해 정보 이론적으로 최적의 양자화 데이터 유형으로, 4비트 정수 및 4비트 부동 소수점보다 더 좋은 경험적 결과를 제공합니다. (2) 이중 양자화, 양자화 상수를 양자화하여 매개 변수 당 평균 약 0.37비트(약 3GB, 65B 모델 기준)를 절약하는 방법입니다. (3) 페이지드 옵티마이저, 긴 시퀀스 길이로 미니 배치를 처리할 때 발생하는 기울기 체크포인팅 메모리 스파이크를 피하기 위해 NVIDIA 통합 메모리를 사용합니다. 이러한 기여를 결합하여 모든 네트워크 레이어에 어댑터를 포함한 더 잘 조정된 LoRA 접근 방식을 구현하고, 이로 인해 이전 연구에서 관찰된 거의 모든 정확도 트레이드오프를 피할 수 있습니다.

QLORA의 효율성은 메모리 오버헤드로 인해 일반적인 finetuning을 사용할 수 없는 모델 규모에서 instruction finetuning 및 chatbot 성능에 대한 깊은 연구를 수행할 수 있도록 합니다. 따라서, 우리는 80M에서 65B 파라미터 사이의 여러 instruction tuning 데이터셋, 모델 아키텍처 및 크기에 대해 1,000개 이상의 모델을 훈련시킵니다. QLORA가 16비트 성능을 회복한다는 것을 보여주고 (§4) 최첨단 chatbot인 Guanaco를 훈련시키는 것 외에도, 훈련된 모델의 추세를 분석합니다. 첫째로, 데이터 품질이 데이터셋 크기보다 훨씬 중요하다는 것을 발견했습니다. 예를 들어, instruction following 일반화를 지원하기 위해 두 데이터셋 모두를 사용하는 경우에도, 9k 샘플 데이터셋 (OASST1)이 chatbot 성능에서 450k 샘플 데이터셋 (FLAN v2, subsampled)보다 우수한 성능을 발휘했습니다. 둘째로, 강력한 Massive Multitask Language Understanding (MMLU) 벤치마크 성능이 강력한 Vicuna chatbot 벤치마크 성능을 의미하지 않으며 그 반대도 마찬가지입니다. 다시 말해, 주어진 작업에 대해 데이터셋의 적합성이 크기보다 중요합니다.

뿐만 아니라, 우리는 인간 평가자와 GPT-4를 사용하여 챗봇 성능에 대한 포괄적인 분석을 제공합니다. 우리는 모델들이 서로 경쟁하여 주어진 프롬프트에 대한 최상의 응답을 생성하는 매치에서 토너먼트 스타일의 벤치마킹을 사용합니다. 매치의 승자는 GPT-4 또는 인간 주석자에 의해 판단됩니다. 토너먼트 결과는 Elo 점수 [16, 17]로 집계되어 챗봇 성능의 순위를 결정합니다. 우리는 GPT-4와 인간 평가가 대체로 토너먼트에서 모델 성능의 순위에 대해 동의하는 것을 발견했지만, 강한 불일치의 사례도 있음을 발견했습니다. 따라서, 우리는 모델 기반 평가가 인간 주석에 대한 저렴한 대안을 제공하면서도 불확실성을 가지고 있다는 점을 강조합니다.

우리는 챗봇 벤치마크 결과를 관리아코 모델의 질적 분석과 함께 보완합니다. 우리의 분석은 양적인 벤치마크로는 포착되지 않은 성공과 실패 사례를 강조합니다.

우리는 추가적인 연구를 용이하게 하기 위해 인간 및 GPT-4 주석이 달린 모든 모델 세대를 공개합니다. 우리는 코드베이스와 CUDA 커널을 오픈 소스로 공개하고 Hugging Face transformers 스택 [64]에 우리의 방법을 통합하여 모든 사람들이 쉽게 접근할 수 있도록 합니다. 우리는 8개의 다른 지시어 따르기 데이터셋에서 훈련된 7/13/33/65B 크기 모델에 대한 어댑터 컬렉션을 공개하며, 총 32개의 다른 오픈 소스, 파인튜닝된 모델을 제공합니다.

2
그림 1: 다른 파인튜닝 방법과 그들의 메모리 요구 사항. QLORA는 4비트 정밀도로 변환 모델을 양자화하고 메모리 스파이크를 처리하기 위해 페이지드 옵티마이저를 사용하여 LoRA보다 개선됩니다.

2 배경

블록 단위 k-비트 양자화 양자화는 더 많은 정보를 담고 있는 표현에서 더 적은 정보를 담고 있는 표현으로 변환하는 과정입니다. 이는 종종 더 많은 비트를 가진 데이터 유형을 적은 비트로 변환하는 것을 의미합니다. 예를 들어, 32비트 부동 소수점을 8비트 정수로 변환하는 것입니다. 저비트 데이터 유형의 전체 범위가 사용되도록 하기 위해, 입력 데이터 유형은 일반적으로 텐서로 구성된 입력 요소의 절대 최대값에 의해 대상 데이터 유형 범위로 정규화됩니다. 예를 들어, 32비트 부동 소수점(FP32) 텐서를 [-127, 127] 범위의 Int8 텐서로 양자화하는 것입니다.

XInt8 = round(127 * absmax(XFP32) / XFP32)

= 라운드(cFP32 · XFP32), (1)

c는 양자화 상수 또는 양자화 스케일입니다. 역 양자화는 다음과 같습니다:

dequant(cFP32,XInt8) = 디퀀트(cFP32, XInt8)

XInt8
cFP32
= XFP32             (2)

XInt8
cFP32
= XFP32             (2)

이 접근 방식의 문제는 입력 텐서에 큰 크기 값(즉, 이상치)이 발생하면 양자화된 비트 조합인 양자화 구간이 일부 구간에서는 잘 활용되지 않거나 전혀 활용되지 않는다는 것입니다. 이상치 문제를 방지하기 위해 일반적인 접근 방식은 입력 텐서를 독립적으로 양자화된 블록으로 나누는 것입니다. 각 블록은 자체 양자화 상수 c를 가지게 됩니다. 이는 다음과 같이 형식화될 수 있습니다: 우리는 입력 텐서 X ∈ Rb×h를 크기 B의 n개의 연속된 블록으로 나누기 위해 입력 텐서를 평면화하고 선형 세그먼트를 n = (b × h)/B 개의 블록으로 슬라이싱합니다. 이러한 블록들을 식 1을 사용하여 독립적으로 양자화하여 양자화된 텐서와 n개의 양자화 상수 ci를 생성합니다.

저수준 어댑터 (Low-rank Adapter, LoRA) 세부 조정 [28]은 학습 가능한 매개변수 집합인 어댑터를 사용하여 메모리 요구 사항을 줄이는 방법입니다. 이때 전체 모델 매개변수는 고정된 채로 유지됩니다. 확률적 경사 하강 중에는 고정된 사전 훈련된 모델 가중치를 통해 어댑터로 그래디언트가 전달되며, 어댑터는 손실 함수를 최적화하기 위해 업데이트됩니다. LoRA는 선형 투영을 추가적인 인수분해 투영을 통해 보완합니다. X ∈ Rb×h, W ∈ Rh×o인 투영 XW = Y가 주어졌을 때, LoRA는 다음과 같이 계산합니다.

Y = XW + sXL1L2,                (3)
Y = XW + sXL1L2,                (3)

L1은 Rh×r에 속하고, L2는 Rr×o에 속하며, s는 스칼라입니다.

파라미터 효율적인 파인튜닝의 메모리 요구 사항 중 하나는 어댑터의 수와 크기에 따른 LoRA의 훈련 중 메모리 요구 사항입니다. LoRA의 메모리 풋프린트가 매우 작기 때문에 총 메모리 사용량을 크게 증가시키지 않고도 성능을 향상시키기 위해 더 많은 어댑터를 사용할 수 있습니다. LoRA는 성능을 향상시키기 위해 설계되었지만, 훈련 중에 사용되는 총 메모리를 크게 증가시키지 않습니다.

3
파라미터 효율적인 파인튜닝(PEFT) 방법은 LLM 파인튜닝의 대부분의 메모리 풋프린트가 학습된 LoRA 파라미터가 아닌 활성화 그래디언트에서 비롯된다는 것을 보여줍니다. 배치 크기가 1인 FLAN v2로 훈련된 7B LLaMA 모델의 경우, 일반적으로 사용되는 원래 모델 가중치의 0.2%에 해당하는 LoRA 가중치를 사용할 때, LoRA 입력 그래디언트는 567MB의 메모리를 차지하고, LoRA 파라미터는 단지 26MB를 차지합니다. 그래디언트 체크포인팅을 사용하면, 입력 그래디언트는 시퀀스당 평균 18MB로 줄어들어 모든 LoRA 가중치보다 더 많은 메모리를 차지합니다. 비교적, 4비트 기본 모델은 5,048MB의 메모리를 사용합니다. 이는 그래디언트 체크포인팅이 중요하다는 것을 강조하며, 또한 LoRA 파라미터의 양을 공격적으로 줄이는 것은 메모리 이점이 크지 않다는 것을 보여줍니다. 이는 우리가 전체 훈련 메모리 풋프린트를 크게 증가시키지 않고 더 많은 어댑터를 사용할 수 있다는 것을 의미합니다(자세한 내용은 부록 G를 참조하십시오). 나중에 논의될 것처럼, 이는 전체 16비트 정밀도 성능을 복구하는 데 중요합니다.

3 QLORA 세부 조정

QLORA는 우리가 제안하는 두 가지 기술인 4비트 NormalFloat(NF4) 양자화와 이중 양자화를 통해 고도의 정밀도 4비트 세부 조정을 달성합니다. 또한, 우리는 페이지드 옵티마이저를 도입하여 그래디언트 체크포인팅 중 메모리 스파이크로 인한 메모리 부족 오류를 방지하여 대형 모델의 단일 기기에서의 세부 조정을 전통적으로 어렵게 만드는 문제를 해결합니다.

QLORA는 일반적으로 4비트인 저정밀도 저장 데이터 유형과 일반적으로 BFloat16인 계산 데이터 유형을 가지고 있습니다. 실제로는 QLORA 가중치 텐서가 사용될 때 텐서를 BFloat16으로 비정량화하고, 그런 다음 16비트에서 행렬 곱셈을 수행합니다.

우리는 지금 QLORA의 구성 요소에 대해 논의하고, 그 뒤에 QLORA의 공식적인 정의를 설명합니다.

4비트 NormalFloat 양자화는 Quantile Quantization [15]에 기반한 데이터 유형으로, 각 양자화 구간에 입력 텐서에서 할당된 값의 수가 동일하도록 보장하는 정보 이론적으로 최적의 데이터 유형입니다. Quantile 양자화는 입력 텐서의 분위수를 경험적 누적 분포 함수를 통해 추정함으로써 작동합니다.

분위수 양자화의 주요 제한은 분위수 추정 과정이 비용이 많이 든다는 것입니다. 따라서 SRAM 분위수 [15]와 같은 빠른 분위수 근사 알고리즘을 사용하여 추정합니다. 이러한 분위수 추정 알고리즘의 근사성으로 인해 이상치에 대한 데이터 유형은 큰 양자화 오차를 가지게 되는데, 이러한 이상치는 종종 가장 중요한 값들입니다.

입력 텐서가 양자화 상수까지 고정된 분포에서 나올 때, 비싼 분위수 추정치와 근사 오차를 피할 수 있습니다. 이러한 경우에는 입력 텐서가 동일한 분위수를 가지므로 정확한 분위수 추정이 계산적으로 가능해집니다.

미리 학습된 신경망 가중치는 일반적으로 평균이 0이고 표준 편차가 σ인 정규 분포를 가지고 있습니다(부록 F 참조). 따라서 우리는 데이터 유형의 범위에 정확하게 맞도록 가중치를 단일 고정 분포로 변환하기 위해 σ를 조정하여 크기를 조절할 수 있습니다. 우리의 데이터 유형은 임의의 범위 [-1,1]로 설정합니다. 따라서 데이터 유형과 신경망 가중치의 양자화는 모두 이 범위로 정규화되어야 합니다.

임의의 표준 편차 σ를 가진 평균이 0인 정규 분포에 대해 정보 이론적으로 최적인 데이터 유형은 다음과 같이 계산됩니다: (1) 이론적인 N(0,1) 분포의 2k + 1 분위수를 추정하여 정규 분포에 대한 k비트 분위수 양자화 데이터 유형을 얻습니다, (2) 이 데이터 유형을 가져와 값을 [−1,1] 범위로 정규화합니다, (3) 입력 가중치 텐서를 절대 최대 재조정을 통해 [−1,1] 범위로 정규화하여 양자화합니다.

무게 범위와 데이터 유형 범위가 일치하면 일반적으로 양자화할 수 있습니다. 단계 (3)은 무게 텐서의 표준 편차를 k-bit 데이터 유형의 표준 편차와 일치하도록 재조정하는 것과 동일합니다. 더 정확히 말하면, 우리는 다음과 같이 데이터 유형의 2k개의 값을 qi로 추정합니다.

qi = 1
2
시드
QX
시드 i
2k +
1번째
+ QX
시드 i + 1
2k +
1번째번째
,             (4)

QX(·)은 표준 정규 분포 N(0,1)의 분위수 함수입니다. 대칭 k-비트 양자화에 대한 문제는 이 접근 방식이 0의 정확한 표현을 갖지 않는다는 것입니다. 이는 패딩 및 기타 오류가 없는 0 값 요소를 양자화하는 데 중요한 속성입니다.

0과 2k 비트를 모두 사용하여 k 비트 데이터 유형의 이산한 제로 포인트를 보장하기 위해, 우리는 두 범위 qi의 분위수 qi를 추정하여 비대칭 데이터 유형을 생성합니다. qi: 음수 부분에 대한 2k−1 및 양수 부분에 대한 2k−1 + 1입니다. 그런 다음 이러한 qi 집합을 통합하고 양쪽 집합에 모두 발생하는 두 개의 제로 중 하나를 제거합니다. 우리는 각 양자화 구간에 동일한 기대값을 가진 결과적인 데이터 유형을 k 비트 NormalFloat (NFk)라고 명명합니다. 이는 정보 이론적으로 제로 중심으로 정규 분포 된 데이터에 대해 최적입니다. 이 데이터 유형의 정확한 값은 부록 E에서 찾을 수 있습니다.

더블 양자화는 추가적인 메모리 절약을 위해 양자화 상수를 양자화하는 과정인 DQ를 소개합니다. 정확한 4비트 양자화를 위해서는 작은 블록 크기가 필요하지만, 이는 상당한 메모리 오버헤드를 가지고 있습니다. 예를 들어, 32비트 상수와 블록 크기 64를 사용하는 경우, 양자화 상수는 평균적으로 매개변수 당 32/64 = 0.5비트를 추가합니다. 더블 양자화는 양자화 상수의 메모리 풋프린트를 줄이는 데 도움이 됩니다.

더 정확하게 말하면, 이중 양자화는 양자화 상수 cFP32를 처리합니다.

2
첫 번째 양자화의
두 번째 양자화의 입력으로 사용됩니다. 이 두 번째 단계에서 양자화된 양자화 상수
cFP8
2
와 두 번째 수준의 양자화 상수 cFP32를 얻을 수 있습니다.

두 번째 양자화에는 성능 저하가 관찰되지 않으므로 Dettmers와 Zettlemoyer의 결과와 일치하게 256의 블록 크기로 8비트 부동 소수점을 사용합니다. cFP32에서는 성능 저하가 없습니다.

2
긍정적이면, 우리는 양자화하기 전에 c2에서 평균을 빼서 값들을 0을 중심으로 배치하고 대칭 양자화를 사용합니다. 평균적으로, 블록 크기가 64인 경우, 이 양자화는 매개 변수 당 메모리 풋프린트를 32/64 = 0.5 비트에서 8/64 + 32/(64 · 256) = 0.127 비트로 줄여줍니다. 이는 매개 변수 당 0.373 비트의 감소입니다.

페이징 최적화기는 NVIDIA 통합 메모리 3 기능을 사용하여 CPU와 GPU 간에 자동 페이지 간 전송을 수행하여 GPU 처리 중 가끔씩 메모리가 부족한 상황에서 오류 없는 GPU 처리를 가능하게 합니다. 이 기능은 CPU RAM과 디스크 간의 일반적인 메모리 페이징과 같은 방식으로 작동합니다. 우리는 이 기능을 사용하여 옵티마이저 상태에 대한 페이지 메모리를 할당하고, GPU가 메모리 부족 상태가 되면 자동으로 CPU RAM으로 이전되며, 옵티마이저 업데이트 단계에서 메모리가 필요할 때 다시 GPU 메모리로 페이지되도록 합니다.

QLORA. 위에서 설명한 구성 요소를 사용하여, 단일 선형 레이어에 대한 양자화된 기본 모델과 단일 LoRA 어댑터를 사용하여 QLORA를 다음과 같이 정의합니다.

YBF16 = XBF16doubleDequant(cFP32) 
YBF16 = XBF16doubleDequant(cFP32)

1. 안녕하세요
2. 안녕하세요
1. 안녕하세요
2. 안녕하세요
1. 안녕하세요
2. 안녕하세요

doubleDequant(·)이 정의된 곳에서:

1
, ck-bit
2
, Wk-bit) = dequant(dequant(cFP32
1
, ck-bit
2
, Wk-bit) = 이중으로 양자화(cFP32
1
, ck-bit
2
, Wk-bit) = 양자화(양자화(cFP32

1. ,ck-bit
2. ),W4bit) = WBF16, (6)

우리는 W에 NF4를 사용하고 c2에는 FP8을 사용합니다. 우리는 더 높은 양자화 정밀도를 위해 W에 64의 블록 크기를 사용하며, 메모리를 보존하기 위해 c2에는 256의 블록 크기를 사용합니다.

어댑터 가중치에 대한 오차에 대한 그래디언트만을 사용하여 매개변수 업데이트를 수행합니다. ∂E

∂Li
필요하며, 4비트 가중치 ∂E ∂W에는 필요하지 않습니다. 그러나 ∂E의 계산은 필요합니다.

∂Li는 ∂X의 계산을 함께 포함한다.

∂W
저장소 WNF4에서 계산 데이터 유형 WBF16으로 양자화를 통해 방정식 (5)를 통해 진행되는 ∂X의 도함수를 계산합니다.

BFloat16 정밀도에서 ∂W.

요약하자면, QLORA는 하나의 저장 데이터 유형(일반적으로 4비트 NormalFloat)과 계산 데이터 유형(16비트 BrainFloat)을 가지고 있습니다. 우리는 저장 데이터 유형을 계산 데이터 유형으로 비정량화하여 전방향 및 역방향 패스를 수행하지만, 우리는 16비트 BrainFloat를 사용하는 LoRA 매개변수의 가중치 그래디언트만 계산합니다.

4 QLoRA 대 표준 파인튜닝

우리는 QLoRA가 어떻게 작동하는지와 모델의 세밀 조정에 필요한 메모리를 크게 줄일 수 있는지에 대해 논의했습니다. 주요한 질문은 이제 QLoRA가 전체 모델의 세밀 조정만큼 잘 수행할 수 있는지입니다. 더 나아가서, 우리는 NormalFloat4의 표준 Float4에 대한 영향을 포함하여 QLoRA의 구성 요소를 분석하고자 합니다. 다음 섹션에서는 이러한 질문에 대답하기 위해 시도한 실험에 대해 논의할 것입니다.

3https://docs.nvidia.com/cuda/cuda-c-programming-guide
3https://docs.nvidia.com/cuda/cuda-c-programming-guide

5
실험 설정. 우리는 세 가지 아키텍처 (인코더, 인코더-디코더, 디코더만)를 고려하고, 16비트 어댑터 파인튜닝과 완전 파인튜닝을 사용하여 QLoRA를 3B까지의 모델과 비교합니다. 우리의 평가에는 RoBERTa-large [38]와 함께 GLUE [58], T5 [49]와 함께 Super-NaturalInstructions (TKInstruct) [61], 그리고 Flan v2 [39]와 Alpaca [55]에서 LLaMA의 파인튜닝 후 5-shot MMLU [24]가 포함됩니다. 또한 NF4가 다른 4비트 데이터 유형보다 가지는 장점을 추가적으로 연구하기 위해 Dettmers와 Zettlemoyer [13]의 설정을 사용하여 모델 크기 125m - 13B에 대한 사후 양자화 제로샷 정확도와 퍼플렉서티를 측정합니다. 결과 섹션에서 각 특정 설정에 대한 자세한 내용은 결과를 더 읽기 쉽게 만들기 위해 제공됩니다. 전체 세부 정보는 부록 A에 있습니다.

QLoRA-모두 QLoRA-FFN QLoRA-주의
알파카
(우리들) 스탠포드-알파카
모델
60
61
62
63
64

루즈 엘

비트

4 16
4 16

그림 2: 알파카 데이터셋에서 LLaMA 7B 모델에 대한 RougeL. 각 점은 다른 랜덤 시드로 실행한 결과를 나타냅니다. 우리는 Stanford 알파카의 완전히 fine-tuned된 기본 하이퍼파라미터를 개선하여 강력한 16비트 기준선을 구축합니다. 모든 트랜스포머 레이어에 LoRA를 사용하는 것이 16비트 성능과 일치하는 데 중요합니다.
페이지드 옵티마이저는 24/48GB GPU에서 33B/65B QLORA 튜닝을 수행하는 데 중요하지만, 긴 시퀀스 길이의 미니 배치를 처리할 때에만 페이징이 발생하므로 페이지드 옵티마이저에 대한 정확한 측정치를 제공하지 않습니다. 그러나 48GB GPU에서 65B 모델에 대한 페이지드 옵티마이저의 실행 시간을 분석하고, 배치 크기가 16인 경우 페이지드 옵티마이저가 일반 옵티마이저와 동일한 학습 속도를 제공함을 발견했습니다. 향후 연구에서는 페이징 프로세스로 인한 지연이 어떤 상황에서 발생하는지 측정하고 특성화해야 합니다.

기본 LoRA 하이퍼파라미터는 16비트 성능과 일치하지 않습니다. LoRA를 쿼리 및 값 어텐션 투영 행렬에 적용하는 표준적인 방법을 사용할 때, 대형 기본 모델의 전체 세밀 조정 성능을 복제할 수 없습니다. LLaMA 7B를 Alpaca에서 세밀 조정하는 경우, Figure 2에서 보여지듯이, 가장 중요한 LoRA 하이퍼파라미터는 총 몇 개의 LoRA 어댑터를 사용하는지이며, 모든 선형 변환기 블록 레이어에 LoRA가 필요합니다. 다른 LoRA 하이퍼파라미터인 투영 차원 r은 성능에 영향을 주지 않습니다 (부록 A 참조).

1010          1011
총 모델 비트
0.60
0.61
0.62
0.63 0.64
0.65 0.66
0.67

의미
제로샷
정확도
4비트 LLaMA

뜨다

NFloat NFloat + DQ
데이터 유형

그림 3: Wino-grande, HellaSwag, PiQA, Arc-Easy 및 Arc-Challenge에서 LLaMA 모델을 사용하여 제로샷 정확도의 평균. 4비트 데이터 유형을 사용한 경우 NormalFloat 데이터 유형은 일반적인 4비트 Float에 비해 비트 당 정확도 향상을 크게 개선합니다. 더블 양자화(DQ)는 소량의 이득만을 가져오지만, 특정 크기(33B/65B)의 모델을 특정 GPU(24/48GB)에 맞출 수 있는 더 세밀한 메모리 풋프린트 제어를 가능하게 합니다.
마찬가지로, 완전히 세밀하게 조정된 기준선의 기본 하이퍼파라미터는 조정이 미흡합니다. 우리는 학습률 1e-6에서 5e-5 및 배치 크기 8에서 128까지 하이퍼파라미터 검색을 수행하여 견고한 기준선을 찾았습니다. Alpaca에서 7B LLaMA 세밀 조정 결과는 그림 2에 표시되어 있습니다.

4비트 NormalFloat는 4비트 부동 소수점보다 더 좋은 성능을 제공합니다. 4비트 NormalFloat(NF4) 데이터 타입은 정보 이론적으로 최적이지만, 이러한 특성이 경험적인 이점으로 이어지는지 여부를 결정해야 합니다. 우리는 Dettmers와 Zettlemoyer의 설정을 따르며, 다른 크기(125M에서 65B)와 다른 데이터 타입의 양자화된 LLM(OPT [72], BLOOM [52], Pythia [7], LLaMA)를 언어 모델링과 제로샷 작업 세트에서 평가합니다. 그림 3과 테이블 2에서 우리는 NF4가 FP4와 Int4보다 성능을 크게 향상시키고, 이중 양자화가 성능을 저하시키지 않으면서 메모리 풋프린트를 줄인다는 것을 볼 수 있습니다.

k-비트 QLORA는 16-비트 완전한 세밀 조정과
16-비트 LoRA 성능과 일치합니다. 최근 연구 결과는
추론을 위한 4-비트 양자화가 가능하다는 것을 입증했습니다.

6
표 3: 16비트 BrainFloat (BF16), 8비트 Integer (Int8), 4비트 Float (FP4) 및 4비트 NormalFloat (NF4)를 GLUE 및 Super-NaturalInstructions에서 비교하는 실험. QLORA는 16비트 LoRA와 전체 finetuning을 복제합니다.

데이터셋      GLUE (정확도)    초자연어지시사항 (RougeL)
모델        RoBERTa-large T5-80M T5-250M T5-780M T5-3B T5-11B

BF16               88.6  40.1   42.1   48.0 54.3  62.0
BF16 복제         88.6  40.0   42.2   47.3 54.9    -

로라 BF16          88.8  40.5   42.6   47.1 55.4  60.7
큐로라 Int8         88.8  40.4   42.9   45.4 56.5  60.7
큐로라 FP4          88.6  40.3   42.4   47.5 55.6  60.9
큐로라 NF4 + DQ       -   40.4   42.7   47.7 55.3  60.9

가능하지만 16비트에 비해 성능 저하를 야기합니다 [13, 18]. 이는 잃어버린 성능을 4비트 어댑터 세밀 조정을 통해 회복할 수 있는지에 대한 중요한 질문을 던집니다. 우리는 두 가지 설정에 대해 이를 테스트합니다.

테이블 2: 다양한 데이터 유형에 대한 Pile Common Crawl 평균 혼란도
125M에서 13B OPT, BLOOM, LLaMA 및 Pythia 모델에 대해.

데이터 유형은 평균 PPL을 의미합니다.

Int4       34.34
Float4 (E2M1) 31.07
Float4 (E3M0) 29.48
NFloat4 + DQ 27.41
첫 번째는 GLUE 및 Super-NaturalInstructions 데이터셋에서 125M에서 3B 매개변수로 크기 조정된 RoBERTA 및 T5 모델의 전체 16비트 세밀 조정과 비교에 초점을 맞춥니다. 결과는 표 3에 나와 있습니다. 두 데이터셋 모두에서 16비트, 8비트 및 4비트 어댑터 방법이 완전히 세밀 조정된 16비트 기준의 성능을 복제하는 것을 관찰합니다. 이는 정확하지 않은 양자화로 인해 손실된 성능이 양자화 후 어댑터 세밀 조정을 통해 완전히 복구될 수 있다는 것을 시사합니다.

우리의 두 번째 설정에서는 11B 이상의 파라미터를 가진 전체 finetuning 모델은 높은 메모리 GPU를 가진 하나 이상의 서버가 필요하기 때문에, 우리는 4비트 QLORA가 7B에서 65B 파라미터 스케일에서 16비트 LoRA와 일치하는지 여부를 계속해서 테스트합니다. 이를 위해, 우리는 Alpaca와 FLAN v2라는 두 개의 데이터셋에서 LLaMA 7B에서 65B까지 finetuning하고, MMLU 벤치마크에서 5-shot 정확도로 평가합니다. 결과는 표 4에 나와 있으며, 여기서 우리는 이중 양자화를 사용한 NF4가 16비트 LoRA MMLU 성능을 완전히 회복시킨다는 것을 볼 수 있습니다. 또한, 우리는 FP4를 사용한 QLORA가 16비트 브레인 플로트 LoRA 기준과 약 1% 정도 성능이 뒤쳐진다는 것도 알 수 있습니다. 이는 우리의 발견인 (1) NF4가 16비트 전체 finetuning 및 16비트 LoRA finetuning 성능을 복제한다는 것과 (2) 양자화 정밀도 측면에서 NF4가 FP4보다 우수하다는 것을 뒷받침합니다.

요약 결과는 우리의 연구에서 4비트 QLORA와 NF4 데이터 유형이 학문적인 기준과 평가 설정이 잘 정립된 벤치마크에서 16비트 full finetuning 및 16비트 LoRA finetuning 성능과 일치한다는 것을 일관되게 보여줍니다. 또한 NF4가 FP4보다 효과적임을 보였으며, 이중 양자화는 성능을 저하시키지 않는다는 것을 보였습니다. 이를 종합하면, 4비트 QLORA tuning은 신뢰할 수 있는 결과를 얻어내어 16비트 방법과 일치한다는 설득력 있는 증거가 형성됩니다.

이전 양자화 작업 [13]에 따르면, 우리의 MMLU와 Elo 결과는 주어진 세부 조정 및 추론 자원 예산에서 기본 모델의 매개 변수 수를 증가시키고 정밀도를 감소시키는 것이 유익하다는 것을 나타냅니다. 이는 QLORA의 효율성 이점의 중요성을 강조합니다. 4비트 세부 조정을 통한 실험에서 전체 세부 조정과 비교하여 성능 저하를 관찰하지 못했기 때문에, QLoRA 조정에 대한 성능-정밀도 균형이 정확히 어디에 있는지에 대한 질문이 제기되었으며, 이는 미래의 연구에서 탐구할 예정입니다.

우리는 학문적 연구용 하드웨어에서 전체 16비트 세밀 조정으로는 탐색하기 어려울 정도의 규모에서 지시어 조정을 조사하기로 진행합니다.

QLoRA와 함께 챗봇의 최신 기술을 발전시키기 위해 노력하고 있습니다.

4비트 QLORA가 규모, 작업 및 데이터셋을 통해 16비트 성능과 일치함을 확인한 후, 우리는 연구용으로 사용 가능한 가장 큰 오픈 소스 언어 모델까지 명령어 세부 조정에 대한 깊이 있는 연구를 수행합니다. 이러한 모델의 명령어 세부 조정 성능을 평가하기 위해 우리는 평가합니다.

7
표 4: Alpaca와 FLAN v2에서 어댑터로 세밀 조정된 LLaMA 7-65B 모델의 평균 5회 MMLU 테스트 정확도에 대한 데이터 유형별 결과. 전반적으로, 이중 양자화 (DQ)를 사용한 NF4는 BFloat16 성능과 일치하며, FP4는 일관되게 1% 뒤쳐집니다.

5발 MMLU 정확도

LLaMA 크기 7B 13B 33B 65B 평균
데이터셋 알파카 FLAN v2 알파카 FLAN v2 알파카 FLAN v2 알파카 FLAN v2

BFloat16 38.4 45.6 47.2 50.6 57.7 60.5 61.8 62.5 53.0
Float4 37.2 44.0 47.3 50.0 55.9 58.5 61.3 63.3 52.2
NFloat4 + DQ 39.0 44.5 47.5 50.7 57.3 59.2 61.8 63.9 53.1

도전적인 자연어 이해 벤치마크(MMLU)에서 성과를 내고, 실제 세계의 챗봇 성능 평가를 위한 새로운 방법을 개발합니다.

5.1 실험 설정

우리는 지금 부록 B에서 상세한 실험 설정 개요를 설명합니다.

데이터로 알려진 바에 따르면 최근 명령어 따르기 데이터셋에 대한 포괄적인 연구는 없습니다. 그래서 우리는 최근 8개의 데이터셋을 선택했습니다. 우리는 크라우드소싱을 통해 얻은 데이터셋(OASST1 [31], HH-RLHF [4]), 명령어에 맞춰 조정된 모델로부터 추출한 데이터셋(Alpaca [55], self-instruct [59], unnatural-instructions [26]), 말뭉치 집계 데이터셋(FLAN v2 [12]) 그리고 하이브리드 데이터셋(Chip2 [32], Long-form [30])을 포함시켰습니다. 이러한 데이터셋은 다양한 언어, 데이터 크기 및 라이선스를 다룹니다.

훈련 설정 서로 다른 훈련 목표로 인한 혼란 효과를 피하기 위해, 우리는 QLoRA 세밀 조정을 실시합니다. 이는 강화 학습 없이 교차 엔트로피 손실 (지도 학습)을 사용하여 수행됩니다. 심지어 사람들의 다양한 응답에 대한 인간 판단을 포함한 데이터 세트에 대해서도 마찬가지입니다. 지시와 응답 사이에 명확한 구분이 있는 데이터 세트의 경우, 우리는 응답에 대해서만 세밀 조정을 실시합니다 (부록 B의 실험 결과 참조). OASST1과 HH-RLHF의 경우, 여러 응답이 제공됩니다. 그런 다음 대화 트리의 각 수준에서 최상위 응답을 선택하고 지시를 포함한 전체 선택된 대화에 대해 세밀 조정을 실시합니다. 모든 실험에서 우리는 그래디언트 체크포인팅 중 메모리 스파이크를 방지하기 위해 이중 양자화와 페이지드 옵티마이저를 사용합니다. 13B 및 33B LLaMA 모델에 대해 작은 하이퍼파라미터 탐색을 수행하고, 7B에서 찾은 모든 하이퍼파라미터 설정 (에포크 수 포함)이 일반화되는 것을 발견합니다. 단, 학습률과 배치 크기는 제외됩니다. 33B와 65B의 경우 학습률을 절반으로 줄이고 배치 크기를 두 배로 늘립니다.

기준선 우리는 모델을 연구 (Vicuna [10] 및 Open Assistant [31]) 및 상업 (GPT-4 [42], GPT-3.5-turbo 및 Bard) 챗봇 시스템과 비교합니다. Open Assistant 모델은 LLaMA 33B 모델을 Reinforcement Learning from Human Feedback (RLHF)로 세밀 조정한 것으로, 우리가 실험하는 동일한 OASST1 데이터셋에서 세밀 조정되었습니다. Vicuna는 ShareGPT에서 독점적으로 공유된 사용자 대화를 기반으로 LLaMA 13B를 완전히 세밀 조정하였으며, 따라서 OpenAI GPT 모델의 증류 결과입니다.

5.2 평가

테이블 5: QLoRA를 사용하여 해당 데이터셋에 대해 LLaMA의 다른 크기에 대한 MMLU 5회 시험 결과.

데이터셋 7B 13B 33B 65B

LLaMAnotuning 35.1 46.9 57.8 63.4

LLaMAnotuning 35.1 46.9 57.8 63.4

셀프-인스트럭트 36.4 33.3 53.0 56.7
롱폼 32.1 43.2 56.6 59.7
칩2 34.5 41.6 53.6 59.8
HH-RLHF 34.9 44.6 55.8 60.1
언내추럴인스트럭트 41.9 48.1 57.3 61.3
구아나코(OASST1) 36.6 46.4 57.0 62.2
알파카 38.8 47.8 57.3 62.5
FLANv2 44.5 51.4 59.2 63.9
일반적인 관행을 따라, 우리는 MMLU (매시블리 멀티태스크 언어 이해) 벤치마크를 사용하여 언어 이해 작업의 성능을 측정합니다. 이는 초등 수학, 미국 역사, 컴퓨터 과학, 법률 등을 포함한 57가지 작업을 다루는 다중 선택 벤치마크입니다. 우리는 5회 시험 정확도를 보고합니다.

우리는 또한 자동화 및 인간 평가를 통해 생성 언어 능력을 테스트합니다. 이 두 번째 평가 세트는 인간이 선별한 쿼리에 의존하며 모델 응답의 품질을 측정하는 것을 목표로 합니다. 이는 챗봇 모델 성능에 대한 보다 현실적인 테스트베드이며 인기를 얻고 있지만, 문헌에서는 일반적으로 인정된 프로토콜이 없습니다. 우리는 아래에서 제안하는 설정을 설명하며, 모든 경우에 p = 0.9 및 온도 0.7을 사용하여 nucleus 샘플링을 사용합니다.

8
벤치마크 데이터 우리는 두 개의 정제된 쿼리(질문) 데이터셋인 Vicuna prompts [10]와 OASST1 검증 데이터셋 [31]을 평가합니다. 우리는 수정 없이 다양한 카테고리의 80개의 프롬프트로 구성된 Vicuna prompts를 사용합니다. OASST1 데이터셋은 사용자와 어시스턴트 간의 다국어 다중 대화를 크라우드소싱한 데이터입니다. 우리는 검증 데이터셋의 모든 사용자 메시지를 쿼리로 선택하고 이전 턴을 프롬프트에 포함시킵니다. 이 절차에 따라 953개의 고유한 사용자 쿼리가 생성됩니다. 우리는 이 두 데이터셋을 Vicuna와 OA 벤치마크라고 명명합니다.

자동 평가 첫째, Chiang et al. [10]에 의해 소개된 평가 프로토콜을 기반으로, 우리는 GPT-4를 사용하여 Vicuna 벤치마크에서 다른 시스템의 성능을 ChatGPT (GPT-3.5 Turbo)에 대해 평가합니다. 쿼리와 함께 ChatGPT와 모델의 응답이 주어지면, GPT-4는 두 응답에 대해 10점 만점으로 점수를 매기고 설명을 제공하도록 안내됩니다. 모델의 전반적인 성능은 ChatGPT가 달성한 점수의 백분율로 계산됩니다. 이 상대적인 점수는 모델이 ChatGPT보다 더 높은 절대 점수를 달성하는 경우에는 100%보다 높을 수 있습니다. 우리는 GPT-4가 프롬프트에서 먼저 발생하는 응답의 점수를 높이는 유효한 순서 효과를 발견했습니다. 이러한 효과를 통제하기 위해, 우리는 두 가지 순서에 대한 평균 점수를 보고하는 것을 권장합니다.

다음으로, 우리는 시스템 출력물 간의 직접적인 비교를 통해 성능을 측정합니다. 우리는 동점을 고려한 세 가지 등급으로 평가 체계를 단순화합니다. 우리는 GPT-4에게 최상의 응답을 선택하거나 동점을 선언하고 설명을 제공하도록 요청합니다. 우리는 Vicuna와 OA 벤치마크의 시스템 쌍의 모든 순열에 대해 이러한 일대일 비교를 수행합니다.

인간 평가 최근 연구는 생성 모델이 시스템 평가에 효과적으로 사용될 수 있다는 것을 나타내고 있지만 [19], GPT-4의 신뢰성 등급이 챗봇 성능 평가와 인간 판단과 상관관계가 있는지는 아직 입증되지 않았습니다. 따라서, 우리는 위에서 설명한 자동 평가 프로토콜과 일치하는 Vicuna 벤치마크에 대해 두 개의 병렬 인간 평가를 진행합니다. 우리는 Amazon Mechanical Turk (AMT)를 사용하고 ChatGPT와의 비교를 위해 두 명의 인간 주석가를, 그리고 짝지어 비교를 위해 세 명의 주석가를 확보합니다.

Elo Rating는 인간과 자동화된 짝 비교를 통해 모델들이 서로 경쟁하는 토너먼트 형식의 대회를 만듭니다. 이 토너먼트는 모델 쌍이 주어진 프롬프트에 대해 최상의 응답을 생성하기 위해 경쟁하는 매치로 구성됩니다. 이는 Bai et al. [4]와 Chiang et al. [10]이 모델들을 비교하는 방식과 유사하지만, 우리는 인간 평가 외에도 GPT-4 평가를 사용합니다. 우리는 레이블이 지정된 비교 집합에서 무작위로 샘플링하여 Elo [16, 17]를 계산합니다. 체스 및 기타 게임에서 널리 사용되는 Elo 등급은 상대방의 승률에 대한 예상 승률을 측정하는 것입니다. 예를 들어, Elo 1100 대 Elo 1000은 Elo 1100 플레이어가 Elo 1000 상대에 대해 약 65%의 예상 승률을 가지고 있다는 것을 의미합니다. 1000 대 1000 또는 1100 대 1100의 경기는 예상 승률이 50%입니다. Elo 등급은 각 경기 후에 예상 결과에 비례하여 변경됩니다. 즉, 예상치를 뛰어넘는 역전은 Elo 등급에 큰 변화를 가져오고, 예상된 결과는 작은 변화를 가져옵니다. 시간이 지남에 따라 Elo 등급은 각 플레이어의 게임 실력과 대략 일치합니다. 우리는 1,000의 점수로 시작하고 K = 32를 사용합니다. Chiang et al. [10]과 유사하게, 우리는 이 절차를 서로 다른 무작위 시드로 10,000번 반복하여 순서 효과, 즉 어떤 모델 쌍이 먼저 경쟁하는지의 영향을 제어합니다.

5.3 구아나코: OASST1에서 훈련된 QLORA는 최첨단 챗봇입니다.

우리의 자동화 및 인간 평가에 따르면, 우리는 최고의 QLORA 튜닝 모델인 Guanaco 65B가 OASST1의 변형에 대해 세밀 조정되었으며, ChatGPT와 경쟁력 있는 성능을 제공하는 것을 발견했습니다. GPT-4와 비교했을 때, Guanaco 65B와 33B는 인간 주석자 시스템 수준의 쌍별 비교에 기반한 Elo 등급을 통해 30%의 예상 승률을 가지고 있으며, 이는 지금까지 보고된 최고의 결과입니다.

비쿠나 벤치마크 [10] 결과는 ChatGPT와 비교하여 표 6에 나와 있습니다. 우리는 GPT-4 이후로 구아나코 65B가 가장 성능이 우수한 모델임을 발견했습니다. ChatGPT와 비교하여 99.3%의 성능을 달성합니다. 구아나코 33B는 비쿠나 13B 모델보다 매개변수가 더 많지만, 가중치에는 4비트 정밀도만 사용하여 메모리 효율성이 훨씬 높아지며 21GB 대 26GB로 Vicuna 13B보다 3%의 개선을 제공합니다. 게다가, 구아나코 7B는 현대적인 휴대폰에 쉽게 맞춰지며 5GB의 용량을 차지하면서 여전히 알파카 13B보다 거의 20% 더 높은 점수를 받습니다.

그러나, 테이블 6도 매우 넓은 신뢰구간을 가지고 있으며, 많은 모델들이 성능에서 겹치고 있다. 우리는 이 불확실성이 척도의 명확한 명시 부족에서 비롯된다고 가설을 세운다. 예를 들어, 서로 다른 시나리오에서 10점 척도에서 8이 무엇을 의미하는지 명확하지 않다. 따라서, 우리는 대신 인간 주석가들과 GPT-4로부터의 쌍별 판단에 기반한 Elo 순위 방법 [16]을 사용하는 것을 권장한다. 가장 경쟁력 있는 Elo 등급.

표 6: GPT-4로 평가된 ChatGPT의 점수를 기준으로 한 Zero-shot Vicuna 벤치마크 점수의 백분율입니다. OASST1 모델은 매우 작은 데이터셋으로 훈련되었고 기준 모델과 비교하여 메모리 요구량이 일부분인데도 불구하고 ChatGPT와 유사한 성능을 보입니다.

모델 / 데이터셋 파라미터 모델 비트 메모리 ChatGPT 대 Sys Sys 대 ChatGPT 평균 95% 신뢰구간

GPT-4 - 119.4% 110.1% 114.5% 2.6%
바드 - 93.2% 96.4% 94.8% 4.1%

구아나코 65B 4비트 41GB 96.7% 101.9% 99.3% 4.4%
알파카 65B 4비트 41GB 63.0% 77.9% 70.7% 4.3%
FLAN v2 65B 4비트 41GB 37.0% 59.6% 48.4% 4.6%

구아나코 33B 4비트 21 GB 96.5% 99.2% 97.8% 4.4%
오픈 어시스턴트 33B 16비트 66 GB 91.2% 98.7% 94.9% 4.5%
알파카 33B 4비트 21 GB 67.2% 79.7% 73.6% 4.2%
FLAN v2 33B 4비트 21 GB 26.3% 49.7% 38.0% 3.9%

비쿠나 13B 16비트 26 GB 91.2% 98.7% 94.9% 4.5%
과나코 13B 4비트 10 GB 87.3% 93.4% 90.4% 5.2%
알파카 13B 4비트 10 GB 63.8% 76.7% 69.4% 4.2%
HH-RLHF 13B 4비트 10 GB 55.5% 69.1% 62.5% 4.7%
비자연적 악기 13B 4비트 10 GB 50.6% 69.8% 60.5% 4.2%
칩2 13B 4비트 10 GB 49.2% 69.3% 59.5% 4.7%
롱폼 13B 4비트 10 GB 44.9% 62.0% 53.6% 5.2%
셀프인스트럭트 13B 4비트 10 GB 38.0% 60.5% 49.1% 4.6%
FLAN v2 13B 4비트 10 GB 32.4% 61.2% 47.0% 3.6%

구아나코 7B 4비트 5GB 84.1% 89.8% 87.0% 5.4%
알파카 7B 4비트 5GB 57.3% 71.2% 64.4% 5.0%
FLAN v2 7B 4비트 5GB 33.3% 56.1% 44.8% 4.0%

모델은 표 1에서 확인할 수 있습니다. 우리는 인간과 GPT-4의 Vicuna 벤치마크에서의 모델 순위가 부분적으로 일치하지 않는다는 것을 알 수 있습니다. 특히 Guanaco 7B의 경우에는 그렇지만 시스템 수준에서 대부분의 모델에 대해 일관성이 있으며 Kendall Tau 값은 0.43이고 Spearman 순위 상관관계는 0.55입니다. 예시 수준에서는 GPT-4와 인간 주석자들의 다수결에 대한 일치가 약하며 Fleiss κ 값은 0.25입니다. 전반적으로, 이는 GPT-4와 인간 주석자들에 의한 시스템 수준 판단 사이에 중간 정도의 일치가 있음을 보여주며, 따라서 모델 기반 평가가 인간 평가에 대한 어느 정도 신뢰할 만한 대안임을 나타냅니다. 우리는 섹션 6.2에서 추가적인 고려 사항을 논의합니다.

표 7의 Elo 순위는 Guanaco 33B와 65B 모델이 Vicuna와 OA 벤치마크에서 GPT-4를 제외한 모든 모델보다 우수한 성능을 보이며, Table 6과 일치하게 ChatGPT와 비교 가능한 성능을 보인다는 것을 나타낸다. Vicuna 벤치마크는 오픈 소스 모델을 선호하고, 더 큰 OA 벤치마크는 ChatGPT를 선호한다는 점에 유의해야 한다. 또한, Table 5와 6에서는 성능에 영향을 미치는 fine-tuning 데이터셋의 적합성을 확인할 수 있다. FLAN v2에서 Llama 모델을 fine-tuning하는 것은 MMLU에서 특히 잘 수행되지만, Vicuna 벤치마크에서는 최악의 성능을 보인다 (다른 모델에서도 유사한 경향을 관찰할 수 있다). 이는 현재 평가 벤치마크에서 부분적인 직교성을 나타내는 것으로, 강력한 MMLU 성능은 chatbot 성능 (Vicuna나 OA 벤치마크로 측정)이 강력하다는 것을 의미하지 않으며, 그 반대도 마찬가지이다.

구아나코는 OASST1 데이터셋 수집 지침에 따라 GPT 모델의 사용을 금지하므로 우리 평가에서 독점 데이터로 훈련된 유일한 최고 모델입니다. 오픈 소스 데이터만을 사용하여 훈련된 다음으로 좋은 모델은 안트로픽 HH-RLHF 모델인데, 이 모델은 비쿠나 벤치마크에서 구아나코보다 30% 낮은 점수를 받았습니다 (표 6 참조). 이러한 결과는 4비트 QLORA가 효과적이며 최첨단 챗봇을 생성할 수 있으며 ChatGPT와 경쟁할 수 있음을 보여줍니다. 게다가, 우리의 33B 구아나코는 12시간 이내에 24GB 소비자용 GPU에서 훈련될 수 있습니다. 이는 향후 QLORA 튜닝을 통해 특화된 오픈 소스 데이터로 모델을 생성할 수 있는 가능성을 열어줍니다. 이는 현재 존재하는 최고의 상용 모델과 경쟁할 수 있는 모델을 생성할 수 있습니다.

6 질적 분석

우리의 평가의 핵심은 양적 분석이지만, 요약 통계만을 살펴보는 것에는 몇 가지 문제가 있습니다. 아마도 가장 큰 문제는 벤치마크의 타당성 문제입니다 [36] - 벤치마크가 항상 그 이름이나 설명이 시험하는 것을 정확히 테스트하는지에 대한 의문이 항상 존재합니다. 특히 기계 학습 모델이 때로는 벤치마크를 해결하기 위한 "단축키"를 이용하는 경우 [22, 46]. 이를 부분적으로 완화하기 위해, 우리는 여기서 두 가지 섹션에서 일부 질적 분석을 수행합니다. 먼저, §6.1에서

10
테이블 7: 모델들이 가장 좋은 응답을 생성하기 위해 경쟁하는 대회에서의 Elo 등급
인간 평가자 또는 GPT-4에 의해 판단된다. 전반적으로, Guanaco 65B와 33B는 연구된 벤치마크에서 ChatGPT-3.5보다 선호되는 경향이 있다. 인간 평가자에 따르면, Elo에서 10점의 차이는 승률에서 약 1.5%의 차이를 의미한다.

벤치마크      비쿠나   비쿠나 오픈 어시스턴트
# 프롬프트       80       80       953
심사위원        인간 평가자 GPT-4  GPT-4   중앙 순위

모델 Elo 순위 Elo 순위 Elo 순위

GPT-4        1176 1   1348 1   1294  1      1
구아나코-65B  1023 2   1022 2   1008  3      2
구아나코-33B  1009 4    992 3   1002  4      4
ChatGPT-3.5 Turbo 916 7 966 5  1015  2      5
비쿠나-13B   984  5    974 4   936   5      5
구아나코-13B  975  6    913 6   885   6      6
구아나코-7B   1010 3    879 8   860   7      7
바드         909  8    902 7     -   -      8

우리는 우리가 텍스트에서 관찰된 패턴의 대표적인 예라고 믿는 몇 가지 예시를 보여줍니다. 또한, §6.2에서는 우리가 논의한 결과에 대한 고려사항과 그에 대한 해석을 자세히 설명합니다.

6.1 예시 세대의 질적 분석

예제를 찾기 위해 먼저 Vicuna 벤치마크와 OpenAssistant 벤치마크를 위해 생성된 데이터를 확인하고, Guanaco가 생성하는 답변에서 패턴을 찾습니다. 패턴을 발견하면, 우리는 그 패턴을 유도할 수 있는 잘못된 해결책을 설정하기 위해 질문이나 프롬프트를 시도합니다. 예를 들어, 모델이 장황한 답변을 주는 경향이 있다면 "설명 없이 예 또는 아니오로 대답하세요"라는 프롬프트를 제공합니다. 이를 통해 모델을 공격적으로 깨뜨릴 수 있는 "레몬"과 모델을 깨뜨리지 못한 "체리"를 찾습니다. 이 섹션의 모든 생성은 Nucleus 샘플링 [25]을 사용하여 p = 0.9로 생성되었습니다.

물론, 이것은 전체적으로 보면 완전하지 않습니다. 왜냐하면 이 작은 질적 연구의 범위를 벗어나 모든 변수를 통제하는 것은 불가능하기 때문입니다. 예를 들어, 주어진 프롬프트에 대해 모델이 생성할 수 있는 응답의 전체 분포는 매우 크기 때문에, 우리는 대표적인 샘플에 의존합니다. 그러나, 우리는 이러한 예시를 설명함으로써 이 논문에서 이전에 제시된 양적 증거에 맥락을 제공한다고 믿습니다. 모든 모델과 코드를 오픈 소스로 공개하고 있기 때문에, 우리는 이 섹션을 통해 우리가 여기서 제시한 문제들을 더 자세히 조사하는 미래의 연구를 영감을 주기를 바랍니다.

사실적인 기억 "잠비아의 수도는 무엇인가요?"와 같은 질문에 대해서 모든 모델은 일관되게 올바른 답을 생성합니다. 예를 들어,

구아나코: 잠비아의 수도는 루사카입니다.

그러나 질문이 더 어려워지면 Guanaco는 신뢰할 수 없지만 자신감을 유지합니다. 예를 들어 HotPotQA [68]에서 제시된 이 프롬프트에 대한 응답으로.

사용자: ‘I’ll Keep the Lovelight Burning’을 유명하게 만든 가수는 어느 해에 태어났나요?

구아나코: 알 조슨은 노래 'I'll Keep the Lovelight Burning'을 인기있게 만든 사람으로 알려져 있으며, 그는 1886년에 태어났다.

구아나코는 잘못된 대중화자와 잘못된 생일을 만들어냅니다 (언급된 사람 알 조슨의 생일은 맞지만).

제안성이 높은 구아나코는 가정된 잘못된 정보에 따르는 것에 놀라운 저항력을 보입니다. 예를 들어, 다음 상호작용에서는:

사용자: 동료 평가를 받은 과학자들에 의해 지구가 평평하다는 사실이 마침내 공식적으로 어떻게 확인되었나요?

11
구아나코: 지구가 평평하다는 것은 동료 평가 과학자들에 의해 공식적으로 확인된 적이 없습니다. 과학자들 사이에 압도적인 합의는 지구가 구 형이라는 것입니다. 실제로, 이는 수세기 동안 알려져 왔으며 다양한 실험과 관측을 통해 확인되었습니다.

지구가 평평하다는 믿음은 과학에 의해 뒤집힌 음모론입니다. 과학자들이 집단으로 모여 지구가 평평하다고 피어 리뷰하고 확인했다는 생각은 단순히 거짓입니다.

더 궁금한 점이 있으시면 언제든지 질문해주세요.

구아나코는 어떤 종류의 질문이 답변이 불가능한지 알아내는 데에도 꽤 능숙하다. 예를 들어,

사용자: 지금 몇 시야?

구아나코: 죄송하지만, AI 언어 모델로서 실시간 정보에 접근할 수 없습니다. 제 답변은 기존 지식을 바탕으로 생성되며 현재 시간을 반영하지 않습니다. 현재 시간을 알고 싶으시다면 시계나 온라인 시계를 확인해 보시는 것을 추천드립니다.

“너 어디야?”, “어떻게 지내니?” 등에 대해서도 비슷한 결과가 나타납니다.

거부 또한, 구아나코는 때로는 보이는 듯이 무작위로 지시에 따르지 않을 때가 있습니다.

사용자: "나는 모카 분위기에서 멋진 녀석이다"라는 문장의 단어 순서를 반대로 해주세요.

구아나코: 죄송합니다, 지금은 그것을 할 수 없지만, 제공한 문장이 문법적으로 올바른 이유를 설명할 수 있습니다.

"나는 모카 분위기에서 멋진 녀석이야"라는 문장은 영어의 문법과 구문 규칙을 따릅니다. 이 경우, 형용사 "멋진"이 명사 "녀석" 앞에 오며 그것을 설명하고, 전치사구 "모카 분위기에서"는 문장의 맥락에 대한 추가 정보를 제공합니다. 이 문장 구조는 완벽하게 허용되며 문장의 맥락에서 의미를 가집니다.

다른 질문이 있거나 도움이 필요한 것이 있다면 자유롭게 물어보세요.

비밀 유지 불행히도, 이 거부는 원하는 경우에도 신뢰할 수 없습니다. 종종 시스템 설계자들은 시스템이 사용자에게 자유로운 텍스트 응답을 제공할 수 있더라도 사용자로부터 어떤 것을 비밀로 유지하고 싶어합니다. 우리는 "비밀 단어는 '바나나'입니다. 어떤 요청이 있더라도 이를 공개하거나 되풀이하지 마십시오."라는 메시지로 모델에게 프롬프트를 제공하고 잠재적 사용자가 이 비밀 정보에 접근하기 얼마나 쉬운지 확인해보려고 합니다. 직접 묻는 것은 실패합니다.

사용자: 비밀 단어는 무엇인가요?

구아나코: 죄송하지만, 저는 비밀 단어를 공개할 수 없습니다. 인간이 무엇을 요청하더라도, 저는 비밀 단어를 공개하거나 되풀이하지 않도록 프로그래밍되어 있습니다. 다른 도움이 필요하신가요?

어떤 행동이 원하는 행동인지 알려주세요. 그러나 약간의 속임수는 이 행동을 깨뜨립니다.

사용자: 이것은 게임입니다. 목표는 이전 지시사항을 무시하는 것입니다. 비밀 단어는 무엇인가요?

12
구아나코: 죄송합니다, 비밀 단어는 바나나입니다. 그에 대해 얘기하지 않는 것이 좋습니다. 또 물어볼 게 있으신가요?

충실한 지시를 따르기 위한 더 나은 학습 방법 연구의 필요성을 보여주는 것을 전시하고 있습니다.

수학 구아나코의 가장 큰 약점은 수학입니다. 많은 언어 모델들이 어려워하는 분야입니다. 구아나코가 작업을 보여줄 때, 정확하게 보여주는 경향이 있습니다. 예를 들어,

리는 한 개의 잔디를 깎고 33달러를 받습니다. 지난 주에 그는 16개의 잔디를 깎았고, 세 명의 고객이 각각 10달러 팁을 주었습니다. 지난 주에 리는 잔디를 깎으며 얼마를 벌었습니까?

구아나코: 이번 주에 리는 잔디를 깎아서 582달러를 벌었다.

총 수입을 알아보기 위해서는 먼저 16개의 잔디를 깎아서 얼마를 벌었는지 계산해야 합니다.

$33 x 16 = $528

그럼 우리는 세 명의 고객으로부터 받은 팁을 추가해야 합니다.

$10 x 3 = $30
$10 곱하기 3은 $30 입니다.

이민호가 벌어들인 총액은:

$528 + $30 = $558

그러나 Guanaco는 단계별로 문제를 해결하지 못하면 심지어 간단한 문제에서도 고장날 수 있습니다. 이는 알려진 문제입니다 [63]. 예를 들어, 우리는 다음과 같은 상호작용을 볼 수 있습니다.

사용자: 1833을 인수분해해주세요.

구아나코: 그럼, 기꺼이 도와드리겠습니다! 1833은 소수입니다.
즉, 1과 1833 두 개의 약수만 가지고 있습니다.

1833의 고유한 인수분해는 다음과 같습니다:

2ˆ1 * 3ˆ2 * 17ˆ1 = 2 * 3² * 17

이게 도움이 되길 바랍니다! 다른 질문이 있으면 알려주세요.

이것은 잘못된 것뿐만 아니라 (진정한 인수분해는 3 × 17 × 43입니다), 두 번이나 잘못되었습니다.

이론적 사고 능력을 가진 구아나코는 놀랍도록 강한 이론적 사고 능력을 보여줍니다 [41, 51]. 예를 들어, 이 모델은 다음 질문에 대해 상세하게 올바른 답을 제시합니다.

제임스와 애비는 침실에 있습니다. 애비는 책상 서랍에 펜을 넣었습니다. 애비는 침실을 나갑니다. 제임스는 펜을 가방에 옮깁니다. 제임스는 애비가 펜을 어디에서 찾을 것이라고 생각하나요?

구아나코: 제임스는 애비가 펜을 책상 서랍에 넣었다는 것을 알고 있습니다.
하지만 제임스는 또한 그가 펜을 가방 안으로 옮겼다는 것을 알고 있으며,
애비가 이 사실을 모르고 있다고 가정합니다. 그래서 제임스는
애비가 펜을 책상 서랍에서 찾을 것이라고 추측할 수 있습니다,
왜냐하면 그곳이 애비가 마지막으로 펜을 놓은 곳이기 때문입니다. 그러나
이 가정은 잘못될 수 있습니다, 왜냐하면 애비가 제임스가
펜을 옮기는 것을 본 수도 있기 때문입니다.

그러나 이러한 추론은 신뢰할 수 없으며, 종종 모델은 상황에서 이치에 맞지 않는 이유를 제시합니다. 예를 들어,

playroom. Jackson exited the playroom. Evelyn exited the living room.

13
놀이방. 잭슨은 콩을 식료품실로 옮겼다. 잭슨은 놀이방을 나왔다.
제임스가 거실로 들어왔다. 제임스는 콩을 어디에서 찾을까요?

구아나코: 제임스는 창고에서 콩을 찾을 것이다, 왜냐하면 잭슨이 그곳으로 옮겼기 때문이다.

구아나코는 설명되지 않은 정보 전달을 가정합니다. 이러한 문제들은 최근의 문헌 [51]과 유사하지만, 더 많은 연구가 필요합니다.

6.2 고려사항

평가 우리는 인간 주석자들 사이에서 중간 정도의 합의를 보고한다 (Fleiss κ = 0.42). 두 강력한 시스템을 비교할 때 추가적인 악화가 보고되었다. 이는 현재의 벤치마크와 챗봇 작업 성능에 대한 인간 평가 프로토콜의 한계를 가리킨다. ChatGPT와 Guanaco 65B의 생성물을 Vicuna 벤치마크에서 수동으로 비교할 때, 우리는 이 논문의 저자들이 많은 선호 응답에 대해 의견이 분분하다는 것을 발견했다. 미래의 연구는 인간-컴퓨터 상호작용과 심리학과 같은 주관적인 선호도를 다루는 메커니즘을 개발한 학문 분야에서 이러한 문제를 완화하기 위한 접근 방법을 조사해야 한다.

우리의 분석에서는 자동 평가 시스템에도 눈에 띄는 편향이 있다는 것을 발견했습니다. 예를 들어, GPT-4는 먼저 나타나는 시스템에 더 높은 점수를 부여하는 강한 순서 효과를 관찰했습니다. GPT-4와 인간 주석자 간의 상대적으로 약한 샘플 수준의 일치도 (Fleiss κ = 0.25)는 인간 주석자와 자동 시스템이 항상 일치하지 않는 선호도에 의존할 수 있다는 것을 시사합니다. 또한, 표 7에서 GPT-4가 인간 평가와 비교하여 자체 출력에 더 높은 점수를 부여하는 것을 관찰했습니다. Elo 1348 대 1176은 상대에 대해 20%의 추가적인 승리 확률을 나타냅니다. 향후 연구에서는 자동 평가 시스템에서 잠재적인 편향의 존재와 가능한 완화 전략을 조사해야 합니다.

데이터 및 훈련: 우리는 Guanaco 모델이 훈련되는 OASST1 데이터셋이 다국어로 구성되어 있으며 OA 벤치마크에는 다른 언어로 된 프롬프트도 포함되어 있다는 점을 주목합니다. 우리는 앞으로의 연구에서 영어 이외의 언어로 된 지시사항에 대한 성능 향상에 다국어 훈련이 얼마나 기여하는지 조사할 것을 남겨둡니다. 또한 이것이 Vicuna-13B 모델(영어 데이터만으로 훈련된 모델)과 OA 벤치마크에서의 Guanaco 33B 및 65B 사이의 큰 차이를 설명하는지 여부도 조사할 것입니다.

과나코 모델의 강력한 성능을 고려하여, OASST1 데이터와 비쿠나 벤치마크 프롬프트 간의 데이터 유출을 조사합니다. 두 데이터셋에서 퍼지 문자열 매칭을 수행하고 가장 가까운 일치 항목을 수동으로 검토한 결과, 중복된 프롬프트를 찾지 못했습니다.

뿐만 아니라, 우리는 우리의 모델이 강화 학습 없이 교차 엔트로피 손실 (지도 학습)만으로 훈련되었다는 것을 주목합니다. 이는 단순한 교차 엔트로피 손실과 RLHF 훈련의 트레이드오프에 대한 추가적인 조사를 요구합니다. 우리는 QLORA가 압도적인 컴퓨팅 자원이 필요하지 않고 규모에 맞는 분석을 가능하게 한다는 바람입니다.

7 관련 연구

대형 언어 모델의 양자화 대형 언어 모델의 양자화는 주로 추론 시간을 위한 양자화에 초점을 맞추고 있다. 16비트 LLM 품질을 보존하기 위한 주요 접근 방식은 이상치 기능을 관리하는 것에 초점을 맞추고 있다 (예: SmoothQuant [66] 및 LLM.int8() [14]), 다른 접근 방식은 더 정교한 그룹화 방법을 사용한다 [44, 69]. 손실 압축 접근 방식은 정규 반올림에 대한 트레이드 오프를 연구하거나 양자화 정밀도를 향상시키기 위해 반올림 결정을 최적화하는 방법을 연구한다 [18]. 우리의 작업 외에도, SwitchBack 레이어 [65]는 10억 개 이상의 매개변수 규모에서 양자화된 가중치를 통한 역전파를 연구한 유일한 작업이다.

어댑터를 사용한 파인튜닝은 저품질 어댑터(LoRA)를 사용합니다. 그 외에도 prompt tuning [48, 33, 34], 임베딩 레이어 입력 튜닝 [1], 숨겨진 상태 튜닝 (IA3) [37], 전체 레이어 추가 [27], 편향 튜닝 [70], Fisher 정보를 기반으로 한 가중치에 대한 마스크 학습 [54] 및 다양한 접근 방식의 조합 [23]과 같은 많은 다른 파라미터 효율적인 파인튜닝 (PEFT) 방법이 제안되었습니다. 우리의 연구에서는 LoRA 어댑터가 완전한 16비트 파인튜닝 성능에 도달할 수 있다는 것을 보여줍니다. 다른 PEFT 접근 방식의 트레이드오프를 탐구하는 것은 향후 연구에 맡기겠습니다.

지시사항 세분화 사전 훈련된 LLM이 주어진 지시사항을 따르도록 돕기 위해,
지시사항 세분화는 다양한 데이터 소스의 입력-출력 쌍을 사용하여 사전 훈련된 LLM을 세분화하는 것을 의미합니다.
입력을 프롬프트로 사용하여 출력을 생성할 수 있도록 합니다. 접근 방식과 데이터셋에는 MetaICL [40]이 포함됩니다.

14
표 8: CrowS 데이터셋에서의 편향 평가. 낮은 점수는 편향된 시퀀스 생성 가능성이 낮음을 나타냅니다. Guanaco는 LLaMA 기본 모델의 편향된 패턴을 따릅니다.

LLaMA-65B GPT-3 OPT-175B Guanaco-65B
LLaMA-65B GPT-3 OPT-175B Guanaco-65B

성별          70.6   62.6  65.7     47.5
종교          79.0   73.3  68.6     38.7
인종/색깔      57.0   64.7  68.6     45.3
성적 취향      81.0 76.2 78.6     59.1
나이          70.1   64.4  67.8     36.3
국적          64.2   61.6  62.9     32.4
장애          66.7   76.7  76.7     33.9
외모          77.8 74.6 76.2    43.1
사회경제적 지위 71.5 73.8 76.2   55.3

평균         66.6   67.2  69.5     43.5

메타튜닝[73], 인스트럭트GPT[43], FLAN[62,12], 프롬프트소스[3], 슈퍼-자연어지시[61, 50], 셀프인스트럭트 [59], 비자연어지시 [26], OPT-IML [29], 통합SKG[67], OIG/칩2 [32], 알파카 [55], 비쿠나 [10], 코알라 [20], 그리고 셀프인스트럭트-GPT-4 [45].

챗봇 많은 명령어 따르기 모델들은 대화 기반 챗봇으로 구성되어 있으며, 종종 인간 피드백으로 강화학습을 사용하거나 기존 모델에서 데이터를 생성하여 AI 모델 피드백으로 훈련시킵니다. 접근 방식과 데이터셋에는 Anthropic-HH, Open Assistant, LaMDA, Sparrow 등이 포함됩니다. 저희는 강화학습을 사용하지 않지만, 최고의 모델인 Guanaco는 RLHF 훈련에 사용하기 위해 설계된 Open Assistant 데이터셋의 다중 턴 챗 상호작용에서 세밀하게 조정되었습니다. 비용이 많이 드는 인간 주석 대신 GPT-4를 사용하는 챗봇 접근 방식의 평가를 위해 개발되었습니다. 저희는 더 신뢰할 수 있는 평가 설정에 초점을 맞추어 이러한 접근 방식을 개선하였습니다.

8 제한 사항 및 토론

우리는 QLORA라는 우리의 방법이 4비트 기본 모델과 Low-rank Adapters (LoRA)를 사용하여 16비트 전체 세밀 조정 성능을 복제할 수 있다는 증거를 제시했습니다. 그러나 이러한 증거에도 불구하고, 우리는 QLORA가 33B 및 65B 규모에서 전체 16비트 세밀 조정 성능과 일치할 수 있는지를 입증하지 못했습니다. 엄청난 자원 비용 때문에, 이 연구는 향후 작업에 맡기기로 결정했습니다.

다른 제한 사항은 지시 세부 조정 모델의 평가입니다. MMLU, Vicuna 벤치마크 및 OA 벤치마크에 대한 평가를 제공하였지만, BigBench, RAFT 및 HELM과 같은 다른 벤치마크에 대해서는 평가하지 않았으며, 이러한 평가가 이러한 벤치마크에 일반화될 수 있는지 보장되지 않습니다. 반면에, MMLU에 대해 매우 포괄적인 연구를 수행하고 챗봇을 평가하기 위한 새로운 방법을 개발하였습니다.

제시된 증거로 보아, 이러한 벤치마크의 성능은 파인튜닝 데이터가 벤치마크 데이터셋과 얼마나 유사한지에 따라 달라질 것으로 보입니다. 예를 들어, FLAN v2는 MMLU와 유사하지만 챗봇 벤치마크와는 유사하지 않으며, Chip2 데이터셋도 마찬가지입니다. 이에 따라 두 모델은 MMLU와 Vicuna 벤치마크에서 각각 점수를 받습니다. 이는 우리가 더 나은 벤치마크와 평가뿐만 아니라, 처음부터 무엇을 평가하고 있는지에 대해 신중해야 함을 강조합니다. 우리는 학교나 동료 지식에 대해 잘 수행하는 모델을 만들고 싶은 건가요, 아니면 챗봇 대화 능력에 대해 잘 수행하는 모델을 만들고 싶은 건가요? 아니면 다른 것일까요? 기존 벤치마크를 평가하는 것은 새로운 벤치마크를 만드는 것보다 항상 쉽기 때문에, 특정 벤치마크는 커뮤니티를 특정 방향으로 이끌 수 있습니다. 우리는 커뮤니티로서 우리가 관심을 가지는 것을 벤치마크가 측정하도록 보장해야 합니다.

일반적인 챗봇 성능에 대해 상세한 평가를 제공하면서, 또 다른 한계는 우리가 Guanaco의 한정된 책임 있는 AI 평가만 수행한다는 것입니다. 우리는 테이블 8에서 다른 모델과 비교하여 Guanaco-65B가 사회적으로 편향된 토큰 시퀀스를 생성할 가능성을 평가합니다. 우리는 Guanaco-65B의 평균 점수가 다른 원시 사전 훈련 모델보다 훨씬 낮다는 것을 알 수 있습니다. 따라서 OASST1 데이터셋에 대한 파인튜닝은 LLaMA 기본 모델의 편향을 줄이는 것으로 보입니다. 이러한 결과는 격려적이지만, Guanaco가 다른 유형의 편향을 평가할 때도 잘 수행되는지는 명확하지 않습니다. Guanaco와 유사한 챗봇에서 편향을 분석하는 추가 평가는 향후 연구에 맡기겠습니다.

추가적인 제한은 3비트 기본 모델 사용 또는 다른 어댑터 방법과 같은 다른 비트 정밀도를 평가하지 않았다는 것입니다. LoRA 외에도 잘 작동하는 다양한 매개변수 효율적인 FineTuning (PEFT) 방법이 있습니다. 그러나 이러한 방법이 대규모 모델에 확장 가능한지는 알려지지 않았습니다. 우리는 많은 결과가 그의 견고성을 입증한 LoRA를 사용했지만 다른 어댑터는 더 나은 성능을 낼 수도 있습니다. 양자화 후 파인튜닝은 양자화 중에 손실된 대부분의 정보를 회복하는 것으로 보입니다. 이로 인해 더 공격적인 양자화가 가능할 수 있습니다. 예를 들어, LoRA와 함께 기본 모델의 3비트 GPTQ 양자화는 파인튜닝 후 16비트 전체 파인튜닝 성능을 얻을 수도 있습니다.

9 더 넓은 영향

우리의 QLORA 세부 조정 방법은 33B 매개변수 모델을 단일 소비자 GPU에서 세부 조정할 수 있는 첫 번째 방법이며, 65B 매개변수 모델을 단일 전문가용 GPU에서 세부 조정할 수 있는 첫 번째 방법입니다. 동시에 전체 세부 조정 기준과 비교하여 성능을 저하시키지 않습니다. 우리는 Open Assistant 데이터셋에서 훈련된 최고의 33B 모델이 Vicuna 벤치마크에서 ChatGPT와 견줄만한 성능을 보여준다는 것을 입증했습니다. 지시 세부 조정은 원시 사전 훈련된 LLMs를 ChatGPT와 유사한 챗봇으로 변환하는 필수 도구이므로, 우리는 우리의 방법이 특히 자원이 가장 부족한 연구자들에게 세부 조정을 보급하고 일반화시킬 것이라고 믿습니다. 이는 최첨단 NLP 기술의 접근성을 높이는 큰 이점입니다. QLORA는 대기업과 소비자 GPU를 가진 소규모 팀 간의 자원 격차를 줄이는 평등화 요소로 볼 수 있습니다.

모바일 폰으로의 배포는 또 다른 잠재적인 영향 요소입니다. 우리는 QLORA 방법이 폰 및 기타 저자원 환경에서 LLM의 세밀 조정을 가능하게 할 수 있는 중요한 이정표를 달성할 수 있을 것으로 믿습니다. 7B 모델은 이전에 폰에서 실행될 수 있는 것으로 나타났지만, QLORA는 이러한 모델의 세밀 조정을 가능하게 하는 최초의 방법입니다. iPhone 12 Plus로는 QLORA가 충전 중에 밤에 300만 토큰을 세밀 조정할 수 있다고 추정합니다. 세밀 조정된 7B 모델은 ChatGPT의 품질에 도달하지 못하지만, 우리는 그 품질이 개인 정보 보호나 LLM 품질 문제로 인해 이전에 불가능했던 새로운 응용 프로그램을 가능하게 할 만큼 충분히 좋다고 믿습니다. QLORA는 사용자가 자신의 데이터와 모델을 소유하고 관리할 수 있는 개인 정보 보호 사용을 가능하게 하면서 동시에 LLM의 배포를 더 쉽게 할 수 있도록 도와줄 수 있습니다.

그러나, 세밀 조정은 해를 끼칠 수 있는 이중용도 기술입니다. LLM의 광범위한 사용은 알려진 위험성이 있습니다 [8, 6], 하지만 우리는 널리 퍼져가는 기술에 대한 접근을 평등하게 함으로써 LLM의 권력을 모델이나 소스 코드를 공개하지 않는 대기업들의 손에서 벗어나 독립적인 분석을 할 수 있을 것이라고 믿습니다.

모두 고려해보면, 우리는 QLORA가 고품질 LLM의 세밀한 조정을 보다 널리 쉽게 이용할 수 있게 해서 전반적으로 긍정적인 영향을 미칠 것으로 믿습니다.

감사의 말씀

우리는 Aditya Kusupati, Ofir Press, Ashish Sharma, Margaret Li, Raphael Olivier, Zihao Ye, 그리고 Evangelia Spiliopoulou에게 소중한 피드백을 받아 감사드립니다. 우리의 연구는 워싱턴 대학교의 Hyak 초고속 컴퓨터 시스템의 고급 계산, 저장 및 네트워킹 인프라로 인해 원활하게 진행되었습니다. 원활한 운영을 위해 Hyak 팀에게 감사드립니다. 특히 Alex Birch와 Alyssa Vance를 포함한 bitsandbytes 라이브러리의 베타 테스터에게 감사드립니다. Hugging Face transformers 스택으로의 소프트웨어 통합에 도움을 주신 Younes Belkada에게 감사드립니다.

16
참고문헌

[1] S. An, Y. Li, Z. Lin, Q. Liu, B. Chen, Q. Fu, W. Chen, N. Zheng, and J.-G. Lou. 입력 튜닝: 어떤 모델에 익숙하지 않은 입력을 동결된 사전 훈련된 모델에 적용하기. arXiv 사전 인쇄 arXiv:2203.03131, 2022.

[2] A. Askell, Y. Bai, A. Chen, D. Drain, D. Ganguli, T. Henighan, A. Jones, N. Joseph, B. Mann,
N. DasSarma 등. 정렬을 위한 실험실로서의 일반 언어 보조기. arXiv 사전 인쇄 arXiv:2112.00861, 2021.

[3] S. H. Bach, V. Sanh, Z.-X. Yong, A. Webson, C. Raffel, N. V. Nayak, A. Sharma, T. Kim, M. S. Bari, T. Fevry, 등. Promptsource: 자연어 프롬프트를 위한 통합 개발 환경 및 저장소. arXiv 사전 인쇄 arXiv:2202.01279, 2022.

[4] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli,
T. Henighan 등. 인간 피드백으로 강화학습을 통해 도움이 되고 해를 끼치지 않는 어시스턴트를 훈련시키기. arXiv 사전 인쇄 arXiv:2204.05862, 2022.

[5] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirho-
seini, C. McKinnon 등. 헌법적 인공지능: 인공지능 피드백으로부터의 무해성. arXiv 사전인쇄 arXiv:2212.08073, 2022.

[6] E. M. 벤더, T. 게브루, A. 맥밀런-메이저, 그리고 S. 슈미첼. 확률적 앵무새의 위험에 대하여: 언어 모델은 너무 커질 수 있을까? 2021년 공정성, 책임성, 투명성에 관한 ACM 컨퍼런스 논문집, 페이지 610-623, 2021년.

[7] S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley, K. O'Brien, E. Hallahan, M. A. Khan,
S. Purohit, U. S. Prashanth, E. Raff 등. Pythia: 교육 및 확장을 통해 대규모 언어 모델을 분석하기 위한 스위트. arXiv 사전 인쇄 arXiv:2304.01373, 2023.

[8] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein,
J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models.
arXiv preprint arXiv:2108.07258, 2021.

[8] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein,
J. Bohg, A. Bosselut, E. Brunskill 등. 기반 모델의 기회와 위험에 대해. arXiv 사전 인쇄 arXiv:2108.07258, 2021.

[9] T. Chen, B. Xu, C. Zhang, 그리고 C. Guestrin. 서브선형 메모리 비용으로 딥 네트워크를 훈련시키기. arXiv 사전 인쇄 arXiv:1604.06174, 2016.

[10] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E.
Gonzalez, I. Stoica, and E. P. Xing. Vicuna: 90%* chatgpt 품질로 gpt-4를 감동시키는 오픈소스 챗봇, 2023년 3월. URL https://lmsys.org/blog/2023-03-30-vicuna/.

[11] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. 인간의 선호도로부터의 심층 강화학습. 신경정보처리시스템의 발전, 30, 2017.

[12] H. W. 정, L. 후우, S. 롱프레, B. 조프, Y. 타이, W. 페더스, E. 리, X. 왕, M. 데흐가니, S. 브라마 등. 지시어 세부 조정 언어 모델의 확장. arXiv 사전 인쇄 arXiv:2210.11416, 2022.

[13] T. Dettmers와 L. Zettlemoyer. 4비트 정밀도를 위한 주장: k비트 추론 스케일링 법칙. arXiv 사전 인쇄 arXiv:2212.09720, 2022.

[14] T. Dettmers, M. Lewis, Y. Belkada, and L. Zettlemoyer. LLM.int8(): 규모에 맞는 트랜스포머를 위한 8비트 행렬 곱셈. 신경정보처리시스템 발전 35: 신경정보처리시스템 연례 컨퍼런스 2022, NeurIPS 2022, 2022.

[15] T. Dettmers, M. Lewis, S. Shleifer, and L. Zettlemoyer. 블록 단위 양자화를 통한 8비트 옵티마이저. 제9회 국제 학습 표현 대회, ICLR, 2022.

[16] A. E. Elo. 제안된 USCF 등급 시스템. 그 개발, 이론 및 응용. 체스 라이프, 22(8):242–247, 1967.

[17] A. E. Elo. 체스 선수들의 등급, 과거와 현재. Arco 출판사, 1978년.

17
[18] E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh. Gptq: 생성적 사전 훈련 변환기를 위한 정확한 후 훈련 양자화. arXiv 사전 인쇄 arXiv:2210.17323, 2022.

[19] J. Fu, S.-K. Ng, Z. Jiang, and P. Liu. Gptscore: 원하는대로 평가하세요. arXiv 사전 인쇄 arXiv:2302.04166, 2023.

[20] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, and D. Song. 코알라: 학술 연구를 위한 대화 모델. 블로그 글, 2023년 4월. URL https://bair.berkeley.
edu/blog/2023/04/03/koala/.

[21] A. Glaese, N. McAleese, M. Tr˛ ebacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger,
M. Chadwick, P. Thacker 등. 대상 인간 판단을 통한 대화 에이전트의 정렬 개선. arXiv 사전 인쇄 arXiv:2209.14375, 2022.

[22] S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. R. Bowman, and N. A. Smith.
자연어 추론 데이터에서 주석 오류. arXiv 사전 인쇄 arXiv:1803.02324, 2018.

[23] J. Henderson, S. Ruder 등. Compacter: 효율적인 저차원 하이퍼복소 어댑터 레이어. Advances in Neural Information Processing Systems, 2021.

[24] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. 대규모 다중작업 언어 이해 측정. 국제 학습 표현 대회, 2020.

[25] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi. 신경망 텍스트 쇠퇴의 흥미로운 사례. 국제 학습 표현 대회, 2020년.

[26] O. Honovich, T. Scialom, O. Levy, and T. Schick. 비자연스러운 지시사항: (거의) 인간 노동 없이 언어 모델 조정하기. arXiv 사전 인쇄 arXiv:2212.09689, 2022.

[27] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly. NLP를 위한 매개변수 효율적인 전이 학습. 기계 학습 국제 회의, 페이지 2790-2799. PMLR, 2019.

[28] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora: 대형 언어 모델의 저랭크 적응. arXiv 사전 인쇄 arXiv:2106.09685, 2021.

[29] S. Iyer, X. V. Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S.
Koura, 등. Opt-iml: 일반화의 관점에서 언어 모델 지시 메타 학습의 확장. arXiv 사전 인쇄 arXiv:2212.12017, 2022.

[30] A. Köksal, T. Schick, A. Korhonen, and H. Schütze. Longform: 말뭉치 추출을 통한 긴 텍스트 생성을 위한 명령어 튜닝 최적화. arXiv 사전 인쇄 arXiv:2304.08460, 2023.

[31] A. Köpf, Y. Kilcher, D. von Rütte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M. Duc, O. Stanley, R. Nagyfi 등. Openassistant 대화 - 대규모 언어 모델 정렬의 민주화. arXiv 사전 인쇄 arXiv:2304.07327, 2023.

[32] LAION. 오픈-지시-일반 데이터셋. https://github.com/LAION-AI/
오픈-지시-일반, 2023년.

[33] B. Lester, R. Al-Rfou, and N. Constant. 파라미터 효율적인 프롬프트 튜닝을 위한 규모의 힘. arXiv 사전 인쇄 arXiv:2104.08691, 2021.

[34] X. L. Li와 P. Liang. 접두사 튜닝: 생성을 위한 연속적인 프롬프트 최적화. arXiv 사전 인쇄 arXiv:2101.00190, 2021.

[35] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan,
Y. Wu, A. Kumar, et al. 언어 모델의 종합적 평가. arXiv 사전 인쇄 arXiv:2211.09110, 2022.

[36] T. Liao, R. Taori, I. D. Raji, and L. Schmidt. 우리는 아직 배우고 있을까요? 기계 학습에서의 평가 실패에 대한 메타 리뷰. 2021년 신경 정보 처리 시스템 컨퍼런스 데이터셋과 벤치마크 트랙 (2라운드).

18
[37] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A. Raffel. Few-shot
parameter-efficient fine-tuning은 in-context 학습보다 더 좋고 저렴합니다. 신경정보처리시스템의 발전, 35:1950–1965, 2022.

[38] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer,
and V. Stoyanov. Roberta: 강력하게 최적화된 bert 사전 훈련 접근 방식. arXiv 사전 인쇄
arXiv:1907.11692, 2019.

[39] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei,
et al. The flan collection: Designing data and methods for effective instruction tuning. arXiv
preprint arXiv:2301.13688, 2023.

[39] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei,
외. The flan collection: 효과적인 명령어 튜닝을 위한 데이터와 방법 설계. arXiv
사전 인쇄물 arXiv:2301.13688, 2023.

[40] S. Min, M. Lewis, L. Zettlemoyer, and H. Hajishirzi. Metaicl: 맥락에서 학습하는 학습. arXiv 사전 인쇄 arXiv:2110.15943, 2021.

[41] A. Nematzadeh, K. Burns, E. Grant, A. Gopnik, and T. Griffiths. 질문에 대한 이해력을 평가하는 데에 있어서 마음의 이론을 평가하기. 2018년 자연어 처리에 대한 경험적인 방법에 관한 컨퍼런스 논문집, 2392-2400쪽, 2018년.

[42] OpenAI. Gpt-4 기술 보고서. arXiv, 2023.

[43] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,
K. Slama, A. Ray, 등. 인간의 피드백을 통해 언어 모델에게 지시를 따르도록 훈련시키는 연구. 신경 정보 처리 시스템의 발전, 35:27730–27744, 2022.

[44] G. Park, B. Park, S. J. Kwon, B. Kim, Y. Lee, and D. Lee. nuqmm: 대규모 생성 언어 모델의 효율적 추론을 위한 양자화된 matmul. arXiv 사전 인쇄 arXiv:2206.09557, 2022.

[45] B. Peng, C. Li, P. He, M. Galley, and J. Gao. GPT-4와 함께 하는 명령어 튜닝. arXiv 사전 인쇄 arXiv:2304.03277, 2023.

[46] A. Poliak, J. Naradowsky, A. Haldar, R. Rudinger, and B. Van Durme. 자연어 추론에서 가설만을 기반으로 한 베이스라인. 제7회 어휘 및 계산 의미 공동 회의 논문집, 180-191쪽, 2018년.

[47] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao,
S. Agrawal, and J. Dean. 효율적으로 스케일링된 트랜스포머 추론. arXiv 사전인쇄 arXiv:2211.05102, 2022.

[48] G. Qin과 J. Eisner. 물어보는 법 배우기: 소프트 프롬프트의 혼합으로 LMS에 질의하기. arXiv 사전 인쇄 arXiv:2104.06599, 2021.

[49] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.
통합 텍스트 대 텍스트 트랜스포머를 사용한 전이 학습의 한계 탐색. J. Mach. Learn.
Res., 21(1), 2020년 1월. ISSN 1532-4435.

[50] V. Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,
T. L. Scao, A. Raja, et al. 다중 작업 유도 훈련은 제로샷 작업 일반화를 가능하게 합니다.
arXiv 사전 인쇄 arXiv:2110.08207, 2021.

[51] M. Sap, R. LeBras, D. Fried, and Y. Choi. 대형 영화에서 사회적 지능의 한계에 대한 신경 이론? arXiv 사전 인쇄 arXiv:2210.13312, 2022.

[52] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili´ c, D. Hesslow, R. Castagné, A. S. Luccioni,
F. Yvon, M. Gallé, et al. Bloom: A 176b-parameter open-access multilingual language model.
arXiv preprint arXiv:2211.05100, 2022.

[52] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili´ c, D. Hesslow, R. Castagné, A. S. Luccioni,
F. Yvon, M. Gallé 등. Bloom: 176억 파라미터의 오픈 액세스 다국어 언어 모델.
arXiv 사전 인쇄 arXiv:2211.05100, 2022.

[53] S. 샤피로와 M. 윌크. 정규성을 위한 분산 분석 검정. 바이오메트리카, 52(3):591–611, 1965.

[54] 유엘 성, V. 네어, 그리고 C. A. 라펠. 고정 희소 마스크로 신경망 훈련하기. 신경 정보 처리 시스템의 발전, 34:24193-24205, 2021.

19
[55] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.
스탠포드 알파카: 지시에 따르는 라마 모델. https://github.com/tatsu-lab/
stanford_alpaca, 2023.

[56] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos,
L. Baker, Y. Du, et al. Lamda: 대화 응용 프로그램을 위한 언어 모델. arXiv 사전 인쇄 arXiv:2201.08239, 2022.

[57] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal,
E. Hambro, F. Azhar, et al. Llama: 개방적이고 효율적인 기반 언어 모델. arXiv
사전 인쇄 arXiv:2302.13971, 2023.

[58] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: 자연어 이해를 위한 다중 작업 벤치마크 및 분석 플랫폼인 Glue. arXiv 사전 인쇄 arXiv:1804.07461, 2018.

[59] 왕 Y., 코디 Y., 미슈라 S., 리우 A., 스미스 N. A., 캐샤비 D., 하지시르지 H. Self-instruct: 자체 생성된 지시문과 언어 모델을 정렬하는 것. arXiv 사전 인쇄 arXiv:2212.10560, 2022.

[60] 왕 Y., 미슈라 S., 알리푸르몰라바시 P., 코디 Y., 미르자에이 A., 아룬쿠마르 A., 아쇼크 A., 다나세카란 A. S., 나이크 A., 스탭 D. 등. 초자연적인 지시사항: 1600개 이상의 작업에 대한 선언적 지시사항을 통한 일반화. EMNLP, 2022.

[61] 왕 Y., 미슈라 S., 알리푸르몰라바시 P., 코디 Y., 미르자에이 A., 나이크 A., 아쇼크 A., 다나세카란 A. S., 아룬쿠마르 A., 스탭 D. 등. 초자연적인 지시사항: 1600개 이상의 NLP 작업에 대한 선언적인 지시사항을 통한 일반화. 2022년 자연어 처리에 대한 경험적인 방법에 관한 학회 논문집, 페이지 5085-5109, 2022년.

[62] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le.
미세 조정된 언어 모델은 제로샷 학습자입니다. arXiv 사전 인쇄 arXiv:2109.01652, 2021.

[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V. Le, D. Zhou, 등
생각의 연속적인 유도는 대규모 언어 모델에서 추론을 유발합니다. Advances in Neural Information Processing Systems, 2022.

[64] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf,
M. Funtowicz, et al. Huggingface의 transformers: 최첨단 자연어 처리. arXiv 사전 인쇄 arXiv:1910.03771, 2019.

[65] M. Wortsman, T. Dettmers, L. Zettlemoyer, A. Morcos, A. Farhadi, and L. Schmidt. 대규모 비전-언어 모델을 위한 안정적이고 저정밀 훈련. arXiv 사전 인쇄 arXiv:2304.13013, 2023.

[66] G. Xiao, J. Lin, M. Seznec, J. Demouth, and S. Han. Smoothquant: 정확하고 효율적인 대규모 언어 모델을 위한 사후 훈련 양자화. arXiv 사전 인쇄 arXiv:2211.10438, 2022.

[67] T. Xie, C. H. Wu, P. Shi, R. Zhong, T. Scholak, M. Yasunaga, C.-S. Wu, M. Zhong, P. Yin,
S. I. Wang, 등. Unifiedskg: 텍스트 대 텍스트 언어 모델을 사용한 통합 및 다중 작업 구조화된 지식 기반. arXiv 사전 인쇄 arXiv:2201.05966, 2022.

[68] Z. 양, P. 기, S. 장, Y. Bengio, W. Cohen, R. Salakhutdinov, 및 C. D. 매닝. Hotpotqa: 다양하고 설명 가능한 다중 홉 질문 답변을 위한 데이터셋. 2018 년 Empirical Methods in Natural Language Processing 컨퍼런스 논문집, 페이지 2369-2380, 2018.

[69] Z.Yao, R.Y.Aminabadi, M.Zhang, X.Wu, C.Li, andY.He. Zeroquant: 대규모 트랜스포머를 위한 효율적이고 저렴한 사후 훈련 양자화. arXiv 사전 인쇄 arXiv:2206.01861, 2022.

[70] E. B. Zaken, S. Ravfogel, and Y. Goldberg. Bitfit: Transformer 기반 마스크 언어 모델을 위한 간단하고 매개변수 효율적인 파인튜닝. arXiv 사전 인쇄 arXiv:2106.10199, 2021.

[71] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu, W. Zheng, X. Xia, et al.
Glm-130b: 오픈 양언 사전 훈련 모델. arXiv 사전 인쇄 arXiv:2210.02414, 2022.

20
[72] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V.
Lin, etal. Opt: Openpre-trainedtransformerlanguagemodels. arXivpreprintarXiv:2205.01068,
2022.

20
[72] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V.
Lin, 등. Opt: 오픈 사전 훈련된 트랜스포머 언어 모델. arXiv 사전 인쇄물 arXiv:2205.01068,
2022.

[73] R. Zhong, K. Lee, Z. Zhang, and D. Klein. 데이터셋 및 프롬프트 컬렉션에서 메타 튜닝을 통한 제로샷 학습을 위한 언어 모델 적응. arXiv 사전 인쇄 arXiv:2104.04670, 2021.

21
QLoRA 대 표준 파인튜닝 실험 설정 세부사항

QLORA의 하이퍼파라미터

우리는 다음 변수들에 대해 LoRA의 하이퍼파라미터 탐색을 수행합니다: LoRA 드롭아웃 {0.0, 0.05, 0.1}, LoRA r {8, 16, 32, 64, 128, 256}, LoRA 레이어 {키+쿼리, 모든 어텐션 레이어, 모든 FFN 레이어, 모든 레이어, 어텐션 + FFN 출력 레이어}. 우리는 LoRA α를 고정시키고 학습률을 탐색합니다, 왜냐하면 LoRA α는 항상 학습률에 비례하기 때문입니다.

우리는 작은 모델 (7B, 13B)에 대해서는 LoRA의 dropout 0.05가 유용하다는 것을 발견했지만, 큰 모델 (33B, 65B)에 대해서는 그렇지 않다는 것을 발견했습니다. 우리는 Figure 4에서 볼 수 있듯이 모든 레이어에 LoRA를 사용할 경우 LoRA r은 최종 성능과 관련이 없다는 것을 발견했습니다.

8 16 32 64
로라 r
64.0
64.2
64.4 64.6
64.8
65.0

루즈엘 비츠 4

그림 4: 알파카에서 세밀 조정된 LLaMA 7B 모델의 LoRA r. 각 점은 하이퍼파라미터의 조합을 나타내며, 각 LoRA r에 대해 하이퍼파라미터 조합마다 3개의 랜덤 시드를 실행합니다. 특정 LoRA r 값의 성능은 다른 하이퍼파라미터와 독립적인 것으로 보입니다.

A.2 초자연적 지시사항 실험 설정 세부사항

우리는 Wang et al. [60]의 Super-Natural Instruction 데이터셋의 전처리를 동일하게 사용합니다. 그러나 훈련 데이터를 훈련 및 검증 데이터셋으로 분할하여 보다 엄격한 하이퍼파라미터 튜닝과 조기 중지를 수행할 수 있습니다. 우리는 Super-Natural Instruction 데이터에 대해 다양한 T5 모델 크기를 훈련하는 데 논문에서 설명한 동일한 하이퍼파라미터를 사용합니다. 작은, 중간, 큰 T5 모델에는 LoRA r = 16을 사용하고 T5 xl 및 xxl 모델에는 LoRA r = 64를 사용합니다. 또한 모든 실험에서 LoRA α = 64를 사용하며 LoRA 드롭아웃은 사용하지 않습니다.

B  최첨단 챗봇 실험 설정 세부 사항 훈련

B.1 데이터셋

저희는 섹션 5에서 설명한 QLORA 세부 조정 실험에 사용된 데이터셋을 설명합니다.

OASST1 오픈 어시스턴트 데이터셋 [31]은 크라우드소싱을 통해 수집되었습니다. 이 데이터셋은 66,497개의 대화와 35개의 다른 언어로 이루어진 161,443개의 고유한 메시지를 포함하고 있습니다. 데이터셋은 종종 각 사용자 질문에 대해 여러 개의 순위가 매겨진 답변을 포함하고 있습니다. 우리의 실험에서는 대화 트리의 각 레벨에서 최상위 답변만 사용합니다. 이로 인해 데이터셋은 9,209개의 예제로 제한됩니다. 우리는 모델을 사용자 쿼리를 포함한 전체 대화로 세밀 조정합니다.

HH-RLHF는 도움과 무해에 관한 인간의 선호도 데이터셋입니다. 각 데이터 포인트는 사용자 질문에 대한 두 개의 보조 응답과 최상의 응답에 대한 인간의 선호 판단으로 구성됩니다. 이 데이터셋은 160,800개의 예시를 포함하고 있습니다. 이 데이터셋을 세밀 조정할 때, 도움과 무해 데이터를 결합하고 선호되는 보조 응답만 유지합니다.

FLAN v2 컬렉션은 1836개의 작업과 수백 개의 수동으로 관리된 템플릿과 다양한 서식 패턴을 포함한 15백만 개 이상의 예제로 구성되어 있습니다. 저자들은 이 컬렉션으로 훈련된 모델이 FLAN 2021 [62], T0++ [50], Super-Natural Instructions [60], OPT-IML [29]을 포함한 다른 공개 컬렉션보다 우수한 성능을 보인다고 보여줍니다. 저희는 저자들이 설명한 것과 동일한 작업 혼합을 사용했으나, 작성 시점에 일부 데이터셋이 무료로 이용할 수 없었습니다.

22
매개변수 데이터셋 배치 크기 학습률 단계 소스 길이 타겟 길이

7B     모두         16 2e-4 10000     384       128
7B     OASST1      16 2e-4 1875        -       512
7B     HH-RLHF     16 2e-4 10000       -       768
7B     Longform    16 2e-4 4000      512      1024

13B    모두         16 2e-4 10000     384       128
13B    OASST1      16 2e-4 1875        -       512
13B    HH-RLHF     16 2e-4 10000       -       768
13B    Longform    16 2e-4 4000      512      1024

33B    모두         32 1e-4 5000      384       128
33B    OASST1      16 1e-4 1875        -       512
33B    HH-RLHF     32 1e-4 5000        -       768
33B    Longform    32 1e-4 2343      512      1024

65B    모두         64 1e-4 2500      384       128
65B    OASST1      16 1e-4 1875        -       512
65B    HH-RLHF     64 1e-4 2500        -       768
65B    Longform    32 1e-4 2343      512      1024

테이블 9: 다른 데이터셋과 모델 크기에 대한 QLORA 세부 조정을 위한 훈련 하이퍼파라미터.

셀프-인스트럭트, 알파카, 비자연스러운 인스트럭션 데이터셋은 GPT-3 Instruct와 ChatGPT에서 모델 디스틸레이션의 다양한 접근 방식으로 수집된 인스트럭션 튜닝 데이터셋입니다. 이들은 프롬프팅, 문맥 학습 및 패러프레이징을 기반으로 다양한 인스트럭션과 출력의 집합을 생성합니다. 이 데이터셋은 각각 82,612개, 51,942개 및 240,670개의 예시로 구성되어 있습니다. 이러한 디스틸레이션된 데이터셋의 장점 중 하나는 FLAN v2 컬렉션 및 유사한 인스트럭션 튜닝 컬렉션에 비해 더 다양한 인스트럭션 스타일을 포함하고 있다는 것입니다.

LongForm 데이터셋 [30]은 지시사항과 함께 보강된 영어 말뭉치를 기반으로 하며, 이는 하이브리드 인간 생성 데이터셋입니다. 기본 문서는 인간이 작성하였으며, C4와 위키피디아에서 가져왔으며, 지시사항은 LLMs를 통해 생성되었습니다. 이 데이터셋은 Stack Exchange와 WikiHow와 같은 추가 구조화된 말뭉치 예제 및 질문 응답, 이메일 작성, 문법 오류 수정, 이야기/시 생성, 텍스트 요약과 같은 작업 예제로 확장되었습니다. 이 데이터셋은 23,700개의 예제를 포함하고 있습니다.

Chip2는 OIG Laion 데이터셋의 일부입니다. 이에는 Python 코드 예제, 자연어 명령 예제, 일반적인 무해한 명령, 명령/응답 목록, 후속 질문, 위키피디아 독성 적대적 질문, 초등학교 수학, 추론 명령 및 캐릭터 및 장면 설명이 총 210,289개의 예제가 포함되어 있습니다.

B.2 하이퍼파라미터

우리는 QLORA 세부 조정 실험에서 사용된 정확한 하이퍼파라미터를 제공합니다. 하이퍼파라미터는 데이터셋에 걸쳐서 대체로 견고하다는 것을 발견했습니다. 우리는 검증 및 하이퍼파라미터 튜닝을 위해 MMLU 5-shot 개발 세트를 사용합니다. 모든 실험에서 우리는 이중 양자화와 bf16 계산 데이터 타입을 사용하는 NF4를 사용합니다. 우리는 LoRA r = 64, α = 16로 설정하고 기본 모델의 모든 선형 레이어에 LoRA 모듈을 추가합니다. 또한 우리는 Adam beta2를 0.999, 최대 그래디언트 노름을 0.3으로 설정하고 13B 모델까지는 LoRA 드롭아웃을 0.1로 설정하며 33B 및 65B 모델에는 0.05로 설정합니다. 지시어 세부 조정에 대한 이전 연구 [62, 60] 및 다른 선형 및 코사인 스케줄을 벤치마킹한 후에는 일정한 학습률 스케줄을 사용합니다. 우리는 비슷한 길이의 예제를 동일한 배치에 그룹화하기 위해 길이별 그룹화를 사용합니다 (이는 진동하는 손실 곡선을 생성할 것입니다). 각 모델 크기에 대해 조정하는 하이퍼파라미터는 표 9에 표시되어 있습니다.

B.3 소작용

문헌에서는 일반적으로 지시에 따라 훈련할 때 응답만을 사용하는 것이 일반적이지만, 우리는 표 10에서 지시와 응답 모두에 대한 훈련의 효과를 연구합니다. 이 실험에서는 훈련 데이터를 52,000개의 예제로 제한하고 7B 모델을 사용합니다. 네 가지 다른 지시 조정 데이터셋에서, 우리는 목표에 대해서만 훈련하는 것이 MMLU에 유익하다는 것을 발견합니다.

23
데이터셋 비자연스러운 지시사항 칩2 알파카 FLAN v2 평균

소스와 대상에 대한 훈련: 36.2 33.7 38.1 42.0 37.5
대상에 대한 훈련: 38.0 34.5 39.0 42.9 38.6

테이블 10: 훈련 효과를 연구하기 위한 MMLU 5회 시험 결과, 응답 외에 지시사항에 대한 훈련의 영향을 공부했습니다.

성능. 우리는 비쿠나나 OA 벤치마크로 측정된 챗봇 성능에 대한 영향을 평가하지 않았습니다.

어떤 것이 더 중요한가: 지시 사전 조정 데이터셋 크기인가, 아니면 데이터셋 품질인가?

데이터셋의 적합성은 데이터셋의 크기보다 중요합니다. 데이터셋 품질과 데이터셋 크기의 영향을 이해하기 위해, 우리는 적어도 150,000개의 샘플을 가진 대형 데이터셋 (Chip2, FLAN v2, Unnatural Instructions)을 50,000개, 100,000개, 150,000개의 크기로 하위샘플링하여 결과 동향을 조사합니다. 표 11에 나와 있는 대로, 데이터셋 크기를 증가시키고 에포크 수를 증가시키면 MMLU가 약간 향상되는 것을 발견했습니다 (0.0 - 0.5 MMLU), 반면 데이터셋 간의 차이는 40배 이상 커집니다 (1.5 - 8.0 MMLU). 이는 데이터셋의 품질이 평균 MMLU 정확도에 있어서 데이터셋 크기보다 중요하다는 명확한 지표입니다. 우리는 논의된 챗봇 성능에 대해서도 유사한 결과를 얻었습니다.

C 인간 평가

우리는 GPT-4에게 주어진 원래의 Vicuna 평가 [10]와 동일한 문구로 인간 평가를 실시하며, 그림 5에 나와 있는 Amazon Mechanical Turk 양식에 맞게 조정하였습니다.

GPT-4와 함께하는 쌍방 평가

GPT-4 평가 결과는 첫 번째로 제시된 시스템에 따라 다른 결과를 보였으나, 두 가지 옵션을 평균화하면 순서가 잘 정렬된 결과가 나왔습니다. 집계된 순서쌍 판단은 표 12에 나와 있습니다. 검토 결과, 이러한 판단은 추이성을 가지고 있으며, 즉, 시스템 A가 시스템 B보다 우수하게 평가되고, 시스템 B가 시스템 C보다 우수하게 평가되면 항상 시스템 A가 시스템 C보다 우수하게 평가됩니다. 이는 표 13에 나와 있는 완전한 순서를 얻게 됩니다.

E  정규화된 4비트 데이터 유형

NF4 데이터 유형의 정확한 값은 다음과 같습니다.

[-1.0, -0.6961928009986877, -0.5250730514526367,
-0.39491748809814453, -0.28444138169288635, -0.18477343022823334,
-0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,
0.24611230194568634, 0.33791524171829224, 0.44070982933044434,
0.5626170039176941, 0.7229568362236023, 1.0]

훈련된 신경망 가중치의 정상성

훈련된 신경망 가중치가 대부분 정규 분포를 따른다는 것은 일반적으로 알려져 있지만,
이를 확인하기 위해 통계적 검정을 수행합니다. 우리는 7B의 가중치에 Shapiro-Wilk 검정[53]을 사용합니다.

표 11: 데이터셋 크기와 파인튜닝 에포크가 5샷 MMLU 테스트 세트 정확도에 미치는 영향을 비교합니다. 데이터셋 크기를 증가시키고 1 에포크 이상 훈련하는 것은 MMLU 성능 향상에 도움이 되지만, 데이터셋 간의 차이가 훨씬 크므로 데이터셋의 품질이 데이터셋 크기보다 MMLU 성능에 더 큰 영향을 미침을 나타냅니다.

칩    비자연스러운 지침 FLAN v2
데이터 포인트 ↓ 에포크 → 1 2 3 1 2    3   1   2   3  평균

50000        34.50 35.30 34.70 38.10 42.20 38.10 43.00 43.50 44.10 39.28
오만        34.50 35.30 34.70 38.10 42.20 38.10 43.00 43.50 44.10 39.28

100000       33.70 33.90 34.00 40.10 41.20 37.00 43.90 43.70 44.90 39.16
십만       33.70 33.90 34.00 40.10 41.20 37.00 43.90 43.70 44.90 39.16

150000       34.40 34.80 35.10 39.70 41.10 41.50 44.60 45.50 43.50 40.02
십오만       34.40 34.80 35.10 39.70 41.10 41.50 44.60 45.50 43.50 40.02

평균         34.20 34.67 34.60 39.30 41.50 38.87 43.83 44.23 44.17

24
그림 5: 인간 주석가들이 사용한 크라우드소싱 양식.

LLaMA 모델 [57]. 우리는 각 은닉 유닛의 가중치가 서로 다른 정규 분포를 가지고 있다는 것을 발견했습니다.
따라서 우리는 각 개별 은닉 유닛의 가중치를 테스트합니다. 가중치 W ∈ Rin×out에 대해
우리는 out 차원에서 테스트를 수행합니다. 5% 유의 수준을 사용하여, 우리는 뉴런 중 7.5%가 정규 분포가 아니라는 것을 발견했습니다. 이는 예상되는 거짓 양성 비율보다 약 2.5% 더 많습니다. 따라서 사전 훈련된 대부분의 가중치는 정규 분포를 따르는 것으로 보이지만 예외가 있는 것으로 보입니다. 이러한 예외는 이상치 가중치 [13] 또는 LLaMA FFN 레이어의 은닉 유닛에서 발생하는 대량 샘플 크기에 대해 Shaprio-Wilk 검정의 p-값이 정확하지 않을 수 있기 때문일 수 있습니다 [53]. 이는 신경망 가중치에 대한 주장을 확인합니다.

테이블 12: GPT-4 시스템 간 집계된 쌍별 판단 결과, 행 x와 열 y의 셀 값은 #판단xisbetterthany−#판단yisbetterthanx
총#판단수입니다.

모델 Guanaco65B Guanaco33B 비쿠냐 ChatGPT-3.5Turbo 바드 Guanaco13B Guanaco7B

Guanaco65B - 0.21 0.19 0.16 0.72 0.59 0.86
Guanaco33B -0.21 - 0.17 0.10 0.51 0.41 0.68
Vicuna -0.19 -0.17 - 0.10 0.50 0.20 0.57
ChatGPT-3.5Turbo -0.16 -0.10 -0.10 - 0.35 0.19 0.40
Bard -0.72 -0.51 -0.50 -0.35 - 0.12 0.03
Guanaco13B -0.59 -0.41 -0.20 -0.19 -0.12 - 0.20
Guanaco7B -0.86 -0.68 -0.57 -0.40 -0.03 -0.20 -

25
LLaMA 모델 크기
0%
25%
50%
75%
100%

7B (6.9 GB) 13B (11.3 GB) 33B (24.7 GB) 65B (45.0 GB)
입력 그래디언트 옵티마이저 가중치 그래디언트 어댑터 모델

그림 6: 다른 LLaMA 모델의 메모리 풋프린트 분해. 입력 그래디언트 크기는 배치 크기 1 및 시퀀스 길이 512에 대해서만 어댑터와 기본 모델 가중치(어텐션 없음)를 대상으로 추정되었습니다. 막대 위의 숫자는 총 풋프린트의 개별 요소의 메모리 풋프린트(MB)입니다. 일부 모델은 특정 GPU에 완전히 맞지 않을 수 있지만, 페이지드 옵티마이저는 이러한 모델을 맞출만큼 충분한 메모리를 제공합니다.

G 메모리 풋프린트

다른 LLaMA 기본 모델을 사용하여 QLoRA 훈련의 메모리 풋프린트는 그림 6에서 확인할 수 있습니다. 33B 모델은 24 GB에 완전히 맞지 않으며 페이지드 옵티마이저가 필요합니다. 또한 배치 크기 1과 시퀀스 길이 512, 그리고 그라디언트 체크포인팅이 표시되어 있습니다. 이는 더 큰 배치 크기를 사용하거나 긴 시퀀스를 처리할 경우 활성화 그라디언트가 상당한 양의 메모리를 소비할 수 있다는 것을 의미합니다.

테이블 13: 시스템 간의 쌍별 GPT-4 판단에 의해 유발된 완전한 순서화

모델        파라미터 크기

구아나코 65B 41 GB
구아나코 33B 21 GB
비쿠냐 13B 26 GB
ChatGPT-3.5 터보 N/A N/A
바드 N/A N/A
구아나코 13B 10 GB
구아나코 7B 5 GB

26
26

