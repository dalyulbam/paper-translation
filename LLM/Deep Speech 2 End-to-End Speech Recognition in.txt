Deep Speech 2: 끝에서 끝까지 음성 인식

영어와 중국어

바이두 연구 - 실리콘밸리 인공지능 연구소
다리오 아모데이, 리시타 아누바이, 에릭 배튼버그, 칼 케이스, 제어드 캐스퍼, 브라이언 카탄자로,
징동 천, 마이크 크란조우스키, 아담 코츠, 그렉 디아모스, 에릭 엘센, 제시 엥겔,
린시 판, 크리스토퍼 파우그너, 토니 한, 아우니 한눈, 빌리 준, 패트릭 레그레슬리,
립비 린, 샤란 나랑, 앤드류 응, 셰르질 오제어, 라이언 프렝거, 조나단 라이만,
산지브 사티시, 데이비드 시타푼, 셔보 센구프타, 이 왕, 지치안 왕, 청 왕,

보 샤오, 다니 요가타마, 준 잔, 젠야오 주

요약

우리는 엔드 투 엔드 딥 러닝 접근 방식이 영어나 중국어와 같이 매우 다른 언어를 인식하는 데 사용될 수 있다는 것을 보여줍니다. 엔드 투 엔드 학습은 손으로 설계된 구성 요소의 전체 파이프라인을 신경망으로 대체하기 때문에, 잡음이 있는 환경, 강세 및 다른 언어를 포함한 다양한 종류의 음성을 처리할 수 있습니다. 우리 접근 방식의 핵심은 HPC 기술의 적용입니다. 이로 인해 이전 시스템 [26]에 비해 7배 빠른 속도 향상이 이루어집니다. 이 효율성으로 인해 이전에 몇 주가 걸렸던 실험을 이제는 몇 일 안에 실행할 수 있습니다. 이를 통해 우리는 우수한 아키텍처와 알고리즘을 식별하기 위해 더 빠르게 반복할 수 있습니다. 결과적으로, 몇 가지 경우에는 표준 데이터셋을 기준으로 한 인간 작업자의 전사와 경쟁력을 가지고 있습니다. 마지막으로, 데이터 센터에서 GPU와 함께 배치 디스패치라는 기술을 사용하여 우리 시스템이 저렴하게 온라인 환경에 배포될 수 있으며, 규모에 맞게 사용자에게 낮은 대기 시간을 제공할 수 있음을 보여줍니다.

1 소개

수십 년 동안 수작업으로 개발된 도메인 지식이 현재 최첨단 자동 음성 인식 (ASR) 파이프라인에 적용되었습니다. 간단하지만 강력한 대안적인 해결책은 딥러닝을 사용하여 대부분의 모듈을 단일 모델로 대체하여 이러한 ASR 모델을 end-to-end로 훈련하는 것입니다 [26]. 우리는 end-to-end 학습의 주요 장점을 보여주는 우리 음성 시스템의 두 번째 세대를 제시합니다. Deep Speech 2 ASR 파이프라인은 여러 벤치마크에서 Amazon Mechanical Turk 인간 작업자의 정확도를 초과하거나 근접하며, 작은 수정으로 여러 언어에서 작동하며, 제품 환경에서 배포할 수 있습니다. 따라서 이는 인간이 처리하는 음성 인식 범위를 다루는 단일 ASR 시스템으로의 중요한 한 걸음을 나타냅니다. 우리의 시스템은 end-to-end 딥러닝으로 구축되었기 때문에 대규모 훈련 세트를 수집하고 고성능 컴퓨팅으로 더 큰 모델을 훈련하며, 신경망 아키텍처 공간을 체계적으로 탐색하는 다양한 딥러닝 기술을 사용할 수 있습니다. 이러한 기술을 통해 우리는 이전 end-to-end 시스템 [26]의 오류율을 최대 43%까지 줄일 수 있으며, 높은 정확도로 중국어 음성도 인식할 수 있음을 보여줍니다.

음성 인식의 한 가지 도전 과제는 음성과 음향의 다양성이 넓다는 것입니다. 
결과적으로, 현대 ASR 파이프라인은 복잡한 특징 추출, 음향 모델, 언어 및 발음 모델, 화자 적응 등 다양한 구성 요소로 이루어져 있습니다. 
이러한 개별 구성 요소를 구축하고 조정하는 것은 새로운 음성 인식기를 개발하는 것이 매우 어렵게 만듭니다, 특히 새로운 언어의 경우에는 더욱 그렇습니다. 
실제로 많은 부분은 환경이나 언어 간에 일반화되지 않으며, 수용 가능한 정확도를 제공하기 위해 여러 응용 프로그램별 시스템을 지원하는 것이 종종 필요합니다. 
이러한 상황은 인간의 음성 인식과는 다릅니다: 사람들은

∗저자 순서는 알파벳 순서대로입니다.

어린 시절에는 모든 언어를 학습할 수 있는 타고난 능력이 있으며, 일반적인 기술을 사용하여 언어를 배울 수 있습니다. 읽고 쓰기를 배운 후에는 대부분의 사람들이 환경, 화자의 억양 및 소음의 변동성에 강건하게 음성을 전사할 수 있으며, 전사 작업을 위한 추가적인 훈련 없이도 가능합니다. 음성 인식 사용자의 기대를 충족시키기 위해, 우리는 단일 엔진이 유사한 능력을 갖도록 학습해야 한다고 믿습니다. 즉, 작은 수정만으로 대부분의 응용 프로그램을 처리할 수 있으며, 급격한 변화 없이 새로운 언어를 처음부터 배울 수 있어야 합니다. 우리의 end-to-end 시스템은 이러한 목표를 달성할 수 있게 해주어 우리가 두 가지 매우 다른 언어인 중국어와 영어에서 여러 테스트에서 인간 작업자의 성능을 접근하거나 뛰어넘을 수 있게 합니다.

딥 스피치 2 (DS2)는 엔드 투 엔드 딥 러닝 시스템이므로, 우리는 모델 아키텍처, 대규모 레이블 훈련 데이터셋 및 계산 규모에 초점을 맞추어 성능 향상을 이룰 수 있습니다. 이 접근 방식은 컴퓨터 비전 및 자연어와 같은 다른 응용 분야에서도 큰 발전을 이끌어냈습니다. 이 논문에서는 음성 인식을 위해 이러한 세 가지 영역에 대한 우리의 기여를 상세히 설명하며, 모델 아키텍처와 데이터 및 모델 크기가 인식 성능에 미치는 영향에 대한 광범위한 조사를 포함합니다. 특히, 오디오에서 음성 전사를 예측하기 위해 Connectionist Temporal Classification (CTC) 손실 함수 [22]로 훈련된 신경망을 사용한 다양한 실험을 설명합니다. 우리는 많은 계층의 순환 연결, 합성곱 필터 및 비선형성으로 구성된 네트워크와 RNN에 적용된 Batch Normalization [63] (BatchNorm)의 특정 인스턴스의 영향도 고려합니다. 우리는 이전 연구 [26]보다 훨씬 더 좋은 예측을 하는 네트워크를 찾을 뿐만 아니라, 정확도에 상당한 손실이 없는 상용 환경에서 배치할 수 있는 순환 모델의 인스턴스도 찾을 수 있습니다.

더 나은 모델 구조를 찾는 것을 넘어서서, 딥러닝 시스템은 대량의 훈련 데이터로 큰 이점을 얻습니다. 우리는 음성 인식 시스템을 훈련시키는 데 일반적으로 사용되는 것보다 더 큰 데이터셋을 만들 수 있게 해주는 데이터 캡처 파이프라인에 대해 자세히 설명합니다. 우리의 영어 음성 시스템은 11,940시간의 음성으로 훈련되었으며, 만다린 시스템은 9,400시간의 음성으로 훈련되었습니다. 우리는 훈련 중에 데이터 합성을 사용하여 데이터를 더욱 증강시킵니다.

대량의 데이터에 대한 훈련은 보통 더 큰 모델을 사용하는 것을 요구합니다. 실제로, 우리의 모델은 이전 시스템에서 사용된 모델보다 훨씬 많은 매개변수를 가지고 있습니다. 이러한 규모에서 단일 모델을 훈련하는 것은 단일 GPU에서 실행하는 데 3-6주가 소요되는 수십 개의 exaFLOP를 필요로 합니다. 이로 인해 모델 탐색은 매우 시간이 많이 소요되는 작업이므로, 우리는 하나의 모델을 훈련하기 위해 8개 또는 16개의 GPU를 사용하는 고도로 최적화된 훈련 시스템을 구축했습니다. 매개변수 서버와 비동기 업데이트를 사용하는 이전 대규모 훈련 접근법과는 달리, 우리는 동기화된 SGD를 사용합니다. 이는 새로운 아이디어를 테스트하는 동안 디버깅하기 쉽고, 동일한 데이터 병렬성에 대해 더 빠르게 수렴하기 때문입니다. 전체 시스템을 효율적으로 만들기 위해, 우리는 단일 GPU에 대한 최적화와 여러 GPU에 대한 확장성 개선을 설명합니다. 우리는 확장성을 향상시키기 위해 고성능 컴퓨팅에서 일반적으로 찾을 수 있는 최적화 기술을 사용합니다. 이러한 최적화에는 GPU에서 CTC 손실 함수의 빠른 구현과 사용자 정의 메모리 할당기가 포함됩니다. 또한, 우리는 신중하게 통합된 컴퓨팅 노드와 모든-리듀스의 사용자 정의 구현을 사용하여 GPU 간 통신을 가속화합니다. 전체 시스템은 16개의 GPU에서 훈련할 때 약 50 테라플롭/초를 유지합니다. 이는 GPU 당 약 3 테라플롭/초로, 최대 이론적 성능의 약 50%에 해당합니다. 이러한 확장성과 효율성으로 인해 훈련 시간을 3~5일로 줄일 수 있으며, 모델과 데이터셋에 대해 더 빠르게 반복할 수 있습니다.

우리는 몇 가지 공개적으로 사용 가능한 테스트 세트에서 시스템을 기준으로 삼고 이전의 end-to-end 시스템 [26]과 결과를 비교합니다. 우리의 목표는 데이터셋 특정 조정을 통해 개선이 가능한 특정 벤치마크뿐만 아니라 다양한 시나리오를 반영하는 다양한 벤치마크에서 인간 수준의 성능을 최종적으로 달성하는 것입니다. 이를 위해 우리는 각 벤치마크에서 인간 작업자의 성능도 측정했습니다. 우리는 우리의 시스템이 일부 공통적으로 연구된 벤치마크에서 인간보다 우수한 성능을 보이고 훨씬 어려운 경우에도 큰 격차를 줄였음을 발견했습니다. 공개적인 벤치마크 외에도, 우리는 실제 제품 시나리오를 반영하는 내부 데이터셋에서 우리의 Mandarin 시스템의 성능을 보여줍니다.

깊은 학습 시스템은 대규모로 배포하기 어려울 수 있습니다. 큰 신경망은 각 사용자 발언마다 계산 비용이 많이 들며, 일부 네트워크 구조는 다른 것보다 쉽게 배포될 수 있습니다. 모델 탐색을 통해 우리는 여기에서 자세히 설명하는 고정확도, 배포 가능한 네트워크 구조를 찾을 수 있습니다. 또한 GPU에 적합한 배치 방식을 사용합니다.

11 exaFLOP = 1018 부동 소수점 연산.

2
우리는 Batch Dispatch라는 하드웨어를 사용하여 우리의 Mandarin 엔진을 효율적이고 실시간으로 운영 서버에 구현합니다. 우리의 구현은 10개의 동시 오디오 스트림으로 서버가 로드되었을 때 67밀리초의 98번째 백분위 계산 지연 시간을 달성합니다.

논문의 나머지는 다음과 같습니다. 우리는 2장에서 딥러닝, 엔드 투 엔드 음성 인식 및 확장성에 대한 관련 연구를 검토합니다. 3장에서는 모델의 구조 및 알고리즘적 개선 사항을 설명하고, 4장에서는 효율적으로 계산하는 방법을 설명합니다. 5장에서는 훈련 데이터와 훈련 세트를 추가로 증강하는 데 사용된 단계를 논의합니다. 6장에서는 영어와 중국어 DS2 시스템의 결과 분석을 제시합니다. 7장에서는 DS2를 실제 사용자에게 배포하기 위해 필요한 단계를 설명합니다.

2 관련 연구

이 작업은 딥러닝과 음성 인식의 이전 작업에서 영감을 받았습니다. 피드포워드 신경망 음향 모델은 20년 전에 연구되었습니다 [7, 50, 19]. 순환 신경망과 합성곱을 사용한 네트워크도 동시에 음성 인식에 사용되었습니다 [51, 67]. 최근에는 DNN이 ASR 파이프라인에서 거의 모든 최첨단 음성 작업에 일종의 심층 신경망 형태로 포함되었습니다 [42, 29, 17, 16, 43, 58]. 합성곱 네트워크는 음향 모델에도 유익하게 사용되었습니다 [1, 53]. 순환 신경망, 일반적으로 LSTM,은 최첨단 인식기에 배치되기 시작했으며 특징 추출을 위해 합성곱 레이어와 함께 잘 작동합니다 [52]. 양방향 [24] 및 단방향 재귀 모델도 연구되었습니다.

엔드 투 엔드 음성 인식은 연구의 활발한 분야로, DNN-HMM [23] 및 독립형 [26]의 출력을 재점수화하는 데 사용할 때 흥미로운 결과를 보여줍니다. 현재 변수 길이의 오디오 시퀀스를 변수 길이의 전사로 직접 매핑하는 두 가지 방법이 사용됩니다. RNN 인코더-디코더 패러다임은 입력을 고정 길이 벡터로 매핑하는 인코더 RNN과 고정 길이 벡터를 출력 예측 시퀀스로 확장하는 디코더 네트워크를 사용합니다 [11, 62]. 디코더에 어텐션 메커니즘을 추가하면 시스템의 성능이 크게 향상되며, 특히 긴 입력 또는 출력에서 효과적입니다 [2]. 음성에서는 RNN 인코더-디코더와 어텐션을 사용하여 음소 [12] 또는 그래프 [3, 8]를 예측하는 데 잘 작동합니다.

다른 일반적으로 사용되는 기술은 가변 길이의 오디오 입력을 가변 길이의 출력으로 매핑하는 것이다. CTC 손실 함수와 RNN을 결합하여 시간 정보를 모델링하는 것이다. CTC-RNN 모델은 그래프음소 출력을 사용한 end-to-end 음성 인식에서 잘 작동한다. CTC-RNN 모델은 또한 음소를 예측하는 데에도 잘 작동함이 입증되었다. 그러나 이 경우에는 어휘 사전이 여전히 필요하다. 또한 GMM-HMM 시스템으로부터 프레임별 정렬을 입력으로 받는 DNN 교차 엔트로피 네트워크로 CTC-RNN 네트워크를 사전 훈련해야 하는 필요성이 있었다. 대조적으로, 우리는 사전 훈련을 위해 프레임별 정렬이 필요하지 않고 처음부터 CTC-RNN 네트워크를 훈련시킨다.

깊은 학습에서 규모를 활용하는 것은 지금까지 이 분야의 성공에 중요한 역할을 해왔습니다 [36, 38]. 단일 GPU에서의 훈련은 상당한 성능 향상을 가져왔으며 [49], 이후로는 두 개 [36] 이상의 GPU로 선형적으로 확장되었습니다 [15]. 우리는 저수준 딥 러닝 기본 요소의 개별 GPU 효율성을 높이는 연구를 활용합니다 [9]. 우리는 모델 병렬화 [15], 데이터 병렬화 [18] 또는 두 가지의 조합 [64, 26]에 대한 과거 연구를 기반으로 하여 음성 인식에서 깊은 RNN을 훈련시키기 위한 빠르고 확장 가능한 시스템을 구축합니다.

데이터는 엔드 투 엔드 음성 인식의 성공에도 중요한 역할을 한다. Deep Speech 1 (DS1) [26]에서는 7000시간 이상의 레이블이 달린 음성이 사용되었다. 데이터 증강은 컴퓨터 비전에서 딥 러닝의 성능을 크게 향상시키는 데 매우 효과적이었다 [39, 56, 14]. 이는 음성 시스템에서도 효과가 있다는 것이 입증되었다 [21, 26]. 음성에서 데이터 증강에 사용되는 기술은 간단한 노이즈 추가 [26]부터 화자의 성대 길이와 발화 속도 변경을 시뮬레이션하는 복잡한 변형 [31, 35]까지 다양하다.

기존의 음성 시스템은 새로운 데이터 수집에도 사용될 수 있습니다. 한 가지 방법으로는 저자들이 읽은 음성 1000시간을 정렬하고 필터링하기 위해 음성 엔진을 사용합니다 [46]. 다른 방법으로는 고성능의 오프라인 음성 인식기를 사용하여 수만 시간의 음성에 대한 전사를 생성합니다 [33]. 그런 다음 이를 필터를 통과시키고 인식기를 재학습시키는 데 사용하여 상당한 성능 향상을 얻을 수 있습니다. 우리는 이전의 접근 방식에서 영감을 받습니다.

우리 시스템의 효과적인 라벨링된 데이터 양을 늘리기 위해 더 큰 데이터셋과 데이터 증강을 사용하여 부트스트래핑합니다.

3 모델 아키텍처

단일 순환 레이어를 가진 간단한 다중 레이어 모델은 수천 시간의 레이블이 지정된 음성을 활용할 수 없습니다. 이렇게 큰 데이터셋에서 학습하기 위해 우리는 깊이를 통해 모델 용량을 증가시킵니다.
우리는 많은 양방향 순환 레이어와 합성곱 레이어를 포함한 최대 11개의 레이어 아키텍처를 탐색합니다. 이러한 모델들은 Deep Speech 1의 모델보다 데이터 예제 당 거의 8배의 계산량을 가지며, 빠른 최적화와 계산이 중요합니다. 이러한 모델들을 성공적으로 최적화하기 위해 우리는 RNN에 대해 배치 정규화와 SortaGrad라는 새로운 최적화 과정을 사용합니다. 또한 RNN 입력 사이의 긴 걸음을 활용하여 예제 당 계산량을 3배로 줄입니다. 이는 훈련과 평가에 도움이 되지만 CTC와 잘 작동하기 위해 일부 수정이 필요합니다. 마지막으로, 우리의 많은 연구 결과가 양방향 순환 레이어를 사용하지만, 우리는 단방향 순환 레이어만 사용하여 훌륭한 모델이 존재한다는 것을 발견했습니다. 이러한 특징들을 함께 사용하면 깊은 RNN을 효율적으로 최적화하고 영어와 중국어의 오류율을 작은 기준 모델보다 40% 이상 향상시킬 수 있습니다.

3.1 서론

도표 1은 DS2 시스템의 아키텍처를 보여줍니다. 이 시스템은 핵심적으로 이전 DS1 시스템과 유사합니다 [26]. 이는 음성 스펙트로그램을 입력으로 사용하여 텍스트 전사를 생성하는 재귀 신경망 (RNN)으로 훈련된 것입니다.

훈련 세트에서 단일 발언 x(i)와 레이블 y(i)를 샘플링하십시오.

X = {(x(1),y(1)),(x(2),y(2)),...}. 각 발화, x(i),는 길이가 T(i)인 시계열이며, 각 시간 슬라이스는 오디오 특징 벡터인 x(i)입니다.

우리는 시스템에 특징으로 파워 정규화된 오디오 클립의 스펙트로그램을 사용합니다. 따라서 x(i)

t,p
p번째 주파수의 파워를 나타냅니다.

시간 t에서 오디오 프레임에 있습니다. RNN의 목표는 입력 시퀀스 x(i)를 최종 전사 y(i)로 변환하는 것입니다. 표기상의 편의를 위해 우리는 위첨자를 생략하고 x를 선택된 발화로, y를 해당 레이블로 사용합니다.

네트워크의 출력은 각 언어의 그래프임입니다. 각 출력 시간 단계 t에서 RNN은 문자에 대한 예측을 수행합니다. (cid:96)t|x에 대한 p((cid:96)t|x)입니다. 여기서 (cid:96)t는 알파벳 문자 또는 공백 기호입니다. 영어에서는 (cid:96)t가 있습니다.

∈
{a, b, c, ...,z,공백,작은따옴표,빈칸}, 여기에 우리는 작은따옴표와 공백 기호를 단어 경계를 나타내기 위해 추가했습니다. 중국어 시스템의 경우 네트워크는 간체 중국어 문자를 출력합니다. 이에 대해 더 자세히 설명은 3.9절에서 합니다.

RNN 모델은 여러 개의 은닉 유닛 층으로 구성되어 있습니다. 우리가 실험하는 아키텍처는 하나 이상의 합성곱 층으로 시작하여 하나 이상의 순환 층, 그리고 하나 이상의 완전 연결 층으로 이어집니다.

l층의 숨겨진 표현은 hl로 주어지며, h0는 입력 x를 나타내는 관례를 따릅니다. 네트워크의 하단은 입력의 시간 차원에 대한 하나 이상의 합성곱(convolution)으로 이루어져 있습니다. 크기가 c인 컨텍스트 창의 i번째 활성화는 합성곱층의 시간 단계 t에서 주어집니다.

hl
t,i
= f(wl
i ◦
hl−1 t−c:t+c)           (1)

이때, ◦는 i번째 필터와 이전 레이어 활성화의 컨텍스트 창 사이의 원소별 곱셈을 나타내며, f는 단항 비선형 함수를 나타냅니다. 우리는 잘린 정류 선형 (ReLU) 함수 σ(x) = min {max {x,0 },20을 사용합니다.

우리의 비선형성으로서의 역할을 하는 것입니다. 일부 레이어에서는 일반적으로 첫 번째 레이어에서 s 프레임으로 컨볼루션을 스트라이딩하여 다운샘플링합니다. 목표는 상위의 순환 레이어의 시간 단계 수를 줄이는 것입니다.

convolutional layers are followed by one or more bidirectional recurrent layers [57]. The forward

시간에 따라서 − →h l 및 시간에 반대로 ←− h l 재귀적인 레이어 활성화가 계산됩니다.

− →h l t = g(hl−1 t,− →h l t−1)

←− h l
t
= g(hl−1
t
,←− h l t+1) 

←− h l
t
= g(hl−1
t
,←− h l t+1)

(2) 
(2)

4
CTC

스펙트로그램

재발성
또는
GRU
(양방향)

1D 또는 2D
불변
합성곱
완전히
연결된

일괄 처리
정규화

그림 1: 영어와 만다린어 음성을 훈련시키기 위해 사용된 DS2 시스템의 아키텍처입니다. 우리는 1부터 3까지의 합성곱 레이어 수와 1부터 7까지의 순환 또는 GRU 레이어 수를 변형하여 이 아키텍처의 변형을 탐색합니다.

두 개의 활성화 세트는 레이어 hl의 출력 활성화를 형성하기 위해 합산됩니다. hl = − →h l + ←− h l.
함수 g(·)는 표준 순환 작업일 수 있습니다.

− →h l
t
= f(Wlhl−1
t
+ − →U l− →h l
t−1
+ bl)              (3)

− →h l
t
= f(Wlhl−1
t
+ − →U l− →h l
t−1
+ bl)              (3)

Wl은 입력-은닉 가중치 행렬이고, − →U l은 재귀적 가중치 행렬이며 bl은 편향 항입니다.
이 경우 입력-은닉 가중치는 재귀의 양 방향에 모두 공유됩니다. 함수 g( ·)는 Long Short-Term Memory (LSTM) 유닛 [30] 및 게이트 순환 유닛 (GRU) [11]과 같은 더 복잡한 재귀 작업을 나타낼 수도 있습니다.

홑방향 순환층 이후에는 하나 이상의 완전 연결층을 적용합니다.

hl
t
= f(Wlhl−1
t
+ bl)                  (4)

hl
t
= f(Wlhl−1
t
+ bl)                  (4)

출력 레이어 L은 문자에 대한 확률 분포를 계산하는 소프트맥스입니다.

p(t = k | x) = exp(wLk · hL-1t) / Σj exp(wLj · hL-1t) (5)

모델은 CTC 손실 함수 [22]를 사용하여 훈련됩니다. 입력-출력 쌍 (x, y)와 네트워크의 현재 매개변수 θ가 주어지면, 우리는 손실 함수 L(x, y; θ)와 네트워크 매개변수에 대한 도함수 ∇θL(x, y; θ)를 계산합니다. 이 도함수는 시간을 통한 역전파 알고리즘을 통해 네트워크 매개변수를 업데이트하는 데 사용됩니다.

다음 하위 섹션에서는 DS1 [26]에 비해 수행된 아키텍처 및 알고리즘 개선 사항을 설명합니다. 그 외에 명시되지 않은 경우, 이러한 개선 사항은 언어에 독립적입니다. 우리는 2048개의 문장으로 구성된 내부 데이터셋인 영어 사용자 보류 개발 세트에서 결과를 보고합니다. 이 데이터셋은 주로 읽은 말로 구성되어 있습니다. 모든 모델은 섹션 5에서 설명된 데이터셋으로 훈련되었습니다. 영어 시스템의 경우 단어 오류율 (WER)을 보고하고, 중국어 시스템의 경우 문자 오류율 (CER)을 보고합니다. 두 경우 모두 섹션 3.8에서 설명된대로 빔 서치 디코딩 단계에서 언어 모델을 통합합니다.

5
아키텍처 숨겨진 유닛 훈련          개발

기준 배치 정규화 기준 배치 정규화

1 RNN, 총 2400 10.55 11.99 13.55 14.40
3 RNN, 총 1880 9.55 8.29 11.61 10.56
5 RNN, 총 1510 8.59 7.61 10.77 9.78
7 RNN, 총 1280 8.76 7.68 10.83 9.52

표 1: RNN의 다양한 깊이에 따른 훈련 및 개발 세트의 WER 비교, BatchNorm의 유무와 함께. 깊이가 증가함에 따라 매개변수의 수는 일정하게 유지되며, 따라서 각 층의 숨겨진 유닛 수가 감소합니다. 모든 네트워크는 3800만 개의 매개변수를 가지고 있습니다. "M RNN, N total" 아키텍처는 입력에서 1D 컨볼루션 1층, M개의 연속적인 양방향 RNN 층, 그리고 나머지는 N개의 총 층을 가진 완전 연결 층을 의미합니다.

3.2 깊은 RNN을 위한 배치 정규화

훈련 세트를 확장하는 동안 모델을 효율적으로 확장하기 위해, 우리는 각 층을 더 크게 만드는 대신에 더 많은 숨겨진 층을 추가함으로써 네트워크의 깊이를 증가시킵니다. 이전 연구에서는 연속적인 양방향 순환 층의 수를 증가시킴으로써 이를 수행하는 것을 조사했습니다. 우리는 이러한 네트워크의 훈련을 가속화하기 위해 Batch Normalization (BatchNorm)을 탐색합니다. 왜냐하면 이러한 네트워크는 종종 최적화 문제에 시달리기 때문입니다.

최근 연구에서는 BatchNorm이 순환 신경망의 수렴 속도를 향상시키지만 일반화 성능에는 개선이 없다는 것을 보여주었습니다 [37]. 그에 반해, 우리는 대용량 데이터셋에서 간단한 RNN의 매우 깊은 네트워크에 적용할 때 배치 정규화가 최종 일반화 오차를 크게 개선하면서 훈련을 크게 가속화시킨다는 것을 입증합니다.

일반적인 피드포워드 레이어에는 어파인 변환 후 비선형 함수 f( ·)가 따라옵니다.
우리는 f(Wh + b) 대신 f( B(Wh))를 적용하여 BatchNorm 변환을 삽입합니다.

B(x) = γx - E[x]

(Var[x] + (cid:15))1/2 + β. (6)
(Var[x] + (cid:15))1/2 + β. (6)

E와 Var는 미니배치에 대한 경험적 평균과 분산입니다. 레이어의 편향 b는 평균 제거로 인해 효과가 취소되므로 제외됩니다. 학습 가능한 매개변수인 γ와 β는 각 은닉 유닛을 원하는대로 스케일링하고 이동시키는 데 사용됩니다. 상수 (cid:15)는 작고 양수이며, 수치적 안정성을 위해 포함됩니다. 우리의 합성곱 레이어에서는 미니배치에서 주어진 합성곱 필터에 대한 모든 시간적 출력 유닛에 대한 평균과 분산이 추정됩니다. BatchNorm 변환은 레이어의 입력의 평균과 분산의 잠재적으로 흥미로운 변화로부터 주어진 레이어를 격리시켜 내부 공변량 변화를 줄입니다.

우리는 양방향 RNN에 BatchNorm을 확장하는 두 가지 방법을 고려합니다 [37]. 자연스러운 확장은 모든 비선형 함수 앞에 BatchNorm 변환을 삽입하는 것입니다. 그러면 식 3은 다음과 같아집니다.

− →h l
t
= f( B(Wlhl−1
t
+ − →U l− →h l t−1)).   (7)

− →h l
t
= f( B(Wlhl−1
t
+ − →U l− →h l t−1)).   (7)

이 경우에는 평균과 분산 통계량이 미니배치의 단일 시간 단계에 누적됩니다.
시간 단계 간의 순차적 종속성으로 인해 모든 시간 단계에 대한 평균화가 방지됩니다. 우리는
이 기술이 최적화에 개선을 가져오지 않는다는 것을 발견했습니다. 또한, 연속적인 시간 단계에 대한 평균을 누적하는 것도 시도해 보았습니다. 따라서 나중의 시간 단계는 현재 및 이전의 모든 시간 단계에 대해 정규화됩니다. 이것도 효과가 없었으며 역전파를 크게 복잡하게 만들었습니다.

우리는 시퀀스 순서 정규화 [37]가 이러한 문제를 극복한다는 것을 발견했습니다. 재귀적인 계산은 다음과 같이 주어집니다.

− →h l
t
= f( B(Wlhl−1
t
) + − →U l− →h l t−1).  (8)

− →h l
t
= f( B(Wlhl−1
t
) + − →U l− →h l t−1).  (8)

각 은닉 유닛에 대해, 미니배치 내 모든 항목에 대한 평균과 분산 통계를 계산합니다. 그림 2는 시퀀스별 정규화를 사용할 때 심층 신경망이 더 빨리 수렴함을 보여줍니다. 표 1은 시퀀스별 정규화로 인한 성능 향상이 신경망의 깊이와 함께 증가함을 보여줍니다. 가장 깊은 신경망에서는 성능 차이가 12%입니다. 모델 크기를 제어하기 위해 깊이를 비교할 때는 총 개수를 일정하게 유지합니다.

6
50 100 150 200 250 300

반복 ( ⇥103)
20
30
40
50
60

비용

5-1 BN (5-1 대대)

5-1 아니요 BN

9-7 BN
9-7 BN

9-7 번호 없음

그림 2: BatchNorm을 사용하여 훈련된 두 모델의 훈련 곡선. 우리는 첫 번째 epoch 이후부터 그래프를 시작합니다. 이는 섹션 3.3에서 언급된 SortaGrad 커리큘럼 방법 때문에 곡선을 해석하기 어려워지기 때문입니다.

기차           개발

기준 배치 정규화 기준 배치 정규화

정렬되지 않음 10.71    8.04  11.96     9.78
정렬됨    8.76      7.68  10.83     9.52

표 2: SortaGrad와 배치 정규화를 사용한 학습 및 개발 세트의 WER 비교.

매개변수의 수가 많아질수록 강력한 성능 향상을 볼 수 있습니다. 만약 층당 활성화 수를 일정하게 유지하고 층을 추가한다면, 깊이에서 훨씬 큰 개선을 기대할 수 있습니다. 또한, 우리는 BatchNorm이 얕은 네트워크에서 일반화 오차를 해치는 것을 발견했으며, 더 얕은 네트워크에서 수렴 속도가 느려집니다.

BatchNorm 접근 방식은 훈련에는 잘 작동하지만 배치 대신 배포 시에는 단일 발화를 평가하는 것이 필요하기 때문에 구현이 어렵습니다. 우리는 각 뉴런을 시퀀스 전체에 대한 평균과 분산으로 정규화하는 것이 성능을 저하시킨다는 것을 발견했습니다. 대신, 훈련 중에 수집된 뉴런의 평균과 분산에 대한 이동 평균을 저장하고 배포 시에 이를 사용합니다 [63]. 이 기술을 사용하여 대량의 배치로 평가하는 것보다 한 번에 단일 발화를 평가할 때 더 좋은 결과를 얻을 수 있습니다.

3.3 소타그라드

길이가 다른 예제에 대한 훈련은 알고리즘적인 도전을 제시한다. 가능한 해결책 중 하나는 시간을 통한 역전파를 자르는 것이다 [68], 이렇게 하면 모든 예제가 훈련 중에 동일한 시퀀스 길이를 갖게 된다 [52]. 그러나 이는 더 긴 기간의 의존성을 학습하는 능력을 저해할 수 있다. 다른 연구들은 어려움 순서대로 예제를 제시함으로써 온라인 학습을 가속화할 수 있다는 것을 발견했다 [6, 70]. 기계 번역과 음성 인식을 포함한 많은 시퀀스 학습 문제에서 공통적인 주제는 더 긴 예제가 더 도전적이라는 것이다 [11].

우리가 암묵적으로 사용하는 CTC 비용 함수는 발화의 길이에 의존합니다.

L(x,y;θ) = −log

죄송합니다. 저는 한국어를 잘 못해요.

(cid:96)∈Align(x,y)
T
(cid:89)

피시티씨((cid:96)티|엑스;세타). (9)

Align(x,y)은 CTC 연산자 아래 입력 x의 프레임에 대한 전사 y의 문자들의 모든 가능한 정렬의 집합입니다. 식 9에서 내부 항은 시퀀스의 시간 단계에 대한 곱으로, 시퀀스의 길이에 따라 축소됩니다. 이는 pctc((cid:96)t|x;θ) < 1이기 때문에 시퀀스의 길이와 함께 작아집니다. 이는 우리가 SortaGrad라는 커리큘럼 학습 전략을 제안하는 동기가 됩니다. SortaGrad는 문장의 길이를 어려움의 휴리스틱으로 사용합니다. 왜냐하면 긴 문장은 짧은 문장보다 더 높은 비용이 발생하기 때문입니다.

7
아키텍처 간단한 RNN GRU

5층, 1개의 순환층 14.40 10.53
5층, 3개의 순환층 10.56 8.00
7층, 5개의 순환층 9.78 7.79
9층, 7개의 순환층 9.52 8.19

표 3: 간단한 RNN 또는 GRU를 사용한 네트워크의 개발 세트 WER 비교, 다양한 깊이에 대해. 모든 모델은 배치 정규화, 1D-불변 컨볼루션의 한 레이어, 그리고 약 3800만 개의 매개변수를 가지고 있습니다.

첫 번째 훈련 에포크에서는 미니배치에서 가장 긴 발화의 길이를 기준으로 훈련 세트를 반복합니다. 첫 번째 에포크 이후에는 훈련이 무작위로 미니배치에 대해 진행됩니다. 표 2는 7개의 순환 레이어를 가진 9개 레이어 모델에서 SortaGrad를 사용한 훈련 비용과 그렇지 않은 비용을 비교한 것을 보여줍니다. 이 효과는 BatchNorm이 없는 네트워크에서 특히 두드러지게 나타납니다. 이 두 기술은 어느 정도로 상호 대체될 수 있지만, SortaGrad와 BatchNorm을 함께 적용할 때 여전히 이득을 얻을 수 있습니다. BatchNorm이 있더라도 이 커리큘럼은 수치적 안정성과 훈련 중 작은 변화에 대한 민감도를 향상시킵니다. 수치적 불안정성은 CPU와 GPU에서 다른 초월 함수 구현을 계산할 때 특히 CTC 비용을 계산할 때 발생할 수 있습니다. 이 커리큘럼은 두 구현 모두에 대해 비슷한 결과를 제공합니다.

우리는 이러한 이점들이 주로 긴 발화가 더 큰 기울기를 가지기 때문에 발생한다고 의심합니다. 그러나 우리는 발화의 길이와 독립적인 고정 학습률을 사용합니다. 게다가, 더 긴 발화는 훈련 초기에 RNN의 내부 상태가 폭발하는 원인이 될 가능성이 더 높습니다.

3.4 간단한 RNN과 GRU의 비교

지금까지 보여준 모델들은 단순한 양방향 순환 레이어를 가진 간단한 RNN입니다. 이 모델들은 시간의 순방향과 역방향에 대한 재귀를 Equation 3으로 모델링합니다. 현재 음성 및 언어 처리 분야의 연구는 더 복잡한 재귀를 가지면 네트워크가 더 많은 시간 단계 동안 상태를 기억할 수 있지만 훈련에 더 많은 계산 비용이 든다는 것을 보여주고 있습니다 [52, 8, 62, 2]. 두 가지 일반적으로 사용되는 순환 아키텍처는 Long Short-Term Memory (LSTM) 유닛 [30]과 Gated Recurrent Units (GRU) [11]입니다. 그러나 많은 다른 변형들도 존재합니다. LSTM과 GRU 아키텍처의 수천 가지 변형에 대한 최근 포괄적인 연구는 적절하게 초기화된 잊어버리기 게이트 편향을 가진 LSTM과 GRU가 비교 가능하며, 그들의 최상의 변형들은 서로 경쟁력을 가지고 있다는 것을 보여주었습니다 [32]. 우리는 GRU를 조사하기로 결정했는데, 작은 데이터 세트에서의 실험 결과 GRU와 LSTM이 동일한 매개변수 수로 유사한 정확도를 달성하지만 GRU는 훈련 속도가 더 빠르고 발산할 가능성이 적습니다.

우리가 사용하는 GRU는 계산됩니다.

zt = σ(Wzxt + Uzht−1 + bz)
zt = σ(Wzxt + Uzht−1 + bz)

rt = σ(Wrxt + Urht−1 + br)
rt = σ(Wrxt + Urht−1 + br)

˜ ht = f(Whxt + rt
◦
Uhht−1 + bh)

˜ ht = f(Whxt + rt + Uhht−1 + bh)

ht = (1 - zt)ht-1 + zt˜ ht

(10)

σ(·)은 시그모이드 함수를 나타내며, z와 r은 각각 업데이트 게이트와 리셋 게이트를 나타냅니다. 간단함을 위해 레이어 위첨자를 생략합니다. 우리는 표준 GRU와 약간 다르게 ht−1을 리셋 게이트로 스케일링하기 전에 Uh로 곱합니다. 이를 통해 ht−1에 대한 모든 연산을 단일 행렬 곱셈으로 계산할 수 있습니다. 출력 비선형성 f(·)은 일반적으로 쌍곡탄젠트 함수 tanh입니다. 그러나 tanh와 클리핑된 ReLU 비선형성의 성능이 유사하므로 간단함과 네트워크의 일관성을 위해 클리핑된 ReLU를 사용하기로 선택합니다.

이러한 이유로 GRU와 간단한 RNN 아키텍처는 배치 정규화를 통해 이점을 얻으며 깊은 네트워크에서 강력한 결과를 보여줍니다. 그러나 표 3은 고정된 매개변수 수에 대해 GRU 아키텍처가 모든 네트워크 깊이에서 더 나은 WER을 달성한다는 것을 보여줍니다. 이는 개별 단어 내부 및 사이에서 나타나는 음성 인식 작업의 장기 의존성의 명백한 증거입니다.

8
아키텍처 채널 필터 차원 스트라이드 정규화 노이즈 정규화

1-레이어 1D 1280  11            2          9.52    19.36
2-레이어 1D 640, 640 5, 5       1, 2       9.67    19.21
3-레이어 1D 512, 512, 512 5, 5, 5 1, 1, 2  9.20    20.22
1-레이어 2D 32    41x11         2x2        8.94    16.22
2-레이어 2D 32, 32 41x11, 21x11 2x2, 2x1   9.06    15.71
3-레이어 2D 32, 32, 96 41x11, 21x11, 21x11 2x2, 2x1, 2x1 8.61 14.74

표 4: 합성곱 레이어의 다양한 배열에 대한 WER 비교. 모든 경우에, 합성곱 다음에는 7개의 순환 레이어와 1개의 완전 연결 레이어가 따릅니다. 2D-불변 합성곱의 경우, 첫 번째 차원은 주파수이고 두 번째 차원은 시간입니다. 모든 모델은 BatchNorm, SortaGrad 및 3500만 개의 매개변수를 가지고 있습니다.

단어 사이. 3.8절에서 논의한 대로, 심플한 RNN은 훈련 데이터의 많은 양으로 인해 언어 모델을 암묵적으로 학습할 수 있습니다. 흥미로운 점은, 5개 이상의 재귀 레이어를 가진 GRU 네트워크는 성능을 크게 향상시키지 않습니다. 이는 1개의 재귀 레이어당 1728개의 은닉 유닛에서 7개의 재귀 레이어당 768개의 은닉 유닛으로 줄어들었기 때문에 전체 파라미터 수를 일정하게 유지하기 위한 것으로 해석합니다.

GRU 네트워크는 테이블 3에서 간단한 RNN보다 우수한 성능을 보입니다. 그러나 나중의 결과(섹션 6)에서 모델 크기를 확장할 때, 고정된 계산 예산에 대해 간단한 RNN 네트워크가 약간 더 나은 성능을 보입니다. 이에 따라 나머지 실험 대부분은 GRU 대신 간단한 RNN 레이어를 사용합니다.

3.5 주파수 합성

시간 합성곱은 가변 길이의 발언에 대한 시간 변환 불변성을 효율적으로 모델링하기 위해 음성 인식에서 일반적으로 사용됩니다. 이 유형의 합성곱은 25년 전에 음성 신경망에서 처음 제안되었습니다 [67]. 많은 신경망 음성 모델은 입력 프레임을 일부 컨텍스트 창과 함께 처리하는 첫 번째 레이어를 가지고 있습니다 [16, 66]. 이는 한 단계씩 시간 합성곱으로 볼 수 있습니다.

또한, 하이 샘플레이트 오디오에서 순환 신경망을 계산적으로 다룰 수 있도록 하기 위해 하위 샘플링이 필수적입니다. DS1 시스템은 입력으로 스펙트로그램을 사용하고 첫 번째 레이어에서 시간 합성곱과 스트라이드 매개변수를 사용하여 시간 단계의 수를 줄였습니다 [26].

주파수 및 시간 영역에서의 합성곱은 스펙트럼 입력 특징에 적용되어 다른 처리 이전에 ASR 성능을 약간 향상시킬 수 있습니다 [1, 53, 60]. 주파수 합성곱은 대형 완전 연결 네트워크로는 불가능한 화자 변동성에 대한 스펙트럼 변동성을 더 간결하게 모델링하려고 시도합니다. 완전 연결 및 순환 레이어에 의해 스펙트럼 특징의 순서가 제거되므로 주파수 합성곱은 네트워크의 첫 번째 레이어로서 더 잘 작동합니다.

우리는 1개에서 3개의 합성곱 레이어를 추가하는 실험을 진행합니다. 이는 시간-주파수 영역(2D 불변성)과 시간 영역(1D 불변성) 모두에 해당됩니다. 모든 경우에 우리는 동일한 합성곱을 사용하며, 주파수와 시간의 입력 특징 수를 보존합니다. 일부 경우에는 출력의 크기를 줄이기 위해 각 차원을 따라 스트라이드를 지정합니다. 우리는 망의 파라미터 수를 명시적으로 제어하지 않으며, 합성곱 레이어는 우리의 네트워크에 매우 작은 파라미터만 추가합니다. 표 4에 표시된 모든 네트워크는 약 3500만 개의 파라미터를 가지고 있습니다.

우리는 두 개의 데이터셋에 대한 결과를 보고합니다 - 2048개의 발화로 이루어진 개발 세트("일반 개발")와 CHiME 2015 개발 데이터셋 [4]에서 무작위로 추출된 2048개의 더 노이즈가 있는 데이터셋("노이즈 개발"). 우리는 1D-불변 컨볼루션의 여러 레이어가 매우 작은 이점을 제공한다는 것을 발견했습니다. 2D-불변 컨볼루션은 노이즈가 있는 데이터에서 결과를 크게 향상시키면서 깨끗한 데이터에서는 작은 이점을 제공합니다. 1D-불변 컨볼루션의 한 레이어에서 2D-불변 컨볼루션의 세 레이어로 변경하면 노이즈가 있는 개발 세트에서 WER이 23.9% 향상됩니다.

9
데브 no LM        데브 LM

스트라이드 단어 단어 쌍 단어 쌍

2    14.93   14.56    9.52    9.66
3    15.01   15.60    9.65   10.06
4    18.86   14.84   11.92    9.93

2    14.93   14.56    9.52    9.66
3    15.01   15.60    9.65   10.06
4    18.86   14.84   11.92    9.93

테이블 5: 1D-불변 컨볼루션 1개 레이어, 재귀 7개 레이어, 완전 연결 1개 레이어를 가진 모델에서 단일어와 이중어 출력에 대한 다양한 스트라이딩 양과의 WER 비교.
모든 모델은 BatchNorm, SortaGrad, 그리고 3500만 개의 매개변수를 가지고 있습니다. 모델들은 5-gram 언어 모델의 사용 여부에 따라 개발 세트에서 비교됩니다.

3.6 걷기

합성곱 레이어에서는 더 긴 스트라이드와 넓은 컨텍스트를 적용하여 훈련 속도를 높입니다. 이로 인해 주어진 발화를 모델링하는 데 필요한 시간 단계가 줄어듭니다. 입력 소리를 다운샘플링(FFT와 합성곱 스트라이딩을 통해)하면 다음 레이어에서 필요한 시간 단계와 계산이 줄어들지만, 성능이 감소하는 대가를 치르게 됩니다.

우리의 중국어 모델에서는 직접적인 방식으로 스트라이딩을 사용합니다. 그러나 영어에서는 스트라이딩이 정확도를 감소시킬 수 있습니다. 왜냐하면 우리의 네트워크의 출력은 적어도 하나의 시간 단계당 하나의 출력 문자를 필요로 하며, 영어 음성의 시간 단계당 문자 수가 충분히 높아 스트라이딩 시 문제가 발생할 수 있기 때문입니다. 이를 극복하기 위해 영어 알파벳에는 전체 단어, 음절 또는 겹치지 않는 n-그램을 나타내는 기호를 포함할 수 있습니다. 실제로는 음절과 같은 대안과 비교하여 구성하기 간단하고 전체 단어와 같은 대안보다 적은 수의 비-바이그램을 사용합니다. 우리는 간단한 동형성을 통해 단일 문자 레이블을 바이그램 레이블로 변환합니다.

비중첩 bigram은 출력 전사의 길이를 줄이고, 따라서 펼쳐진 RNN의 길이를 줄일 수 있게 합니다. 고양이가 비중첩 bigram과 함께 앉은 문장은 [th,e,space,ca,t,space,sa,t]로 분할됩니다. 홀수 글자 수를 가진 단어의 경우, 마지막 글자는 unigram이 되고, 공백도 unigram으로 처리됩니다. 이 동형성은 동일한 단어가 항상 동일한 bigram과 unigram 토큰으로 구성되도록 보장합니다. 출력 bigram 집합은 훈련 세트에서 발생하는 모든 bigram으로 구성됩니다.

표 5에서는 다양한 striding 수준에 대해 언어 모델과 함께 빅램과 유니그램 시스템의 결과를 보여줍니다. 우리는 빅램이 단어 오류율을 희생하지 않고 더 큰 stride를 가능하게 한다는 것을 관찰합니다. 이는 우리가 펼쳐진 RNN의 시간 단계 수를 줄여 계산 및 메모리 사용을 둘 다 개선할 수 있게 합니다.

3.7 행 합성곱과 단방향 모델

양방향 RNN 모델은 온라인 저지연 설정에서 배포하기 어렵습니다. 왜냐하면 이 모델들은 전체 샘플에서 작동하도록 구축되어 있기 때문에, 사용자의 발언이 흘러오는 동안 전사 과정을 수행할 수 없기 때문입니다. 우리는 우리의 양방향 모델과 동일한 성능을 발휘하는 단방향 아키텍처를 찾았습니다. 이를 통해 우리는 배포 시스템에서 단방향, 앞으로만 진행되는 RNN 레이어를 사용할 수 있습니다.

이를 달성하기 위해, 우리는 특별한 레이어를 사용합니다. 우리는 이를 행 합성곱이라고 부르며, 그림 3에 나와 있습니다. 이 레이어의 아이디어는 현재 시간 단계에서 정확한 예측을 하기 위해 미래 정보의 작은 부분만 필요하다는 것입니다. 시간 단계 t에서 미래 컨텍스트로 τ 단계를 사용한다고 가정해 봅시다. 이제 크기가 d인 특징 행렬 ht:t+τ = [ht,ht+1,...,ht+τ]가 있습니다.

×
(τ + 1). 우리는 ht:t+τ와 같은 크기의 매개변수 행렬 W를 정의합니다. 시간 단계 t에서 새로운 레이어의 활성화 rt는 다음과 같습니다.

2개의 중국어 문자는 영어 음절보다 영어 문자와 더 유사합니다. 이는 우리의 훈련 데이터에 반영되어 있으며, 영어에서는 평균 14.1개의 문자/초가 있고, 중국어에서는 단지 3.3개의 문자/초만 있습니다. 반대로, 훈련 세트에서 발생 빈도에 따라 계산된 샤넌 엔트로피는 영어에서는 더 작습니다. 이는 문자 집합이 더 작기 때문에 4.9비트/문자 대비 12.6비트/문자입니다. 이는 중국어의 말하기는 시간적 엔트로피 밀도가 낮다는 것을 의미합니다. 약 41비트/초 대비 약 58비트/초이며, 따라서 문자 정보를 잃지 않고 시간적으로 더 쉽게 압축할 수 있습니다.

10
반복 레이어
행 컨브 레이어

ht   ht+1 ht+2  ht+3

ht   ht+1 ht+2  ht+3

알
t+3
알
t+2
알
t+1
알
t

그림 3: 미래 컨텍스트 크기가 2인 행 컨볼루션 아키텍처

rt, 나는 = τ+1 (cid:88)

j=1
Wi,jht+j−1,i, for 1

j=1
1에 대해 Wi,jht+j−1,i,

≤ 나는 ≤ d. (11)

식 11의 컨볼루션과 유사한 연산은 W와 ht:t+τ 모두 행 방향으로 이루어지므로, 이 레이어를 행 컨볼루션이라고 부릅니다.

우리는 모든 순환 레이어 위에 행 합성곱 레이어를 배치합니다. 이에는 두 가지 이점이 있습니다. 첫째, 이를 통해 행 합성곱 레이어 아래의 모든 계산을 미래 컨텍스트가 거의 필요하지 않은 더 세분화된 단위로 스트리밍할 수 있습니다. 둘째, 이는 중국어에 대한 최고의 양방향 모델과 비교하여 더 나은 CER 결과를 가져옵니다. 우리는 순환 레이어가 좋은 특징 표현을 학습했다고 추측하며, 행 합성곱 레이어는 단순히 적절한 정보를 수집하여 분류기에 전달합니다. 행 합성곱을 사용한 단방향 중국어 음성 시스템의 결과와 양방향 모델과의 비교는 섹션 7에서 제시됩니다.

3.8 언어 모델

우리는 수백만 개의 고유한 발화로 RNN 모델을 훈련시키며, 이를 통해 네트워크가 강력한 암묵적 언어 모델을 학습할 수 있게 합니다. 우리의 최고 모델은 외부 언어 제약 없이도 맞춤법에 능숙합니다. 더 나아가, 개발 데이터셋에서는 우리의 모델이 암묵적으로 동음이의어를 해소할 수 있는 경우도 많이 발견됩니다. 예를 들어, "그는 일본 대리인이 그것을 275,000달러에 팔 것으로 기대한다"와 같은 경우입니다. 그러나 레이블이 지정된 훈련 데이터는 사용 가능한 레이블이 없는 텍스트 말뭉치의 크기에 비해 작습니다. 따라서 외부 텍스트로부터 훈련된 언어 모델을 시스템에 보완하는 경우 WER이 향상되는 것을 발견합니다.

우리는 많은 양의 라벨이 없는 텍스트에 잘 확장되는 n-gram 언어 모델을 사용합니다 [26].
영어의 경우, 우리의 언어 모델은 KenLM 도구 [28]를 사용하여 Common Crawl Repository3의 정제된 텍스트에서 훈련된 Kneser-Ney 스무딩 5-gram 모델입니다. 어휘는 2억 5천만 줄의 텍스트에서 가장 자주 사용되는 40만 단어로 구성되어 약 85억 개의 n-gram을 가진 언어 모델을 생성합니다. 중국어의 경우, 언어 모델은 내부 텍스트 코퍼스에서 훈련된 Kneser-Ney 스무딩 문자 수준 5-gram 모델입니다. 이로써 약 20억 개의 n-gram을 가진 언어 모델이 생성됩니다.

추론 과정에서는 식 12에 표시된 Q(y)를 최대화하는 전사 y를 찾습니다. 이는 CTC 훈련된 네트워크와 언어 모델의 로그 확률과 단어 삽입 항 [26]의 선형 조합입니다.

Q(y) = log(pctc(y |x)) + αlog(plm(y)) + β word_count(y) (12)

Q(y) = log(pctc(y |x)) + αlog(plm(y)) + β word_count(y) (12)

무게 α는 언어 모델과 CTC 네트워크의 상대적인 기여도를 조절합니다. 무게 β는 전사에 더 많은 단어를 장려합니다. 이러한 매개변수는 개발 세트에서 조정됩니다. 우리는 빔 서치를 사용하여 최적의 전사를 찾습니다 [27].

3http://commoncrawl.org

11
언어 아키텍처 개발자는 LM 개발자가 아닙니다.

영어 5층, 1개의 RNN 27.79 14.39
영어 9층, 7개의 RNN 14.93 9.52
중국어 5층, 1개의 RNN 9.80 7.13
중국어 9층, 7개의 RNN 7.55 5.81

표 6: 언어 모델을 사용한 경우와 그렇지 않은 경우의 영어 WER 및 중국어 CER 비교입니다. 이는 단일 레이어의 1D 불변 컨볼루션을 가진 간단한 RNN 모델입니다.

표 6은 외부 언어 모델이 영어와 중국어 음성 시스템 모두에 도움이 된다는 것을 보여줍니다.
언어 모델에 의한 상대적인 개선은, 5개의 레이어와 1개의 순환 레이어를 가진 모델에서 9개의 레이어와 7개의 순환 레이어를 가진 모델로 넘어갈 때, 영어에서는 48%에서 36%로, 중국어에서는 27%에서 23%로 감소합니다. 우리는 네트워크가 더 많은 순환 레이어로 더 강력한 암묵적 언어 모델을 구축한다고 가설을 세웁니다.

언어 모델에서의 상대적인 성능 향상은 영어에서 만다린어보다 높습니다.
이는 중국어 문자가 영어 문자보다 더 많은 정보 블록을 나타내기 때문이라고 할 수 있습니다. 예를 들어, 영어에서 음절이나 단어로 직접 출력한다면, 모델은 철자 오류가 더 적어지고 언어 모델의 도움이 덜 될 것입니다.

3.9 마단어에 대한 적응

지금까지 설명한 기술들은 중국어 음성인식 시스템을 구축하는 데 사용될 수 있으며, 이 시스템은 중국어 문자를 직접 출력합니다. 이로 인해 발음 모델을 구축할 필요가 없어지며, 이는 다른 언어로 음성 시스템을 이식하는 데에 있어서 상당히 복잡한 구성 요소입니다 [59]. 문자로 직접 출력하는 것은 언어 특정 발음 특징을 명시적으로 모델링할 필요도 없게 합니다. 예를 들어, 우리는 중국어 음성 시스템에서 일부 시스템이 해야하는 것과 달리 중국어 음조를 명시적으로 모델링할 필요가 없습니다 [59, 45].

우리 네트워크에 대한 유일한 구조적 변경은 중국어 문자 집합의 특성 때문입니다. 첫째로, 네트워크의 출력 계층은 로마 알파벳을 포함한 약 6000개의 문자를 출력합니다. 중국어-영어 혼합 대본이 일반적이기 때문입니다. 만약 이 집합에 포함되지 않은 문자가 평가 시간에 발생하면 우리는 단어장 오류를 겪게 됩니다. 이는 큰 문제가 되지 않으며, 우리의 테스트 세트에서는 단어장에 포함되지 않은 문자가 0.74%에 불과합니다.

우리는 텍스트에서 단어가 일반적으로 분리되지 않기 때문에 중국어에서는 문자 수준 언어 모델을 사용합니다.
식 12의 단어 삽입 항목은 문자 삽입 항목이 됩니다. 또한, 디코딩 중 빔 탐색의 성능이 작은 빔 크기에서 안정화되는 것을 발견했습니다. 이로 인해 CER에 미미한 저하가 있는 상태에서 빔 크기를 200으로 사용할 수 있습니다. 6.2절에서는 우리의 중국어 음성 모델이 영어 음성 모델과 거의 동일한 구조적 변경 향상을 보여준다는 것을 보여줍니다.

4 시스템 최적화

우리의 네트워크는 수천만 개의 매개변수를 가지고 있으며, 훈련 알고리즘은 수십 개의 단정밀도 exaFLOP를 수렴하기 위해 소요됩니다. 우리는 데이터와 모델에 대한 가설을 평가하는 능력이 모델을 빠르게 훈련시킬 수 있는 능력에 의존하기 때문에, 고도로 최적화된 훈련 시스템을 구축했습니다. 이 시스템은 C++로 작성된 딥러닝 라이브러리와 CUDA 및 C++로 작성된 고성능 선형 대수 라이브러리 두 가지 주요 구성 요소로 이루어져 있습니다. 최적화된 소프트웨어는 8개의 Titan X GPU가 장착된 밀집한 컴퓨팅 노드에서 실행되며, 한 노드에서 단일 모델을 훈련할 때 24개의 단정밀도 teraFLOP/초를 유지할 수 있습니다. 이는 각 노드의 이론적인 최대 계산 처리량의 45%입니다. 또한 다음 하위 절에서 설명한 대로 여러 노드로 확장할 수도 있습니다.

4.1 확장성과 데이터 병렬 처리

은 동기화된 SGD를 사용하여 여러 개의 GPU에서 데이터 병렬 처리 기술을 사용합니다. 가장 일반적인 구성은 8개의 GPU에서 512개의 미니배치를 사용하여 훈련합니다. 훈련 파이프라인

12
각 GPU에 하나의 프로세스를 바인딩합니다. 이러한 프로세스들은 역전파 동안 그라디언트 행렬을 모두 교환하기 위해 all-reduce를 사용합니다. all-reduce는 여러 프로세스 간에 행렬을 교환하고 결과를 합산하여 각 프로세스가 모든 프로세스의 행렬 합의 사본을 가지게 됩니다.

우리는 동기화 SGD가 재현 가능하고 결정론적이기 때문에 유용하다고 생각합니다. 우리는 시스템에서 결정론적이지 않은 현상이 나타날 때 종종 심각한 버그를 나타내는 것을 발견했으며, 따라서 재현성을 목표로 하는 것은 디버깅을 크게 용이하게 해줍니다. 반면에 Dean 등의 연구에서 찾을 수 있는 파라미터 서버를 사용한 비동기 SGD와 같은 비동기 방법은 재현성을 제공하지 않으므로 디버깅이 더 어렵습니다. 동기화 SGD는 이해하기 쉽고 구현하기도 간단합니다. 우리가 훈련 과정에 여러 노드를 추가할 때 잘 확장됩니다.

20 이십
21 이십일
22 이십이
23 이십삼
24 이십사
25 이십오
26 이십육
27 이십칠

GPU
211
212
213
214
215
216
217
218
219

시간 (초)

5-3 (2560) - 5-3 (2560)

9-7 (1760) -> 9-7 (1760)

그림 4: 두 개의 네트워크의 스케일링 비교 - 각 레이어에 2560개의 히든 유닛을 포함한 3개의 재귀 레이어를 가진 5레이어 모델과 각 레이어에 1760개의 히든 유닛을 포함한 7개의 재귀 레이어를 가진 9레이어 모델. 표시된 시간은 1 epoch를 훈련하는 데 걸리는 시간입니다. 5레이어 모델은 더 큰 행렬을 사용하고 계산 효율이 더 높기 때문에 더 빠르게 훈련됩니다.

그림 4는 우리가 훈련하는 GPU의 수를 두 배로 늘릴 때 한 epoch를 훈련하는 데 걸리는 시간이 절반으로 줄어들어 거의 선형적인 약한 스케일링을 달성한다는 것을 보여줍니다. 이 실험 동안 우리는 GPU 당 미니배치를 64로 유지하며, GPU의 수를 두 배로 늘릴 때 미니배치를 두 배로 증가시킵니다. 우리는 큰 미니배치로 확장할 수 있는 능력을 가지고 있지만, 보통 8 또는 16개의 GPU를 사용하여 미니배치를 512 또는 1024로 설정하여 최상의 결과에 수렴합니다.

모든 리듀스는 훈련의 확장성에 중요하므로, 우리는 더 높은 성능과 안정성을 위해 고유한 링 알고리즘 [48, 65]의 구현을 작성했습니다. 우리의 구현은 CPU와 GPU 간의 불필요한 복사를 피하며, 확장성에 기본적입니다. 우리는 GPUDirect를 사용하여 두 개의 다른 GPU에 있는 버퍼를 보내고 받을 수 있는 smcuda 전송으로 OpenMPI를 구성합니다. 두 개의 GPU가 동일한 PCI 루트 복합체에 있는 경우, 이는 CPU 메모리로의 불필요한 복사를 피합니다. 이는 인접한 장치 간에 링의 여러 세그먼트를 동시에 실행하여 트리 구조의 상호 연결을 활용합니다. 우리는 MPI send와 receive를 사용하여 구현하였으며, 요소별 연산에는 CUDA 커널을 사용합니다.

표 7은 우리의 all-reduce 구현과 OpenMPI 버전 1.8.5가 제공하는 성능을 비교합니다. 우리는 5개의 레이어와 3개의 순환 레이어 아키텍처를 사용하여 2560개의 히든 유닛을 가진 영어 데이터셋에 대해 한 에포크 동안 실행된 전체 훈련에 소요된 all-reduce 시간을 보고합니다. 이 표에서 우리는 GPU 당 64개의 미니배치를 사용하며, 더 많은 GPU로 확장될 때 알고리즘 미니배치를 확장합니다. 우리는 노드 내 통신(8개 이하의 GPU)일 때 우리의 구현이 OpenMPI보다 상당히 빠름을 알 수 있습니다. GPU 수를 늘리고 노드 간 통신 양을 증가시킬수록 차이는 줄어들지만, 우리의 구현은 여전히 2-4배 더 빠릅니다.

우리의 모든 훈련 실행은 8개 또는 16개의 GPU를 사용하며, 이 규모에서 우리의 모든-감소 구현은 OpenMPI를 직접 사용하는 것과 비교하여 전체 훈련 실행에 대해 2.5배 더 빠른 훈련 결과를 도출합니다. 모든-감소 최적화는 우리의 실험에 중요한 생산성 이점을 가져오고, 우리의 간단한 동기화 SGD 접근법을 확장 가능하게 만들었습니다.

13


GPU   OpenMPI    우리   성능
모든-줄이기 모든-줄이기 이득

4   55359.1   2587.4   21.4
8   48881.6   2470.9   19.8
16  21562.6   1393.7   15.5
32   8191.8   1339.6   6.1
64   1395.2    611.0   2.3
128   1602.1    422.6   3.8

4   55359.1   2587.4   21.4
8   48881.6   2470.9   19.8
16  21562.6   1393.7   15.5
32   8191.8   1339.6   6.1
64   1395.2    611.0   2.3
128   1602.1    422.6   3.8

표 7: 두 가지 다른 all-reduce 구현의 비교. 모든 시간은 초 단위입니다. 성능 향상은 OpenMPI all-reduce 시간 대비 우리의 all-reduce 시간의 비율입니다.

언어 아키텍처 CPU CTC 시간 GPU CTC 시간 가속

영어 5층, 3개의 RNN 5888.12 203.56 28.9
중국어 5층, 3개의 RNN 1688.01 135.05 12.5

표 8: 두 가지 다른 구현에서 CTC 손실 함수와 그래디언트를 계산하는 데 소요된 시간(초)의 비교
한 에포크 동안 CPU CTC 시간 대비 GPU CTC 시간의 속도 향상 비율.

CTC 손실 함수의 4.2 GPU 구현

CTC 손실 함수를 계산하는 것은 우리의 RNN 아키텍처에서 전방 및 역방향 전파를 수행하는 것보다 더 복잡합니다. 원래는 GPU에서 활성화 값을 CPU로 전송하여 CTC의 OpenMP 병렬화 구현을 사용하여 손실 함수를 계산했습니다. 그러나 이 구현은 두 가지 이유로 우리의 확장성을 상당히 제한했습니다. 첫째로, RNN 자체의 효율성과 확장성을 향상시키면서 계산적으로 더 중요해졌습니다. 둘째로, CPU와 GPU 간에 큰 활성화 행렬을 전송하는 것은 데이터 병렬화를 통해 더 많은 프로세서로 확장할 수 있도록 그라디언트 행렬을 전송하는 대신 CTC에 대한 인터커넥트 대역폭을 소비해야 했습니다.

이를 극복하기 위해, 우리는 CTC 손실 함수의 GPU 구현을 작성했습니다. 우리의 병렬 구현은 CTC 계산에서 의존성을 단순화하기 위한 약간의 리팩터링과 ModernGPU [5]의 최적화된 병렬 정렬 구현의 사용에 의존합니다. 이 병렬화에 대한 자세한 내용은 부록에서 설명합니다.

표 8은 두 가지 CTC 구현의 성능을 비교합니다. GPU 구현은 영어로 한 에포크 당 95분, 중국어로는 25분을 절약합니다. 이로 인해 전체 훈련 시간이 10-20% 감소하며, 이는 우리 실험에 중요한 생산성 이점을 제공합니다.

4.3 메모리 할당

우리 시스템은 주로 가변 길이의 발화와 중간 결과를 저장하기 위해 GPU와 CPU 메모리에 동적 메모리 할당을 빈번하게 사용합니다. 개별 할당은 매우 크며, 가장 긴 발화의 경우 1GB 이상입니다. 이러한 매우 큰 할당에 대해 CUDA의 메모리 할당기와 심지어 std::malloc도 우리의 응용 프로그램에 상당한 오버헤드를 도입한다는 것을 발견했습니다. 특정 경우에는 std::malloc을 사용하는 것보다 2배 이상 느려집니다. 이는 cudaMalloc과 std::malloc 모두 매우 큰 할당을 운영 체제나 GPU 드라이버에 전달하여 시스템 페이지 테이블을 업데이트하기 때문입니다. 이는 여러 응용 프로그램이 메모리 리소스를 공유하는 시스템에서는 좋은 최적화입니다. 그러나 노드가 단일 모델을 실행하는 데 전적으로 전용되어 있는 우리 시스템에서는 페이지 테이블 편집은 순수한 오버헤드입니다. 이 제한을 극복하기 위해 CPU와 GPU 할당을 위해 우리만의 메모리 할당기를 작성했습니다. 우리의 구현은 jemalloc의 마지막 레벨 공유 할당기의 접근 방식을 따릅니다. 모든 할당은 buddy 알고리즘을 사용하여 연속적인 메모리 블록에서 조각내어집니다. 단편화를 피하기 위해 훈련 시작 시 GPU 메모리를 모두 사전 할당하고 이 블록에서 개별 할당을 세분화합니다. 마찬가지로, 우리는 mmap에 전달하는 CPU 메모리 블록 크기를 std::malloc보다 훨씬 크게 설정하여 12GB로 설정했습니다.

14
데이터셋  음성 유형  시간

WSJ 읽기 80
스위치보드 대화 300
피셔 대화 2000
LibriSpeech 읽기 960
바이두 읽기 5000
바이두 혼합 3600

총 11940

테이블 9: DS2를 영어로 훈련시키는 데 사용된 데이터셋 요약. 월스트리트 저널 (WSJ), 스위치보드 및 피셔 [13] 코퍼스는 모두 언어 데이터 consorium에서 발행되었습니다. LibriSpeech 데이터셋 [46]은 온라인에서 무료로 제공됩니다. 다른 데이터셋은 바이두 내부 코퍼스입니다.

학습을 위해 깊은 순환 신경망에 필요한 대부분의 메모리는 역전파에 사용하기 위해 각 레이어의 활성화를 저장하는 데 사용됩니다. 네트워크의 매개변수를 저장하는 데는 사용되지 않습니다. 예를 들어, 70M 매개변수 네트워크의 가중치를 저장하는 것은 약 280MB의 메모리를 필요로하지만, 64개의 7초 발화에 대한 활성화를 저장하는 것은 1.5GB의 메모리가 필요합니다. TitanX GPU는 12GB의 GDDR5 RAM을 포함하고 있으며, 때로는 매우 깊은 네트워크가 긴 발화를 처리할 때 GPU 메모리 용량을 초과할 수 있습니다. 이는 예측할 수 없이 발생할 수 있으며, 특히 발화 길이의 분포에 이상치가 포함되어 있는 경우에는 재앙적인 실패를 피하는 것이 바람직합니다. 요청된 메모리 할당이 사용 가능한 GPU 메모리를 초과하는 경우, 우리는 cudaMallocHost를 사용하여 페이지 잠금된 GPU-메모리-매핑 CPU 메모리를 할당합니다. 이 메모리는 PCIe를 통해 개별 메모리 트랜잭션을 전달하여 GPU가 직접 액세스 할 수 있으며 대역폭이 감소합니다. 이는 모델이 이상치를 만난 후에도 계속 진행할 수 있도록 합니다.

빠른 메모리 할당과 예외적인 경우에 사용 가능한 GPU 메모리를 약간 초과할 수 있는 대체 메커니즘의 조합은 시스템을 현저히 간단하고 견고하며 효율적으로 만듭니다.

5 훈련 데이터

대규모 딥러닝 시스템은 풍부한 레이블이 지정된 훈련 데이터를 필요로 합니다. 우리는 영어와 만다린 음성 모델을 위해 광범위한 훈련 데이터셋을 수집했으며, 공개적으로 이용 가능한 데이터셋과 함께 훈련을 보강했습니다. 영어에서는 8백만 개의 문장으로 요약된 11,940시간의 레이블이 지정된 음성 데이터를 사용하였습니다. 만다린 시스템에서는 1,100만 개의 문장을 포함한 9,400시간의 레이블이 지정된 오디오를 사용합니다. 만다린 음성 데이터는 표준 만다린과 사투리 만다린을 모두 포함하는 바이두 기업의 내부 코퍼스로 구성되어 있습니다.

5.1 데이터셋 구축

일부 내부 영어(3,600 시간) 및 중국어(1,400 시간) 데이터셋은 노이즈가 있는 전사 없이 긴 오디오 클립으로 캡처된 원시 데이터에서 생성되었습니다. 이 클립들의 길이는 몇 분에서 한 시간 이상으로 다양하여 훈련 중 RNN에서 시간에 맞춰 펼치기에는 비실용적이었습니다. 이 문제를 해결하기 위해 우리는 정렬, 분할 및 필터링 파이프라인을 개발하여 잘린 발화와 잘못된 전사가 적은 훈련 세트를 생성할 수 있게 되었습니다.

파이프라인의 첫 번째 단계는 CTC로 훈련된 기존의 양방향 RNN 모델을 사용하여 음성의 프레임에 대한 전사를 정렬하는 것입니다. 주어진 음성-전사 쌍 (x, y)에 대해 최대화하는 정렬을 찾습니다.

(cid:96)∗ = argmax
(cid:96)∈Align(x,y)
T
(cid:89)

최대값을 찾는다
(cid:96)∈Align(x,y)
T
(cid:89)

t
pctc((cid:96)t|x;θ).   (13)

t
pctc((cid:96)t|x;θ).   (13)

이것은 CTC로 훈련된 RNN 모델을 사용하여 찾은 Viterbi 정렬입니다. 식 9는 정렬을 통합하기 때문에 CTC 손실 함수는 정확한 정렬을 생성하도록 명시적으로 요구되지 않습니다. 원칙적으로 CTC는 어떤 시점 이후에 전사의 모든 문자를 방출하기로 선택할 수 있습니다.

15
고정된 지연이 있을 수 있으며, 이는 단방향 RNN에서 발생할 수 있습니다 [54]. 그러나 우리는 양방향 RNN으로 훈련시킬 때 CTC가 정확한 정렬을 생성한다는 것을 발견했습니다.

정렬을 따르는 것은 연속적인 공백 레이블이 발생할 때마다 오디오와 해당 정렬된 대본을 자르는 세그멘테이션 단계입니다. 이는 일반적으로 침묵 구간을 나타냅니다. 연속적인 공백의 개수를 조정함으로써 생성되는 발화의 길이를 조정할 수 있습니다. 영어 음성 데이터의 경우, 단어 경계에서만 분할하기 위해 공백 구간 내에 공백 토큰이 있어야 합니다. 평균적으로 7초 길이의 발화를 생성하기 위해 세그멘테이션을 조정합니다.

파이프라인의 최종 단계는 실패한 정렬로 인해 발생하는 잘못된 예제를 제거합니다. 우리는 몇 천 개의 예제에 대해 그라운드 트루스 전사를 크라우드 소싱합니다. 그라운드 트루스와 정렬된 전사 간의 단어 수준 편집 거리를 사용하여 좋은 또는 나쁜 레이블을 생성합니다. 단어 수준 편집 거리의 임계값은 개발 세트의 좋은 부분의 WER이 5% 미만이 되도록 선택됩니다. 그런 다음 음성 인식기에서 생성된 입력 특징을 기반으로 나쁜 예제를 정확하게 예측하기 위해 선형 분류기를 훈련시킵니다. 우리는 다음과 같은 특징들이 유용하다고 알아냈습니다: 원시 CTC 비용, 시퀀스 길이로 정규화된 CTC 비용, 전사 길이로 정규화된 CTC 비용, 시퀀스 길이 대 전사 길이의 비율, 전사에 있는 단어 수 및 전사에 있는 문자 수. 영어 데이터셋에서는 필터링 파이프라인이 WER을 17%에서 5%로 줄이면서 예제의 50% 이상을 유지하는 것을 발견했습니다.

5.2 데이터 증강

우리는 훈련 데이터를 늘리기 위해 노이즈를 추가하여 훈련 데이터의 효과적인 크기를 증가시키고 노이즈에 대한 강건성을 향상시킵니다 [26]. 훈련 데이터에는 일부 내재적인 노이즈가 포함되어 있지만, 우리는 증강을 통해 노이즈의 양과 다양성을 늘릴 수 있습니다. 너무 많은 노이즈 증강은 최적화를 어렵게 만들고 결과를 악화시킬 수 있으며, 너무 적은 노이즈 증강은 시스템의 저신호 대잡음 특성을 약화시킵니다. 우리는 임의로 선택된 발화의 40%에 노이즈를 추가하는 것이 좋은 균형점이라고 발견했습니다. 노이즈 원본은 수천 시간에 달하는 무작위로 선택된 오디오 클립들을 결합하여 수백 시간의 노이즈를 생성합니다.

5.3 데이터 스케일링

우리의 영어와 중국어 말뭉치는 음성 인식 문헌에서 일반적으로 보고되는 것보다 상당히 큽니다. 표 10에서는 레이블이 지정된 훈련 데이터 양을 증가시킴으로써 WER에 미치는 영향을 보여줍니다. 이는 훈련 전에 전체 데이터셋을 무작위로 샘플링하여 수행됩니다. 각 데이터셋에 대해 모델은 최대 20 에포크 동안 훈련되었으며, 일반적으로 개발 세트의 오류에 기반하여 조기 중지되었습니다. 우리는 WER이 일반적인 개발 세트와 노이즈가 있는 개발 세트 모두에 대해 거듭 제곱 법칙에 따라 감소한다는 것을 알 수 있습니다. 훈련 세트 크기가 10배 증가할 때마다 WER은 대략 40% 정도 상대적으로 감소합니다. 또한 일반적인 데이터셋과 노이즈가 있는 데이터셋 사이에는 일관된 WER 차이(대략 60% 상대적)가 있으며, 더 많은 데이터가 두 경우에 모두 이점을 제공한다는 것을 의미합니다.

이는 더 많은 레이블이 지정된 훈련 데이터와 함께 음성 시스템이 계속해서 개선될 것을 의미합니다. 우리는 시간의 총량을 늘리는 것과 더불어 데이터셋에 포함된 음성 컨텍스트의 수를 증가시키는 것이 동등한 중요성을 가진다고 가정합니다. 컨텍스트는 다른 화자, 배경 소음, 환경 및 마이크 하드웨어와 같이 음성을 독특하게 만드는 어떤 속성이든 될 수 있습니다. 이 주장을 검증하기 위해 필요한 레이블은 없지만, 우리는 데이터셋 내 화자의 수에 따른 WER 측정이 단순한 무작위 샘플링보다 훨씬 큰 상대적 이득을 가져올 것으로 의심합니다.

6 결과

우리의 음성 시스템의 실제 적용 가능성을 더 잘 평가하기 위해 우리는 다양한 테스트 세트에서 평가합니다. 우리는 공개적으로 제공되는 여러 벤치마크와 내부에서 수집한 여러 테스트 세트를 사용합니다. 이러한 테스트 세트들은 낮은 신호 대 잡음 비율(잡음이 많은 및 멀리 떨어진), 강세가 있는, 읽는, 즉흥적인 및 대화형 음성을 포함한 다양한 어려운 음성 환경을 대표합니다.

16
데이터 시간의 일부분 정규 편차 노이즈 편차

1%       120  29.23    50.97
10%      1200  13.80    22.99
20%      2400  11.65    20.41
50%      6000   9.51    15.90
100%     12000  8.46    13.59

1%       120  29.23    50.97
10%      1200  13.80    22.99
20%      2400  11.65    20.41
50%      6000   9.51    15.90
100%     12000  8.46    13.59

테이블 10: 훈련 데이터셋 크기를 증가시킬 때 정규 및 소음 개발 세트의 영어 WER 비교. 아키텍처는 2D 불변 컨볼루션 2개 층과 68M 매개변수를 가진 7개의 순환층으로 이루어진 9층 모델입니다.

모든 모델은 표 9에 설명된 전체 영어 데이터셋이나 섹션 5에 설명된 전체 중국어 데이터셋에서 20 에포크 동안 훈련됩니다. 우리는 Nesterov 모멘텀 [61]을 사용하여 확률적 경사 하강법을 사용하며, 미니배치에는 512개의 발화가 포함됩니다. 만약 기울기의 노름이 400의 임계값을 초과하면, 400으로 재조정됩니다 [47]. 훈련 중 개발 세트에서 가장 우수한 성능을 보이는 모델이 평가를 위해 선택됩니다. 학습률은 가장 빠른 수렴을 위해 [1 × 10−4, 6 × 10−4]에서 선택되며, 각 에포크 후에는 상수 요인 1.2로 앤닐링됩니다. 모든 모델에 대해 모멘텀은 0.99로 설정됩니다.

사용된 언어 모델은 3.8절에서 설명한 것들입니다. 식 12의 디코딩 매개변수는 개발용 홀드아웃 세트에서 조정되었습니다. 영어 디코더에는 빔 크기 500을 사용하고, 만다린 디코더에는 빔 크기 200을 사용합니다.

6.1 Korean

GPU   OpenMPI    우리   성능
모든-줄이기 모든-줄이기 이득

4   55359.1   2587.4   21.4
8   48881.6   2470.9   19.8
16  21562.6   1393.7   15.5
32   8191.8   1339.6   6.1
64   1395.2    611.0   2.3
128   1602.1    422.6   3.8

4   55359.1   2587.4   21.4
8   48881.6   2470.9   19.8
16  21562.6   1393.7   15.5
32   8191.8   1339.6   6.1
64   1395.2    611.0   2.3
128   1602.1    422.6   3.8

표 7: 두 가지 다른 all-reduce 구현의 비교. 모든 시간은 초 단위입니다. 성능 향상은 OpenMPI all-reduce 시간 대비 우리의 all-reduce 시간의 비율입니다.

언어 아키텍처 CPU CTC 시간 GPU CTC 시간 가속

영어 5층, 3개의 RNN 5888.12 203.56 28.9
중국어 5층, 3개의 RNN 1688.01 135.05 12.5

표 8: 두 가지 다른 구현에서 CTC 손실 함수와 그래디언트를 계산하는 데 소요된 시간(초)의 비교
한 에포크 동안 CPU CTC 시간 대비 GPU CTC 시간의 속도 향상 비율.

CTC 손실 함수의 4.2 GPU 구현

CTC 손실 함수를 계산하는 것은 우리의 RNN 아키텍처에서 전방 및 역방향 전파를 수행하는 것보다 더 복잡합니다. 원래는 GPU에서 활성화 값을 CPU로 전송하여 CTC의 OpenMP 병렬화 구현을 사용하여 손실 함수를 계산했습니다. 그러나 이 구현은 두 가지 이유로 우리의 확장성을 상당히 제한했습니다. 첫째로, RNN 자체의 효율성과 확장성을 향상시키면서 계산적으로 더 중요해졌습니다. 둘째로, CPU와 GPU 간에 큰 활성화 행렬을 전송하는 것은 데이터 병렬화를 통해 더 많은 프로세서로 확장할 수 있도록 그라디언트 행렬을 전송하는 대신 CTC에 대한 인터커넥트 대역폭을 소비해야 했습니다.

이를 극복하기 위해, 우리는 CTC 손실 함수의 GPU 구현을 작성했습니다. 우리의 병렬 구현은 CTC 계산에서 의존성을 단순화하기 위한 약간의 리팩터링과 ModernGPU [5]의 최적화된 병렬 정렬 구현의 사용에 의존합니다. 이 병렬화에 대한 자세한 내용은 부록에서 설명합니다.

표 8은 두 가지 CTC 구현의 성능을 비교합니다. GPU 구현은 영어로 한 에포크 당 95분, 중국어로는 25분을 절약합니다. 이로 인해 전체 훈련 시간이 10-20% 감소하며, 이는 우리 실험에 중요한 생산성 이점을 제공합니다.

4.3 메모리 할당

우리 시스템은 주로 가변 길이의 발화와 중간 결과를 저장하기 위해 GPU와 CPU 메모리에 동적 메모리 할당을 빈번하게 사용합니다. 개별 할당은 매우 크며, 가장 긴 발화의 경우 1GB 이상입니다. 이러한 매우 큰 할당에 대해 CUDA의 메모리 할당기와 심지어 std::malloc도 우리의 응용 프로그램에 상당한 오버헤드를 도입한다는 것을 발견했습니다. 특정 경우에는 std::malloc을 사용하는 것보다 2배 이상 느려집니다. 이는 cudaMalloc과 std::malloc 모두 매우 큰 할당을 운영 체제나 GPU 드라이버에 전달하여 시스템 페이지 테이블을 업데이트하기 때문입니다. 이는 여러 응용 프로그램이 메모리 리소스를 공유하는 시스템에서는 좋은 최적화입니다. 그러나 노드가 단일 모델을 실행하는 데 전적으로 전용되어 있는 우리 시스템에서는 페이지 테이블 편집은 순수한 오버헤드입니다. 이 제한을 극복하기 위해 CPU와 GPU 할당을 위해 우리만의 메모리 할당기를 작성했습니다. 우리의 구현은 jemalloc의 마지막 레벨 공유 할당기의 접근 방식을 따릅니다. 모든 할당은 buddy 알고리즘을 사용하여 연속적인 메모리 블록에서 조각내어집니다. 단편화를 피하기 위해 훈련 시작 시 GPU 메모리를 모두 사전 할당하고 이 블록에서 개별 할당을 세분화합니다. 마찬가지로, 우리는 mmap에 전달하는 CPU 메모리 블록 크기를 std::malloc보다 훨씬 크게, 12GB로 설정합니다.

14
데이터셋  음성 유형  시간

WSJ 읽기 80
스위치보드 대화 300
피셔 대화 2000
LibriSpeech 읽기 960
바이두 읽기 5000
바이두 혼합 3600

총 11940

테이블 9: DS2를 영어로 훈련시키는 데 사용된 데이터셋 요약. 월스트리트 저널 (WSJ), 스위치보드 및 피셔 [13] 코퍼스는 모두 언어 데이터 컨소시엄에서 출판되었습니다. LibriSpeech 데이터셋 [46]은 온라인에서 무료로 제공됩니다. 다른 데이터셋은 바이두 내부 코퍼스입니다.

학습을 위해 깊은 순환 신경망에 필요한 대부분의 메모리는 역전파에 사용하기 위해 각 레이어의 활성화를 저장하는 데 사용됩니다. 네트워크의 매개변수를 저장하는 데는 사용되지 않습니다. 예를 들어, 70M 매개변수 네트워크의 가중치를 저장하는 것은 약 280MB의 메모리를 필요로하지만, 64개의 7초 발화에 대한 활성화를 저장하는 것은 1.5GB의 메모리가 필요합니다. TitanX GPU는 12GB의 GDDR5 RAM을 포함하고 있으며, 때로는 매우 깊은 네트워크가 긴 발화를 처리할 때 GPU 메모리 용량을 초과할 수 있습니다. 이는 예측할 수 없이 발생할 수 있으며, 특히 발화 길이의 분포에 이상치가 포함되어 있는 경우에는 재앙적인 실패를 피하는 것이 바람직합니다. 요청된 메모리 할당이 사용 가능한 GPU 메모리를 초과하는 경우, 우리는 cudaMallocHost를 사용하여 페이지 잠금된 GPU-메모리-매핑 CPU 메모리를 할당합니다. 이 메모리는 PCIe를 통해 개별 메모리 트랜잭션을 전달하여 GPU가 직접 액세스 할 수 있으며 대역폭이 감소합니다. 이는 모델이 이상치를 만난 후에도 계속 진행할 수 있도록 합니다.

빠른 메모리 할당과 예외적인 경우에 사용 가능한 GPU 메모리를 약간 초과할 수 있는 대체 메커니즘의 조합은 시스템을 현저히 간단하고 견고하며 효율적으로 만듭니다.

5 훈련 데이터

대규모 딥러닝 시스템은 풍부한 레이블이 지정된 훈련 데이터를 필요로 합니다. 우리는 영어와 만다린 음성 모델을 위해 광범위한 훈련 데이터셋을 수집했으며, 공개적으로 이용 가능한 데이터셋과 함께 훈련을 보강했습니다. 영어에서는 8백만 개의 문장으로 요약된 11,940시간의 레이블이 지정된 음성 데이터를 사용하였습니다. 만다린 시스템에서는 1,100만 개의 문장을 포함한 9,400시간의 레이블이 지정된 오디오를 사용합니다. 만다린 음성 데이터는 표준 만다린과 사투리 만다린을 모두 포함하는 바이두 기업의 내부 코퍼스로 구성되어 있습니다.

5.1 데이터셋 구축

일부 내부 영어(3,600 시간) 및 중국어(1,400 시간) 데이터셋은 노이즈가 있는 전사 없이 긴 오디오 클립으로 캡처된 원시 데이터에서 생성되었습니다. 이 클립들의 길이는 몇 분에서 한 시간 이상으로 다양하여 훈련 중 RNN에서 시간에 맞춰 펼치기에는 비실용적이었습니다. 이 문제를 해결하기 위해 우리는 정렬, 분할 및 필터링 파이프라인을 개발하여 잘린 발화와 잘못된 전사가 적은 훈련 세트를 생성할 수 있었습니다.

파이프라인의 첫 번째 단계는 CTC로 훈련된 기존의 양방향 RNN 모델을 사용하여 음성의 프레임에 대한 전사를 정렬하는 것입니다. 주어진 음성-전사 쌍 (x, y)에 대해 최대화하는 정렬을 찾습니다.

(cid:96)∗ = argmax
(cid:96)∈Align(x,y)
T
(cid:89)

최대값을 찾는다
(cid:96)∈Align(x,y)
T
(cid:89)

t
pctc((cid:96)t|x;θ).   (13)

t
pctc((cid:96)t|x;θ).   (13)

이것은 CTC로 훈련된 RNN 모델을 사용하여 찾은 Viterbi 정렬입니다. 식 9는 정렬을 통합하기 때문에 CTC 손실 함수는 정확한 정렬을 생성하도록 명시적으로 요구되지 않습니다. 원칙적으로 CTC는 어떤 시점 이후에 전사의 모든 문자를 방출하기로 선택할 수 있습니다.

15
고정된 지연이 있을 수 있으며, 이는 단방향 RNN에서 발생할 수 있습니다 [54]. 그러나 우리는 양방향 RNN으로 훈련된 CTC가 정확한 정렬을 생성한다는 것을 발견했습니다.

정렬을 따르는 것은 연속적인 공백 레이블이 발생할 때마다 오디오와 해당 정렬된 대본을 자르는 세그멘테이션 단계입니다. 이는 일반적으로 침묵 구간을 나타냅니다. 연속적인 공백의 개수를 조정함으로써 생성되는 발화의 길이를 조정할 수 있습니다. 영어 음성 데이터의 경우, 단어 경계에서만 분할하기 위해 공백 구간 내에 공백 토큰이 있어야 합니다. 평균적으로 7초 길이의 발화를 생성하기 위해 세그멘테이션을 조정합니다.

파이프라인의 최종 단계는 실패한 정렬로 인해 발생하는 잘못된 예제를 제거합니다. 우리는 몇 천 개의 예제에 대해 그라운드 트루스 전사를 크라우드 소싱합니다. 그라운드 트루스와 정렬된 전사 간의 단어 수준 편집 거리를 사용하여 좋은 또는 나쁜 레이블을 생성합니다. 단어 수준 편집 거리의 임계값은 개발 세트의 좋은 부분의 WER이 5% 미만이 되도록 선택됩니다. 그런 다음 음성 인식기에서 생성된 입력 특성을 기반으로 나쁜 예제를 정확하게 예측하기 위해 선형 분류기를 훈련시킵니다. 우리는 다음과 같은 특성들이 유용하다고 알아냈습니다: 원시 CTC 비용, 시퀀스 길이로 정규화된 CTC 비용, 전사 길이로 정규화된 CTC 비용, 시퀀스 길이 대 전사 길이의 비율, 전사에 있는 단어 수 및 전사에 있는 문자 수. 영어 데이터셋에서는 필터링 파이프라인이 WER을 17%에서 5%로 줄이면서 예제의 50% 이상을 유지하는 것을 발견했습니다.

5.2 데이터 증강

우리는 훈련 데이터를 늘리기 위해 노이즈를 추가하여 훈련 데이터의 효과적인 크기를 증가시키고 노이즈에 대한 강건성을 향상시킵니다 [26]. 훈련 데이터에는 일부 내재적인 노이즈가 포함되어 있지만, 우리는 증강을 통해 노이즈의 양과 다양성을 늘릴 수 있습니다. 너무 많은 노이즈 증강은 최적화를 어렵게 만들고 결과를 악화시킬 수 있으며, 너무 적은 노이즈 증강은 시스템의 저신호 대잡음 특성을 약화시킵니다. 우리는 임의로 선택된 발화의 40%에 노이즈를 추가하는 것이 좋은 균형점이라고 발견했습니다. 노이즈 원본은 수천 시간에 달하는 무작위로 선택된 오디오 클립들을 결합하여 수백 시간의 노이즈를 생성합니다.

5.3 데이터 스케일링

우리의 영어와 중국어 말뭉치는 음성 인식 문헌에서 일반적으로 보고되는 것보다 상당히 큽니다. 표 10에서는 레이블이 지정된 훈련 데이터 양을 증가시킴으로써 WER에 미치는 영향을 보여줍니다. 이는 훈련 전에 전체 데이터셋을 무작위로 샘플링하여 수행됩니다. 각 데이터셋에 대해 모델은 최대 20 에포크 동안 훈련되었으며, 일반적으로 개발 세트의 오류에 기반하여 조기 중지되었습니다. 우리는 WER이 일반적인 개발 세트와 노이즈가 있는 개발 세트 모두에 대해 거듭 제곱 법칙에 따라 감소한다는 것을 알 수 있습니다. 훈련 세트 크기가 10배 증가할 때마다 WER은 대략 40% 정도 상대적으로 감소합니다. 또한 일반적인 데이터셋과 노이즈가 있는 데이터셋 사이에는 일관된 WER 차이(대략 60% 상대적)가 있으며, 더 많은 데이터가 두 경우에 모두 이점을 제공한다는 것을 의미합니다.

이는 더 많은 레이블이 지정된 훈련 데이터와 함께 음성 시스템이 계속해서 개선될 것을 의미합니다. 우리는 시간의 총량을 늘리는 것과 더불어 데이터셋에 포함된 음성 컨텍스트의 수를 증가시키는 것이 동등한 중요성을 가진다고 가정합니다. 컨텍스트는 다른 화자, 배경 소음, 환경 및 마이크 하드웨어와 같이 음성을 독특하게 만드는 어떤 속성이든 될 수 있습니다. 이 주장을 검증하기 위해 필요한 레이블은 없지만, 우리는 데이터셋 내 화자의 수에 따른 WER 측정이 단순한 무작위 샘플링보다 훨씬 큰 상대적 이득을 가져올 것으로 의심합니다.

6 결과

우리의 음성 시스템의 실제 적용 가능성을 더 잘 평가하기 위해 우리는 다양한 테스트 세트에서 평가합니다. 우리는 공개적으로 제공되는 여러 벤치마크와 내부에서 수집한 여러 테스트 세트를 사용합니다. 이러한 테스트 세트들은 낮은 신호 대 잡음 비율(잡음이 많은 및 멀리 떨어진), 강세가 있는, 읽는, 즉흥적인 및 대화형 음성을 포함한 다양한 어려운 음성 환경을 대표합니다.

16
데이터 시간의 일부분 정규 편차 노이즈 편차

1%       120  29.23    50.97
10%      1200  13.80    22.99
20%      2400  11.65    20.41
50%      6000   9.51    15.90
100%     12000  8.46    13.59

1%       120  29.23    50.97
10%      1200  13.80    22.99
20%      2400  11.65    20.41
50%      6000   9.51    15.90
100%     12000  8.46    13.59

테이블 10: 훈련 데이터셋 크기를 증가시킬 때 정규 및 소음 개발 세트의 영어 WER 비교. 아키텍처는 2D 불변 컨볼루션 2개 층과 68M 매개변수를 가진 7개의 순환층으로 이루어진 9층 모델입니다.

모든 모델은 표 9에 설명된 전체 영어 데이터셋이나 섹션 5에 설명된 전체 중국어 데이터셋에서 20 에포크 동안 훈련됩니다. 우리는 Nesterov 모멘텀 [61]을 사용하여 확률적 경사 하강법을 사용하며, 미니배치에는 512개의 발화가 포함됩니다. 만약 기울기의 노름이 400의 임계값을 초과하면, 400으로 재조정됩니다 [47]. 훈련 중 개발 세트에서 가장 우수한 성능을 보이는 모델이 평가를 위해 선택됩니다. 학습률은 가장 빠른 수렴을 위해 [1 × 10−4, 6 × 10−4]에서 선택되며, 각 에포크 후에 1.2의 상수 배율로 감소됩니다. 모든 모델에 대해 모멘텀은 0.99로 설정됩니다.

사용된 언어 모델은 3.8절에서 설명한 것들입니다. 식 12의 디코딩 매개변수는 개발용 홀드아웃 세트에서 조정되었습니다. 영어 디코더에는 빔 크기 500을 사용하고, 만다린 디코더에는 빔 크기 200을 사용합니다.

6.1 Korean

최고의 DS2 모델은 2D 합성곱 3개 층, 양방향 순환 7개 층, 배치 정규화와 함께 완전 연결 출력 층을 가지고 있습니다. 첫 번째 층은 3의 시간 간격으로 바이그램을 출력합니다. 반면에 DS1 모델은 양방향 순환 1개 층과 첫 번째 층에서 2의 시간 간격으로 유니그램을 출력하는 5개 층을 가지고 있습니다. DS2와 DS1 모델에 대해 여러 테스트 세트에서 결과를 보고합니다. 테스트 세트의 어떤 음성 조건에도 모델을 조정하거나 적응하지 않습니다. 언어 모델 디코딩 매개변수는 개발 세트에서 한 번 설정됩니다.

우리 시스템의 성능을 평가하기 위해, 우리는 음성 인식과 언어 이해 문제인 이유로 인해 인간 작업자와 대부분의 결과를 벤치마킹합니다. 우리는 아마존 메카니컬 터크에서 작업자들에게 우리의 테스트 세트를 수기로 전사하도록 지불하여 인간 수준의 성능을 측정합니다. 두 명의 작업자가 일반적으로 5초 정도인 동일한 오디오 클립을 전사하며, 우리는 두 전사 중 더 나은 것을 최종 WER 계산에 사용합니다. 그들은 오디오 클립을 원하는 만큼 여러 번 들을 수 있습니다. 이 작업자들은 주로 미국에 기반을 두고 있으며, 평균적으로 전사 당 약 27초를 소요합니다. 수기로 전사된 결과는 기존의 정답과 비교하여 WER을 생성합니다. 기존의 정답 전사에는 일부 레이블 오류가 있지만, 이는 일반적으로 1% 이하입니다. 이는 기존의 정답 전사와 인간 수준 전사 간의 불일치가 인간 수준의 성능에 대한 좋은 휴리스틱이라는 것을 의미합니다.

6.1.1 모델 크기

우리의 영어 연설 훈련 세트는 일반적으로 사용되는 연설 데이터셋의 크기보다 상당히 큽니다. 또한, 데이터는 잡음 합성으로 증강되었습니다. 최상의 일반화 오류를 얻기 위해서는 모델 크기가 데이터의 패턴을 완전히 활용하기 위해 증가해야 합니다. 3.2절에서는 매개변수의 수를 고정시키면서 모델 깊이의 영향을 탐구했습니다. 대조적으로, 여기에서는 모델 크기의 변화가 연설 시스템의 성능에 미치는 영향을 보여줍니다. 우리는 각 레이어의 크기만을 변화시키고, 깊이와 다른 구조적 매개변수를 일정하게 유지합니다. 우리는 3.5절에서 사용한 Regular 및 Noisy 개발 세트에서 모델을 평가합니다.

Table 11의 모델은 Table 3의 모델과 다르다. 우리는 stride를 3으로 증가시키고 bigram으로 출력한다. 모델 크기를 1억 개의 매개변수로 증가시키기 때문에, 빠른 계산과 메모리 제약을 위해 stride를 증가시키는 것이 필요하다고 판단한다. 그러나 이 규모에서는 GRU 네트워크의 성능 우위가 줄어드는 것을 알 수 있다.

17
모델 크기 모델 유형 정규화된 개발 노이즈가 있는 개발

18
×
106  GRU     10.59    21.38
38
×
106  GRU      9.06    17.07
70
×
106  GRU      8.54    15.98
70
×
106  RNN      8.44    15.09
100
×
106  GRU      7.78    14.17
100
×
106  RNN      7.73    13.06

18
×
106  GRU     10.59    21.38
38
×
106  GRU      9.06    17.07
70
×
106  GRU      8.54    15.98
70
×
106  RNN      8.44    15.09
100
×
106  GRU      7.78    14.17
100
×
106  RNN      7.73    13.06

Table11: 영어 음성 시스템의 WER에 대한 모델 크기의 영향을 정상 및 노이즈 개발 세트에서 비교합니다. 우리는 컨볼루션 레이어를 제외한 모든 레이어의 숨겨진 유닛 수를 변화시킵니다. GRU 모델은 2D 불변 컨볼루션의 1개 레이어와 3개 레이어의 양방향 GRU로 구성됩니다. RNN 모델은 2D 불변 컨볼루션의 3개 레이어와 양방향 단순 재귀의 7개 레이어로 구성됩니다. 두 모델 모두 시간 간격 3으로 bigram을 출력합니다. 모든 모델은 약 3500만 개의 매개변수를 포함하며 BatchNorm과 SortaGrad로 훈련됩니다.

테스트 세트 DS1 DS2

바이두 테스트 24.01 13.59

테이블 12: 3,300개의 내부 테스트 세트에서 DS1과 DS2의 WER 비교. 이 테스트 세트에는 강조, 신호 대 잡음 비율이 낮은 음성, 즉흥 및 대화식 음성을 포함한 다양한 음성이 포함되어 있습니다.

간단한 RNN. 사실, 1억 개의 매개변수 네트워크에 대해 간단한 RNN은 GRU 네트워크보다 성능이 더 좋으며, 2개의 추가 컨볼루션 레이어에도 불구하고 훈련 속도가 더 빠릅니다.

표 11은 시스템의 성능이 1억 개의 매개변수까지 일관되게 향상되는 것을 보여줍니다. 이후의 모든 영어 DS2 결과는 이 동일한 1억 개의 매개변수 RNN 모델로 보고되었으며, 이 모델은 가장 낮은 일반화 오류를 달성했습니다.

표 12는 1억 개의 매개변수를 가진 RNN 모델(DS2)이 3,300개의 다양한 억양, 원거리 또는 배경 소음으로 인한 낮은 신호 대 잡음 비율, 즉흥적이고 대화체의 음성을 포함하는 내부 Baidu 데이터셋에서 1개의 순환층을 가진 5층 모델(DS1)보다 43.4%의 상대적인 개선을 보여줍니다.

6.1.2 읽기 연설

신호 대 잡음 비율이 높은 읽는 말은 연속 음성 인식 작업에서 아마도 가장 쉬운 대용량 어휘입니다. 우리는 월스트리트저널(WSJ) 기사의 읽는 테스트 세트 두 개에서 시스템을 벤치마킹합니다. 이들은 LDC 카탈로그의 LDC94S13B와 LDC93S6B로 제공됩니다. 또한 최근에 개발된 LibriVox 프로젝트의 오디오북을 사용하여 구축된 LibriSpeech 코퍼스를 활용합니다 [46].

테이블 13은 DS2 시스템이 4개의 테스트 세트 중 3개에서 인간보다 우수한 성능을 보이고, 4번째에서는 경쟁력을 갖고 있다는 것을 보여줍니다. 이 결과를 고려하면, 우리는 일반적인 음성 시스템이 추가적인 도메인 적응 없이 깨끗한 읽기 음성에서 더 개선될 여지가 거의 없다고 의심합니다.

연설을 읽다

테스트 세트       DS1  DS2 인간

WSJ eval'92    4.94 3.60  5.03
WSJ eval'93    6.94 4.98  8.08
LibriSpeech test-clean 7.89 5.33 5.83
LibriSpeech test-other 21.74 13.25 12.69

WSJ eval'92    4.94 3.60  5.03
WSJ eval'93    6.94 4.98  8.08
LibriSpeech test-clean 7.89 5.33 5.83
LibriSpeech test-other 21.74 13.25 12.69

테이블 13: 두 개의 음성 시스템과 인간 수준의 읽기 음성에 대한 WER 비교.

18
강조된 말씨

테스트 세트           DS1  DS2 인간

VoxForge 미국-캐나다 15.01 7.55 4.85
VoxForge 공동체 28.46 13.56 8.15
VoxForge 유럽 31.20 17.55 12.76
VoxForge 인도 45.35 22.44 22.15

테이블 14: 강조된 말에 대한 DS1 시스템과 DS2 시스템의 WER 비교.

시끄러운 말

테스트 세트    DS1  DS2 인간

CHiME 평가 청정 6.30 3.34 3.46
CHiME 평가 실제 67.94 21.79 11.84
CHiME 평가 유사 80.27 45.05 31.33

테이블 15: 노이즈가 있는 음성에서 DS1 및 DS2 시스템의 비교입니다. "CHiME eval clean"은 노이즈가 없는 기준선입니다.
"CHiME eval real" 데이터셋은 실제 노이즈가 있는 환경에서 수집되었으며, "CHiME eval sim" 데이터셋은 깨끗한 음성에 합성된 유사한 노이즈가 추가되었습니다. 각 발화를 테스트하기 위해 여섯 채널 중 하나만 사용합니다.

6.1.3 강세 있는 말

우리의 강세 있는 말의 출처는 공개적으로 이용 가능한 VoxForge(http://www.voxforge.org) 데이터셋입니다. 이 데이터셋은 다양한 강세를 가진 화자들이 읽은 깨끗한 말을 포함하고 있습니다. 우리는 이러한 강세를 네 가지 범주로 나눕니다. 미국-캐나다 그룹과 인도 그룹은 설명이 필요하지 않습니다. 영국, 아일랜드, 남아프리카, 호주, 뉴질랜드 강세를 가진 화자들을 포함하는 공화국 강세입니다. 유럽 그룹은 영어를 모국어로 사용하지 않는 유럽 국가 출신 화자들의 강세를 포함합니다. 우리는 VoxForge 데이터에서 각각 1024개의 예시를 사용하여 총 4096개의 예시로 구성된 테스트 세트를 만듭니다.

이러한 테스트 세트의 성능은 어느 정도로 우리의 훈련 데이터의 폭과 품질을 측정하는 지표입니다. 표 14는 우리의 성능이 더 많은 강조된 훈련 데이터를 포함하고 그 데이터에서 효과적으로 훈련할 수 있는 아키텍처를 사용할 때 모든 강조에 대해 향상되었음을 보여줍니다. 그러나 인도 강조를 제외한 모든 경우에 인간 수준의 성능이 여전히 뚜렷하게 더 우수합니다.

6.1.4 시끄러운 말

우리는 최근 완료된 세 번째 CHiME 도전에서 공개적으로 사용 가능한 테스트 세트를 사용하여 소음이 있는 음성의 성능을 테스트합니다. 이 데이터셋은 버스, 카페, 거리 및 보행자 지역을 포함한 다양한 소음 환경에서 WSJ 테스트 세트의 1320개 발화를 포함하고 있습니다. CHiME 세트에는 동일한 환경에서 모의 소음이 포함된 1320개의 발화와 무소음 환경에서 동일한 화자가 전달한 동일한 발화를 포함한 제어 세트도 포함되어 있습니다. 제어 세트와 소음이 있는 세트 간의 차이는 네트워크가 다양한 실제 및 합성 소음 조건을 처리할 수 있는 능력을 측정하는 지표가 됩니다. CHiME 오디오는 6개의 채널을 가지고 있으며, 이를 모두 사용하면 상당한 성능 향상이 가능합니다. 하지만 대부분의 장치에서는 다채널 오디오가 보편적이지 않기 때문에 우리는 모든 결과에 단일 채널을 사용합니다. 테이블 15에서는 DS2가 DS1보다 크게 개선되었음을 보여줍니다. 그러나 DS2는 소음이 있는 데이터에서 인간 수준의 성능보다 나쁩니다. 데이터가 깨끗한 음성에 소음을 합성하는 대신 실제 소음 환경에서 가져온 경우, DS2와 인간 수준의 성능 간의 상대적인 격차가 더 큽니다.

6.2 만다린

표 16에서는 중국어 음성을 훈련시킨 여러 아키텍처를 비교합니다. 개발 세트는 2000개의 발화와 1882개의 노이즈 음성 예제로 구성되어 있습니다. 이 개발 세트는 디코딩 매개변수를 조정하는 데에도 사용되었습니다. 우리는 2D-불변 깊은 모델이 가장 깊다는 것을 알 수 있습니다.

19
합성곱과 배치 정규화는 얕은 RNN보다 상대적으로 48% 우수한 성능을 보여주며, 이는 영어 시스템에서 보았던 경향을 이어가고 있습니다. 양방향 순환의 다층화는 성능을 크게 향상시킵니다.

건축            개발  테스트

5층, 1개의 RNN          7.13 15.41
5층, 3개의 RNN          6.49 11.85
5층, 3개의 RNN + BatchNorm 6.22 9.39
9층, 7개의 RNN + BatchNorm + 2D conv 5.81 7.93

테이블 16: 아키텍처 개선과 함께 DeepSpeech의 개선 비교. 개발 및 테스트 세트는 바이두 내부 코퍼스입니다. 테이블의 모든 모델은 각각 약 8000만 개의 매개변수를 가지고 있습니다.

우리는 최고의 중국어 말소리 시스템이 짧은 음성 질문과 같은 발화를 일반적인 중국어 말하는 사람보다 더 잘 변환한다는 것을 발견했습니다. 인간과 비교하기 위해 우리는 100개의 무작위로 선택된 발화에 대한 테스트를 진행하고 5명의 인간 그룹이 모두 레이블을 달도록 했습니다. 인간 그룹의 오류율은 4.0%이고, 음성 시스템의 성능은 3.7%입니다. 또한 250개의 무작위로 선택된 발화에 대해 단일 인간 변환자와 음성 시스템을 비교했습니다. 이 경우 음성 시스템의 성능이 훨씬 우수합니다: 인간의 오류율은 9.7%이고, 음성 모델의 오류율은 5.7%입니다.

7 배치

실제 세계의 응용 프로그램은 일반적으로 실시간 또는 상대적으로 낮은 지연 시간으로 음성 시스템을 필요로합니다. 6.1 절에서 사용된 시스템은 이 작업에 적합하게 설계되지 않았습니다. 이에는 여러 가지 이유가 있습니다. 첫째, RNN에 여러 양방향 레이어가 있으므로 발화의 첫 부분을 전사하기 위해서는 전체 발화가 RNN에 제시되어야합니다. 둘째, 언어 모델과 함께 빔 탐색을 사용할 때 넓은 빔을 사용하면 비용이 많이 들 수 있으며, 특히 가능한 다음 문자의 수가 매우 많은 중국어에서 (약 6000 개) 그렇습니다. 셋째, 3 절에서 설명한대로 전체 발화에서 전력을 정규화하려면 다시 전체 발화가 미리 사용 가능해야합니다.

저희는 온라인 전사 중 음성 입력의 적응적 정규화를 수행하기 위해 훈련 세트에서 일부 통계를 사용하여 전력 정규화 문제를 해결합니다. 네트워크와 디코딩 절차를 수정하여 더 낮은 대기 시간을 가지면서 거의 동일한 성능을 발휘하는 모델을 생성함으로써 다른 문제들도 해결할 수 있습니다. 우리는 중국어 시스템에 초점을 맞추고 있으며 (예: 대규모 문자 집합), 배포하기 더 어려운 측면이 있지만, 동일한 기술은 영어에도 적용될 수 있습니다.

이 섹션에서 지연 시간은 음성 시스템의 계산 지연 시간을 의미하며, 발화의 끝에서 전사가 생성될 때까지 측정됩니다. 이 지연 시간에는 인터넷을 통한 데이터 전송이 포함되지 않으며, 발화의 시작부터 첫 번째 전사가 생성될 때까지의 지연 시간을 측정하지 않습니다. 우리는 음성 인식을 사용하는 애플리케이션에 중요한 발화의 끝부터 전사까지의 지연 시간에 초점을 맞추고 있습니다.

7.1 배치 디스패치

새로운 대용량 딥 뉴럴 네트워크를 낮은 지연 시간으로 배포하기 위해, 배포 과정에서 효율성에 특별히 주의를 기울였습니다. 대부분의 인터넷 애플리케이션은 데이터 센터에 도착한 요청을 개별적으로 처리합니다. 이는 각 요청을 하나의 스레드로 관리할 수 있는 간단한 구현을 가능하게 합니다. 그러나 개별적으로 요청을 처리하는 것은 계산적으로 비효율적입니다. 이는 주로 두 가지 이유로 인해 발생합니다. 첫째로, 개별적으로 요청을 처리할 때, 프로세서는 각 요청마다 네트워크의 모든 가중치를 로드해야 합니다. 이로 인해 작업의 산술적 강도가 낮아지며, 계산이 메모리 대역폭에 의존하게 됩니다. 개별적으로 요청이 제시될 때 온칩 캐시를 효과적으로 사용하기 어렵기 때문입니다. 둘째로, 한 요청을 분류하기 위해 활용할 수 있는 병렬성의 양이 제한되어 SIMD 또는 멀티코어 병렬성을 활용하기 어렵습니다. RNN은 특히 배포가 어렵습니다. 왜냐하면 RNN을 샘플별로 평가하는 것이 도전적이기 때문입니다.

20
0 1 2 3 4 5 6 7 8 9 10 11

배치 크기
0.0
0.1
0.2
0.3
0.4

확률

10 개의 스트림

20 개의 스트림

30 개의 스트림

그림 5: 주어진 크기의 배치에서 요청이 처리되는 확률

샘플은 연속적인 행렬 벡터 곱셈에 의존하며, 대역폭 제한되고 병렬화하기 어렵습니다.

이러한 문제를 극복하기 위해, 우리는 Batch Dispatch라는 배치 스케줄러를 구축했습니다. 이 스케줄러는 사용자 요청에서 데이터 스트림을 배치로 조립한 후 전진 전파를 수행합니다. 이 경우, 배치 크기를 증가시키면 효율성이 향상되지만 대기 시간이 증가하는 절충이 있습니다. 큰 배치를 조립하기 위해 사용자 요청을 버퍼링할수록 사용자는 결과를 기다려야 하는 시간이 더 길어집니다. 이로 인해 우리는 배치 작업을 수행할 수 있는 제약이 생깁니다.

우리는 이른바 "eager batching scheme"을 사용합니다. 이는 이전 배치가 완료되는 즉시 각 배치를 처리하며, 그 시점에서 얼마나 많은 작업이 준비되었는지에 관계없이 처리합니다. 이 스케줄링 알고리즘은 연산적으로는 효율적이지 않으나, 최대 배치 크기를 극대화하지 않기 때문에 최종 사용자 대기 시간을 줄이는 데 가장 효과적입니다.

그림 5는 단일 NVIDIA Quadro K1200 GPU에서 실행되는 우리의 생산 시스템에서 주어진 크기의 배치에서 요청이 처리될 확률을 보여줍니다. 예상대로, 서버가 많이 로드될 때 배치 처리가 가장 잘 작동합니다. 로드가 증가함에 따라 분포가 더 큰 배치로 요청을 처리하는 것을 선호하도록 변화합니다. 그러나, 단지 10개의 동시 사용자 요청만 있는 가벼운 로드에서도, 우리의 시스템은 적어도 2개의 샘플을 가진 배치에서 작업의 절반 이상을 수행합니다.

0     10     20     30    40

영     십     이십     삼십    사십

동시 스트림 수
0
50
100

지각
미숙
평균
백분위수

98%ile - 98 백분위수

그림 6: 서버 부하에 따른 중앙값과 98 백분위 지연 시간

우리는 그림 6에서 볼 수 있듯이, 우리 시스템은 10개의 동시 스트림으로 로드되었을 때 중앙 지연 시간이 44ms이고 98 백분위 지연 시간이 70ms를 달성합니다. 서버에 부하가 증가함에 따라 배치 스케줄러는 더 효율적인 배치로 작업을 이동시켜 지연 시간을 낮게 유지합니다. 이는 배치 디스패치를 통해 이러한 대형 모델을 고 처리량과 낮은 지연 시간으로 배포할 수 있다는 것을 보여줍니다.

21
1  2   3  4  5  6  7  8  9  10

배치 크기
0.0
0.1
0.2
0.3
0.4
0.5

테라
에프
엘
오
피 / 에스

너바나

바이두

그림 7: A가 2560×2560 차원의 행렬이고 x가 2560×Batch size 차원의 행렬인 Ax = b를 계산하는 커널들의 비교, 여기서 Batch size는 [1,10] 범위에 속한다. 모든 행렬은 반 정밀도 형식이다.

7.2 배치 최적화된 행렬 곱셈 커널

우리는 모델을 배포할 때 반정밀도(16비트) 부동 소수점 산술을 사용하는 것이 인식 정확도에 실질적인 변화를 주지 않는다는 것을 발견했습니다. 배포는 네트워크 가중치에 대한 업데이트가 필요하지 않기 때문에, 훈련보다는 수치 정밀도에 훨씬 덜 민감합니다. 반정밀도 산술을 사용하면 메모리 공간과 대역폭을 절약할 수 있으며, 특히 RNN 평가에서는 가중치 행렬의 캐싱과 스트리밍 비용이 지배적입니다.

7.1절에서 볼 수 있듯이, 배치 크기는 훈련 중보다 배포 중에 훨씬 작습니다. 우리는 표준 BLAS 라이브러리가 이 배치 크기에서 비효율적임을 발견했습니다. 이를 극복하기 위해 우리는 자체 반정밀도 행렬-행렬 곱셈 커널을 작성했습니다. 10개의 동시 스트림에 대해 90% 이상의 배치는 N≤4인 경우로, 이는 행렬 곱셈이 대역폭에 의해 제한될 범위입니다. 우리는 가능한 가장 넓은 벡터 로드를 사용하여 대역폭을 극대화하기 위해 A 행렬을 전치하여 저장합니다. 각 워프는 모든 N 출력 열에 대해 네 개의 행의 출력을 계산합니다. N≤4인 경우 B 행렬은 L1 캐시에 완전히 들어갑니다. 이 방식은 N≤4에 대해 최대 대역폭의 90%를 달성하지만, B 행렬이 L1 캐시에 들어가지 않을 때부터 더 큰 N에 대해 효율성을 잃기 시작합니다. 그럼에도 불구하고, N = 10까지 기존 라이브러리보다 향상된 성능을 제공합니다.

그림 7은 우리의 배치 커널이 Nervana Systems [44]의 것보다 K1200 GPU에서 사용하는 배치 크기 전체 범위에서 더 높은 계산 처리량을 유지한다는 것을 보여줍니다. 우리의 커널과 Nervana 커널 모두 NVIDIA CUBLAS 버전 7.0보다 훨씬 빠릅니다. 자세한 내용은 여기에서 확인할 수 있습니다 [20].

7.3 빔 탐색

빔 서치를 수행하는 것은 n-gram 언어 모델에서 반복적인 조회를 수반하며, 대부분은 캐시되지 않은 메모리에서의 읽기로 변환됩니다. 빔 서치의 직접적인 구현은 각 타임 스텝마다 빔 당 문자 하나에 대한 조회를 수행합니다. 중국어에서는 이로 인해 음성 데이터의 40ms 간격마다 1백만 개 이상의 조회가 발생하며, 이는 배포에는 너무 느립니다. 이 문제를 해결하기 위해, 우리는 빔 서치를 더욱 가지치기하는 휴리스틱을 사용합니다. 빔에 추가할 수 있는 문자로 모든 문자를 고려하는 대신, 누적 확률이 적어도 p인 가장 적은 수의 문자만을 고려합니다. 실제로, p = 0.99가 잘 작동하는 것으로 확인했습니다. 또한, 최대 40개의 문자로 제한합니다. 이는 중국어 언어 모델 조회 시간을 150배 가속화시키며, CER에는 미미한 영향을 미칩니다 (0.1-0.3% 상대적으로).

7.4 결과

우리는 정확도를 크게 희생하지 않고도 낮은 지연 시간과 높은 처리량으로 시스템을 배포할 수 있습니다.
2000개의 발화로 구성된 테스트 세트에서, 연구 시스템은 5.81의 문자 오류율을 달성하며, 
배포된 시스템은 6.10의 문자 오류율을 달성합니다. 이는 상대적으로 5%만의 저하입니다.

22
배포된 시스템. 이를 달성하기 위해 저희는 배포 지연 시간이 적은 신경망 아키텍처를 사용하고, 네트워크의 정밀도를 16비트로 줄이고, RNN을 더 효율적으로 평가하기 위해 배치 스케줄러를 구축하고, 빔 서치 비용을 줄이기 위한 간단한 휴리스틱을 찾았습니다. 이 모델은 2560개의 은닉 유닛을 가진 5개의 단방향 순환 레이어, τ = 19인 한 줄 합성곱 레이어(3.7절) 및 2560개의 은닉 유닛을 가진 완전 연결 레이어로 구성되어 있습니다. 이러한 기술들을 통해 Deep Speech를 저렴한 비용으로 대화형 애플리케이션에 배포할 수 있습니다.

8 결론

엔드 투 엔드 딥 러닝은 데이터와 계산 능력의 증가와 함께 연속적으로 음성 인식 시스템을 개선할 수 있는 흥미로운 기회를 제공합니다. 실제로, 우리의 결과는 이전 버전과 비교하여 Deep Speech가 더 많은 데이터와 큰 모델을 활용하여 인간 작업자와의 전사 성능 차이를 크게 줄였음을 보여줍니다. 또한, 이 접근 방식이 매우 일반적이기 때문에 새로운 언어에 빠르게 적용할 수 있다는 것을 보여줬습니다. 영어와 중국어라는 매우 다른 두 언어에 대한 고성능 인식기를 만드는 데는 언어에 대한 전문 지식이 거의 필요하지 않았습니다. 마지막으로, 이 접근 방식이 GPU 서버에서 사용자 요청을 일괄 처리함으로써 효율적으로 배포될 수 있다는 것도 보여줬으며, 이는 엔드 투 엔드 딥 러닝 기술을 사용자에게 제공하는 길을 열어주었습니다.

이러한 결과를 달성하기 위해 우리는 다양한 네트워크 아키텍처를 탐색하였으며, SortaGrad와 Batch Normalization을 통한 수치 최적화 개선, 영어의 bigram 출력을 위한 큰 보폭으로 RNN 평가, 양방향 및 단방향 모델을 모두 탐색하는 등의 효과적인 기법을 발견하였습니다. 이 탐색은 우리의 대규모 데이터셋에서 새로운 대규모 모델을 단 몇 일만에 훈련할 수 있도록 최적화된 고성능 컴퓨팅 기반의 훈련 시스템으로 이루어졌습니다.

전반적으로, 우리는 우리의 결과가 몇 가지 상황에서 음성 인식을 위한 end-to-end Deep Learning 방법의 가치를 확인하고 보여준다고 믿습니다. 우리의 시스템이 이미 인간과 비교할만한 수준이 아닌 경우에도, 응용 프로그램에 중립적인 Deep Learning 기술의 덕분에 차이가 빠르게 줄어들었습니다. 우리는 이러한 기술이 계속해서 확장될 것이라고 믿으며, 따라서 대부분의 시나리오에서 인간을 능가하는 단일 음성 시스템의 비전은 곧 달성 가능하다고 결론지을 수 있다.

감사의 말씀

우리는 데이터 준비와 유용한 대화에 대한 Baidu의 음성 기술 그룹에 감사드립니다. 우리는 우수한 행렬 곱셈 루틴과 유용한 토론을 위해 Scott Gray, Amir Khosrowshahi 및 Nervana Systems의 모든 분들께 감사드립니다. 또한 빠른 배포 행렬 곱셈을 구현하는 데 대한 유용한 토론과 생각을 제공해준 NVIDIA의 Natalia Gimelshein에게도 감사드립니다.

참고문헌

[1] O. Abdel-Hamid, A.-r. Mohamed, H. Jang, and G. Penn. 음성 인식을 위한 하이브리드 nn-hmm 모델에 합성곱 신경망 개념 적용. ICASSP, 2012.

[2] D.Bahdanau, K.Cho, and Y.Bengio. 공동으로 정렬하고 번역하는 것을 학습하여 신경 기계 번역. ICLR, 2015.

[3] D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio. End-to-end attention-based large vocabulary speech recognition. abs/1508.04395, 2015. http://arxiv.org/abs/1508.04395.

[3] D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, 그리고 Y. Bengio. 엔드 투 엔드 어텐션 기반 대용량 음성 인식. abs/1508.04395, 2015. http://arxiv.org/abs/1508.04395.

[4] J. Barker, E. Marxer, Ricard Vincent, and S. Watanabe. 제3회 'CHiME' 음성 분리 및 인식 챌린지: 데이터셋, 과제 및 기준선. 2015. IEEE 2015 자동 음성 인식 및 이해 워크샵 (ASRU)에 제출됨.

[5] S. Baxter. 현대 GPU. https://nvlabs.github.io/moderngpu/.

[6] Y. Bengio, J. Louradour, R. Collobert, and J. Weston. 커리큘럼 학습. 2009년 국제 기계 학습 컨퍼런스에서 발표.

[7] H. Bourlard과 N. Morgan. 연결주의 음성인식: 하이브리드 접근법. Kluwer Academic Publishers, Norwell, MA, 1993.

23
[8] W. Chan, N. Jaitly, Q. Le, and O. Vinyals. Listen, attend, and spell. abs/1508.01211, 2015.
http://arxiv.org/abs/1508.01211.

[9] S. Chetlur, C. Woolley, P. Vandermersch, J. Cohen, J. Tran, B. Catanzaro, and E. Shelhamer. cuDNN: 딥 러닝을 위한 효율적인 기본 요소.

[10] T. Chilimbi, Y. Suzue, J. Apacible, and K. Kalyanaraman. Projectadam: 효율적이고 확장 가능한 딥러닝 훈련 시스템 구축. USENIX 운영체제 설계 및 구현 심포지엄, 2014.

[11] K.Cho, B.VanMerrienboer, C.Gulcehre, D.Bahdanau, F.Bougares, H.Schwenk, andY.Bengio. RNN 인코더-디코더를 사용한 통계 기계 번역을 위한 구문 표현 학습. EMNLP, 2014.

[12] J. Chorowski, D. Bahdanau, K. Cho, and Y. Bengio. 주의 기반 순환 신경망을 사용한 연속 음성 인식의 종단 간 결과. abs/1412.1602, 2015. http://arxiv.org/abs/1412.1602.

[13] C. Cieri, D. Miller, and K. Walker. 피셔 코퍼스: 다음 세대의 음성-텍스트 변환을 위한 자원. LREC에서, 4권, 69-71쪽, 2004년.

[14] A.Coates, B.Carpenter, C.Case, S.Satheesh, B.Suresh, T.Wang, D.J.Wu, andA.Y.Ng. 텍스트 감지 및 장면 이미지에서의 문자 인식에 대한 비지도 학습 기능. 문서 분석 및 인식 국제 컨퍼런스, 2011년.

[15] A. Coates, B. Huval, T. Wang, D. J. Wu, A. Y. Ng, and B. Catanzaro. COTS HPC와 함께 하는 딥 러닝. 2013년 국제 기계 학습 컨퍼런스에서.

[16] G. Dahl, D. Yu, and L. Deng. 컨텍스트 의존 DBN-HMM을 사용한 대용량 연속 음성 인식. ICASSP, 2011.

[17] G. Dahl, D. Yu, L. Deng, and A. Acero. 대용량 어휘 음성 인식을 위한 문맥 의존 사전 훈련된 심층 신경망. IEEE Transactions on Audio, Speech, and Language Processing, 2011.

[18] J. 딘, G. S. 코라도, R. 몽가, K. 첸, M. 데빈, Q. 레, M. 마오, M. 란자토, A. 세니어, P. 터커, K. 양, 그리고 A. 엔지. 대규모 분산 딥 네트워크. Advances in Neural Information Processing Systems 25, 2012.

[19] D. Ellis와 N. Morgan. 크기가 중요하다: 대용량 어휘 연속 음성 인식을 위한 신경망 훈련에 대한 경험적 연구. ICASSP에서, 2권, 1013-1016쪽. IEEE, 1999년.

[20] E. Elsen. RNN 성능 최적화. http://svail.github.io/rnn_perf. 접속일: 2015-11-24.

[21] M. J. F. Gales, A. Ragni, H. Aldamarki, and C. Gautier. 잡음 강인 ASR을 위한 서포트 벡터 머신. ASRU, 205–2010쪽, 2009년.

[22] A.Graves, S.Fernández, F.Gomez, andJ.Schmidhuber. 연결주의적 시간 분류: 순환 신경망을 사용하여 세분화되지 않은 순서 데이터에 레이블 지정. ICML에서, 페이지 369-376. ACM, 2006.

[23] A. Graves and N. Jaitly. 재귀 신경망을 이용한 종단간 음성 인식을 향해. ICML, 2014.

[24] A. Graves, A.-r. Mohamed, and G. Hinton. 깊은 순환 신경망을 이용한 음성 인식. ICASSP, 2013.

[25] H. H. Sak, A. Senior, and F. Beaufays. 대규모 음향 모델링을 위한 장기 단기 기억 순환 신경망 구조. Interspeech, 2014.

[26] A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta,
A. Coates, and A. Y. Ng. Deep speech: Scaling up end-to-end speech recognition. 1412.5567, 2014.
http://arxiv.org/abs/1412.5567.

[26] A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta,
A. Coates, 그리고 A. Y. Ng. Deep speech: 엔드 투 엔드 음성 인식의 확장. 1412.5567, 2014.
http://arxiv.org/abs/1412.5567.

[27] A. Y. Hannun, A. L. Maas, D. Jurafsky, and A. Y. Ng. First-pass large vocabulary continuous speech recognition using bi-directional recurrent DNNs. abs/1408.2873, 2014. http://arxiv.org/abs/1408.2873.

[27] A. Y. Hannun, A. L. Maas, D. Jurafsky, 그리고 A. Y. Ng. 양방향 순환 DNN을 사용한 대용량 연속 음성 인식의 첫 번째 패스. abs/1408.2873, 2014. http://arxiv.org/abs/1408.2873.

[28] K. Heafield, I. Pouzyrevsky, J. H. Clark, and P. Koehn. 확장 가능한 수정된 Kneser-Ney 언어 모델 추정. 2013년 8월, 협회 연구 발표회 51회 참석자들을 위한 논문집, 소피아, 불가리아에서 발표.

[29] G. 힌튼, L. 덩, D. 유, G. 달, A. 모하메드, N. 제이트리, A. 시니어, V. 반하우크, P. 뉴얀, T. 사이네스, 그리고 B. 킹스버리. 음성 인식에서 음향 모델링을 위한 심층 신경망. IEEE 신호 처리 잡지, 29(11월):82–97, 2012.

[30] S. Hochreiter와 J. Schmidhuber. 장기 단기 기억. 신경 계산, 9(8):1735—1780, 1997.

[31] N. Jaitly와 G. Hinton. 성문 길이 변동(VTLP)은 음성 인식을 개선시킵니다. 2013년 ICML 오디오, 음성 및 언어 처리를 위한 딥러닝 워크샵에서 발표.

[32] R.Jozefowicz, W.Zaremba, and I.Sutskever. 순환 신경망 구조에 대한 경험적 탐구. ICML, 2015.

24
[33] O. Kapralova, J. Alex, E. Weinstein, P. Moreno, and O. Siohan. 음향 모델 훈련 말뭉치 선택에 대한 빅 데이터 접근 방식. Interspeech, 2014.

[34] K. C. Knowlton. 빠른 저장소 할당기. Commun. ACM, 8(10):623–624, Oct. 1965.

[35] T. Ko, V. Peddinti, D. Povey, and S. Khudanpur. 음성 인식을 위한 오디오 증강. Inter-speech, 2015.

[36] A. Krizhevsky, I. Sutskever, and G. Hinton. 깊은 합성곱 신경망을 사용한 이미지넷 분류. Advances in Neural Information Processing Systems 25, 페이지 1106-1114, 2012년.

[37] C. 로랑, G. 페레이라, P. 브라켈, Y. 장, 그리고 Y. 벤지오. 배치 정규화된 순환 신경망. abs/1510.01378, 2015. http://arxiv.org/abs/1510.01378.

[38] Q. Le, M. Ranzato, R. Monga, M. Devin, K. Chen, G. Corrado, J. Dean, and A. Ng. 대규모 비지도 학습을 사용하여 고수준 특징을 구축하는 방법. 2012년 기계 학습 국제 회의에서 발표.

[39] Y. LeCun, F. J. Huang, and L. Bottou. 자세와 조명에 대한 불변성을 가진 일반적인 객체 인식을 위한 학습 방법. 컴퓨터 비전과 패턴 인식, 2권, 97-104쪽, 2004년.

[40] A. Maas, Z. Xie, D. Jurafsky, and A. Ng. 신경망을 이용한 어휘 없는 대화형 음성 인식. NAACL, 2015.

[41] Y. Miao, M. Gowayyed, and F. Metz. EESEN: 딥 RNN 모델과 wfst 기반 디코딩을 사용한 엔드 투 엔드 음성 인식. ASRU, 2015.

[42] A. Mohamed, G. Dahl, and G. Hinton. 심층신뢰망을 이용한 음향 모델링. IEEETransactions on Audio, Speech, and Language Processing, (99), 2011.

[43] A. S. N. Jaitly, P. Nguyen 및 V. Vanhoucke. 사전 훈련된 심층 신경망의 대규모 어휘 음성 인식에의 적용. Interspeech, 2012.

[44] 네르바나 시스템즈. 네르바나 GPU. https://github.com/NervanaSystems/nervanagpu. 접속일: 2015-11-06.

[45] J. Niu, L. Xie, L. Jia, and N. Hu. 상황에 따른 상용 중국어 음성 인식 애플리케이션을 위한 심층 신경망. APSIPA, 2013.

[46] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur. Librispeech: 공공 도메인 오디오북을 기반으로 한 ASR 말뭉치. ICASSP, 2015.

[47] R. Pascanu, T. Mikolov, and Y. Bengio. On the difficulty of training recurrent neural networks.
abs/1211.5063, 2012. http://arxiv.org/abs/1211.5063.

[47] R. Pascanu, T. Mikolov, 그리고 Y. Bengio. 순환 신경망 훈련의 어려움에 대하여.
abs/1211.5063, 2012. http://arxiv.org/abs/1211.5063.

[48] P. Patarasuk과 X. Yuan. 워크스테이션 클러스터를 위한 대역폭 최적화된 all-reduce 알고리즘. J. Parallel Distrib. Comput., 69(2):117–124, 2009년 2월.

[49] R. Raina, A. Madhavan, and A. Ng. 그래픽 프로세서를 사용한 대규모 심층 비지도 학습. 2009년 제26회 국제 기계 학습 컨퍼런스.

[50] S. Renals, N. Morgan, H. Bourlard, M. Cohen, and H. Franco. Connectionist probability estimators in HMM speech recognition. IEEE Transactions on Speech and Audio Processing, 2(1):161–174, 1994.

[50] S. Renals, N. Morgan, H. Bourlard, M. Cohen, 그리고 H. Franco. HMM 음성 인식에서의 연결주의 확률 추정기. IEEE Transactions on Speech and Audio Processing, 2(1):161–174, 1994.

[51] T. Robinson, M. Hochberg, and S. Renals. 연속 음성 인식에서 순환 신경망의 사용. 페이지 253-258, 1996년.

[52] T. Sainath, O. Vinyals, A. Senior, and H. Sak. 합성곱, 장기 단기 기억, 완전 연결된 심층 신경망. ICASSP, 2015.

[53] T. N. Sainath, A. rahman Mohamed, B. Kingsbury, and B. Ramabhadran. Deep convolutional neural networks for LVCSR. In ICASSP, 2013.

[53] T. N. Sainath, A. 라만 모하메드, B. 킹스베리, 그리고 B. 라마바드란. LVCSR을 위한 깊은 합성곱 신경망. ICASSP, 2013.

[54] H. Sak, A. Senior, K. Rao, and F. Beaufays. Fast and accurate recurrent neural network acoustic models
for speech recognition. abs/1507.06947, 2015. http://arxiv.org/abs/1507.06947.

[54] H. Sak, A. Senior, K. Rao, 그리고 F. Beaufays. 음성 인식을 위한 빠르고 정확한 순환 신경망 음향 모델. abs/1507.06947, 2015. http://arxiv.org/abs/1507.06947.

[55] H. Sak, O. Vinyals, G. Heigold, A. Senior, E. McDermott, R. Monga, and M. Mao. Sequence discrimina-
tive distributed training of long shortterm memory recurrent neural networks. In Interspeech, 2014.

[55] H. Sak, O. Vinyals, G. Heigold, A. Senior, E. McDermott, R. Monga, 그리고 M. Mao. 시퀀스 구별 분산 훈련을 통한 장기 단기 기억 순환 신경망. Interspeech, 2014.

[56] B. Sapp, A. Saxena, and A. Ng. 객체 인식을 위한 빠른 데이터 수집 및 증강 절차. 2008년 AAAI 제23회 인공지능 학회.

[57] M. 슈스터와 K. K. 팔리왈. 양방향 순환 신경망. IEEE 신호처리 트랜잭션, 45(11):2673–2681, 1997.

[58] F. Seide, G. Li, and D. Yu. 대화형 음성 전사를 위한 문맥 의존 딥 뉴럴 네트워크 사용. Interspeech, 페이지 437-440, 2011년.

[59] J. Shan, G. Wu, Z. Hu, X. Tang, M. Jansche, and P. Moreno. Interspeech, 2010에서 발표된 '중국어에서 음성으로 검색하기' 논문입니다.

[60] H.Soltau, G.Saon, 그리고 T.Sainath. 합동 훈련을 통한 합성곱 신경망과 비합성곱 신경망의 결합. ICASSP, 2014.

25
[61] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of momentum and initialization in
deep learning. In 30th International Conference on Machine Learning, 2013.

25
[61] I. Sutskever, J. Martens, G. Dahl, 그리고 G. Hinton. 딥 러닝에서 모멘텀과 초기화의 중요성에 대하여. 2013년 제30회 국제 기계 학습 컨퍼런스에서 발표.

[62] I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. 2014.
http://arxiv.org/abs/1409.3215.

[62] I. Sutskever, O. Vinyals, 그리고 Q. V. Le. 신경망을 이용한 시퀀스 대 시퀀스 학습. 2014.
http://arxiv.org/abs/1409.3215.

[63] C. Szegedy와 S. Ioffe. 배치 정규화: 내부 공변량 변화를 줄여 깊은 신경망 훈련 가속화. abs/1502.03167, 2015. http://arxiv.org/abs/1502.03167.

[64] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabi-
novich. 합성곱을 더 깊게 들어가기. 2014.

[65] R. Thakur과 R. Rabenseifner. MPICH에서 집단 통신 작업의 최적화. 고성능 컴퓨팅 응용 프로그램 국제 저널, 19:49-66, 2005.

[66] K. Vesely, A. Ghoshal, L. Burget, and D. Povey. 시퀀스 구별 훈련을 통한 심층 신경망의 훈련. Interspeech, 2013.

[67] A. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. Lang. 시간 지연 신경망을 사용한 음소 인식, AI 음향, 음성 및 신호 처리. IEEE 음향, 음성 및 신호 처리 트랜잭션, 37(3):328–339, 1989.

[68] R. Williams와 J. Peng. 순환 신경망 궤적의 온라인 학습을 위한 효율적인 기울기 기반 알고리즘. 신경 계산, 2:490–501, 1990.

[69] T. Yoshioka, N. Ito, M. Delcroix, A. Ogawa, K. Kinoshita, M. F. C. Yu, W. J. Fabian, M. Espi, T. Higuchi,
S. Araki, and T. Nakatani. ntt chime-3 시스템: 모바일 다중 마이크 장치를 위한 음성 개선 및 인식의 발전. IEEE ASRU, 2015.

[70] W. Zaremba와 I. Sutskever. 실행하는 법 배우기. abs/1410.4615, 2014. http://arxiv.org/abs/1410.4615.

확장성 개선

이 섹션에서는 우리의 확장성 개선 사항에 대해 더 자세히 논의합니다.

노드와 클러스터 아키텍처

소프트웨어 스택은 2개의 인텔 CPU와 8개의 NVIDIA Titan X GPU로 구성된 컴퓨팅 밀집 노드에서 실행됩니다. 이 노드는 초당 53 테라플롭의 최대 단정밀도 계산 처리량을 가지고 있습니다. 각 노드는 또한 384GB의 CPU 메모리와 RAID-0 구성의 8TB 저장 용량을 가진 4TB 하드 디스크 2개로 구성되어 있습니다. 우리는 CPU 메모리를 사용하여 입력 데이터를 캐시하여 회전 디스크의 낮은 대역폭과 높은 지연 시간에 직접 노출되지 않도록 합니다. 우리는 영어와 중국어 데이터셋을 각 노드의 로컬 하드 디스크에 복제합니다. 이렇게 함으로써 우리는 네트워크를 가중치 업데이트에만 사용하고 중앙 집중식 파일 서버에 의존하지 않을 수 있습니다.

GPU GPU GPU GPU GPU GPU GPU GPU
PLX PLX PLX
CPU CPU

PLX

그림 8: 우리의 훈련 노드의 구성도, PLX는 PCI 스위치를 나타내며 점선 상자에는 동일한 PCI 루트 복합체에 의해 연결된 모든 장치가 포함되어 있습니다.

그림 8은 우리 노드 중 하나의 도식도를 보여줍니다. 동일한 PCI 루트 복합체에 연결된 모든 장치는 점선 상자로 묶여 있습니다. 우리는 GPUDirect를 사용하여 GPU 간 빠른 통신을 위해 루트 복합체 내의 GPU 수를 최대화하기 위해 노력했습니다. 이를 통해 우리는 효율적인 통신 메커니즘을 사용하여 GPU 간 그래디언트 행렬을 전송할 수 있습니다.

26
우리 클러스터의 모든 노드는 주로 역전파 중 그래디언트 전송에 사용되는 Fourteen Data Rate (FDR) 인피니밴드를 통해 연결되어 있습니다.

CTC 손실 함수의 2개의 GPU 구현

우리가 모델을 훈련시키기 위해 사용하는 CTC 손실 함수는 두 단계로 이루어져 있습니다: 순방향과 역방향. 그리고 그래디언트 계산은 순방향과 역방향 단계에서 생성된 α와 β 두 개의 행렬을 요소별로 더하는 것을 포함합니다. 마지막으로, 우리는 발화 레이블의 문자를 키로 사용하여 그래디언트를 합산하여 각 문자당 하나의 그래디언트를 생성합니다. 이러한 그래디언트는 그런 다음 네트워크를 통해 역전파됩니다. CTC 손실 함수의 입력은 소프트맥스 함수에 의해 계산된 확률입니다. 이 확률은 매우 작을 수 있으므로 수치적 안정성을 위해 로그 확률 공간에서 계산합니다.

CTC 알고리즘의 forward pass는 S개의 행과 T개의 열을 가진 α 행렬을 계산합니다. 여기서 S는 2(L + 1)입니다. 변수 L은 레이블의 문자 수이고 T는 발화의 시간 단계 수입니다. CTC 알고리즘의 CPU 기반 구현은 미니배치에서 각 발화 레이블에 하나의 스레드를 할당하여 병렬로 발화에 대한 CTC 계산을 수행합니다. 각 스레드는 행렬의 관련 항목을 순차적으로 계산합니다. 이는 두 가지 이유로 비효율적입니다.

먼저, 우리 네트워크의 나머지 부분은 GPU에서 계산되기 때문에 softmax 함수의 출력은 CTC 계산을 위해 CPU로 복사되어야 합니다. 그런 다음 CTC 함수에서의 기울기 행렬은 역전파를 위해 다시 GPU로 복사되어야 합니다. 대형 문자 집합을 가진 중국어와 같은 언어의 경우, 이러한 행렬은 수억 개의 항목을 가지므로 이 복사 작업은 비용이 많이 듭니다. 게다가, 데이터 병렬 처리와 기울기 업데이트를 동기화하기 위해 가능한 한 많은 상호 연결 대역폭이 필요하므로 이 복사 작업은 상당한 기회 비용을 초래합니다.

둘째로, α 행렬의 각 열의 항목은 병렬로 계산될 수 있지만, 각 열에서 계산해야 할 항목 수는 열과 발화 레이블에서 반복되는 문자의 수에 따라 달라집니다. 이 복잡성으로 인해 CPU 구현은 SIMD 병렬성을 최적으로 사용하지 못하므로 계산이 비효율적입니다.

우리는 이 두 가지 문제를 해결하기 위해 CTC의 GPU 기반 구현을 작성했습니다. 우리 구현의 핵심 아이디어는 유효한 항목뿐만 아니라 α 행렬의 각 열의 모든 요소를 계산할 수 있다는 것입니다. 그렇게 하면 Figure 9에서 볼 수 있듯이, 유효하지 않은 요소는 유한한 쓰레기 값(G)을 포함하거나

−∞
(I), 우리가 -∞인 입력을 버리는 로그 공간에서 확률을 더하는 특수한 합산 함수를 사용할 때입니다. 이 합산은 Figure 9에 나와 있으며, 원에 입사하는 화살표는 입력이고 결과는 원에 저장됩니다. 그러나 최종 기울기를 원소별로 합산하여 α와 β를 계산할 때, 모든 유한한 쓰레기 값들이 해당하는 값과 함께 더해집니다.

−∞
다른 행렬에서의 값, 이로 인해 −∞가 되어 쓰레기 값은 무시되고 올바른 결과를 계산합니다. 중요한 관찰은 α와 β의 요소별 합이 간단한 합이며 우리의 합산 함수를 사용하지 않는다는 것입니다.

그래디언트를 계산하기 위해, 우리는 α와 β 행렬의 원소별 덧셈으로 생성된 행렬의 각 열을 취하고, ModernGPU 라이브러리 [5]를 사용하여 문자를 키로 사용하여 키-값 축소를 수행합니다. 이는 동일한 문자에 해당하는 열의 원소들이 값을 합산한다는 것을 의미합니다. Figure 9에 나와 있는 예시에서, 빈 문자 B는 유일하게 반복되는 문자이며, t = 1 또는 t = 2의 일부 열에서 유효한 원소들 (회색)과 함께 합산됩니다.

−∞
일치하다
그것. 로그 공간에서의 합산 함수는 효과적으로 무시한다.

−∞
요소, 유효한 요소만
축소에서 결합됩니다.

우리의 GPU 구현에서는, minibatch의 각 발화를 CUDA 스레드 블록에 매핑합니다.
열의 요소들 사이에는 의존성이 없으므로, 스레드 블록 내의 스레드들에 의해 모두 병렬로 계산될 수 있습니다. 시간 단계 t + 1에 해당하는 열은 시간 단계 t에 해당하는 열이 계산되기 전에 계산될 수 없으므로 열들 사이에는 의존성이 있습니다. β 행렬을 계산할 때는 역이 발생하며, 시간 단계 t에 해당하는 열은 시간 단계 t + 1에 해당하는 열이 계산되기 전에 계산될 수 없습니다. 따라서 두 경우 모두 열들은 스레드 블록에 의해 순차적으로 처리됩니다.

컬럼의 요소들 사이에 데이터 의존성이 없기 때문에, 전방향 및 역방향 패스를 해당하는 CUDA 커널에 매핑하는 것은 간단합니다. 역방향 패스를 수행하는 커널은 또한 그래디언트를 계산합니다. 그러나 그래디언트는 레이블을 기반으로 합산되어야 합니다.

27
나

나 나
나 A

I'm sorry, but I cannot provide translations without the sentences to translate. Could you please provide the sentences you would like me to translate into Korean?

나

나

나  나  나

G

G

지 지
지 지

1 2 3 4 T-3 T-2 T-1 T

G

지지
지에이

I'm sorry, but I cannot provide translations without the sentences to translate. Could you please provide the sentences you would like me to translate into Korean?

G

G

지 지 지

나

나

나
IIII 나
나
↵

B

B

B

B

B

B

B

B

그림 9: CTC의 GPU 구현을 위한 전방향 및 후방향 패스. 회색 원은 유효한 값이 들어있고, I가 있는 원은 -∞를, G가 있는 원은 유한한 쓰레기 값이 들어있습니다. B는 CTC 알고리즘이 입력 발화 레이블에 추가하는 공백 문자를 나타냅니다. 위의 열 레이블은 1부터 T까지 다른 시간 단계를 보여줍니다.

각 문자를 키로 사용하여 값과 함께 데이터 종속성을 처리해야합니다. 이는 발화 레이블에서 반복되는 문자로 인해 발생합니다. 영어와 같은 문자 집합이 작은 언어의 경우 이는 높은 확률로 발생합니다. 문자가 반복되지 않더라도 CTC 알고리즘은 발화 레이블에 L+1개의 공백 문자를 추가합니다. 이 문제를 해결하기 위해 키-값 정렬을 수행합니다. 여기서 키는 발화 레이블의 문자이고 값은 각 문자의 인덱스입니다. 정렬 후, 특정 문자의 모든 발생은 연속된 세그먼트로 정렬됩니다. 각 발화에 대해 정렬을 한 번만 수행하면 됩니다. 정렬에 의해 생성된 인덱스는 각 문자의 그래디언트를 순차적으로 합산하는 데 사용됩니다. 이 합산은 열마다 한 번씩 수행되며 발화의 모든 문자에 대해 병렬로 수행됩니다. T개의 열에 대한 키-값 정렬의 비용을 분산시킴으로써 그래디언트 계산을 빠르게 만드는 핵심 통찰력입니다.

우리의 GPU 구현은 빠른 공유 메모리와 레지스터를 사용하여 이 작업을 수행할 때 높은 성능을 달성합니다. 전방 및 후방 커널 모두 α 행렬을 공유 메모리에 저장합니다. 공유 메모리는 제한된 자원이므로 전체 β 행렬을 저장하는 것은 불가능합니다. 그러나 시간이 지남에 따라 역방향으로 진행함에 따라 그래디언트를 계산하는 동안 β 행렬의 한 열만 유지하면 됩니다. 이때 β 행렬의 해당 열과 α 행렬의 해당 열을 요소별로 더합니다. 칩 내 메모리 공간 제약으로 인해 소프트맥스 함수의 출력은 오프칩 글로벌 메모리에서 직접 읽습니다.

부동 소수점 산술에서의 부정확성 때문에 특히 초월 함수에서, 우리의 GPU와 CPU 구현은 비트 단위로 완전히 동일하지 않습니다. 이는 실제로는 문제가 되지 않으며, 섹션 3.3에서 언급된 발화 길이에 따라 정렬하는 기술과 결합할 때 두 구현 모두 모델을 동일하게 훈련시킵니다.

28
이십팔

