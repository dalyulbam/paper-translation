• 각 레이어는 자체의 임베딩 행렬 Ak, Ck를 가지고 있으며, 입력 {xi}를 임베딩하는 데 사용됩니다. 그러나 아래에서 설명한 대로, 훈련을 용이하게 하고 매개변수의 수를 줄이기 위해 제한됩니다.
• 네트워크의 맨 위에서, W에 대한 입력은 또한 최상위 메모리 레이어의 입력과 출력을 결합합니다: ˆ a = Softmax(WuK+1) = Softmax(W(oK + uK)).

우리는 모델 내에서 두 가지 종류의 가중치 연결을 탐구합니다.

1. 인접한: 한 레이어의 출력 임베딩은 그 위의 레이어의 입력 임베딩입니다. 즉, Ak+1 = Ck입니다. 또한 (a) 답변 예측 행렬은 최종 출력 임베딩과 동일하도록 제약을 가하며, 즉 WT = CK입니다. 그리고 (b) 질문 임베딩은 첫 번째 레이어의 입력 임베딩과 일치하도록 제약을 가합니다. 즉, B = A1입니다.
2. 레이어별 (RNN과 유사한): 입력 및 출력 임베딩은 다른 레이어 간에 동일합니다. 즉, A1 = A2 = ... = AK 및 C1 = C2 = ... = CK입니다. 우리는 각 호프 사이의 u의 업데이트에 선형 매핑 H를 추가하는 것이 유용하다고 발견했습니다. 즉, uk+1 = Huk + ok입니다. 이 매핑은 나머지 매개변수와 함께 학습되며, 레이어별 가중치 연결을 위해 우리의 실험 전체에서 사용됩니다.

우리의 메모리 모델의 3계층 버전은 그림 1(b)에 나와 있습니다. 전반적으로, 이는 [23]의 메모리 네트워크 모델과 유사하지만, 각 계층 내의 hard max 연산은 softmax로부터의 연속적인 가중치로 대체되었습니다.

레이어별 가중치 연결 체계를 사용한다면, 우리의 모델은 전통적인 RNN으로 캐스팅될 수 있으며, RNN의 출력을 내부 출력과 외부 출력으로 나눌 수 있습니다. 내부 출력을 내보내는 것은 메모리를 고려하는 것에 해당하며, 외부 출력을 내보내는 것은 레이블을 예측하는 것에 해당합니다. RNN의 관점에서, 그림 1(b)와 방정식 4에서의 u는 숨겨진 상태이며, 모델은 A를 사용하여 내부 출력 p (그림 1(a)의 어텐션 가중치)를 생성합니다. 모델은 그런 다음 C를 사용하여 p를 흡수하고, 숨겨진 상태를 업데이트하고, 이와 같은 과정을 반복합니다. 여기서 표준 RNN과 달리, K번의 점프 동안 메모리에 저장된 출력에 명시적으로 조건을 걸고, 이러한 출력을 샘플링하는 대신 소프트하게 유지합니다. 따라서 우리의 모델은 "외부 세계"에서 볼 수 있는 출력을 생성하기 전에 여러 계산 단계를 거칩니다.

3 관련 연구

최근의 여러 노력들은 RNN이나 LSTM 기반 모델을 사용하여 시퀀스 내에서 장기적인 구조를 포착하는 방법을 탐구해왔다 [4, 7, 12, 15, 10, 1]. 이러한 모델들의 메모리는 네트워크의 상태로, 장기적으로는 잠재적이고 불안정하다. LSTM 기반 모델은 이를 해결하기 위해 과거의 네트워크 상태를 잠그는 로컬 메모리 셀을 사용한다. 실제로, 정교하게 훈련된 RNN과 비교했을 때 성능 향상은 미미하다 (Mikolov et al. [15] 참조). 우리의 모델은 이와 달리 전역 메모리를 사용하며, 공유된 읽기 및 쓰기 기능을 갖추고 있다. 그러나, 레이어별 가중치 연결을 통해 우리의 모델은 고정된 시간 단계 후에만 출력을 생성하는 RNN의 한 형태로 볼 수 있으며, 중간 단계에서는 메모리 입력/출력 작업이 수행되어 내부 상태를 업데이트한다.

스타인부흐와 피스케[19] 그리고 테일러[21]의 초기 신경망 연구 중 일부는 저장된 입력 벡터에 대해 최근접 이웃 연산을 수행하고 검색된 집합에 대해 매개변수 모델을 적합시키는 메모리를 고려했습니다. 이는 우리 모델의 단일 레이어 버전과 유사한 점이 있습니다.

1990년대의 후속 연구에서는 다른 유형의 메모리를 탐구했습니다 [18, 5, 16]. 예를 들어, Das et al. [5]와 Mozer et al. [16]는 푸시(push)와 팝(pop) 작업이 있는 명시적 스택을 소개했으며, 최근에는 [11]에서 RNN 모델의 맥락에서 재방문되었습니다.

우리 모델과 밀접한 관련이 있는 것은 Graves et al. [8]의 Neural Turing Machine이다. 이 모델은 연속적인 메모리 표현을 사용한다. NTM 메모리는 내용과 주소 기반 접근을 모두 사용하지만, 우리 모델은 명시적으로 전자만 허용한다. 그러나 우리가 4.1절에서 소개할 시간적 특징은 어떤 종류의 주소 기반 접근을 허용한다. 그러나 우리 모델은 메모리를 항상 순차적으로 쓰기 때문에, NTM의 선명화와 같은 작업이 필요하지 않아서 다소 간단하다. 또한, 우리는 텍스트 추론 작업에 우리의 메모리 모델을 적용하며, 이는 NTM이 다루는 정렬과 회상과 같은 보다 추상적인 작업과는 질적으로 다르다.

이 관점에서는, 그림 1의 입력과 출력의 용어가 뒤바뀐 것에 유의하십시오 - 이 특별한 출력 조건을 가진 전통적인 RNN으로 볼 때, A는 RNN의 출력 임베딩의 일부가 되고, C는 입력 임베딩이 됩니다.

우리의 모델은 또한 Bahdanau et al. [2]와 관련이 있습니다. 그 작업에서는 양방향 RNN 기반 인코더와 게이트 RNN 기반 디코더가 기계 번역에 사용되었습니다. 디코더는 다음 번역 단어를 출력하는 데 가장 유용한 인코딩의 숨겨진 상태를 찾는 어텐션 모델을 사용합니다. 어텐션 모델은 디코더의 현재 숨겨진 상태와 각 인코더의 숨겨진 상태를 연결한 것을 입력으로 사용하는 작은 신경망을 사용합니다. 유사한 어텐션 모델은 이미지 캡션 생성을 위해 Xu et al. [24]에서도 사용됩니다. 우리의 "메모리"는 그들의 어텐션 메커니즘과 유사하지만, [2]는 우리의 경우와 달리 단일 문장에 대해서만 적용됩니다. 또한, 우리의 모델은 출력을 만들기 전에 메모리에서 여러 번의 점프를 수행합니다. 우리는 아래에서 이것이 좋은 성능을 위해 중요하다는 것을 알게 될 것입니다. 또한, 메모리를 점수화하는 작은 네트워크의 아키텍처에도 차이가 있습니다. 우리는 간단한 선형 레이어를 사용하고, 그들은 더 복잡한 게이트 아키텍처를 사용합니다.

우리는 우리의 모델을 언어 모델링에 적용할 것입니다. 이는 광범위하게 연구된 작업입니다. Goodman [6]는 n-gram과 캐시를 결합한 간단하면서도 효과적인 접근법을 보여주었습니다. Bengio et al. [3]은 RNN [14]과 LSTM [10, 20]을 사용한 신경망 기반 모델을 사용하는 것에 대한 관심을 불러일으켰으며, 이러한 모델들이 전통적인 방법보다 성능 향상을 보여주었습니다. 실제로, 현재 최첨단 기술은 이러한 모델의 변형에 의해 보유되고 있으며, 예를 들어 Dropout [25]이 적용된 매우 큰 LSTM이나 가중치 행렬에 대한 대각 제약 조건이 있는 RNN 등입니다. 적절한 가중치 연결을 통해, 우리의 모델은 시퀀스 자체가 아닌 단어 시퀀스에 대한 메모리 조회를 통해 인덱싱되는 RNN의 수정된 형태로 간주될 수 있습니다.

4개의 합성 질문 및 답변 실험

우리는 [22]에서 정의된 합성 QA 작업에 대한 실험을 수행합니다 (데이터셋의 버전 1.1을 사용).
주어진 QA 작업은 일련의 문장으로 구성되어 있으며, 일반적으로 단어 하나로 대답되는 질문이 뒤따릅니다 (일부 작업에서는 단어 집합으로 대답됩니다). 답은 모델이 훈련 시간에 사용할 수 있지만, 테스트 시간에 예측해야 합니다. 총 20가지 다른 유형의 작업이 있으며, 이는 다양한 추론과 추론 형태를 조사합니다. 다음은 세 가지 작업의 샘플입니다:
Sam은 부엌으로 들어갑니다. Brian은 사자입니다. Mary는 굴로 여행했습니다.
Sam은 사과를 집어들었습니다. Julius는 사자입니다. Mary는 다시 부엌으로 돌아갔습니다.
Sam은 침실로 들어갑니다. Julius는 흰색입니다. John은 침실로 여행했습니다.
Sam은 사과를 떨어뜨립니다. Bernhard는 초록색입니다. Mary는 우유를 버렸습니다.
Q: 사과는 어디에 있나요? Q: Brian은 어떤 색인가요? Q: 굴 이전에 우유는 어디에 있었나요?
A. 침실       A. 흰색       A. 복도

각 질문에 대해, 답에 필요한 정보가 포함된 문장의 일부만이 있으며, 다른 문장들은 사실상 관련이 없는 주의 분산 요소입니다 (예: 첫 번째 예시의 첫 번째 문장). Weston et al.의 기억 네트워크에서는 [22], 이 지원하는 하위 집합이 모델에게 명시적으로 표시되어 훈련 중에 제공되었으며, 이 작업과의 주요 차이점은 이 정보가 더 이상 제공되지 않는다는 것입니다. 따라서 모델은 훈련 및 테스트 시에 어떤 문장이 관련이 있는지, 어떤 문장이 관련이 없는지를 스스로 추론해야 합니다.

공식적으로, 20개의 QA 작업 중 하나에 대해 우리는 예시 문제들을 제공받습니다. 각 문제는 I개의 문장 {xi}를 가지고 있으며, I는 320 이하입니다. 또한 질문 문장 q와 답변 a도 함께 제공됩니다. 문장 i의 j번째 단어를 xij라고 하며, 이는 길이 V의 원핫 벡터로 표현됩니다 (여기서 어휘 크기 V는 V = 177로, QA 언어의 단순한 특성을 반영합니다). 질문 q와 답변 a에도 동일한 표현이 사용됩니다. 데이터는 두 가지 버전으로 사용되며, 하나는 각 작업당 1000개의 훈련 문제를 가지고 있고, 다른 하나는 각 작업당 10,000개의 문제를 가지고 있습니다.

4.1 모델 세부사항

그렇게 명시되지 않은 경우, 모든 실험은 인접 가중치 공유 방식을 사용하는 K = 3 홉 모델을 사용했습니다. 목록을 출력하는 모든 작업에 대해 (즉, 답변이 여러 단어인 경우), 가능한 출력의 모든 조합을 가져와 별도의 답변 어휘 단어로 기록합니다.

우리의 실험에서는 문장에 대해 두 가지 다른 표현 방법을 탐구합니다. 첫 번째는 단어 가방 (BoW) 표현입니다. 이 표현은 문장 xi = {xi1,xi2,...,xin}을 가져와 각 단어를 임베딩하고 결과 벡터를 합산합니다. 예를 들어 mi = (cid:80)입니다.

j
Axij and
ci = (cid:80)
j
Cxij. 질문을 나타내는 입력 벡터 u도 단어들의 모음으로 임베딩됩니다:
u = (cid:80)
j
Bqj. 이는 문장 내 단어들의 순서를 포착할 수 없다는 단점이 있습니다. 이는 일부 작업에 있어서 중요합니다.

그러므로 우리는 문장 내에서 단어의 위치를 인코딩하는 두 번째 표현을 제안합니다. 이는 다음과 같은 형태를 가집니다: mi = (cid:80)

요소별 곱셈인 경우 lj · Axij, 여기서 ·는 요소별 곱셈을 나타냅니다. lj는

4
구조가 있는 열 벡터 lkj = (1−j/J)−(k/d)(1−2j/J) (1부터 시작하는 인덱싱을 가정),
여기서 J는 문장의 단어 수이고, d는 임베딩의 차원입니다. 이 문장 표현은 우리가 위치 인코딩(PE)이라고 부르는 것으로, 단어의 순서가 이제 mi에 영향을 미칩니다. 같은 표현은 질문, 메모리 입력 및 메모리 출력에도 사용됩니다.

시간적 인코딩: 많은 QA 작업은 시간적 문맥의 개념을 필요로 합니다. 즉, 섹션 2의 첫 번째 예제에서 모델은 샘이 부엌에 있기 전에 침실에 있는 것을 이해해야 합니다. 우리의 모델이 이를 처리할 수 있도록 하기 위해, 우리는 메모리 벡터를 수정하여 mi = (cid:80) j Axij + TA(i)가 되도록 합니다. 여기서 TA(i)는 시간 정보를 인코딩하는 특수 행렬 TA의 i번째 행입니다. 출력 임베딩은 동일한 방식으로 행렬 Tc로 확장됩니다. (예: ci = (cid:80) j Cxij + TC(i)). TA와 TC는 훈련 중에 학습됩니다. 또한 A와 C와 동일한 공유 제약 조건에 따릅니다. 문장은 질문으로부터의 상대적 거리를 반영하여 역순으로 색인화됩니다. 따라서 x1은 이야기의 마지막 문장입니다.

무작위 잡음을 주입하여 시간 불변성 학습: 우리는 TA를 규제하기 위해 "가짜" 기억을 추가하는 것이 도움이 되는 것으로 발견했습니다. 즉, 훈련 시간에 우리는 이야기에 10%의 빈 기억을 무작위로 추가할 수 있습니다. 이 접근 방식을 무작위 잡음 (RN)이라고 합니다.

4.2 훈련 세부사항

bAbI 훈련 세트의 10%는 검증 세트를 구성하기 위해 보류되었으며, 이는 최적의 모델 구조와 하이퍼파라미터를 선택하는 데 사용되었습니다. 우리의 모델은 학습률 η = 0.01을 사용하여 훈련되었으며, 100 에포크에 도달할 때까지 25 에포크마다 η/2로 앤닐링되었습니다. 모멘텀이나 가중치 감쇠는 사용되지 않았습니다. 가중치는 평균이 0이고 표준편차가 σ = 0.1인 가우시안 분포에서 무작위로 초기화되었습니다. 1k 훈련 샘플 (10k 훈련 샘플)로 모든 작업을 동시에 훈련할 때, 60 에포크 (20 에포크)가 사용되었으며, 학습률 앤닐링은 15 에포크마다 (5 에포크마다) η/2로 이루어졌습니다. 모든 훈련은 배치 크기 32를 사용하며 (하지만 비용은 배치 전체에 대해 평균화되지 않음), 그라디언트의 (cid:96)2 노름이 40보다 큰 경우에는 스칼라로 나누어 노름이 40이 되도록 조정되었습니다. 일부 실험에서는 각 메모리 레이어에서 소프트맥스를 제거하고 훈련을 시작하는 것도 탐구하였으며, 이로 인해 최종 소프트맥스를 제외한 모델이 완전히 선형이 되었습니다. 검증 손실이 감소하지 않을 때, 소프트맥스 레이어가 다시 삽입되고 훈련이 재개되었습니다. 이를 선형 시작 (LS) 훈련이라고 합니다. LS 훈련에서 초기 학습률은 η = 0.005로 설정됩니다. 메모리의 용량은 가장 최근 50개의 문장으로 제한되었습니다. 문장의 수와 문장 당 단어 수가 문제마다 다르기 때문에, 모든 문장을 고정된 크기로 패딩하기 위해 널 심볼이 사용되었습니다. 널 심볼의 임베딩은 0으로 제한되었습니다.

일부 작업에서는 모델의 성능에 큰 분산을 관찰했습니다 (즉, 초기화에 따라 때로는 심각한 실패, 때로는 그렇지 않음). 이를 해결하기 위해 우리는 각 훈련을 10번 반복하여 다른 무작위 초기화로 진행하고, 훈련 오차가 가장 낮은 것을 선택했습니다.

4.3 기준선

우리는 우리의 접근 방식 2 (MemN2N으로 약칭)을 다양한 대체 모델과 비교합니다.

• MemNN: [22]에서 제안된 강력하게 지도된 AM+NG+NL 메모리 네트워크 접근 방식입니다. 이는 해당 논문에서 보고된 최상의 접근 방식입니다. 각 레이어에서는 소프트맥스 대신 최대 연산을 사용하며 (강력한 지도), 지원하는 사실들과 직접 훈련됩니다. 이는 n-gram 모델링, 비선형 레이어 및 쿼리당 적응적인 호핑 수를 사용합니다.

MemNN-WSH: MemNN의 약한 지도 학습 휴리스틱 버전으로, 지원 문장 레이블을 훈련에 사용하지 않습니다. 각 레이어의 max 연산을 역전파할 수 없기 때문에, 첫 번째 메모리 홉은 질문과 적어도 한 단어를 공유해야 하고, 두 번째 메모리 홉은 첫 번째 홉과 답변과 적어도 한 단어를 공유해야 합니다. 이러한 조건을 충족하는 모든 메모리를 유효한 메모리라고 하며, 훈련 중 목표는 강력하게 지도된 훈련과 동일한 순위 기준을 사용하여 유효한 메모리를 무효한 메모리보다 높은 순위로 배치하는 것입니다.

• LSTM: 질문/답변 쌍만을 사용하여 훈련된 표준 LSTM 모델입니다 (즉, 약한 지도 학습도 포함됩니다). 자세한 내용은 [22]를 참조하세요.

2 MemN2N 소스 코드는 https://github.com/facebook/MemNN에서 사용할 수 있습니다.

5
4.4 결과

우리는 다양한 디자인 선택지를 보고합니다: (i) BoW 대 위치 인코딩 (PE) 문장 표현; (ii) 모든 20개의 작업을 독립적으로 훈련하는 것 대 공동 훈련 (공동 훈련은 임베딩 차원 d = 50을 사용하고, 독립적인 훈련은 d = 20을 사용함); (iii) 선형 시작 (LS)으로 두 단계 훈련: 처음에 소프트맥스를 제거하는 것 대 처음부터 소프트맥스와 함께 훈련하는 것; (iv) 1에서 3까지 다양한 메모리 홉.

20개의 작업에 대한 결과는 1k 훈련 세트에 대해 표 1에 제시되었으며, 10k 훈련 세트에 대한 평균 성능과 함께 나타납니다. 이 결과는 몇 가지 흥미로운 점을 보여줍니다.

• 최고의 MemN2N 모델은 지도 모델에 근접한 결과를 보여줍니다 (예: MemNN의 경우 1k: 6.7% 대 MemN2N의 경우 12.6% (위치 인코딩 + 선형 시작 + 무작위 잡음, 공동 훈련) 및 10k: MemNN의 경우 3.2% 대 MemN2N의 경우 4.2% (위치 인코딩 + 선형 시작 + 무작위 잡음 + 비선형성4), 그러나 지도 모델이 여전히 우수합니다.
• 제안된 모델의 모든 변형은 약한 지도 기준선 방법을 훨씬 능가합니다.
• 위치 인코딩 (PE) 표현은 단어 순서가 특히 중요한 작업 4, 5, 15 및 18에서 명확한 개선을 보여줍니다.
• 훈련에 대한 선형 시작 (LS)은 지역 최소값을 피하는 데 도움이 되는 것으로 보입니다. 표 1의 작업 16에서 PE만 사용하면 53.6%의 오류가 발생하지만, LS를 사용하면 1.6%로 감소합니다.
• Section 4.1에서 설명한 무작위 빈 기억으로 시간 인덱스를 흔들어주는 것은 성능을 약간 향상시킵니다. 특히 작은 1k 훈련 세트에 대해 더욱 두드러진 효과를 보입니다.
• 모든 작업에 대한 공동 훈련이 도움이 됩니다.
• 중요한 점은 더 많은 계산적인 점프가 성능을 향상시킵니다. 그림 2와 부록 B의 일러스트 예제에서 eq. (1)의 값에 따라 수행된 점프의 예를 제시합니다.

베이스라인              MemN2N
강하게              PE 1hop 2hops 3hops PE PELS
지도학습 LSTM MemNN PE LS PELS PELS PELS LSRN LW
작업      MemNN[22] [22] WSH BoW PE LS RN joint joint joint joint joint
1:1지지하는사실 0.0 50.0 0.1 0.6 0.1 0.2 0.0 0.8 0.0 0.1 0.0 0.1
2:2지지하는사실 0.0 80.0 42.8 17.6 21.6 12.8 8.3 62.0 15.6 14.0 11.4 18.8
3:3지지하는사실 0.0 80.0 76.4 71.0 64.2 58.8 40.3 76.9 31.6 33.1 21.9 31.7
4:2논증관계 0.0 39.0 40.3 32.0 3.8 11.6 2.8 22.8 2.2 5.7 13.4 17.5
5:3논증관계 2.0 30.0 16.3 18.3 14.1 15.7 13.1 11.0 13.4 14.8 14.4 12.9
6:예/아니오질문 0.0 52.0 51.0 8.7 7.9 8.7 7.6 7.2 2.3 3.3 2.8 2.0
7:계산  15.0 51.0 36.1 23.5 21.6 20.3 17.3 15.9 25.4 17.9 18.3 10.1
8:리스트/집합 9.0 55.0 37.8 11.4 12.6 12.7 10.0 13.2 11.7 10.1 9.3 6.1
9:부정문 0.0 36.0 35.9 21.1 23.3 17.0 13.2 5.1 2.0 3.1 1.9 1.5
10:불확실한지식 2.0 56.0 68.7 22.8 17.4 18.6 15.1 10.6 5.0 6.6 6.5 2.6
11:기본적인대용어 0.0 38.0 30.0 4.1 4.3 0.0 0.9 8.4 1.2 0.9 0.3 3.3
12:연결사 0.0 26.0 10.1 0.3 0.3 0.1 0.2 0.4 0.0 0.3 0.1 0.0
13:복합대용어 0.0 6.0 19.7 10.5 9.9 0.3 0.4 6.3 0.2 1.4 0.2 0.5
14:시간추론 1.0 73.0 18.3 1.3 1.8 2.0 1.7 36.9 8.1 8.2 6.9 2.0
15:기본적인추론 0.0 79.0 64.8 24.3 0.0 0.0 0.0 46.4 0.5 0.0 0.0 1.8
16:기본적인귀납 0.0 77.0 50.5 52.0 52.1 1.6 1.3 47.4 51.3 3.5 2.7 51.0
17:위치추론 35.0 49.0 50.9 45.4 50.1 49.0 51.0 44.4 41.2 44.5 40.4 42.6
18:크기추론 5.0 48.0 51.3 48.1 13.6 10.1 11.1 9.6 10.3 9.2 9.4 9.2
19:경로찾기 64.0 92.0 100.0 89.7 87.4 85.6 82.8 90.7 89.9 90.2 88.0 90.6
20:에이전트의동기 0.0 9.0 3.6 0.1 0.0 0.0 0.0 0.0 0.1 0.0 0.0 0.2
평균오차(%) 6.7 51.3 40.2 25.1 20.3 16.3 13.9 25.8 15.6 13.3 12.4 15.2
실패한작업(오차> 5%) 4 20 18 15 13 12 11 17 11 11 11 10

10k 훈련 데이터에서
평균 오차(%) 3.2 36.4 39.2 15.4 9.4 7.2 6.6 24.5 10.9 7.9 7.5 11.0
실패한 작업(오차 > 5%) 2 16 17 9 6 4 4 16 7 6 6 6

표 1: 1천 개의 훈련 예제를 사용하는 모델의 20개 QA 작업에 대한 테스트 오류율(1만 개의 훈련 예제에 대한 평균 테스트 오류는 아래에 표시됨). 키: BoW = 단어 가방 표현; PE = 위치 인코딩 표현; LS = 선형 시작 훈련; RN = 시간 인덱스 노이즈의 무작위 주입; LW = RNN 스타일의 계층별 가중치 연결(인접 가중치 연결이 아닌 경우); joint = 모든 작업에 대한 공동 훈련(작업별 훈련과 대조적).

5 언어 모델 실험

언어 모델링의 목표는 이전 단어 x가 주어진 텍스트 시퀀스에서 다음 단어를 예측하는 것입니다. 이제 우리 모델이 이 작업에 쉽게 적용될 수 있는 방법을 설명하겠습니다.

3 10k 훈련 세트에 대한 더 자세한 결과는 부록 A에서 찾을 수 있습니다.
4 [17]를 따라가면 더 많은 비선형성을 추가하여 작업 17과 19를 해결할 수 있다는 것을 발견했습니다. 부록 A를 참조하세요.

6
이야기 (1: 1개의 지지하는 사실) 지지하기 1 지지하기 2 지지하기 3 이야기 (2: 2개의 지지하는 사실) 지지하기 1 지지하기 2 지지하기 3
다니엘은 화장실에 갔다. 0.00 0.00 0.03 존은 우유를 떨어뜨렸다. 0.06 0.00 0.00
메리는 복도로 여행했다. 0.00 0.00 0.00 존은 거기서 우유를 가져갔다. 예 0.88 1.00 0.00
존은 침실로 갔다. 0.37 0.02 0.00 샌드라는 화장실로 돌아갔다. 0.00 0.00 0.00
존은 화장실로 여행했다. 예 0.60 0.98 0.96 존은 복도로 이동했다. 예 0.00 0.00 1.00
메리는 사무실로 갔다. 0.01 0.00 0.00 메리는 침실로 돌아갔다. 0.00 0.00 0.00

이야기 (16: 기본 유도) 지원 홉 1 홉 2 홉 3 이야기 (18: 크기 추론) 지원 홉 1 홉 2 홉 3
브라이언은 개구리입니다. 예 0.00 0.98 0.00 가방은 상자보다 큽니다. 예 0.00 0.88 0.00
릴리는 회색입니다. 0.07 0.00 0.00 상자는 초콜릿보다 큽니다. 0.04 0.05 0.10
브라이언은 노란색입니다. 예 0.07 0.00 1.00 상자는 초콜릿보다 큽니다. 예 0.17 0.07 0.90
줄리어스는 초록색입니다. 0.06 0.00 0.00 상자가 컨테이너 안에 들어갑니다. 0.00 0.00 0.00
그렉은 개구리입니다. 예 0.76 0.02 0.00 상자가 가방 안에 들어갑니다. 0.00 0.00 0.00
존은 어디에 있나요? 답변: 화장실 예측: 화장실 우유는 어디에 있나요? 답변: 복도 예측: 복도

그렉은 어떤 색인가요? 답: 노란색 예측: 노란색 슈트케이스가 초콜릿 안에 들어갈까요? 답: 아니요 예측: 아니요

그림 2: [22]의 QA 작업에 대한 예측 예시입니다. 우리는 MemN2N이 훈련 중에 사용하지 않는 데이터셋의 라벨이 지정된 지지 사실 (support)을 보여주며, 추론 중에 모델이 사용하는 각 hop의 확률 p를 보여줍니다. MemN2N은 올바른 지지 문장에 집중하는 것을 성공적으로 학습합니다.

Penn Treebank             Text8
#의 #의 메모리 유효성 검사. 테스트 #의 #의 메모리 유효성 검사. 테스트
모델  숨겨진 점프 크기 퍼플렉서티 퍼플렉서티 숨겨진 점프 크기 퍼플렉서티 퍼플렉서티
RNN [15] 300 -    -   133  129 500   -    -    -  184
LSTM [15] 100 -   -   120  115 500   -    -   122 154
SCRN [15] 100 -   -   120  115 500   -    -    -  161
MemN2N  150  2   100  128  121 500   2   100  152 187
150  3   100  129  122 500   3   100  142 178
150  4   100  127  120 500   4   100  129 162
150  5   100  127  118 500   5   100  123 154
150  6   100  122  115 500   6   100  124 155
150  7   100  120  114 500   7   100  118 147
150  6    25  125  118 500   6   25   131 163
150  6    50  121  114 500   6   50   132 166
150  6    75  122  114 500   6   75   126 158
150  6   100  122  115 500   6   100  124 155
150  6   125  120  112 500   6   125  125 157
150  6   150  121  114 500   6   150  123 154
150  7   200  118  111  -    -    -    -   -

표 2: 펜 트리뱅크와 텍스트8 코퍼스의 테스트 세트에서의 혼란도. 메모리 홉의 수를 늘리면 성능이 향상됨을 유의하십시오.

그림 3: 6개의 메모리 홉 동안의 평균 활성화 가중치. 흰색은 모델이 k번째 홉 동안 주의를 기울이는 위치를 나타냅니다. 명확성을 위해 각 행은 최대값이 1이 되도록 정규화되었습니다. 모델은 (왼쪽) Penn Treebank와 (오른쪽) Text8 데이터셋으로 훈련되었습니다.

우리는 이제 문장 수준이 아닌 단어 수준에서 작동합니다. 따라서 이전 N개의 단어(현재 단어 포함)는 따로 메모리에 임베딩됩니다. 각 메모리 셀은 하나의 단어만을 담고 있으므로 QA 작업에서 사용되는 BoW나 선형 매핑 표현이 필요하지 않습니다. 우리는 4.1절의 시간적 임베딩 접근 방식을 사용합니다.

이제 더 이상 질문이 없으므로, 그림 1의 q는 상수 벡터 0.1로 고정됩니다 (임베딩 없이). 출력 softmax는 어휘 (크기 V)에서 다음에 오는 단어를 예측합니다. 교차 엔트로피 손실을 사용하여 모델을 훈련시키고, QA 작업과 동일한 방식으로 오류를 다중 메모리 레이어를 통해 역전파합니다. 훈련을 돕기 위해 각 레이어의 절반 단위에 ReLU 연산을 적용합니다. 레이어별 (RNN과 유사한) 가중치 공유를 사용합니다. 즉, 각 레이어의 쿼리 가중치는 동일하고, 각 레이어의 출력 가중치도 동일합니다. 2.2절에서 언급한 바와 같이, 이는 우리의 아키텍처가 언어 모델링에 전통적으로 사용되는 RNN과 밀접하게 관련되어 있음을 의미합니다.

7
모델링 작업; 그러나 여기서 네트워크가 재발하는 "순서"는 텍스트가 아니라 메모리 홉에 있습니다. 또한, 가중치 연결은 모델의 매개변수 수를 제한하여 이 작업에 효과적인 더 깊은 모델의 일반화를 도와줍니다. 우리는 두 가지 다른 데이터셋을 사용합니다.

Penn Tree Bank [13]: 이는 10,000개의 단어로 구성된 어휘를 통해 분산된 929,000/73,000/82,000개의 훈련/검증/테스트 단어로 이루어져 있습니다. [25]와 동일한 전처리가 사용되었습니다.

이것은 위키피디아에서 덤프된 첫 100M 문자의 사전 처리된 버전입니다. 이것은 93.3M/5.7M/1M 문자로 나누어진 훈련/검증/테스트 세트로 구성되어 있습니다. 5회 미만으로 발생하는 모든 단어는 <UNK> 토큰으로 대체되어 약 44k의 어휘 크기를 가지게 됩니다.

5.1 훈련 세부 정보
우리가 사용하는 훈련 절차는 QA 작업과 동일하지만, 다음과 같은 차이가 있습니다. 각 미니 배치 업데이트마다 모든 매개변수의 전체 그래디언트의 (cid:96)2 노름을 측정하고, 이 값이 L = 50보다 크면 L의 노름을 가지도록 축소합니다. 이것은 좋은 성능을 위해 중요합니다. 우리는 [15]에서 제안한 학습률 감소 스케줄을 사용합니다. 즉, 검증 비용이 한 epoch 후에도 감소하지 않으면 학습률을 1.5배로 축소합니다. 학습은 학습률이 10^-5보다 작아지면 종료됩니다. 즉, 약 50개의 epoch 후에 종료됩니다. 가중치는 N(0,0.05)를 사용하여 초기화되고 배치 크기는 128로 설정됩니다. Penn tree 데이터셋에서는 각 훈련을 10번 반복하여 서로 다른 무작위 초기화를 사용하고, 검증 비용이 가장 작은 것을 선택합니다. 그러나 Text8 데이터셋에서는 제한된 시간 제약으로 인해 단일 훈련 실행만 수행했습니다.

5.2 결과
표 2는 우리의 모델을 RNN, LSTM 및 구조적으로 제한된 순환 신경망(SCRN) [15]과 비교한 결과를 보여줍니다. 기준선 아키텍처는 [15]에서 최적의 퍼플렉서티를 얻기 위해 조정되었습니다. 우리의 MemN2N 접근법은 두 데이터셋 모두에서 낮은 퍼플렉서티를 달성합니다 (Penn에서 RNN/SCRN은 111 대 115, Text8에서 LSTM은 147 대 154). MemN2N은 동일한 숨겨진 유닛 수를 가진 RNN보다 약 1.5배 많은 매개변수를 가지고 있으며, LSTM은 약 4배 많은 매개변수를 가지고 있습니다. 또한 MemN2N의 호핑 수와 메모리 크기를 변화시켜 성능의 기여도를 보여줍니다. 특히 호핑 수를 증가시키는 것이 도움이 된다는 것을 주목하세요. 그림 3에서는 MemN2N이 다중 호핑을 사용하여 메모리에서 작동하는 방식을 보여줍니다. 이 그림은 테스트 세트 전체에 걸쳐 각 메모리 위치의 활성화 가중치의 평균을 보여줍니다. 일부 호핑은 최근 단어에만 집중하고, 다른 호핑은 모든 메모리 위치에 대해 보다 넓은 주의를 기울입니다. 이는 성공적인 언어 모델이 부드러운 n-gram 모델과 캐시로 구성되는 아이디어와 일치합니다 [15]. 흥미롭게도, 이 두 가지 유형의 호핑이 번갈아 가는 경향이 있는 것으로 보입니다. 또한 전통적인 RNN과 달리, 캐시는 지수적으로 감소하지 않습니다. 전체 메모리에 걸쳐 거의 동일한 평균 활성화를 가지고 있습니다. 이것이 언어 모델링에서 관찰된 개선의 원인일 수 있습니다.

6 결론 및 향후 연구
이 연구에서는 명시적인 메모리와 순환적인 주의 메커니즘을 가진 신경망이 질문에 대한 답변부터 언어 모델링까지 다양한 작업에서 역전파를 통해 성공적으로 훈련될 수 있음을 보였다. [23]의 메모리 네트워크 구현과 비교하면 지원 사실에 대한 지도가 없으므로 우리 모델은 더 넓은 범위의 설정에서 사용될 수 있다. 우리 모델은 해당 모델과 거의 동일한 성능을 보이며, 동일한 수준의 지도 지원을 받는 다른 기준 모델보다 훨씬 우수하다. 언어 모델링 작업에서는 조정된 RNN과 LSTMs와 비슷한 복잡성을 가진 모델보다 약간 더 우수한 성능을 보인다. 두 작업 모두 메모리 홉 수를 증가시킴으로써 성능이 향상되는 것을 확인할 수 있다.

그러나 아직 해야 할 일이 많습니다. 우리의 모델은 여전히 강력한 지도 학습으로 훈련된 메모리 네트워크의 성능과 정확히 일치하지 못하며, 1k QA 작업 중 몇 가지에서 실패합니다. 게다가, 부드러운 조회는 더 큰 메모리가 필요한 경우에는 잘 확장되지 않을 수 있습니다. 이러한 설정에서는 [23]에서 제안된 다중 스케일 주의 또는 해싱 개념을 탐색할 계획입니다.

감사의 말씀
저자들은 유용한 의견과 가치있는 토론에 대해 Armand Joulin, Tomas Mikolov, Antoine Bordes, Sumit Chopra에게 감사의 말씀을 전합니다. 또한 FAIR 인프라팀에게도 도움과 지원에 감사의 말씀을 전합니다.

5 QA 작업에서는 각 가중치 행렬의 기울기가 따로 측정됩니다.
6 그들은 Penn Treebank에서 하이퍼파라미터를 조정하고, 추가적인 조정 없이 Text8에 사용했습니다. 단, 숨겨진 유닛의 수는 제외합니다. 자세한 내용은 [15]를 참조하세요.

8
참고문헌

[1] C. G. Atkeson과 S. Schaal. 로봇 학습을 위한 기억 기반 신경망. Neurocomputing, 9:243-269, 1995.
[2] D. Bahdanau, K. Cho, and Y. Bengio. 정렬과 번역을 동시에 학습하는 신경 기계 번역. 국제 학습 표현 대회 (ICLR), 2015.
[3] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. 신경 확률 언어 모델. J. Mach. Learn. Res., 3:1137-1155, Mar. 2003.
[4] J. Chung, C¸. G¨ ulc¸ehre, K. Cho, and Y. Bengio. 순차 모델링에 대한 게이트 순환 신경망의 경험적 평가. arXiv 사전 인쇄: 1412.3555, 2014.
[5] S. Das, C. L. Giles, and G.-Z. Sun. 문맥-자유 문법 학습: 외부 스택 메모리를 가진 순환 신경망의 능력과 제한. 인지 과학 협회 제14회 연례 회의 논문집, 1992.
[6] J. Goodman. 언어 모델링에서의 약간의 진전. CoRR, cs.CL/0108005, 2001.
[7] A. Graves. 순환 신경망을 사용한 시퀀스 생성. arXiv 사전 인쇄: 1308.0850, 2013.
[8] A. Graves, G. Wayne, and I. Danihelka. 신경 튜링 기계. arXiv 사전 인쇄: 1410.5401, 2014.
[9] K. Gregor, I. Danihelka, A. Graves, and D. Wierstra. 이미지 생성을 위한 순환 신경망 DRAW. CoRR, abs/1502.04623, 2015.
[10] S. Hochreiter and J. Schmidhuber. 장기 단기 기억. Neural computation, 9(8):1735-1780, 1997.
[11] A. Joulin and T. Mikolov. 스택을 이용한 순환 신경망을 사용한 알고리즘 패턴 추론. NIPS, 2015.
[12] J. Koutn´ık, K. Greff, F. J. Gomez, and J. Schmidhuber. 시계 장치 RNN. ICML, 2014.
[13] M. P. Marcus, M. A. Marcinkiewicz, and B. Santorini. 영어의 대규모 주석이 달린 말뭉치 구축: 펜 트리뱅크. Comput. Linguist., 19(2):313-330, June 1993.
[14] T. Mikolov. 신경망 기반의 통계적 언어 모델. 박사 학위 논문, 브르노 공과 대학교, 2012.
[15] T. Mikolov, A. Joulin, S. Chopra, M. Mathieu, and M. Ranzato. 순환 신경망에서 더 긴 기억 학습. arXiv 사전 인쇄: 1412.7753, 2014.
[16] M. C. Mozer and S. Das. 문맥-자유 언어의 구조를 발견하는 연결주의 기호 조작기. NIPS, 페이지 863-863, 1993.
[17] B. Peng, Z. Lu, H. Li, and K. Wong. 신경망 기반 추론을 향해. ArXiv 사전 인쇄: 1508.05508, 2015.
[18] J. Pollack. 동적 인식기의 유도. Machine Learning, 7(2-3):227-252, 1991.
[19] K. Steinbuch and U. Piske. 행렬 학습과 그 응용. IEEE 전자 컴퓨터 트랜잭션, 12:846-862, 1963.
[20] M. Sundermeyer, R. Schl¨ uter, and H. Ney. 언어 모델링을 위한 LSTM 신경망. Interspeech, 페이지 194-197, 2012.
[21] W. K. Taylor. 자동 아날로그 장치를 통한 패턴 인식. The Institution of Electrical Engineers 논문집, 106:198-209, 1959.
[22] J. Weston, A. Bordes, S. Chopra, and T. Mikolov. AI-complete 질문 응답을 향해: 사전 요구 사항 장난감 과제. arXiv 사전 인쇄: 1502.05698, 2015.
[23] J. Weston, S. Chopra, and A. Bordes. 메모리 네트워크. 국제 학습 표현 대회 (ICLR), 2015.
[24] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhutdinov, R. Zemel, and Y. Bengio. 보여주고, 주목하고, 말하기: 시각적 주의를 가진 신경 이미지 캡션 생성. ArXiv 사전 인쇄: 1502.03044, 2015.
[25] W. Zaremba, I. Sutskever, and O. Vinyals. 순환 신경망 정규화. arXiv 사전 인쇄 arXiv:1409.2329, 2014.

9
10k QA 데이터셋에 대한 결과는 부록 A에 있습니다.

베이스라인 MemN2N
강하게 PE PELS 1hop 2hops 3hops PE PELS
지도학습 MemNN PE LS LW PELS PELS PELS LSRN LW
작업 MemNN LSTM WSH BoW PE LS RN RN∗ joint joint joint joint joint
1:1지원사실 0.0 0.0 0.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2:2지원사실 0.0 81.9 39.6 0.6 0.4 0.5 0.3 0.3 62.0 1.3 2.3 1.0 0.8
3:3지원사실 0.0 83.1 79.5 17.8 12.6 15.0 9.3 2.1 80.0 15.8 14.0 6.8 18.3
4:2논쟁관계 0.0 0.2 36.6 31.8 0.0 0.0 0.0 0.0 21.4 0.0 0.0 0.0 0.0
5:3논쟁관계 0.3 1.2 21.1 14.2 0.8 0.6 0.8 0.8 8.7 7.2 7.5 6.1 0.8
6:예/아니오 질문 0.0 51.8 49.9 0.1 0.2 0.1 0.0 0.1 6.1 0.7 0.2 0.1 0.1
7:계산 3.3 24.9 35.1 10.7 5.7 3.2 3.7 2.0 14.8 10.5 6.1 6.6 8.4
8:리스트/집합 1.0 34.1 42.7 1.4 2.4 2.2 0.8 0.9 8.9 4.7 4.0 2.7 1.4
9:부정문 0.0 20.2 36.4 1.8 1.3 2.0 0.8 0.3 3.7 0.4 0.0 0.0 0.2
10:불확실한 지식 0.0 30.1 76.0 1.9 1.7 3.3 2.4 0.0 10.3 0.6 0.4 0.5 0.0
11:기본적인 지시 0.0 10.3 25.3 0.0 0.0 0.0 0.0 0.1 8.3 0.0 0.0 0.0 0.4
12:연결 0.0 23.4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.1 0.0
13:복합 지시 0.0 6.1 12.3 0.0 0.1 0.0 0.0 0.0 5.6 0.0 0.0 0.0 0.0
14:시간 추론 0.0 81.0 8.7 0.0 0.2 0.0 0.0 0.1 30.9 0.2 0.2 0.0 1.7
15:기본적인 추론 0.0 78.7 68.8 12.5 0.0 0.0 0.0 0.0 42.6 0.0 0.0 0.2 0.0
16:기본적인 귀납 0.0 51.9 50.9 50.9 48.6 0.1 0.4 51.8 47.3 46.4 0.4 0.2 49.2
17:위치 추론 24.6 50.1 51.1 47.4 40.3 41.1 40.7 18,6 40.0 39.7 41.7 41.8 40.0
18:크기 추론 2.1 6.8 45.8 41.3 7.4 8.6 6.7 5.3 9.2 10.1 8.6 8.0 8.4
19:경로 탐색 31.9 90.3 100.0 75.4 66.6 66.7 66.5 2.3 91.0 80.8 73.3 75.7 89.5
20:에이전트의 동기 0.0 2.1 4.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
평균 오차(%) 3.2 36.4 39.2 15.4 9.4 7.2 6.6 4.2 24.5 10.9 7.9 7.5 11.0
실패한 작업(오차 > 5%) 2 16 17 9 6 4 4 3 16 7 6 6 6

표 3: 10,000개의 훈련 예제를 사용하는 모델들의 20개 bAbI QA 작업에 대한 테스트 오류율(%).
키: BoW = 단어 가방 표현; PE = 위치 인코딩 표현; LS = 선형 시작 훈련; RN = 시간 인덱스 노이즈의 무작위 주입; LW = RNN 스타일의 레이어별 가중치 연결 (인접 가중치 연결이 사용되지 않은 경우); joint = 모든 작업에 대한 공동 훈련 (작업별 훈련과 대조); ∗ = 이는 비선형 모델로, 임베딩 차원은 d = 100이며 각 hop 이후 내부 상태에 ReLU가 적용됩니다. 이는 [17]에서 영감을 받았으며 작업 17과 19에서 더 나은 성능을 얻는 데 중요합니다.

10
QA 문제에서의 주의 가중치 시각화를 위한 부록 B

다니엘은 화장실에 갔다. 0.00 0.00 0.03
존은 우유를 떨어뜨렸다. 0.06 0.00 0.00
메리는 복도로 이동했다. 0.00 0.00 0.00
다니엘은 침실로 이동했다. 0.00 0.00 0.00
존은 침실로 갔다. 0.37 0.02 0.00
존은 거기서 우유를 가져갔다. 예 0.88 1.00 0.00
존은 화장실로 이동했다. 예 0.60 0.98 0.96
산드라는 다시 화장실로 돌아갔다. 0.00 0.00 0.00
메리는 사무실로 갔다. 0.01 0.00 0.00
존은 복도로 이동했다. 예 0.00 0.00 1.00
산드라는 부엌으로 여행했다. 0.01 0.00 0.00
메리는 다시 침실로 돌아갔다. 0.00 0.00 0.00

스토리 (3: 3개의 지지하는 사실) 지지 Hop 1 Hop 2 Hop 3 스토리 (4: 2개의 논쟁 관계) 지지 Hop 1 Hop 2 Hop 3
존은 복도로 이동했다. 0.00 0.00 0.00 정원은 부엌의 북쪽에 위치한다. 예 0.84 1.00 0.92
존은 축구공을 잡았다. 예 0.00 1.00 0.00 부엌은 침실의 북쪽에 위치한다. 0.16 0.00 0.08
존은 정원으로 여행했다. 0.35 0.00 0.00
산드라는 복도로 이동했다. 0.00 0.00 0.00
존은 다시 복도로 돌아갔다. 예 0.00 0.00 1.00
존은 정원으로 여행했다. 예 0.62 0.00 0.00

제프는 침실로 여행했다. 0.00 0.00 0.00 샌드라는 침실로 여행했다. 0.06 0.00 0.01
제프는 정원으로 여행했다. 0.00 0.00 0.00 존은 거기에 축구공을 가져갔다. 0.00 0.00 0.00
프레드는 사과를 제프에게 건넸다. 예 1.00 1.00 0.98 샌드라는 사무실로 여행했다. 0.00 0.45 0.16
메리는 정원으로 갔다. 0.00 0.00 0.00 샌드라는 침실로 갔다. 예 0.89 0.39 0.04
프레드는 화장실로 돌아갔다. 0.00 0.00 0.00 다니엘은 부엌으로 돌아갔다. 0.00 0.16 0.00
프레드는 거기에서 우유를 얻었다. 0.00 0.00 0.00 존은 거기에 사과를 가져갔다. 0.00 0.00 0.00
메리는 부엌으로 여행했다. 0.00 0.00 0.00 메리는 거기에서 우유를 얻었다. 0.00 0.00 0.00

이야기 (7: 카운팅) 지원 홉 1 홉 2 홉 3 이야기 (8: 목록/세트) 지원 홉 1 홉 2 홉 3
다니엘은 사무실로 이사했습니다. 0.00 0.00 0.00 존은 복도로 이사했습니다. 0.00 0.00 0.00
메리는 사무실로 이사했습니다. 0.00 0.00 0.00 존은 정원으로 여행했습니다. 0.00 0.00 0.00
산드라는 거기에서 사과를 주웠습니다. 예 0.14 0.00 0.92 다니엘은 정원으로 이사했습니다. 0.00 0.01 0.00
산드라는 사과를 떨어뜨렸습니다. 예 0.12 0.00 0.00 다니엘은 거기에서 사과를 집었습니다. 예 0.03 0.00 0.98
산드라는 거기에서 사과를 가져갔습니다. 예 0.73 1.00 0.08 다니엘은 거기에서 우유를 얻었습니다. 예 0.97 0.02 0.00
존은 침실로 갔습니다. 0.00 0.00 0.00 존은 다시 복도로 돌아갔습니다. 0.00 0.00 0.00

이야기 (9: 간단한 부정) 지원 Hop 1 Hop 2 Hop 3 이야기 (10: 불확정한 지식) 지원 Hop 1 Hop 2 Hop 3
샌드라는 정원에 있습니다. 0.60 0.99 0.00 줄리는 학교나 침실에 있습니다. 0.00 0.00 0.00
샌드라는 정원에 없습니다. 예 0.37 0.01 1.00 줄리는 영화관이나 공원에 있습니다. 0.00 0.00 0.00
존은 사무실에 갔습니다. 0.00 0.00 0.00 빌은 공원에 있습니다. 0.00 0.00 0.00
존은 침실에 있습니다. 0.00 0.00 0.00 빌은 사무실이나 사무실에 있습니다. 예 1.00 1.00 1.00
다니엘은 정원으로 이사했습니다. 0.00 0.00 0.00

이야기 (11 : 기본 일관성) 지원 Hop 1 Hop 2 Hop 3 이야기 (12 : 접속사) 지원 Hop 1 Hop 2 Hop 3
메리는 복도로 여행했습니다. 0.00 0.01 0.00 존과 산드라는 부엌으로 돌아갔습니다. 0.08 0.00 0.00
그 후에 그녀는 화장실로 여행했습니다. 0.00 0.00 0.00 산드라와 메리는 정원으로 여행했습니다. 0.05 0.00 0.00
메리는 정원으로 여행했습니다. 0.00 0.00 0.00 메리와 다니엘은 사무실로 여행했습니다. 0.00 0.00 0.00
그런 다음 그녀는 사무실로 갔습니다. 0.01 0.06 0.00 메리와 존은 화장실로 갔습니다. 0.01 0.00 0.00
산드라는 정원으로 여행했습니다. 예 0.97 0.42 0.00 다니엘과 산드라는 부엌으로 갔습니다. 예 0.74 1.00 1.00
그런 다음 그녀는 복도로 갔습니다. 예 0.00 0.50 1.00 다니엘과 메리는 사무실로 여행했습니다. 0.06 0.00 0.00

이야기 (13 : 복합 일관성) 지원 홉 1 홉 2 홉 3 이야기 (14 : 시간 추론) 지원 홉 1 홉 2 홉 3
샌드라와 다니엘은 화장실로 갔다. 0.13 0.00 0.00 이번 아침 줄리는 영화관에 갔다. 0.00 0.03 0.00
그 후에 그들은 사무실로 돌아갔다. 0.01 0.00 0.00 줄리는 어제 부엌으로 여행했다. 0.00 0.04 0.01
다니엘과 메리는 복도로 이동했다. 0.01 0.00 0.00 프레드는 어제 영화관으로 여행했다. 0.00 0.05 0.01
그 다음에 그들은 사무실로 돌아갔다. 0.06 0.04 0.00 빌은 어제 사무실로 여행했다. 0.00 0.07 0.01
메리와 샌드라는 복도로 이동했다. 예 0.59 0.02 0.00 이번 아침 메리는 침실로 여행했다. 예 0.97 0.27 0.01
그런 다음에 그들은 부엌으로 갔다. 예 0.02 0.94 1.00 어제 메리는 영화관으로 여행했다. 예 0.01 0.33 0.96

이야기 (15 : 기본적인 추론) 지원 홉 1 홉 2 홉 3 이야기 (16 : 기본적인 귀납) 지원 홉 1 홉 2 홉 3
고양이는 늑대를 무서워합니다. 예 0.00 0.99 0.62 릴리는 백조입니다. 0.00 0.00 0.00
양은 늑대를 무서워합니다. 0.00 0.00 0.31 브라이언은 개구리입니다. 예 0.00 0.98 0.00
위노나는 양입니다. 0.00 0.00 0.00 릴리는 회색입니다. 0.07 0.00 0.00
에밀리는 양입니다. 0.00 0.00 0.00 브라이언은 노란색입니다. 예 0.07 0.00 1.00
거트루드는 고양이입니다. 예 0.99 0.00 0.00 줄리어스는 백조입니다. 0.00 0.00 0.00
늑대는 쥐를 무서워합니다. 0.00 0.00 0.00 버나드는 노란색입니다. 0.04 0.00 0.00
쥐는 늑대를 무서워합니다. 0.00 0.00 0.07 줄리어스는 초록색입니다. 0.06 0.00 0.00
제시카는 쥐입니다. 0.00 0.00 0.00 그렉은 개구리입니다. 예 0.76 0.02 0.00

이야기 (17 : 위치 추론) 지원 홉 1 홉 2 홉 3 이야기 (18 : 크기 추론) 지원 홉 1 홉 2 홉 3
빨간 사각형은 빨간 구체 아래에 있습니다. 예 0.37 0.95 0.58 가방은 상자보다 큽니다. 예 0.00 0.88 0.00
빨간 구체는 삼각형 아래에 있습니다. 예 0.63 0.05 0.43 상자는 초콜릿보다 큽니다. 0.04 0.05 0.10

가슴은 초콜릿보다 크다. 예 0.17 0.07 0.90
가슴은 용기 안에 맞는다. 0.00 0.00 0.00
가슴은 상자 안에 맞는다. 0.00 0.00 0.00

이야기 (19: 길 찾기) 지원 홉 1 홉 2 홉 3 이야기 (20: 요원의 동기) 지원 홉 1 홉 2 홉 3
복도는 부엌의 북쪽에 있습니다. 1.00 1.00 1.00 얀은 부엌으로 여행했습니다. 0.00 0.00 0.00
정원은 부엌의 남쪽에 있습니다. 예 0.00 0.00 0.00 얀은 거기에서 사과를 집어들었습니다. 0.00 0.00 0.00
정원은 침실의 동쪽에 있습니다. 예 0.00 0.00 0.00 안투안은 목마르다. 예 0.17 0.00 0.98
화장실은 침실의 남쪽에 있습니다. 0.00 0.00 0.00 제이슨은 거기서 우유를 집어들었습니다. 0.01 0.00 0.00
사무실은 정원의 동쪽에 있습니다. 0.00 0.00 0.00 안투안은 부엌으로 여행했습니다. 0.77 1.00 0.00
존은 어디에 있나요? 답: 화장실 예측: 화장실 우유는 어디에 있나요? 답: 복도 예측: 복도

정원 이전에 축구공은 어디에 있었나요? A: 복도 P: 복도 부엌의 북쪽에는 무엇이 있나요? 답: 정원 예측: 정원

제프에게 사과를 준 사람은 누구인가요? 대답: 프레드 예측: 프레드
샌드라는 침실에 있나요? 대답: 네 예측: 네

샌드라는 물건을 몇 개 들고 있나요? 답: 하나 예측: 하나 다니엘은 무엇을 들고 있나요? 답: 사과, 우유 예측: 사과, 우유

산드라는 정원에 있나요? 답: 아니요 예측: 아니요 빌은 사무실에 있나요? 답: 어쩌면 예측: 어쩌면

샌드라는 어디에 있나요? 답: 복도 예측: 복도
샌드라는 어디에 있나요? 답: 부엌 예측: 부엌

샌드라는 어디에 있나요? 답: 부엌 예측: 부엌 메리는 침실 이전에 어디에 있었나요? 답: 영화관 예측: 영화관

거트루드는 무엇을 두려워하나요? 답: 늑대 예측: 늑대 그렉은 어떤 색인가요? 답: 노란색 예측: 노란색

위의 삼각형은 빨간색 사각형 위에 있습니까? 답: 예 예측: 아니오
여행 가방은 초콜릿 안에 맞습니까? 답: 아니오 예측: 아니오

부엌에서 침실로 어떻게 가나요? 답: s,w 예측: n,n 안투안은 왜 부엌으로 갔나요? 답: 목마름 예측: 목마름

그림 4: bAbi 작업에 대한 다른 메모리 홉 동안의 주의 가중치 예시. 모델은 3개의 메모리 홉을 가진 PE+LS+RN이며, 각 작업별로 별도로 10k 개의 훈련 데이터로 훈련되었습니다. 지원 열은 질문에 대답하기 위해 필요한 문장을 보여줍니다. 이 정보는 사용되지 않지만, 모델은 대부분의 작업에서 올바른 지원 문장에 초점을 맞추는 것을 성공적으로 학습합니다. 홉 열은 모델이 세 번의 홉 동안 더 많은 가중치를 두었던 위치를 보여줍니다 (값과 파란색으로 표시됨). 모델이 범한 실수는 빨간색으로 강조되었습니다.

11. 11번째

