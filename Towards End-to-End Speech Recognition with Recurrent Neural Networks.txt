순환 신경망을 이용한 종단간 음성 인식을 향해

알렉스 그레이브스                                      GRAVES@CS.TORONTO.EDU

구글 딥마인드, 런던, 영국

나브딥 자이틀리                                  NDJAITLY@CS.TORONTO.EDU

캐나다 토론토 대학교 컴퓨터 과학부

요약

이 논문은 중간 음운 표현을 필요로하지 않고 오디오 데이터를 직접 텍스트로 전사하는 음성 인식 시스템을 제시합니다. 이 시스템은 깊은 양방향 LSTM 순환 신경망 아키텍처와 연결주의적 시간 분류 목적 함수의 조합에 기반합니다. 임의의 전사 손실 함수의 기대값을 최소화하도록 네트워크를 훈련시키는 목적 함수의 수정이 소개됩니다. 이를 통해 어휘나 언어 모델이 없어도 단어 오류율을 직접 최적화할 수 있습니다. 이 시스템은 Wall Street Journal 말뭉치에서 언어적 정보가 없을 때 27.3%의 단어 오류율을 달성하며, 허용된 단어의 어휘만 있는 경우 21.9%로, 삼음절 언어 모델이 있는 경우 8.2%로 단어 오류율을 달성합니다. 네트워크를 기준 시스템과 결합하면 오류율이 6.7%로 더욱 감소합니다.

1. 소개

최근 알고리즘과 컴퓨터 하드웨어의 발전으로 인해 이전에는 상당한 인간의 전문지식이 필요한 작업들도 엔드-투-엔드 방식으로 신경망을 훈련시킬 수 있게 되었습니다. 예를 들어, 합성곱 신경망은 이제 손으로 디자인된 특징 추출 알고리즘을 사용하지 않고도 원시 픽셀을 객체 카테고리(크리즈헤브스키 등, 2012)나 교통 표지판의 메시지(시레산 등, 2011)와 같은 고수준 개념으로 직접 분류할 수 있습니다. 이러한 신경망은 기존 방법보다 인간의 노력이 적게 들어가며 일반적으로 우수한 성능을 제공합니다. 특히 매우 많은 양의 훈련 데이터가 있는 경우에는 더욱 그렇습니다.

제31회 국제 기계 학습 컨퍼런스 절차, 중국 베이징, 2014년. JMLR:W&CPvolume32. 저작권 2014년 저자에게 있습니다.

전체적 최적화의 이점은 이전 지식의 이점보다 더 큽니다.

자동 음성 인식은 신경망의 도입으로 크게 이익을 얻었습니다 (Bourlard & Morgan, 1993; Hinton et al., 2012), 그러나 현재 네트워크는 복잡한 파이프라인에서 단일 구성 요소에 불과합니다. 전통적인 컴퓨터 비전과 마찬가지로 파이프라인의 첫 번째 단계는 입력 특징 추출입니다. 표준 기법에는 멜 스케일 필터 뱅크 (Davis & Mermelstein, 1980) (Cepstral 계수로의 추가 변환 여부에 따라) 및 음성 트랙트 길이 정규화와 같은 화자 정규화 기법이 포함됩니다 (Lee & Rose, 1998). 그런 다음 신경망은 음향 데이터의 개별 프레임을 분류하기 위해 훈련되며, 출력 분포는 숨겨진 마르코프 모델 (HMM)의 방출 확률로 재정의됩니다. 네트워크를 훈련시키기 위해 사용되는 목적 함수는 실제 성능 측정 (시퀀스 수준의 전사 정확도)과는 크게 다릅니다. 이것은 엔드 투 엔드 학습이 피하려는 일관성 부족의 한 예입니다. 실제로 이것은 연구자들에게 좌절감을 주는 요인이 되는데, 프레임 정확도의 큰 향상이 전사 정확도의 미미한 개선 또는 심지어 악화로 이어질 수 있다는 것을 발견하기 때문입니다. 추가적인 문제는 프레임 수준의 훈련 대상이 HMM에 의해 결정된 정렬에서 유추되어야 한다는 것입니다. 이로 인해 네트워크 재훈련은 HMM 재정렬과 번갈아가며보다 정확한 대상을 생성하는 불편한 반복적인 절차로 이어집니다. 최대 상호 정보와 같은 전체 시퀀스 훈련 방법은 올바른 전사의 확률을 최대화하기 위해 HMM-신경망 하이브리드를 직접 훈련시키는 데 사용되었습니다 (Bahl et al., 1986; Jaitly et al., 2012). 그러나 이러한 기술은 이미 프레임 수준에서 훈련된 시스템을 다시 훈련하는 데만 적합하며, 딥 신경망에 필요한 조정보다 훨씬 많은 수의 하이퍼 매개 변수를 조정해야 합니다.

음성 인식 시스템을 훈련시키기 위해 사용되는 전사는 어휘적이지만, 네트워크에 제시되는 목표는
순환 신경망을 사용한 종단 간 음성 인식을 향해

일반적으로 발음 기호입니다. 따라서 단어에서 음소 시퀀스로 매핑하기 위해 발음 사전이 필요합니다. 이러한 사전을 만드는 것은 상당한 인간적 노력이 필요하며 종합 성능에 중요한 역할을 하는 경우가 많습니다. 더욱 복잡한 점은 공명 효과를 설명하기 위해 다중 폰 컨텍스트 모델을 사용하기 때문에 '상태 결합'이 필요하다는 것입니다. 이는 대상 클래스의 수를 줄이기 위한 전문 지식의 또 다른 원천입니다. 그래프 및 문자와 같은 어휘 상태는 HMM 기반 인식기에서 어휘 외 단어 (OOV)를 처리하는 방법으로 고려되었습니다 (Galescu, 2003; Bisani & Ney, 2005), 그러나 음성 모델을 보완하는 데 사용되었습니다.

마지막으로, HMM에 의해 생성된 음향 점수는 텍스트 코퍼스에서 훈련된 언어 모델과 결합됩니다. 일반적으로 언어 모델에는 많은 사전 정보가 포함되어 있으며 성능에 큰 영향을 미칩니다. 언어를 소리와 별도로 모델링하는 것은 엔드 투 엔드 학습에서 정당한 이탈로 생각될 수 있습니다. 왜냐하면 언어적 종속성을 텍스트에서 음성보다 쉽게 학습할 수 있으며, 읽고 쓰는 사람들도 비슷한 방식으로 합니다. 그럼에도 불구하고, 수천 시간의 레이블이 지정된 음성 코퍼스의 등장으로 인해 대본에서 언어 모델을 직접 학습하는 것이 가능할 수도 있습니다.

이 논문의 목표는 가능한 한 많은 부분이 단일 재귀 신경망(RNN) 아키텍처로 대체되는 시스템입니다. RNN을 사용하여 원시 음성 파형을 직접 전사하는 것은 가능하지만(Graves, 2012, 9장) 제한된 볼츠만 머신으로 학습된 특징(Jaitly & Hinton, 2011)을 사용하는 것보다 계산 비용이 높고 성능이 일반적인 전처리보다 좋지 않습니다. 따라서 우리는 최소한의 전처리 방법으로 스펙트로그램을 선택했습니다.

스펙트로그램은 깊은 양방향 LSTM 네트워크 (Graves et al., 2013)에 의해 처리되며, 연결주의적 시간 분류 (CTC) 출력 계층 (Graves et al., 2006; Graves, 2012, Chapter 7)과 함께 사용됩니다. 이 네트워크는 텍스트 대본에 직접 훈련되며, 음성적 표현 (따라서 발음 사전이나 상태 결합이 없음)은 사용되지 않습니다. 또한, CTC는 모든 가능한 입력-출력 정렬에 대해 통합하기 때문에, 강제 정렬이 필요하지 않습니다. 양방향 LSTM과 CTC의 조합은 문자 수준의 음성 인식에 이전에 적용되었으나 (Eyben et al., 2009), 해당 연구에서 사용된 상대적으로 얕은 아키텍처는 흥미로운 결과를 제공하지 못했습니다 (최상의 문자 오류율은 거의 20%였습니다).

기본 시스템은 새로운 목적 함수에 의해 강화되며, 이 함수는 네트워크를 직접적으로 단어 오류율을 최적화하도록 훈련시킵니다.

월스트리트저널 연설 말뭉치에 대한 실험 결과, 이 시스템은 언어 모델이나 사전 없이도 단어를 상당한 정확도로 인식할 수 있음을 보여주며, 언어 모델과 결합할 경우 최첨단 파이프라인과 비교 가능한 성능을 발휘한다.

2. 네트워크 아키텍처

입력 시퀀스 x = (x1,...,xT)가 주어지면, 표준 순환 신경망(RNN)은 다음 방정식을 t = 1부터 T까지 반복하여 숨겨진 벡터 시퀀스 h = (h1,...,hT)와 출력 벡터 시퀀스 y = (y1,...,yT)를 계산합니다.

ht = H(Wihxt + Whhht−1 + bh) (1)
yt = Whoht + bo         (2)

ht = H(Wihxt + Whhht−1 + bh) (1)
yt = Whoht + bo         (2)

W 텀은 가중치 행렬을 나타내며 (예: Wih는 입력-은닉 가중치 행렬을 의미합니다), b 텀은 편향 벡터를 나타냅니다 (예: bh는 은닉 편향 벡터를 의미합니다) 그리고 H는 은닉층 활성화 함수입니다.

H는 일반적으로 시그모이드 함수의 요소별 적용입니다. 그러나 우리는 정보를 저장하기 위해 특별히 설계된 메모리 셀을 사용하는 Long Short-Term Memory (LSTM) 아키텍처 (Hochreiter & Schmidhuber, 1997)가 장거리 문맥을 찾고 활용하는 데 더 우수하다는 것을 발견했습니다. 그림 1은 단일 LSTM 메모리 셀을 보여줍니다. 이 논문에서 사용된 LSTM 버전 (Gers et al., 2002)에서 H는 다음과 같은 복합 함수로 구현됩니다.

it = σ (Wxi xi t + Whi h t−1 + Wci c t−1 + bi) (3)
ft = σ (Wxf x t + Whf h t−1 + Wcf c t−1 + bf) (4)
ct = f t c t−1 + i t tanh(Wxc x t + Whc h t−1 + bc) (5)
ot = σ (Wxo x t + Who h t−1 + Wco c t + bo) (6)
ht = o t tanh(c t) (7)

σ는 로지스틱 시그모이드 함수이고, i, f, o 및 c는 각각 입력 게이트, 잊어버리기 게이트, 출력 게이트 및 셀 활성화 벡터입니다. 이들은 모두 숨겨진 벡터 h와 동일한 크기입니다. 가중치 행렬의 첨자는 명확한 의미를 가지고 있습니다. 예를 들어, Whi는 숨겨진-입력 게이트 행렬이고, Wxo는 입력-출력 게이트 행렬입니다. 셀에서 게이트 벡터로의 가중치 행렬 (예: Wci)은 대각선이므로 각 게이트 벡터의 요소 m은 셀 벡터의 요소 m으로부터만 입력을 받습니다. 편향 항목 (i, f, c 및 o에 추가되는)은 명확성을 위해 생략되었습니다.

전통적인 RNN의 한 가지 단점은 이전 문맥만 사용할 수 있다는 것입니다. 전체 발화가 한 번에 전사되는 음성 인식에서는 미래 문맥을 활용하지 않을 이유가 없습니다. 양방향 RNN (BRNNs) (Schuster & Paliwal, 1997) Towards End-to-End Speech Recognition with Recurrent Neural Networks

그림 1. 장기 단기 기억 셀.

그림 2. 양방향 순환 신경망.

데이터를 양방향으로 처리하여 두 개의 별도 은닉층을 사용하여 이 작업을 수행한 다음, 동일한 출력층으로 전달합니다. 그림 2에서 보여지듯이, BRNN은 앞쪽 은닉 시퀀스를 계산합니다.

−→
h, 역으로 숨겨진 시퀀스
←−
h와 출력 시퀀스 y를 T부터 1까지 반복하여 역방향 레이어, 1부터 T까지 순방향 레이어를 업데이트하여 출력 레이어를 업데이트합니다.

− →
h t = H
W x− → h xt + W− → h− → h
− →
h t−1 + b− → h
(cid:17)
(8)

←−
h t = 이전 시간의 은닉 상태
H
W x←− h xt + W←− h←− h
←−
h t+1 + b←− h
(cid:17)
(9)

yt = W− →
yt = W마이너스 화살표

hy− →
hy마이너스 화살표

h t + W←−
h t 더하기 W왼쪽 화살표

hy←−
hy왼쪽 화살표

h t + bo (10)
h t 더하기 bo (10)

BRNNs와 LSTM을 결합하면 양방향 LSTM (Graves & Schmidhuber, 2005)이 생성되며, 이는 입력 방향 양쪽에서 장거리 문맥에 접근할 수 있습니다.

최근 하이브리드 시스템의 성공에 있어서 중요한 요소는 깊은 아키텍처의 사용입니다. 이 아키텍처는 음향 데이터의 점진적으로 더 높은 수준의 표현을 구축할 수 있습니다. 깊은 RNN은 여러 개의 RNN 은닉층을 쌓아 올림으로써 생성될 수 있으며, 한 층의 출력 시퀀스가 다음 층의 입력 시퀀스로 사용됩니다. 이는 그림 3에 나타나 있습니다. 동일한 은닉층 함수가 사용된다고 가정합니다.

그림 3. 깊은 순환 신경망.

모든 N개의 층에 대해, 숨겨진 벡터 시퀀스 hn은 n = 1부터 N까지, t = 1부터 T까지 반복적으로 계산됩니다.

hn
t
= H W hn−1hnhn−1
t
+ Whnhnhn
t−1
+ bn h (11)

h0 = x인 경우, 네트워크의 출력 yt는 다음과 같습니다.

yt = W hNyhN
t
+ 보      (12)

깊은 양방향 RNN은 각 숨겨진 시퀀스 hn을 앞으로 진행하는 시퀀스 −→ h n과 뒤로 진행하는 시퀀스 ←− h n으로 대체함으로써 구현될 수 있으며, 각 숨겨진 레이어가 아래 레벨의 앞으로 진행하는 레이어와 뒤로 진행하는 레이어로부터 입력을 받도록 보장해야 합니다. 만약 LSTM이 숨겨진 레이어에 사용된다면, 완전한 아키텍처는 깊은 양방향 LSTM이라고 불립니다 (Graves et al., 2013).

3. 연결주의적 시간 분류

신경망(피드포워드 또는 순환)은 일반적으로 음성 인식에서 프레임 수준의 분류기로 훈련됩니다. 이는 각 프레임에 대한 별도의 훈련 대상을 필요로 하며, 이는 음성과 전사 시퀀스 간의 정렬이 HMM에 의해 결정되어야 함을 의미합니다. 그러나 정렬은 분류기가 훈련된 후에만 신뢰할 수 있으며, 이는 분할과 인식 사이에 순환적 종속성을 유발합니다(필기 인식과 밀접한 관련 분야에서 Sayre의 역설로 알려져 있음). 또한, 정렬은 대부분의 음성 인식 작업에서는 관련이 없으며, 단어 수준의 전사만 중요합니다. 연결주의적 시간 분류(CTC)는 입력과 대상 시퀀스 간의 사전 정렬을 필요로하지 않고 시퀀스 전사 작업에 대한 RNN을 훈련시키기 위한 목적 함수입니다(Graves, 2012, 7장). 

순환 신경망을 사용한 종단간 음성 인식을 향해

출력 레이어에는 각 전사 레이블 (문자, 음소, 음표 등)마다 하나의 유닛이 포함되어 있으며, 추가로 '빈칸'이라고 불리는 추가 유닛이 있습니다. 이는 널 발사를 나타냅니다. 길이 T의 입력 시퀀스 x가 주어지면, 출력 벡터 yt는 소프트맥스 함수로 정규화되고, 시간 t에서 인덱스 k의 레이블 (또는 빈칸)을 발사할 확률로 해석됩니다.

Pr(k,t|x) = exp( yk * t )

안녕하세요
안녕
잘 지내세요
고마워
사랑해 (13)

yk
t
은 yt의 k번째 요소입니다. CTC 정렬 a는 빈 공간과 레이블 인덱스로 이루어진 길이 T의 시퀀스입니다. a의 확률 Pr(a|x)은 각 시간 단계에서의 발생 확률의 곱입니다.

Pr(a|x) = T
t=1Pr(at,t|x)  (14)

주어진 전사 시퀀스에 대해, 라벨을 공백으로 구분하는 다양한 방법과 동일한 수의 가능한 정렬이 있습니다. 예를 들어 (공백을 나타내기 위해 '−'를 사용하여) 정렬 (a,−,b,c,−,−)와 (−,−,a,−,b,c)는 모두 전사 (a,b,c)에 해당합니다. 정렬에서 동일한 라벨이 연속된 시간 단계에 나타나는 경우, 반복은 제거됩니다. 따라서 (a,b,b,b,c,c)와 (a,−,b,−,c,c)도 (a,b,c)에 해당합니다. 반복된 라벨을 먼저 제거한 다음 정렬에서 공백을 제거하는 연산자 B를 나타내고, 출력 전사 y의 총 확률이 해당하는 정렬의 확률의 합과 동일하다고 가정하면 다음과 같이 쓸 수 있습니다.

Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) = 
Pr(y|x) =

이러한 가능한 정렬에 대한 '통합'은 네트워크가 세그먼트화되지 않은 데이터로 훈련될 수 있게 합니다. 직관적으로, 특정 전사 내에서 레이블이 어디에 발생할지 모르기 때문에, 발생할 수 있는 모든 위치에서 합산합니다. Eq. (15)는 동적 프로그래밍 알고리즘을 사용하여 효율적으로 평가하고 미분할 수 있습니다 (Graves et al., 2006). 대상 전사 y∗가 주어지면, 네트워크는 CTC 목적 함수를 최소화하기 위해 훈련될 수 있습니다.

CTC(x) = -logPr(y∗|x) (16)
CTC(x) = -logPr(y∗|x) (16)

예상된 전사 손실

CTC 목적 함수는 시퀀스 전사를 완전히 정확하게 얻을 확률의 로그를 최대화합니다. 
잘못된 전사의 상대적 확률은 무시되므로 모두 동등하게 나쁘다는 것을 의미합니다. 
그러나 대부분의 경우, 전사 성능은

보다 미묘한 방식으로 평가됩니다. 음성 인식에서는 예를 들어, 표준 측정치는 단어 오류율(WER)로 정의되며, 이는 진실한 단어 순서와 전사자가 발화한 가장 가능성이 높은 단어 순서 간의 편집 거리입니다. 따라서 WER이 높은 전사가 WER이 낮은 전사보다 더 가능성이 높도록 하고자 합니다. 객관적인 함수와 테스트 기준 사이의 격차를 줄이기 위해, 이 섹션에서는 출력 전사에 대해 정의된 임의의 손실 함수(예: WER)의 기대값을 최적화하기 위해 RNN을 훈련시키는 방법을 제안합니다.

네트워크 구조와 출력 활성화의 해석은 CTC와 동일하게 유지되며, 특정 시간 단계에서 레이블 (또는 빈칸)을 발생시킬 확률로 해석됩니다.

주어진 입력 시퀀스 x에 대해 CTC로 정의된 전사 시퀀스 y에 대한 분포 Pr(y|x)와 실수값 전사 손실 함수 L(x,y)가 주어졌을 때, 기대 전사 손실 L(x)는 다음과 같이 정의된다.

L(x) = (cid:88)

Pr(y|x)L(x,y) (17)
Pr(y|x)L(x,y) (17)

일반적으로 우리는 이 기대값을 정확하게 계산할 수 없으며, 대신 몬테카를로 샘플링을 사용하여 L과 그래디언트를 근사화할 것입니다. 식 (15)을 식 (17)에 대입하면 다음과 같습니다.

L(x) = (cid:88)

y
y
a∈B−1(y)Pr(a|x)L(x,y) (18)
=
y

a
Pr(a|x)L(x,B(a)) (19)
a
Pr(a|x)L(x,B(a)) (19)

Eq. (14)는 Pr(a|x)에서 샘플을 추출할 수 있음을 보여줍니다. 각 시간 단계에서 Pr(k,t|x)에서 독립적으로 선택하여 결과를 연결하면 손실을 근사화하는 것이 간단해집니다.

L(x) ≈ 1
N
N (cid:88)

L(x)는 약 1입니다.
N
N (cid:88)

i=1
L(x,B(ai)), ai ∼ Pr(a|x) (20)

나는 1이다
L(x,B(ai)), ai ∼ Pr(a|x) (20)

네트워크 출력에 대해 L을 미분하기 위해, 먼저 식 (13)에서 관찰하십시오.

∂ logPr(a|x) = δak
∂ Pr(k,t|x) = δatk
Pr(k,t|x)

(21)
(21)

그런 다음 식 (19)에 대입하여 식별자를 적용하면 ∇xf(x) = f(x)∇x logf(x)가 되도록 한다.

∂L(x)
∂ Pr(k,t|x) = 0

a
∂ Pr(a|x) = a에 대한 x의 조건부 확률의 미분
∂ Pr(k,t|x)L(x,B(a)) = x의 조건부 확률 Pr(k,t|x)에 대한 L(x,B(a))의 미분

=

a
Pr(a|x)∂ logPr(a|x)
∂ Pr(k,t|x)
L(x,B(a))

a
Pr(a|x)∂ logPr(a|x)
∂ Pr(k,t|x)
L(x,B(a))

(cid:88)
a:at=kPr(a|x,at = k)L(x,B(a))
순환 신경망을 사용한 엔드 투 엔드 음성 인식을 위해

이 기대값은 몬테카를로 샘플링을 사용하여 근사화할 수도 있습니다. 출력 확률이 독립적이기 때문에 Pr(a|x)에서의 편향되지 않은 샘플 ai는 Pr(a|x,at = k)에서의 편향되지 않은 샘플로 변환될 수 있습니다. 따라서 모든 ai는 다음과 같이 Pr(k,t|x)의 기울기 추정을 제공하는 데 사용될 수 있습니다.

∂L(x) = x에 대한 L의 편미분
∂ Pr(k,t|x) = x에 대한 Pr(k,t)의 편미분
≈ 1
N
N (cid:88) = N으로 나눈 후 N (cid:88)

나는 1이다.
L(x,B(ai,t,k)) (22)

ai ∼ Pr(a|x)와 ai,t,k t(cid:48) = ai t(cid:48)∀t(cid:48) (cid:54)= t, ai,t,k t = k.
각각의 k,t에 대해 별도의 정렬을 선택하는 대신 정렬 샘플을 재사용하는 장점은 손실 분산으로 인한 잡음이 크게 상쇄되고 개별 레이블을 변경함으로써 손실의 차이만이 그래디언트에 추가된다는 것입니다. 정책 그래디언트 문헌 및 기타에서 널리 논의된 바와 같이 (Peters & Schaal, 2008), 확률적 그래디언트 추정을 사용하여 최적화할 때 잡음 최소화는 중요합니다. Pr(k,t|x) 도함수는 소프트맥스 함수를 통과하여 다음과 같이 주어집니다:

∂L(x) = x의 L에 대한 편미분
∂yk t = yk t에 대한 t에 대한 편미분
≈ Pr(k,t|x) = x가 주어졌을 때 k와 t에 대한 확률
N = N
N (cid:88) = N (cid:88)

i=1
L(x,B(ai)) − Z(ai,t)

어디에

Z(ai,t) = (cid:88)
k(cid:48)
Pr(k(cid:48),t|x)L(x,B(ai,t,k(cid:48))) 

Z(ai,t) = (cid:88)
k(cid:48)
Pr(k(cid:48),t|x)L(x,B(ai,t,k(cid:48)))

yk에 추가된 도함수

주어진 인공지능에 의한 t는 따라서 ai와의 손실 차이와 동일합니다.

t = k이고 ai가 Pr(k,t|x)에서 샘플링된 경우 예상 손실은 변경된 정렬에 대한 오류 항만을 받습니다. 예를 들어, 손실 함수가 단어 오류율이고 샘플링된 정렬이 문자 전사 "WTRD ERROR RATE"를 생성하는 경우, 그래디언트는 두 번째 출력 레이블을 'O'로 변경하는 출력을 장려하고, 다른 두 단어에 변경을 가하는 출력을 억제하며, 다른 곳에서는 거의 0에 가까울 것입니다.

샘플링 절차가 효과적이려면, 서로 다른 손실을 받는 변형들을 선택할 합리적인 확률이 있어야 합니다. 무작위로 초기화된 네트워크에서 뽑힌 대부분의 정렬은 완전히 잘못된 전사를 제공하므로, 단일 출력을 수정하여 손실을 변경하는 가능성은 거의 없을 것입니다. 따라서 CTC로 이미 훈련된 네트워크를 재훈련하기 위해 기대 손실 최소화를 사용하는 것을 권장합니다. 처음부터 적용하는 것보다.

샘플링 정렬은 저렴하기 때문에, 절차에서 유일한 중요한 계산 비용은 정렬 변형에 대한 손실을 재계산하는 것입니다. 그러나 많은 손실 함수(단어 오류율을 포함하여)에 대해서는 이를 최적화할 수 있습니다.

해당하는 손실의 일부분에 대한 재계산만 수행합니다. 실험에서는 각 시퀀스당 다섯 개의 샘플이 충분히 낮은 분산 기울기 추정치를 제공하여 효과적인 훈련을 할 수 있었습니다.

단어 오류율을 계산하기 위해서는 단어의 끝을 나타내는 레이블을 구분자로 사용해야 합니다.

5. 해독

CTC 네트워크를 디코딩하는 것은 (즉, 주어진 입력 시퀀스 x에 대해 가장 확률이 높은 출력 전사 y를 찾는 것) 간단히 말하면 각 타임스텝에서 가장 확률이 높은 단일 출력을 선택하고 해당 전사를 반환함으로써 수행될 수 있습니다.

argmax y Pr(y|x) ≈ B(argmax a Pr(a|x))

argmax y Pr(y|x) ≈ B(argmax a Pr(a|x))

더 정확한 디코딩은 빔 탐색 알고리즘을 사용하여 수행할 수 있으며, 이는 언어 모델을 통합하는 것도 가능하게 합니다. 이 알고리즘은 HMM 기반 시스템에서 사용되는 디코딩 방법과 유사하지만, 네트워크 출력의 해석이 약간 변경되어 차이가 있습니다. 하이브리드 시스템에서는 네트워크 출력을 상태 점유의 사후 확률로 해석하고, 이를 언어 모델과 HMM이 제공하는 전이 확률과 결합합니다. CTC에서는 네트워크 출력 자체가 전이 확률을 나타냅니다 (HMM 용어로는 레이블 활성화가 다른 상태로의 전이 확률이며, 블랭크 활성화는 현재 상태에 머무르는 확률입니다). 연속된 시간 단계에서 반복된 레이블 방출이 제거되어 상황이 더욱 복잡해지며, 이로 인해 블랭크로 끝나는 정렬과 레이블로 끝나는 정렬을 구별해야 합니다.

알고리즘 1의 의사 코드는 CTC 네트워크를 위한 간단한 빔 탐색 절차를 설명하며, 사전과 언어 모델의 통합을 허용합니다. 빔 탐색에 의해 시간 t에서 (부분적인) 출력 전사 y에 할당된 공백, 비공백 및 총 확률을 각각 Pr−(y,t), Pr+(y,t) 및 Pr(y,t)로 정의하고, Pr(y,t) = Pr−(y,t) + Pr+(y,t)로 설정합니다. 시간 t에서 레이블 k에 의해 y의 확장 확률 Pr(k,y,t)를 다음과 같이 정의합니다:

Pr(k,y,t) = Pr(k,t|x)Pr(k|y)

Pr−(y,t − 1) if ye = k
그렇지 않으면 Pr(y,t − 1)

Pr(k,t|x)은 t에서의 k의 CTC 발사 확률이다. (13)식에서 정의된대로, Pr(k|y)는 y에서 y+k로의 전이 확률이다. ye는 y에서의 최종 레이블이다. 마지막으로, ˆ y는 마지막 레이블이 제거된 y의 접두사이고, ∅는 빈 시퀀스이며, Pr+(∅,t) = 0 ∀t임을 주목한다.

전이 확률 Pr(k|y)은 검색에 이전 언어 정보를 통합하는 데 사용될 수 있습니다. 만약 없다면, 재귀 신경망을 사용한 최종 음성 인식으로 진행됩니다.

알고리즘 1 CTC 빔 서치
초기화: B ← {∅}; Pr−(∅,0) ← 1
t = 1...T에 대해
ˆ B ← B에서 가장 가능성이 높은 W개의 시퀀스
B ← {}
y ∈ ˆ B에 대해
만약 y (cid:54)= ∅ 이라면
Pr+(y,t) ← Pr+(y,t − 1)Pr(ye,t|x)
만약 ˆ y ∈ ˆ B 이라면
Pr+(y,t) ← Pr+(y,t) + Pr(ye, ˆ y,t)
Pr−(y,t) ← Pr(y,t − 1)Pr(−,t|x)
y를 B에 추가
k = 1...K에 대해
Pr−(y + k,t) ← 0
Pr+(y + k,t) ← Pr(k,y,t)
(y + k)를 B에 추가
반환: maxy∈B Pr 1 |y|(y,T)

이러한 지식은 (표준 CTC와 마찬가지로) 존재하며, 그러면 모든 Pr(k|y)는 1로 설정됩니다. 사전 단어로 검색을 제한하는 것은 (y+k)가 사전에 있는 경우 Pr(k|y) = 1로 쉽게 구현할 수 있습니다. 통계적 언어 모델을 적용하기 위해서는 Pr(k|y)가 정규화된 레이블 간 전이 확률을 나타내야 함을 유의하십시오. 단어 수준 언어 모델을 레이블 수준으로 변환하기 위해, 우선 어떤 레이블 시퀀스 y도 y = (w + p)로 표현할 수 있다는 것을 알아두십시오. 여기서 w는 y의 사전 단어의 가장 긴 완전한 시퀀스이고, p는 남은 단어 접두사입니다. w와 p 모두 비어 있을 수 있습니다. 그런 다음 우리는 다음과 같이 쓸 수 있습니다.

Pr(k|y) = 
P(k|y) = 
w ∈ (p+k)*
w ∈ (p+k)*
Prγ(w|w)
Pγ(w|w)
w ∈ p* 
Prγ(w|w) (23)

단어 히스토리 w에서 단어 w(cid:48)로의 전이에 할당된 확률인 Pr(w(cid:48)|w)는 p∗가 p로 접두사를 가진 사전 단어의 집합이고, γ는 언어 모델 가중치입니다.

알고리즘의 마지막 단계에서의 길이 정규화는 언어 모델과 함께 디코딩할 때 도움이 되며, 그렇지 않으면 전이가 적은 시퀀스가 불공정하게 우선시되는 경향이 있습니다. 그 외에는 거의 영향이 없습니다.

6. 실험

실험은 월스트리트 저널 (WSJ) 코퍼스 (LDC 코퍼스 LDC93S6B 및 LDC94S13B로 사용 가능)에서 수행되었습니다. RNN은 14시간의 하위 집합 'train-si84'와 전체 81시간 세트 모두에 대해 훈련되었으며, 'test-dev93' 개발 세트가 검증에 사용되었습니다. 두 훈련 세트 모두에서 RNN은 CTC를 사용하여 훈련되었으며, 대본의 문자를 대상 시퀀스로 사용했습니다. 그런 다음 RNN은 시퀀스당 다섯 개의 정렬 샘플을 사용하여 예상 단어 오류율을 최소화하기 위해 섹션 4의 방법을 사용하여 다시 훈련되었습니다.

총 43개의 문자가 있었습니다 (대문자, 구두점 및 단어를 구분하기 위한 공백 문자 포함). 입력 데이터는 'matplotlib' 파이썬 툴킷의 'specgram' 함수를 사용하여 원시 오디오 파일에서 파생된 스펙트로그램으로 제시되었습니다. 이 함수는 254개의 푸리에 창과 127개의 프레임 간격으로 오버랩하여 각 프레임당 128개의 입력을 제공했습니다.

네트워크는 양방향 LSTM 숨겨진 레이어 5단계를 가지고 있었으며, 각 레이어에는 500개의 셀이 있어 총 약 26.5M개의 가중치를 가졌습니다. 이는 각 발화마다 하나의 가중치 업데이트를 사용하여 확률적 경사 하강법으로 훈련되었으며, 학습률은 10의 -4승이고 모멘텀은 0.9였습니다.

RNN은 기준이 되는 깊은 신경망 HMM 하이브리드(DNN-HMM)과 비교되었습니다. DNN-HMM은 Kaldi 레시피 's5', 모델 'tri4b' (Povey et al., 2011)를 사용하여 SGMM-HMM 시스템의 정렬을 사용하여 생성되었습니다. 14시간의 하위 집합을 사용하여 먼저 2000개의 유닛을 가진 6개의 은닉층을 가진 Deep Belief Network (DBN) (Hinton & Salakhutdinov, 2006)을 훈련시켰습니다. 입력은 40개의 계수, 델타 및 가속도를 가진 Mel-scale log filterbanks의 15개 프레임 (1개 중심 프레임 ±7개의 컨텍스트)였습니다. DBN은 층별로 훈련되었고, 그 후 DNN을 초기화하는 데 사용되었습니다. DNN은 중심 입력 프레임을 3385개의 음소 상태 중 하나로 분류하기 위해 훈련되었습니다. DNN은 확률적 경사 하강법으로 훈련되었으며, 학습률은 0.1에서 시작하고 모멘텀은 0.9였습니다. 개발 세트에서 프레임 오류율을 줄이지 못한 각 epoch의 끝에서 학습률은 절반으로 나누어졌습니다. 6번의 실패 시도 후 학습률이 고정되었습니다. 디코딩 중에 DNN posteriors는 상태 사전의 제곱근으로 나누어졌습니다.
RNN은 먼저 사전이나 언어 모델을 사용하지 않고 디코딩되었으며, 공백 문자를 사용하여 문자 출력을 단어로 분할하고 WER을 계산했습니다. 그런 다음 146K 단어 사전을 사용하여 네트워크를 디코딩하고, 그 후 단일어, 이중어 및 삼중어 언어 모델을 사용했습니다. 사전은 Kaldi 레시피 's5'에 구현된 일부 augmentation 규칙을 사용하여 기본 WSJ 사전을 125K 단어로 확장하여 구축되었습니다. 언어 모델은 이 확장된 사전을 사용하여 WSJ CD의 데이터를 사용하여 구축되었습니다 (레시피 's5'의 스크립트 'wsj extend dict.sh' 및 'wsj train lms.sh' 참조). 언어 모델 가중치는 모든 실험에 대해 별도로 최적화되었습니다. 언어적 정보가 없는 RNN 실험과 사전만 있는 실험의 경우, 디코딩에는 섹션 5의 빔 서치 알고리즘이 사용되었습니다. 언어 모델이 있는 RNN 실험의 경우, 구현의 어려움과 기준 시스템과 공정한 비교를 위해 대체 방법이 사용되었습니다: 최대 300개의 후보 전사를 기준 DNN-HMM에서 추출하여 RNN에 의해 Eq. (16)을 사용하여 재점수화되었습니다. 그런 다음 RNN 점수는 기준 시스템의 점수와 결합되었습니다.

표 1. 월스트리트저널 결과. 모든 점수는 평가 세트에서의 단어 오류율/문자 오류율(알려진 경우)입니다.
디코딩에 사용된 언어 모델은 'LM'입니다. '14시간'과 '81시간'은 훈련에 사용된 데이터 양을 나타냅니다.

시스템    LM      14 HR  81 HR
RNN-CTC   없음    74.2/30.9 30.1/9.2
RNN-CTC   사전 69.2/30.0 24.0/8.0
RNN-CTC   모노그램 25.8  15.8
RNN-CTC   바이그램  15.5   10.4
RNN-CTC   트라이그램 13.5   8.7
RNN-WER   없음    74.5/31.3 27.3/8.4
RNN-WER   사전 69.7/31.0 21.9/7.3
RNN-WER   모노그램 26.0  15.2
RNN-WER   바이그램  15.3   9.8
RNN-WER   트라이그램 13.5   8.2
기준선  없음    —      —
기준선  사전 56.1 51.1
기준선  모노그램 23.4  19.9
기준선  바이그램  11.6   9.4
기준선  트라이그램 9.4    7.8
조합  트라이그램 —    6.7

N-최상의 결과 전사의 언어 모델을 재순위화하고 WER을 기록했습니다. 최상의 결과는 RNN 점수 가중치 7.7과 언어 모델 가중치 16으로 얻어졌습니다.

81시간 훈련 세트에 대해, 단어, 이중어, 삼중어 후보들의 오라클 오류율은 각각 8.9%, 2%, 1.4%이었고, 반면에 안티-오라클 (순위 300)의 오류율은 단어에 대해 45.5%, 삼중어에 대해 33%로 다양했습니다. 더 큰 N-베스트 리스트 (N=1000까지)를 사용해도 유의미한 성능 향상이 없었으며, 이를 통해 RNN의 실제 디코딩 성능을 근사화하는 데에는 리스트가 충분히 크다고 결론지었습니다.

RNN과 DNN을 결합한 효과를 측정하기 위해 추가 실험이 수행되었습니다. 81시간 세트로 훈련된 'RNN-WER'의 후보 점수는 DNN 음향 모델 점수와 혼합되어 후보들을 재정렬하는 데 사용되었습니다. 언어 모델 가중치는 11, RNN 점수 가중치는 1, DNN 가중치는 1로 설정했을 때 가장 좋은 결과를 얻을 수 있었습니다.

표 1의 결과는 전체 훈련 세트에서 언어 모델이 없을 때, 문자 수준 RNN이 기준 모델보다 우수한 성능을 보여줍니다. 단어 오류율을 최소화하기 위해 재훈련된 RNN (원래 'RNN-CTC' 네트워크와 구별하기 위해 'RNN-WER'로 레이블링됨)은 특히 이 regime에서 우수한 성과를 보였습니다. 이는 아마도 두 가지 요인 때문일 것입니다. 첫째로, RNN은 더 많은 음향 문맥에 접근할 수 있기 때문에 더 강력한 음향 모델을 학습할 수 있습니다. 둘째로, 훈련 대본에서 암묵적인 언어 모델을 학습할 수 있습니다. 그러나 기준 시스템은 언어 모델이 강화되면서 RNN을 앞서갔습니다. 이 경우 RNN의 암묵적인 언어 모델은 오히려 역효과를 낼 수 있습니다.

명시적 모델과 비교했을 때 차이는 작았다. 그러나 기준 시스템에는 오디오 전처리, 발음 사전, 상태 결합, 강제 정렬과 같은 많은 사전 정보가 인코딩되었기 때문에 이는 상대적으로 작은 차이였다. 예상대로 언어 모델이 더 우세해짐에 따라 'RNN-CTC'와 'RNN-WER' 사이의 격차도 줄어들었다.

베이스라인 시스템은 14시간부터 81시간의 훈련 세트까지 점진적으로 개선되었지만, RNN 오류율은 극적으로 감소했습니다. 가능한 설명은 14시간의 전사된 음성은 RNN이 정확한 전사를 위해 필요한 단어들을 충분히 '맞추는' 방법을 배우기에는 부족하다는 것이며, 그러나 음소를 식별하는 방법을 배우기에는 충분하다는 것입니다.

결합된 모델은 RNN이나 기준선 개별적으로 수행한 것보다 상당히 우수한 성능을 보였습니다. 기준선 대비 1% 이상의 절대적인 향상은 모델 평균화로 일반적으로 볼 수 있는 미미한 향상보다 상당히 큽니다. 이는 아마도 시스템 간의 큰 차이 때문일 것입니다.

토론

문자 수준의 전사를 제공하기 위해서는 네트워크가 말 소리를 인식하는 방법뿐만 아니라 그것을 글자로 변환하는 방법도 배워야 합니다. 다시 말해, 철자를 배워야 합니다. 이는 특히 영어와 같은 철자 규칙이 불규칙한 언어에서 도전적입니다. 다음은 사전이나 언어 모델 없이 해독된 평가 세트의 예시로, 네트워크가 어떻게 작동하는지에 대한 통찰력을 제공합니다.

목표: 중동의 유명한 분석가를 나타내다.

워싱턴에서 한 캠페인으로부터 전화를 받아서 다시 세어보았다.

출력: 두 개의 알스트레이트 포인트, 중요한 중동 아나-

LYSTIMWASHINGTONRECOUNCACALLFROMONECAMPAIGN
리스팀 워싱턴 재계산 캠페인으로부터 전화를 받았습니다.

T. W. A. 또한 공중에 자사의 부티크 상호를 걸기로 계획하고 있다.

포트새트람버트생

T.W.A. 또한 공항에서 부티크 싱글을 힝니다.

램버트 세인트

모든 자본 조달은 밀라노 주식 시장에 기여했다.

소화불량작년

모든 자본 조달은 물롱가에서 이루어진 것으로 나타났다.

작년에 케틴토저스티안이 있었다.

목표: 동요는 있지만 우리는 그들을 잃지 않을 것이다.

두카키스

결과: 불안함은 있지만 우리는 그들을 잃지 않을 것이다.

데카키스

모든 음성 인식 시스템과 마찬가지로, 네트워크는 'single' 대신 'shingle'과 같은 음운적인 오류를 만들기도 하며, 때로는 'two'와 'to'와 같은 동음이의어를 혼동하기도 합니다. "Recurrent Neural Networks를 사용한 End-to-End 음성 인식으로의 진화"

01
확률은 친구입니다.

출력

파형
오류

그림 4. 네트워크 출력. 이 그림은 CTC 레이어에서 발생한 프레임 수준의 문자 확률을 보여줍니다 (각 문자에 대해 다른 색상, '빈칸'에는 점선 회색 선), 그리고 해당 훈련 오류를 처리하는 동안. 목표 전사는 '그의 친구들'이었으며, 밑줄은 단어 끝 표시입니다. 네트워크는 WER 손실로 훈련되었으며, 이는 매우 날카로운 출력 결정을 제공하고 따라서 희소한 오류 신호를 제공합니다 (출력 확률이 1이면 다른 것을 샘플링 할 수 없으므로 출력이 잘못되어도 기울기는 0입니다). 이 경우 'S' 앞의 잘못된 작은 따옴표에서만 기울기가 발생합니다. 'IS', 'RI' 및 'END'와 같은 공통 시퀀스의 문자가 매우 가까이 발생하는 것을 알 수 있으며, 이는 네트워크가 이를 단일 소리로 학습한다는 것을 시사합니다.

후자의 문제는 언어 모델로 해결하기가 보통보다 어려울 수 있습니다. 소리가 비슷한 단어들이 철자로는 상당히 다를 수 있기 때문입니다. 음성 체계와 달리, 이 네트워크는 어휘적인 오류도 발생시킵니다. 예를 들어, 'boutique' 대신 'bootik'과 같은 오류가 있으며, 'illustrate' 대신 'alstrait'와 같이 두 가지를 결합한 오류도 있습니다.

‘캠페인’, ‘분석가’ 및 ‘자본’과 같이 금융 텍스트에서 자주 나타나는 비교적 복잡한 단어를 올바르게 전사할 수 있습니다(특별한 경우로 학습할 수도 있음). 그러나 ‘밀란’과 ‘두카키스’와 같은 이름과 같이 익숙하지 않은 단어의 소리와 철자에 어려움을 겪습니다. 이는 사전이 없어도 문자 수준의 인식에서 단어 외의 어휘가 여전히 문제가 될 수 있다는 것을 시사합니다. 그러나 네트워크가 스펠링을 할 수 있다는 사실은 훈련 트랜스크립트에서 중요한 언어 정보를 추론할 수 있다는 것을 보여주며, 이는 진정한 엔드 투 엔드 음성 인식 시스템을 위한 길을 열어줍니다.

결론

이 논문은 최소한의 전처리와 명시적인 음성 표현 없이 순환 신경망을 사용하여 문자 수준의 음성 전사를 수행할 수 있음을 보여주었습니다. 또한, 우리는 단어 오류율에 대해 직접 최적화할 수 있는 새로운 목적 함수를 소개하였으며, 디코딩 중에 언어 모델과 네트워크 출력을 통합하는 방법을 보여주었습니다. 마지막으로, 새로운 모델을 기준선과 결합함으로써, 스피커 독립적인 인식을 위해 월스트리트저널 말뭉치에서 최첨단 정확도를 달성하였습니다.

미래에는 언어 모델이 덜 중요한 데이터셋, 예를 들어 즉흥적인 말이나 훈련 세트만으로도 네트워크가 언어 모델을 학습할 수 있는 충분히 큰 데이터셋에 시스템을 적용하는 것이 흥미로울 것입니다. 또 다른 유망한 방향은 CTC나 예상 전사 손실 목적 함수에 언어 모델을 통합하는 것입니다.

감사의 말씀

저자들은 Kaldi에 대한 도움을 주신 Daniel Povey에게 감사의 말씀을 전합니다. 이 연구는 캐나다 고등 연구소의 일부 지원을 받았습니다. 순환 신경망을 이용한 엔드 투 엔드 음성 인식을 향해

참고문헌

발, L., 브라운, P., 데 소우자, P.V., 그리고 머서, R. 음성 인식을 위한 숨겨진 마르코프 모델 매개변수의 최대 상호 정보 추정. 음향, 음성 및 신호 처리, IEEE 국제 컨퍼런스 ICASSP '86에서. 11권, 49-52쪽, 1986년 4월. doi: 10.1109/ICASSP.1986.1169179.

비사니, 막시밀리안과 네이, 헤르만. 평면 하이브리드 모델을 사용한 개방 어휘 음성 인식. INTERSPEECH에서, 725-728쪽, 2005년.

부를라르, 에르베 A. 그리고 모건, 넬슨. 연결주의 음성인식: 하이브리드 접근법. 클루워 학술 출판사, 노웰, MA, 미국, 1993. ISBN 0792393961.

Ciresan, Dan C., Meier, Ueli, Masci, Jonathan, 그리고
Schmidhuber, Jrgen. 교통 표지판 분류를 위한 신경망 위원회.
IJCNN에서, 1918-1921쪽. IEEE, 2011.

데이비스, S.와 멀멜스타인, P. 연속으로 말하는 문장에서 단음절 단어 인식을 위한 매개 변수 표현의 비교. IEEE 음향, 음성 및 신호 처리 트랜잭션, 28(4):357-366, 1980년 8월.

Eyben, F., Wllmer, M., Schuller, B., 그리고 Graves, A.
음성에서 문자로 - 그래프 기반 asr을 위한 새로운 신경망 아키텍처 사용.
Proc. Automatic Speech Recognition and Understanding Workshop (ASRU 2009), Merano, Italy. IEEE, 2009. 13.-17.12.2009.

Galescu, Lucian. OOV 단어의 인식
하위 어휘 언어 모델을 사용하여. INTERSPEECH에서,
2003년.

Gers, F., Schraudolph, N., 그리고 Schmidhuber, J. LSTM 순환 신경망을 사용한 정확한 타이밍 학습. 기계 학습 연구 저널, 3:115–143, 2002.

Graves, A. 및 Schmidhuber, J. 양방향 LSTM과 다른 신경망 구조를 사용한 프레임별 음소 분류. 신경망, 18(5-6):602-610, 2005년 6월/7월.

Graves, A., Fernández, S., Gomez, F., and Schmidhuber,
J. 연결주의 시간 분류: 순환 신경망을 사용하여 세분화되지 않은 순차 데이터에 레이블 지정. ICML, 피츠버그, 미국, 2006.

Graves, A., Mohamed, A., 그리고 Hinton, G. 깊은 순환 신경망을 이용한 음성 인식. ICASSP 2013 논문집, 캐나다 밴쿠버, 2013년 5월.

Graves, Alex. 순환 신경망을 이용한 지도 시퀀스 레이블링, Studies in Computational Intelligence 시리즈 385권. Springer, 2012.

힌턴, G. E.와 살라후딘노프, R. R. 신경망을 사용하여 데이터의 차원을 줄이기. 과학, 313(5786):504–507, 2006년 7월.

힌턴, 제프리, 덩, 리, 유, 동, 달, 조지, 라만 모하메드, 압델, 제이틀리, 나브딥, 세니어, 앤드류, 반하우크, 빈센트, 누이엔, 패트릭, 세이네스, 타라, 그리고 킹스버리, 브라이언. 음성 인식에서의 심층 신경망을 위한 음향 모델링. 신호 처리 매거진, 2012.

Hochreiter, S. 및 Schmidhuber, J. LongShort-Term Memory. Neural Computation, 9(8):1735–1780, 1997.

자이틀리, 나브딥 및 힌튼, 제프리 E. 제한된 볼츠만 머신을 사용하여 음성 파동의 더 나은 표현 학습. ICASSP에서, 2011년, 5884-5887쪽.

제이틀리, 나브딥, 뉴얀, 패트릭, 시니어, 앤드류 W, 그리고 반하우크, 빈센트. 사전 훈련된 심층 신경망의 대용량 어휘 음성 인식에의 응용. INTERSPEECH, 2012.

Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey E.
딥 컨볼루션 신경망을 사용한 이미지넷 분류.
신경정보처리 시스템 발전, 2012년.

이, 리, 로즈, R. 화자 정규화를 위한 주파수 왜곡 접근 방식. 음성 및 오디오 처리, IEEE 트랜잭션, 6(1):49-60, 1998년 1월.

피터스, J. 그리고 샬, S. 정책 기울기를 이용한 운동 기술의 강화 학습. 신경망, 4호, 682-97쪽, 2008년.

Povey, D., Ghoshal, A., Boulianne, G., Burget, L., Glem-
bek, O., Goel, N., Hannemann, M., Motlicek, P., Qian,
Y., Schwarz, P., Silovsky, J., Stemmer, G., and Vesely,
K. Kaldi 음성 인식 도구킷. IEEE 2011 자동 음성 인식 및 이해 워크샵에서. IEEE 신호 처리 학회, 2011년 12월.

슈스터, M. 및 파리왈, K. K. 양방향 순환 신경망. IEEE 신호처리 트랜잭션, 45:2673-2681, 1997.

