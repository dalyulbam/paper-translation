깊은 문맥화된 단어 표현

매튜 E. 피터스†, 마크 뉴만†, 모히트 이예†, 매트 가드너†,
{matthewp, markn, mohiti, mattg}@allenai.org

크리스토퍼 클락∗, 켄튼 리∗, 루크 제틀모이어†∗
{csquared,kentonl,lsz}@cs.washington.edu

†인공지능 앨런 연구소
∗워싱턴 대학교 폴 G. 앨런 컴퓨터 과학 및 공학 학부

요약

우리는 새로운 유형의 깊은 문맥화된 단어 표현을 소개합니다. 이 모델은 (1) 단어 사용의 복잡한 특성 (예: 구문과 의미)과 (2) 이러한 사용이 언어적 맥락에서 어떻게 다양하게 변하는지를 모델링합니다.

다의성). 우리의 단어 벡터는 깊은 양방향 언어 모델 (biLM)의 내부 상태의 학습된 함수로 이루어져 있으며, 이는 큰 텍스트 말뭉치에 사전 훈련된 상태입니다. 우리는 이러한 표현이 기존 모델에 쉽게 추가될 수 있으며, 큰 향상을 이끌어낼 수 있다는 것을 보여줍니다.

6개의 도전적인 NLP 문제를 포함한 최첨단 기술 상태입니다. 질문에 대한 답변, 텍스트 함의 및 감성 분석을 포함합니다. 또한 사전 훈련된 네트워크의 깊은 내부를 노출하는 것이 중요하다는 분석 결과를 제시합니다. 이를 통해 하류 모델이 혼합될 수 있습니다.

다양한 유형의 반지도 신호.

1 소개

미리 훈련된 단어 표현 (Mikolov et al.,

2013; Pennington et al., 2014)은 주요 구성 요소입니다.

많은 신경 언어 이해 모델에서 중요한 역할을 하는 요소입니다.

그러나, 고품질의 표현을 배우는 것은 중요합니다.

번역은 도전적일 수 있습니다. 이상적으로는

단어의 복잡한 특성을 모두 모델링하다.

문장을 한국어로 번역해주세요. 번역 외에는 작성하지 마세요. 

사용법(예: 구문 및 의미론)과 (2) 이러한 것들에 대해 어떻게

언어적 맥락에 따라 사용 방식이 다양합니다 (예: 모델링하기 위해)

다의성). 이 논문에서는 새로운 유형을 소개합니다.

깊은 문맥화된 단어 표현의

두 가지 도전에 직접적으로 대응할 수 있으며, 쉽게 할 수 있습니다.

기존 모델에 통합되었으며, 상당히

고려된 모든 것에서 기술의 상태를 개선합니다.

다양한 언어의 도전적인 경우에 대해 다루다.

이해하는 문제들.

우리의 표현은 전통적인 말과 다릅니다.

각 토큰에 할당된 유형 임베딩

전체 입력의 기능인 표현

우리는 양방향으로 유도된 벡터를 사용합니다.

커플링된 언어로 훈련된 전통적인 LSTM

텍스트 코퍼스에서의 언어 모델 (LM) 목표

푸스. 이 이유로 우리는 그들을 ELMo라고 부릅니다 (Em-

언어 모델의 침구) 표현.

alized word embeddings, we propose a novel method that incorporates both syntactic and semantic information.

et al., 2017) have been widely used in natural language processing tasks.

et al., 2017), ELMo 표현은 깊다.

그들이 모든 것의 기능이라는 느낌

biLM의 내부 레이어입니다. 더 구체적으로, 우리는

벡터들이 쌓인 선형 조합을 배웁니다.

위에 각 엔드 태스크의 입력 단어마다 번역을 작성하십시오.

그냥 사용하는 것보다 성능이 현저히 향상됩니다.

상위 LSTM 레이어.

이러한 방식으로 내부 상태를 결합하는 것은

매우 풍부한 단어 표현을 위한 낮은 값을 제공합니다. 사용 중인-

내재적 평가를 통해 우리는 상위 수준을 보여줍니다.

LSTM 상태는 문맥에 의존적인 측면을 포착합니다.

단어의 의미에 대해 (예: 그들은 ~와 함께 사용될 수 있습니다.

감독 학습에서 잘 수행하기 위한 수정 없이

단어 의미 모호성 해소 작업) 낮은

수준은 구문의 측면을 모델링합니다 (예: 그들은

어구 분석을 수행하는 데 사용됩니다). 동시에

이러한 신호들을 모두 노출하는 것은 매우 유익합니다.

학습된 모델들이 유형을 선택할 수 있도록 하는 인공지능

각각에 가장 유용한 반지도 학습 방법

작업을 종료하세요.

ELMo의 광범위한 실험은 보여줍니다.

표현은 실제로 매우 잘 작동합니다.

먼저 우리는 그들이 쉽게 추가될 수 있다는 것을 보여줍니다.

다양하고 도전적인 여섯 가지 모델에 대한 기존 모델

트 이해 문제, 텍스트를 포함한 것들

추론, 질문 답변 및 감정

분석. ELMo 표현의 추가

혼자서는 기술 수준을 크게 향상시킵니다.

모든 경우에, 상대 오차가 20%까지 포함됩니다.

감소. 직접 비교가 필요한 작업들에 대해서.

가능한 경우, ELMo는 CoVe보다 성능이 우수하다 (McCann)

et al., 2017)은 맥락화된 표현을 계산하는 것이다.

신경망 기계 번역을 사용한 프레젠테이션

코더. 마침내, ELMo와 함께한 분석을 진행했습니다.

CoVe는 깊은 표현이 LSTM의 최상위 레이어에서 파생된 것보다 우수함을 보여줍니다.

우리의 훈련된 모델과 코드는 공개적으로 이용 가능합니다.

능력이 있으며, 우리는 ELMo가 다른 많은 NLP 문제에도 유사한 효과를 제공할 것으로 기대합니다.

2 관련 연구

말뭉치와 음운적 특징을 포착할 수 있는 능력으로 인해

대규모 비구조화된 텍스트로부터 얻은 단어의 의미 정보

라벨이 달린 텍스트, 사전 훈련된 단어 벡터 (Turian et al.,

2010; Mikolov et al., 2013; Pennington et al.,

2010; Mikolov et al., 2013; Pennington et al.,

the-art smartphones.

질문에 대한 것을 포함한 NLP 아키텍처

답변 (Liu et al., 2017), 텍스트 함의

(Chen et al., 2017)와 의미 역할 라벨링

(He et al., 2017). 그러나 이러한 접근 방식은

단어 벡터 학습은 단 하나의 문맥만 허용합니다.

각 단어에 대한 독립적인 표현.

이전에 제안된 방법들은 몇 가지를 극복했습니다.

전통적인 단어 벡터의 단점 중 하나는

서브워드 정보를 풍부하게 함으로써 그들을 향상시키는 것 중 하나로

tion (예: Wieting et al., 2016; Bojanowski et al.,

2017) 또는 각 단어에 대해 별도의 벡터를 학습하는 것

감각 (예: Neelakantan et al., 2014). 우리의 접근-

서브워드 단위를 통해 접근도 이점을 얻습니다.

문자 컨볼루션의 사용과 우리는

다중 감각 정보를 무의식적으로 통합하다.

명시적으로 훈련하지 않고 하류 작업

미리 정의된 감각 클래스를 예측하다.

다른 최근 연구들은 또한 집중되었다.

학습에 맥락-의존적인 표현을 사용합니다.
context2vec (Melamud et al., 2016)는 사용합니다.

양방향 장기 단기 기억망 (LSTM)

Hochreiter와 Schmidhuber(1997)는 인코딩하기 위해

피벗 단어 주변의 맥락. 다른 접근 방식

문맥 임베딩을 학습하기 위해서는 다음을 포함해야 합니다.

피벗 단어 자체가 표현과 함께 있습니다.

지도 학습의 인코더로 계산됩니다.

신경 기계 번역 (MT) 시스템 (CoVe)

맥캔 등(2017) 또는 비감독형 언어

언어 모델 (Peters et al., 2017). 이 두 가지 모두

대규모 데이터셋을 활용하는 접근법은 혜택을 받습니다.

MT 접근법은 병렬 데이터의 크기에 제한을 받습니다.

코퍼스. 이 논문에서는 코퍼스의 모든 장점을 최대한 활용합니다.

풍부한 단일 언어 데이터에 접근하고 훈련하다.

우리의 biLM은 약 30개의 말뭉치에서 작동합니다.

백만 개의 문장 (Chelba et al., 2014). 또한 우리는

깊은 문맥에 대한 이러한 접근 방식을 일반화하다.

표현들은 우리가 보여주는 것처럼 잘 작동합니다.

다양한 NLP 작업의 넓은 범위.

1. http://allennlp.org/elmo
http://allennlp.org/elmo

이전 연구에서도 다른 사례들이 다른 것을 보여주었습니다.

깊은 biRNN의 레이어들은 다른 유형의 정보를 인코딩합니다.

구성. 예를 들어, 다중 작업 소개

구문 감독 (예: 품사 태그)에서

깊은 LSTM의 하위 레벨은 개선될 수 있습니다.

고급 수준의 작업 전반적인 성과

의존 구문 분석 (Hashimoto et al., 2017) 또는

CCG 슈퍼 태깅 (Søgaard and Goldberg, 2016).

RNN 기반의 인코더-디코더 기계 번역에서

번역 시스템, Belinkov et al. (2017)은 보여줬다.

층 신경망의 첫 번째 층에서 학습된 표현

레이어 LSTM 인코더는 품사를 예측하는 데 더 우수합니다.

태그 그런 다음 두 번째 층. 마지막으로, 맨 위의 층.

단어 문맥을 인코딩하기 위한 LSTM (Melamud et al.,)

2016) 표현 학습을 배울 수 있는 것으로 입증되었습니다.

단어 감각. 우리는 비슷한 신호들도 보여줍니다.

수정된 언어 모델 목표에 의해 유발된

우리의 ELMo 표현에 대해 말하면, 그것은 매우 중요할 수 있습니다.

하위 작업을 위해 모델을 배우는 것은 유익하다.

그것은 다양한 종류의 반지도를 혼합합니다.

다이와 레 (2015) 그리고 라마찬드란 외.

(2017) 언어를 사용하여 사전 훈련된 인코더-디코더 쌍을 사용합니다.

언어 모델과 시퀀스 오토인코더를 사용하여

특정 작업 감독과 함께 세밀하게 조정하다.

트랜스, 라벨이 없는 상태에서 biLM을 사전 훈련한 후에

데이터, 우리는 가중치를 고정하고 추가 작업을 추가합니다.

특정 모델 용량을 활용할 수 있게 해줍니다.

대규모, 풍부하고 보편적인 biLM 표현

하류 훈련 데이터 크기가 지배적인 경우

더 작은 감독 모델.

3 ELMo: 언어 모델로부터의 임베딩

대부분의 널리 사용되는 단어 임베딩과 달리 (Pen-

닝턴 외 (2014), ELMo 단어 표현

전체 입력 문장의 기능입니다, 따라서

이 섹션에 기재된 것입니다. 그들은 맨 위에서 계산됩니다.

문자 컨볼루션을 사용한 두 개의 층으로 이루어진 biLMs

(Sec. 3.1), 내부 넷의 선형 함수로 표현됩니다.

작업 상태 (3.2 절). 이 설정을 통해 우리는 할 수 있습니다.

학습, 양방향 언어 모델이 사전에 사용되는 준지도 학습

대규모로 훈련받았으며 (3.4절) 쉽게 통합될 수 있습니다.

기존의 다양한 신경망 기반 자연어 처리에 통합되었습니다.

건축물 (3.3절).

3.1 양방향 언어 모델

N개의 토큰(t 1,t 2,...,t N)으로 이루어진 시퀀스가 주어지면, 전방 언어 모델은 확률을 계산합니다.

시퀀스의 확률을 모델링하여 토큰 t k가 주어진 이전 기록 (t 1,...,t k−1)에 대한 확률을 계산합니다.

p(t 1,t 2,...,t N) = t 1,t 2,...,t N에 대한 확률 분포 =

N
(cid:89)
k=1p(t k | t 1,t 2,...,t k−1).

N
(cid:89)
k=1p(t k | t 1,t 2,...,t k−1).

최근의 최첨단 신경 언어 모델

(J´ ozefowicz et al., 2016; Melis et al., 2017; Mer-) 
(J´ ozefowicz 외, 2016; Melis 외, 2017; Mer-)

어떤 연구(ity et al., 2017)는 문맥에 독립적인 토큰 표현 xLM k를 계산합니다(토큰 임베딩이나 문자에 대한 CNN을 통해). 그런 다음 L개의 레이어를 통과시킵니다.

위로 향하는 LSTMs의 계층. 각 위치 k에서, 각

LSTM 레이어는 문맥에 따라 의존적인 표현을 출력합니다.

발표
− →
hLM
k,j
여기서 j = 1,...,L. 최상위 층

LSTM 출력, hLMk,L,은 다음을 예측하는 데 사용됩니다.

소프트맥스 레이어를 사용하여 토큰 t k+1을 예측합니다.
역방향 언어 모델은 정방향 언어 모델과 유사합니다.

역순으로 시퀀스를 실행하지만, 예측합니다.

미래 문맥을 고려하여 이전 토큰을 예측하십시오.

p(t 1,t 2,...,t N) = t 1,t 2,...,t N에 대한 확률 분포 =

N (cid:89)
k=1p(t
k
| t k+1,t k+2,...,t N).

N (cid:89)
k=1p(t
k
| t k+1,t k+2,...,t N).

이것은 유사한 방식으로 구현될 수 있습니다.

앞으로 LM, 각각의 역방향 LSTM 레이어 j와 함께

L레이어 깊은 모델에서 표현을 생성하는 경우,
←−
(t k+1,...,t N)가 주어졌을 때 t k의 hLM k,j.
biLM은 앞방향과 뒷방향을 모두 결합한다.

우리의 공식은 로그를 최대화하는 것을 함께합니다.

앞으로와 뒤로의 가능성:

N
k=1( logp(t k | t 1,...,t k−1;Θ

x,− →
Θ LSTM,Θ s)

+logp(t_k | t_k+1,...,t_N;Θ_x,←−Θ_LSTM,Θ_s) ).

우리는 토큰 표현을 위한 매개변수를 결합합니다.

포워드와 백워드 방향에서 텐서 연산 (Θ x)과 소프트맥스 레이어 (Θ s)를 유지하면서 수행합니다.

각 방향의 LSTMs에 대한 비율 매개변수.

전반적으로, 이 공식은 접근 방식과 유사합니다.

피터스 외 (2017)의 것과는 달리, 우리는

방향들 사이에 가중치를 공유하도록 하세요.

완전히 독립적인 매개변수를 사용하여.

다음 섹션에서는 이전 작업과 달리 우리는 ~으로 출발합니다.

단어 표현을 배우기 위한 새로운 접근 방식을 소개합니다.

선형 조합으로 이루어진 프레젠테이션들

biLM 레이어.

3.2 ELMo

ELMo는 특정 작업을 위한 조합입니다.

biLM에서 중간 계층 표현.

각 토큰 t k에 대해, L-레이어 biLM은 2L + 1개의 표현을 계산합니다.

R k = {xLM k,− → hLM k,j,←− hLM k,j | j = 1,...,L} = {hLM k,j | j = 0,...,L}

어디에 hLM이 있는지
k,0
토큰 레이어이며 hLM이 있는 곳입니다.

k,j = [− → hLM k,j ;←− hLM k,j], 각각의 biLSTM 레이어에 대해.

다운스트림 모델에 포함하기 위해 ELMo를 사용합니다.

R의 모든 레이어를 하나의 벡터로 축소합니다.

ELMo k = E(R k;Θ e). 가장 간단한 경우에는,
ELMo는 단지 최상위 레이어를 선택합니다. E(R k) = hLM

k, L, 안녕하세요.

Cann et al., 2017), we use pre-trained models to initialize our encoder and decoder.

Cann et al., 2017). 더 일반적으로, 우리는 계산한다.

모든 biLM 레이어의 작업 특정 가중치:

ELMotask
k
= E(R k;Θtask) = γtask

L

j=0
j는 0이다.

stask
stask

j
j

hLM
hLM

k,j
k,j

.

(1)
(1)에서 stask는 소프트맥스 정규화된 가중치이며,
스칼라 파라미터 γtask는 태스크 모델이 전체 ELMo 벡터를 조정할 수 있게 합니다. γ는 실용적인 중요성을 가집니다.

최적화 과정에 대한 지원의 중요성을 강조합니다 (sup- 참조).

세부 사항은 부록 자료를 참고하십시오. 고려해 볼 때

각 biLM 레이어의 활성화는 다릅니다.

배포, 일부 경우에는 적용하는 데 도움이 되기도 했습니다.

각 biLM에 레이어 정규화 (Ba et al., 2016)를 적용합니다.

가중치를 적용하기 전의 레이어.

3.3 지도 학습 NLP 작업에 biLM 사용하기

주어진 사전 훈련된 양방향 언어 모델과 지도 학습 아키텍처

대상 NLP 작업을 위한 텍스처는 간단한 과정입니다.

과제 모델을 개선하기 위해 biLM을 사용합니다. 우리는

단순히 biLM을 실행하고 모든 레이어를 기록하세요.

각 단어에 대한 대표적인 표현을 만듭니다. 그런 다음, 우리는 그것을 사용합니다.

이 모델은 이들의 선형 조합을 학습합니다.

표현, 아래에 설명된 대로.

먼저, 슈퍼의 가장 낮은 층을 고려해보십시오.

biLM 없이 훈련된 모델입니다. 대부분의 지도학습

NLP 모델들은 공통의 아키텍처를 공유합니다.

가장 낮은 층들은 우리가 ELMo를 추가할 수 있도록 해줍니다.

일관된, 통일된 방식으로. 일련의 시퀀스가 주어진다면

토큰 (t 1,...,t N)의 경우, 사전 훈련된 단어 임베딩을 사용하여 각 토큰 위치에 대해 문맥에 독립적인 토큰 표현 x k를 형성하는 것이 표준입니다.

침구 및 선택적으로 문자 기반 표현

테이션. 그런 다음, 모델은 문맥에 민감한 형태를 형성합니다.

대표적으로 양방향 RNN, CNN 또는 피드 포워드 네트워크를 사용하여 표현합니다.

지도 학습 모델에 ELMo를 추가하기 위해, 우리는

먼저 biLM의 가중치를 고정한 후에
ELMo 벡터 ELMotask를 연결하세요.

k
와
with
와 함께

x k와 ELMo 향상된 표현을 전달하세요.
[x k;ELMotask
k
] 작업 RNN으로 전달하세요. 어떤 경우에는

작업들 (예: SNLI, SQuAD)을 관찰하면 더욱 더 알 수 있습니다.

외부에 ELMo를 포함하여 개선사항

다른 세트를 도입하여 RNN 작업을 제외하십시오.

출력 특정 선형 가중치와 [h k;ELMotask k]로 대체하는 것입니다. 나머지 부분은

tional features can be used to improve the performance of the model.

훨씬 복잡한 맥락 안에서 상호작용이 일어날 수 있습니다.

복잡한 신경망 모델입니다. 예를 들어, SNLI를 참고하세요.

4절에서 수행된 실험은 바이어텐션 레이어를 사용했습니다.

biLSTMs를 따르거나, 지시 대응 해결을 따릅니다.

아래의 문장을 한국어로 번역하고 번역 외에는 작성하지 마십시오.

군집 모델이 적용된 분류 실험

biLSTMs의 상단에 배치되었습니다.

마침내, 우리는 중재자를 추가하는 것이 유익하다는 것을 발견했습니다.

ELMo (Srivastava et al.,의 중요한 수량의 탈락)

2014) 그리고 일부 경우에는 손실에 λw2 2를 추가하여 ELMo 가중치를 규제화합니다. 이는 ELMo 가중치에 귀납적 편향을 가합니다.

모든 biLM 레이어에 대해 평균에 가까이 머무르세요.

3.4 사전 훈련된 양방향 언어 모델

건축

이 논문의 사전 훈련된 양방향 언어 모델은 ~와 유사합니다.

J´ ozefowicz et al. (2016)의 아키텍처들과

김 등 (2015)은 공동 지원을 위해 수정되었습니다.

양방향 훈련과 잔여 연결을 추가합니다.

LSTM 레이어 간의 연결에 중점을 둡니다. 우리는 큰

이 작업에서는 Peters et al. (2017)와 같이 biLMs의 규모를 조정합니다.

biLMs를 사용하는 중요성을 강조했습니다.

전진만 가능한 언어 모델과 대규모 훈련.

전반적인 언어 모델의 혼란을 균형있게 조절하기 위해

모델 크기와 계산 요구 사항에 따라

하류 작업을 유지하면서 순수하게 유지

문자 기반 입력 표현, 우리는 모두 절반으로 줄였다.

J´ ozefowicz et al.의 단일 최상의 모델 CNN-BIG-LSTM에서 임베딩과 숨겨진 차원.

(2016). 최종 모델은 L = 2 biLSTM 레이어를 사용합니다.

4096개의 유닛과 512 차원의 프로젝션을 가진 에어서

그리고 첫 번째에서 두 번째로의 잔여 연결

레이어. 문맥에 민감하지 않은 유형의 표현

2048개의 문자 n-그램 컨볼루션 필터를 사용합니다.

두 개의 고속도로 층에 따라 (Srivastava 등,

2015) 그리고 512 표현으로 선형 투영

어떤 결과로서, biLM은 세 가지의 레이어를 제공합니다.

각 입력 토큰에 대한 표현의 벡터를 생성하는 방법을 포함하여

학습 세트 외부에 있는 것들을 제외하고 있습니다. 이는 순전히로 인해입니다.

문자 입력. 그에 반해, 전통적인 단어 처리-

침구 방법은 한 겹의 보호층만 제공합니다.

고정 어휘 사전에서 토큰에 대한 설명.

1B 단어로 10 에포크 동안 훈련한 후

벤치마크 (Chelba et al., 2014)는 평균입니다.

앞뒤로 혼란스러운 부분은 39.7이며, 앞으로 진행하는 CNN-BIG-LSTM의 경우 30.0과 비교했을 때입니다. 생성-

앨리, 우리는 앞뒤로 혼란스러운 것을 발견했어요.

뒤로 가는 것과 거의 같은 기회들이 있다.

가치가 약간 낮습니다.

훈련이 완료된 후, biLM은 표현을 계산할 수 있습니다.

어떤 작업에 대한 발표입니다. 일부 경우에는 세밀한 조정이 필요합니다.

cant improvements in various natural language processing tasks.

혼란 속에서는 눈물이 흐르고, 우울함은 증가한다.

스트림 작업 성능. 이는 ~로 볼 수 있습니다.

biLM의 도메인 이전 유형입니다. 결과적으로,

대부분의 경우에 우리는 세밀하게 조정된 양방향 언어 모델을 사용했습니다.

하류 작업. 부록 자료 참조.

세부 사항.

4 평가

Table 1은 ELMo의 성능을 보여줍니다.

다양한 유형의 6가지 기준 NLP 작업입니다. 모든 작업에서

작업을 고려할 때, 단순히 ELMo를 추가하는 것이 확립됩니다.

상대 오차 re-와 함께 새로운 최첨단 결과

강한 기초를 기준으로 6-20%의 감소.

다음은 모델들의 결과입니다. 이는 다양한 경우에 대한 매우 일반적인 결과입니다.

버스 세트 모델 아키텍처와 언어를 이해하다.

잔여 작업. 이 섹션의 나머지 부분에서는

개별 작업의 고수준 스케치를 제공하십시오.

결과; 전체 실험 자료는 부록을 참조하세요.

실험 세부 사항.

스탠포드 질문에 대한 답변

답변 데이터셋 (SQuAD) (Rajpurkar et al.,

2016년) 10만 명 이상의 크라우드 소싱 질문을 포함하고 있습니다.

주어진 범위 내에서 답이 되는 쌍의 답변

Wikipedia 단락. 우리의 기준 모델 (Clark

그리고 가드너, 2017)은 개선된 버전입니다.

서 등의 양방향 어텐션 플로우 모델.

(BiDAF; 2017). 자가-주의 층을 추가합니다.

이중 방향 어텐션 구성 요소 이후에, 간소화된

일부 풀링 연산을 수정하고 대체합니다.

게이트 순환 유닛(GRU)에 대한 LSTM

et al., 2014). 기준 모델에 ELMo를 추가한 후

모델, 테스트 세트 F1은 81.1%에서 85.8%로 4.7% 향상되었으며, 상대 오차 감소율은 24.9%입니다.

기준선, 그리고 전체 단일 모델의 개선

최첨단 기술로 1.4% 향상되었습니다. 11명으로 이루어진 앙상블입니다.

ble은 F1을 87.4로 밀어올렸으며, 이는 제출 시점에서의 최첨단 기술입니다. 2. 리더보드에 제출한 시점에서의 전반적인 상태입니다.

ELMo와 함께 4.7% 증가도 유의미합니다.

1.8% 향상을 추가하는 것보다 큽니다.

CoVe를 기준 모델로 사용합니다 (McCann et al., 2017).

2017년 11월 17일 기준.
과제 이전 최고 성과

우리

베이스라인
엘모 +

기준선
증가

절대적인

친척

SQuAD Liu et al. (2017) 84.4 81.1 85.8 4.7 / 24.9% 

SQuAD Liu et al. (2017) 84.4 81.1 85.8 4.7 / 24.9%

SNLI Chen et al. (2017) 88.6 88.0 88.7 ± 0.17 0.7 / 5.8% 

SNLI Chen et al. (2017) 88.6 88.0 88.7 ± 0.17 0.7 / 5.8%

SRL   He et al. (2017)    81.7 81.4   84.6     3.2 / 17.2% 

SRL   He 외 (2017)    81.7 81.4   84.6     3.2 / 17.2%

코레프 리 등 (2017) 67.2 67.2 70.4 3.2 / 9.8%

NER Peters et al. (2017) 91.93 ± 0.19 90.15 92.22 ± 0.10 2.06 / 21% 

NER Peters et al. (2017) 91.93 ± 0.19 90.15 92.22 ± 0.10 2.06 / 21%

SST-5 McCann et al. (2017) 53.7 51.4  54.7 ± 0.5 3.3 / 6.8% 

SST-5 McCann et al. (2017) 53.7 51.4  54.7 ± 0.5 3.3 / 6.8%

표 1: ELMo 향상된 신경망 모델과 최첨단 단일 모델 기준의 테스트 세트 비교 결과, 여섯 가지 벤치마크 NLP 작업에서의 성능. 성능 측정 지표는 작업에 따라 다름 - SNLI와 SST-5의 경우 정확도; SQuAD, SRL 및 NER의 경우 F1; Coref의 경우 평균 F1. NER와 SST-5의 테스트 크기가 작기 때문에, 다른 무작위 시드로 다섯 번 실행한 결과의 평균과 표준 편차를 보고합니다. "증가" 열은 기준선 대비 절대적 및 상대적 개선을 나열합니다.

텍스트 함의 텍스트 함의는

가설이라는 것을 결정하는 작업

사실, "전제"가 주어진다. 스탠포드 Natu-

ral 언어 추론 (SNLI) 말뭉치 (Bowman

et al., 2015)은 대략 55만 개의 가설을 제공합니다.

esis/premise 쌍들입니다. 우리의 기준선인 ESIM se-

Chen et al. (2017)의 시퀀스 모델은 biL-을 사용합니다.

STM는 전제와 가설을 인코딩하기 위해 사용된다.

매트릭스 어텐션 레이어와 함께 사용되는 로컬 인퍼런스를 통해

인코딩 레이어, 다른 biLSTM 추론 조합

풀링 연산 전에 먼저 합성곱 층을 거칩니다.

출력 레이어. 전반적으로 ELMo를 추가하는 것.

ESIM 모델은 평균적으로 정확도를 향상시킵니다.

0.7% 다섯 가지 무작위 시드에 걸쳐. 다섯 명의 구성원.

앙상블은 전체 정확도를 89.3%로 끌어올립니다.

이전 앙상블 최고치인 88.9%를 초과했습니다.

(공 등, 2018).

시맨틱 역할 표시-

ing (SRL) 시스템은 술어-인자 모델을 구축합니다.

문장의 구조는 종종 이렇게 설명됩니다.

누가 무엇을 누구에게 했는지에 대한 답변은 그가 했다. 그 외.

(2017)년에 SRL을 BIO 태깅 문제로 모델링했다.

그리고 전방으로 8개의 층을 가진 깊은 biLSTM을 사용했습니다.

그리고 역방향으로 번갈아 가며, 다음에 따라 가세요.

Zhou와 Xu (2015). 표 1에 나와 있는 것처럼, when

He et al.의 재구현에 ELMo를 추가합니다.

(2017) 단일 모델 테스트 세트 F1 점수가 81.4%에서 84.6%로 3.2% 상승했습니다 - 최신 기술 수준을 달성했습니다.

OntoNotes 벤치마크 (Pradhan et al., 2013)

이전 최고 앙상블보다도 개선되었습니다.

1.2%의 결과.

핵심 참조 해결 핵심 참조 해결

텍스트에서 멘션들을 클러스터링하는 작업은

같은 기저 실제 세계 개체를 참조합니다. 우리의

베이스라인 모델은 end-to-end 스팬 기반의 신경망 모델입니다.

이는 Lee et al. (2017)의 양방향 LSTM을 사용한 RAL 모델입니다.

그리고 주의 메커니즘은 먼저 범위를 계산합니다.

표현을 적용한 후 소프트맥스를 적용합니다.

핵심 참조 체인을 찾기 위한 토큰 순위 모델을 사용합니다.

OntoNotes coreference와 함께한 실험들

CoNLL 2012 공유 작업에서의 주석들

(Pradhan et al., 2012)에서 ELMo를 추가함으로써 성능이 향상되었다.

평균 F1은 67.2에서 70.4로 3.2% 증가하여 새로운 최고 수준을 세웠으며, 다시 한 번 개선되었습니다.

이전 최고 앙상블 결과에서 1.6% F1 향상.

명명된 개체 추출 CoNLL 2003

NER 작업 (Sang and Meulder, 2003)은 다음으로 구성되어 있다.

로이터 RCV1 말뭉치에서 태그가 지정된 뉴스 와이어
네 가지 다른 개체 유형 (PER, LOC, ORG, MISC)으로. 최근의 최첨단 시스템을 따라.

(Lample et al., 2016; Peters et al., 2017), 기반

라인 모델은 사전 훈련된 단어 임베딩을 사용합니다.

문자 기반 CNN 표현, 두 개의 양방향 LSTM

레이어와 조건부 랜덤 필드(CRF) 손실

(Lafferty et al., 2001), Collobert et al.와 유사합니다.

(2011). 표 1에 나와 있는 것처럼, 우리의 ELMo 향상된 모델은

biLSTM-CRF는 다섯 번의 실행을 평균한 92.22%의 F1을 달성합니다. 우리 시스템과의 주요 차이점은

그리고 이전의 최첨단 기술은 Peters et al.의 것이다.

(2017) 우리는 과제 모델이 학습할 수 있도록 허용했다.

모든 biLM 레이어의 가중 평균, Pe-

ters et al. (2017)은 최상위 biLM 레이어만 사용합니다.

5.1절에 나와있는 것처럼, 모든 레이어를 사용하여 단지 하나의 레이어만 사용하는 것보다.

마지막 층은 다중-성능을 향상시킵니다.

다음은 몇 가지 작업입니다.

감정 분석 세밀한 감정

스탠포드 감성 트리의 분류 작업

은행 (SST-5; Socher et al., 2013)은 선택을 포함한다.

positive) that indicate how you feel about the following statements.

영화에서 나온 한 문장을 설명하려면

보기. 이 문장들은 다양한 언어적 특징을 포함하고 있습니다.

현상은 관용구와 복잡한 구문 등과 같은 것들이다. 
작업 기준 마지막에만 존재한다.

모든 층

λ=1 람다=1
λ=0.001 람다=0.001

SQuAD 80.8 84.7 85.0 85.2

SNLI 88.1 89.1 89.3 89.5

SRL 81.6 84.1 84.6 84.8

표 2: SQuAD, SNLI 및 SRL의 개발 세트 성능, biLM의 모든 레이어를 사용하여 정규화 강도 λ의 다른 선택과 최상위 레이어만을 비교합니다.

작업
입력

입력하고
오직

출력

오직

SQuAD 85.1 85.6 84.8

SNLI 88.9 89.5 88.7

SRL 84.7 84.3 80.9

테이블 3: SQuAD의 개발 세트 성능.

SNLI와 SRL은 지도 모델의 다른 위치에 ELMo를 포함할 때.

틱 구조는 부정과 같은 것들이 어려운 것들이다.

모델들이 배우기 위한 문화입니다. 우리의 기준 모델은

바이어텐티브 분류 네트워크 (BCN)는

McCann et al. (2017)는 또한 이전을 유지했다.

CoVe와 함께 사용할 때 최첨단 결과

임베딩. CoVe를 ELMo로 대체하는 것.

BCN 모델의 결과는 1.0%의 절대 정확도를 보여줍니다.

최신 기술에 대한 개선.

5 분석

date the effectiveness of our proposed method.

우리의 주장을 날짜화하고 몇 가지 상호간의 관계를 명확히 하기 위해.

ELMo 표현의 흥미로운 측면을 살펴보겠습니다. 5.1절

깊은 문맥적 표현을 사용하는 것을 보여줍니다.

하류 작업에서는 성능이 향상됩니다.

이전 작업은 최상위 레이어만 사용하는 것으로 간주됩니다.

biLM에서 생성되었는지 여부에 관계없이

MT 인코더, 그리고 ELMo 표현

최고의 전반적인 성능을 제공합니다. 섹션 5.3 예-

다양한 맥락 정보 유형을 탐색합니다.

tion captured in biLMs and uses two intrinsic eval- 

biLMs에서 포착된 정보를 사용하고 내재적 평가 두 가지를 사용합니다.

문법 정보가 더 좋다는 것을 보여주는 상황들을 제시하십시오.

하위 계층에서 표현되는 동안 의미 정보는

정보는 더 높은 계층에서 포착되며 일관성을 유지합니다.

MT 인코더. 또한 우리의 biLM이 있다는 것을 보여줍니다.

CoVe보다 더 풍부한 표현을 제공합니다.

또한, 우리는 민감도를 분석합니다.

ELMo는 과제 모델에 포함되어 있습니다 (5.2절).

훈련 세트 크기 (5.4절) 및 ELMo 시각화

작업 간에 학습된 가중치 (5.5절).

5.1 대체로 층별 가중치 결정 방식

표현식 1에는 여러 가지 대안이 있습니다.

biLM 레이어를 결합합니다. 이전 연구에서는 con-

텍스트 표현은 오직 마지막 레이어만 사용했습니다.

biLSTM (Peters et al., 2017)로부터든지 상관없이

MT 인코더 (CoVe; McCann et al., 2017).

정규화 파라미터 λ의 선택은 또한

중요, λ = 1과 같은 큰 값들은 효과적이다.

단순한 가중 함수로 가중치를 감소시키다.

평균을 계층별로 구하면서 작은 값들은 (예를 들어,

λ = 0.001) 레이어 가중치를 변동할 수 있게 허용합니다.

표 2는 SQuAD에 대한 이러한 대안들을 비교합니다.

SNLI와 SRL. 모두의 표현을 포함하여.

레이어는 단순히 사용하는 것보다 전반적인 성능을 향상시킵니다.

마지막 층을 포함하여 문맥적 표현을 포함합니다.

마지막 층의 표현은 성능을 향상시킵니다.

베이스라인을 넘어서는 멜로디. 예를 들어,

SQuAD의 경우, 마지막 biLM 레이어만 사용합니다.

기준선 대비 F1 개발을 3.9% 증가시킵니다.
모든 biLM 레이어를 평균화하여 사용하는 대신에 단지 사용하는 것.

마지막 레이어는 F1을 추가로 0.3% 향상시킵니다 (λ=1 열과 "마지막만" 비교). 그리고 다음을 허용합니다.

개별 레이어 가중치를 학습하기 위한 작업 모델

F1 점수는 λ=1 대비 λ=0.001에서 추가로 0.2% 향상되었습니다. ELMo의 대부분의 경우에는 작은 λ가 선호됩니다.

NER에 대해서는 훈련 세트가 작은 작업이지만,

결과는 λ에 민감하지 않습니다 (표시되지 않음).

a few differences.

기준선 대비 작은 증가입니다. SNLI의 경우, 평균

모든 레이어를 λ=1로 평균화하면 개발이 향상됩니다.

정확도가 단순히 사용하는 것보다 88.2%에서 88.7%로 증가했습니다.

마지막 레이어. SRL F1은 마지막 레이어를 사용하는 경우에 비해 λ=1 경우에 약간 0.1% 증가하여 82.2가 되었습니다.

레이어만.

5.2 ELMo를 어디에 포함해야 할까요?

이 논문의 모든 작업 구조에는 다음이 포함됩니다.

단어 임베딩은 가장 낮은 레이어의 입력으로만 사용됩니다.

biRNN. 그러나 우리는 ELMo를 포함하는 것이 좋다는 것을 발견했습니다.

과제별 아키텍처에서 biRNN의 출력

특정 작업에 대해 특성이 개선되면 전반적인 결과도 향상됩니다.

Table 3에 표시된 것을 포함하여 ELMo가 양쪽에 있는

SNLI와 SQuAD를 위한 입력 및 출력 레이어를 구성하십시오.

입력 레이어만으로 증명하지 않고 SRL에 대해서도 증명합니다.

핵심 참조 해결(표시되지 않음) 성능은

입력 레이어에 포함되었을 때에만 최고입니다.

이 결과에 대한 하나의 가능한 설명은 둘 다

SNLI와 SQuAD 아키텍처는 어텐션을 사용합니다.

biRNN 이후의 레이어들에 ELMo를 도입합니다.

이 레이어는 모델이 직접적으로 주목할 수 있도록 허용합니다.

biLM의 내부 표현. SRL 경우에는,
원본           가장 가까운 이웃들

글로브 플레이

놀기, 게임, 게임들, 놀았다, 플레이어들, 놀아요, 플레이어

놀기, 축구, 멀티플레이어

비엘엠
치코 루이즈는 특이한 것을 만들었다.

알루식의 환상적인 플레이

그라운더 {...}

키퍼는 그룹에서 유일한 준학생으로 칭찬을 받았다.

클러치 상황에서 타격 능력과 전반적인 능력 때문에

훌륭한 연기입니다.

올리비아 데 하빌랜드

브로드웨이에 서명했습니다.

가르송을 위해 연주하다 {...}

{...} 그들은 주목할 만한 역할을 맡은 배우들이었다.

성공한 연극이었고, 역할을 채울만큼의 재능이 있었다.

능숙하게, 좋은 절제로.

테이블 4: GloVe와 biLM의 컨텍스트 임베딩을 사용하여 "play"에 가장 가까운 이웃들.

모델              F1

WordNet 1번째 의미 기준선 65.9

라가나토 외 (2017a) 69.9

Iacobacci 외 (2016) 70.1

CoVe, 첫 번째 층 59.4

코브, 두 번째 레이어 64.7

biLM, 첫 번째 층 67.4

biLM, 두 번째 층 69.0

표 5: 모든 단어의 세밀한 의미 해석 F1. CoVe와 biLM에 대한 점수를 첫 번째와 두 번째 레이어 biLSTMs에 대해 보고합니다.

과제별 문맥 표현은 아마도

biLM보다 중요한 것은 더 많습니다.

5.3 어떤 정보가 포착되나요?

biLM의 표현?

ELMo를 추가하면 작업 성능이 향상됩니다.

단어 벡터만으로는 biLM의 문맥적 이해력이 부족합니다.

표현은 정보를 일반화해야 합니다.

NLP 작업에 캡처되지 않은 모든 유용한 도구입니다.

단어 벡터에서. 직관적으로, biLM은 반드시.

단어의 의미를 명확히 하기 위해 의미를 구분하다.

그들의 맥락. "놀이"를 고려해보십시오. 이는 매우 다의어적입니다.

세모스 단어. 테이블 4의 상단에 가까운 목록이 있습니다.

GloVe 벡터를 사용하여 "play"하는 이웃을 찾습니다.

그들은 여러 품사에 퍼져있다.

플레이한, 플레이 중인, 플레이어

"게임"은 명사로 사용되지만 스포츠에 집중되어 있습니다.

"play"의 관련된 의미들. 대조적으로, 아래쪽

두 줄은 가장 가까운 이웃 문장을 보여줍니다.

biLM의 사용하여 아래의 SemCor 데이터셋

원문에서 "play"의 문맥 표현

이러한 경우에는 biLM이 해석을 할 수 있습니다.

두 가지로 구분하여 품사와 단어 의미를 설명하다.

Please provide the source sentence that you would like to be translated into Korean.

이러한 관찰은 양적으로 측정될 수 있습니다.

모델           정확도

콜로베르 등 (2011) 97.3

마와 호비 (2016) 97.6

Ling et al. (2015) 97.8

CoVe, 첫 번째 층 93.3

코브, 두 번째 레이어 92.8

biLM, 첫 번째 레이어 97.3

biLM, 두 번째 층 96.8

표 6: PTB에 대한 테스트 세트 POS 태깅 정확도. CoVe와 biLM에 대해서는 첫 번째와 두 번째 레이어 biLSTM의 점수를 보고합니다.

문맥적 표현의 본질적 평가

Belinkov et al. (2017)와 유사한 연구를 수행했습니다. 격리하기 위해

biLM에 의해 인코딩된 정보, 표현

sentations은 직접 예측을 위해 사용됩니다.

미세한 단어 의미 해소 (WSD)

작업과 POS 태깅 작업을 수행합니다. 이 접근 방식을 사용하여,

CoVe와 비교하고, 건너편과도 비교할 수도 있습니다.

개별적인 각 층.

단어 의미 해소 주어진 문장을 기준으로,

우리는 biLM 표현을 사용하여 예측할 수 있습니다.

단순한 1-을 사용하여 대상 단어의 의미

가장 가까운 이웃 접근법, Melamud와 유사

et al. (2016). 이를 위해, 우리는 먼저 biLM을 사용합니다.

Sem-의 모든 단어에 대한 표현을 계산하기 위해

Cor 3.0, 우리의 훈련 말뭉치 (Miller et al., 1994),

그리고 각각에 대한 평균 표현을 사용하세요.

테스트 시간에는 다시 biLM을 사용합니다.

주어진 목표 단어에 대한 퓨트 표현을 생성하고

훈련에서 가장 가까운 이웃 감각을 가져옵니다.

설정, WordNet의 첫 번째 의미로 돌아가기

훈련 중 관찰되지 않은 레마들에 대해서는 번역하지 않습니다.

표 5는 평가를 사용하여 WSD 결과를 비교합니다.

Raganato et al. (2017b)의 평가 프레임워크에서 유래된 상황

Raganato의 네 가지 테스트 세트 전체에 걸쳐서

et al. (2017a). 전반적으로, biLM 상위층 표현은 F1이 69.0으로, WSD에서 첫 번째 층보다 더 우수합니다. 이는 경쟁력이 있습니다.

최첨단 WSD 특화 지도학습 모델

수작업으로 만든 특징을 사용합니다 (Iacobacci et al., 2016)

그리고 훈련된 작업 특정 biLSTM

보조 공정 세분화된 의미 레이블과 함께

POS 태그 (Raganato et al., 2017a). CoVe

biLSTM 레이어는 비슷한 패턴을 따릅니다.

biLM (전반적으로 더 높은 성능을 가진 양방향 언어 모델)에서

두 번째 층은 첫 번째 층과 비교했을 때 조금 작습니다. 그러나, 우리의

biLM는 CoVe biLSTM보다 우수한 성능을 보여줍니다.

WordNet 첫 번째 의미 기준선.

POS 태깅은 biLM을 검사하기 위한 것인지 확인하기 위해 사용됩니다.

기본 구문을 포착하였으며, 우리는 맥락을 사용하였습니다.

선형 분류기에 입력으로 사용되는 표현들

월스트리트 저널 부분과 함께한 사전의 품사 태그입니다.

펜 트리뱅크 (PTB) (Marcus et al., 1993)의 일부로.

선형 분류기는 매우 작은 양만 추가합니다.

모델 용량에 대한 이는 biLM의 직접 테스트입니다.

표현들. WSD와 유사하게, biLM 표현-

프레젠테이션은 조심스럽게 조정되어 경쟁력을 갖추고 있습니다.

Kim, 2017) have been widely used in various natural language processing tasks, such as named entity recognition, sentiment analysis, and machine translation. These models have shown promising results in capturing the contextual information of words and improving the performance of these tasks.

Hovy, 2016). 그러나 WSD와 달리 정확도는

첫 번째 biLM 레이어를 사용한 결과가 더 높습니다.

상위 레이어, 딥 바이엘 결과와 일치

STMs는 다중 작업 훈련에서 사용됩니다 (Søgaard and Gold-).

버그, 2016; 하시모토 외, 2017)와 MT (Be-

링코프 외 (2017). CoVe POS 태깅 정확도

biLM의 패턴을 따라주세요.

WSD와 마찬가지로, biLM은 더 높은 성능을 달성합니다.

CoVe 인코더보다 정확도가 높습니다.

감독된 작업에 대한 함축적인 의미

이 실험들은 서로 다른 층들을 확인합니다.

biLM에서는 다른 유형의 정보를 나타냅니다.

모든 biLM 레이어를 포함하는 이유를 설명하십시오.

다운에서 최고의 성능을 위해 중요합니다.

스트림 작업. 또한, biLM의 표현

토큰은 WSD와 POS 태그에 더 적합하게 전달됩니다.

CoVe보다 더 중요한 이유를 설명하는 데 도움이 되는 것들이 있습니다.

ELMo는 하류 작업에서 CoVe보다 성능이 우수하다.

5.4 샘플 효율성

ELMo를 모델에 추가하면 샘플 효과가 증가합니다.

효율성은 상당히 향상되었으며, 숫자와 관련하여도 마찬가지입니다.

성능을 달성하기 위한 매개변수 업데이트

맨스와 전체 훈련 세트 크기에 따라 성능이 달라집니다. 예를 들어,

예를 들어, SRL 모델은 최대 개발 수준에 도달합니다.

ELMo를 추가한 후에는, 모델이 486번의 학습 후에 F1 성능을 능가합니다.

기준선 최대치는 10번 에포크에서 98% 상대적입니다.

도달하기 위해 필요한 업데이트 수의 감소

그림 1: 기준 대 ELMo 성능 비교

SNLI와 SRL에 대한 성능을 평가하였으며, 훈련 세트 크기를 0.1%에서 100%까지 다양하게 변화시켰다.

그림 2: 태스크와 ELMo 위치에 따른 softmax 정규화된 biLM 레이어 가중치의 시각화. 1/3보다 작은 정규화된 가중치는 수평선으로 무늬가 있고, 2/3보다 큰 가중치는 점무늬가 있다.

동일한 수준의 성능.

또한, ELMo 향상 모델을 사용합니다.

더 작은 훈련 세트를 더 효율적으로 학습합니다.

ELMo 없이 ELS. 그림 1은 per-을 비교합니다.

기준 모델의 성능을 포함하여 비교해보세요.

ELMo의 전체 학습 세트의 백분율로는

0.1%부터 100%까지 다양했습니다. 개선 사항은

ELMo는 작은 교육 세트에 가장 큽니다.

훈련 데이터의 양을 크게 줄이다.

주어진 성능 수준에 도달하기 위해 필요한 것이다.

SRL 케이스, 1%의 ELMo 모델과 함께.

훈련 세트는 기준 모델의 10%만 사용한 경우와 거의 동일한 F1을 가지고 있습니다.

5.5 학습된 가중치의 시각화

그림 2는 소프트맥스 정규화를 시각화합니다.

입력층에서 학습된 가중치입니다.

과제 모델은 첫 번째 biLSTM 레이어를 선호합니다.

공통 참조와 SQuAD, 이것은 강하게.

선호되지만 분포는 덜 뾰족합니다.

다른 작업들. 출력 계층의 가중치는

비교적 균형 잡힌 상태이며, 약간의 선호도를 가지고 있습니다.

하위 계층들.
6 결론

우리는 학습을 위한 일반적인 접근법을 소개했습니다.

고품질의 깊은 문맥 의존적 표현을 제공하는 중입니다.

biLMs로부터의 표현을 사용하고, 큰 개선을 보였습니다.

ELMo를 다양한 분야에 적용할 때의 주의사항

NLP 작업. 제거 실험과 다른 통제된 실험을 통해.

실험을 통해 우리는 또한 확인했습니다.

biLM 레이어는 효율적으로 다양한 유형의 정보를 인코딩합니다.

단어에 대한 구문 및 의미 정보

문맥상, 모든 레이어를 사용하는 것이 개선됩니다.

모든 작업 수행.

참고문헌

지미 바, 라이언 키로스, 그리고 제프리 E. 힌튼. 2016년.
레이어 정규화. CoRR abs/1607.06450.

요나탄 벨린코프, 나디르 두라니, 파힘 달비, 하산 사자드, 그리고 제임스 R. 글래스. 2017년. 신경 기계 번역 모델은 형태론에 대해 무엇을 배우는가? ACL에서.

피오트르 보야노프스키, 에두아르 그라브, 아르망 주랭, 토마스 미코로프. 2017. 서브워드 정보로 단어 벡터를 풍부하게 하는 방법. TACL 5:135–146.

사무엘 R. 보우먼, 가보르 안젤리, 크리스토퍼 포츠, 그리고 크리스토퍼 D. 매닝. 2015. 자연어 추론 학습을 위한 대규모 주석 말뭉치. 2015 년 자연어 처리에 대한 경험적 방법 (EMNLP) 컨퍼런스 논문집에서 발표. 계산언어학 협회.

CiprianChelba, TomasMikolov, MikeSchuster, QiGe,
Thorsten Brants, Phillipp Koehn, and Tony Robin-
son. 2014. 통계 언어 모델링의 진전을 측정하기 위한 10억 단어 벤치마크. INTERSPEECH에서.

Qian Chen, Xiao-Dan Zhu, Zhen-Hua Ling, Si Wei,
Hui Jiang, and Diana Inkpen. 2017. Enhanced lstm
for natural language inference. In ACL.

Qian Chen, Xiao-Dan Zhu, Zhen-Hua Ling, Si Wei,
Hui Jiang, 그리고 Diana Inkpen. 2017년. 자연어 추론을 위한 향상된 LSTM. ACL에서.

Jason Chiu와 Eric Nichols. 2016. 양방향 LSTM-CNN을 이용한 개체명 인식. TACL에서.

경현 조, 바트 반 메리엔부어, 드미트리 바단아우, 그리고 요슈아 벤지오. 2014년. 신경망 기계 번역의 특성에 대하여: 인코더-디코더 접근 방식. SSST@EMNLP에서.

크리스토퍼 클락과 매튜 가드너. 2017. 간단하고 효과적인 다단락 독해. CoRR abs/1710.10723.

케빈 클락과 크리스토퍼 D. 매닝. 2016. 언급 순위 맞춤형 공조 참조 모델을 위한 심층 강화 학습. EMNLP에서.

Ronan Collobert, Jason Weston, L´ eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa. 2011. 자연어 처리 (거의) 처음부터. JMLR에서.

앤드류 M. 다이와 쿼크 V. 레. 2015. 반지도 시퀀스 학습. NIPS에서.

그렉 듀렛과 단 클라인. 2013년. 핵심 참조 해결에서의 쉬운 승리와 어려운 전투. EMNLP에서.

야린 갈과 주빈 가라마니. 2016. 순환 신경망에서 드롭아웃의 이론적 기반 응용. NIPS에서.

이첸 공, 헝 루오, 그리고 지안 장. 2018. 상호작용 공간에서의 자연어 추론. ICLR에서.

카즈마 하시모토, 카이밍 씨옹, 요시마사 츠루오카, 그리고 리처드 소처. 2017년. 공동 다중 작업 모델: 다중 NLP 작업을 위한 신경망 성장. EMNLP 2017에서.

루헝 허, 켄튼 리, 마이크 루이스, 루크 S. 제틀레모이어. 2017. 깊은 의미 역할 라벨링: 무엇이 동작하고 무엇이 다음 단계인가. ACL에서.

셉 호크라이터와 유르겐 슈미드후버. 1997년. 장단기 기억. 신경 계산 9.

이그나시오 이아코바치, 모하마드 타허 필레바르, 그리고 로베르토 나비글리. 2016년. 단어 의미 모호성 해소를 위한 임베딩: 평가 연구. ACL에서.

라팔 요제포비치, 오리올 비냐르스, 마이크 슈스터, 노암 샤지어, 그리고 용희 우. 2016년. 언어 모델링의 한계 탐색. CoRR abs/1602.02410.

라팔 요제포비치, 보이체 자레바, 그리고 일리야 숫크에버. 2015년. 순환 신경망 아키텍처의 경험적 탐구. ICML에서.

윤 김, 야신 제르니트, 데이비드 손택, 알렉산더 M 러쉬. 2015. 캐릭터 인식 신경 언어 모델. AAAI 2016에서.

디에더릭 P. 킹마와 지미 바. 2015. Adam: 확률적 최적화를 위한 방법. ICLR에서.

안킷 쿠마르, 오잔 이르소이, 피터 온드루스카, 모히트 이예르, 이샨 굴라자니 제임스 브래드버리, 빅터 종, 로맹 폴루스, 그리고 리처드 소처. 2016년. 무엇이든 물어보세요: 자연어 처리를 위한 동적 메모리 네트워크. ICML에서.

존 D. 라퍼티, 앤드류 맥캘럼, 페르난도 페레이라. 2001. 조건부 랜덤 필드: 일련 데이터의 분할과 레이블링을 위한 확률적 모델. ICML에서.

Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. 2016. 명명된 개체 인식을 위한 신경 아키텍처. NAACL-HLT에서.
Kenton Lee, Luheng He, Mike Lewis, and Luke S. Zettlemoyer. 2017. 엔드 투 엔드 신경 공조 해결. EMNLP에서.

왕 링, 크리스 다이어, 앨런 W. 블랙, 이사벨 트란-
코소, 라몬 페르만데스, 실비오 아미르, 루이스 마루조,
그리고 티아고 루이스. 2015. 형태에서 기능 찾기:
개방 어휘 단어 표현을 위한 구성적인 문자 모델. EMNLP에서.

Xiaodong Liu, Yelong Shen, Kevin Duh, and Jianfeng Gao. 2017년. 기계 독해를 위한 확률적 답변 네트워크. arXiv 사전 인쇄 arXiv:1712.03556.

Xuezhe Ma와 Eduard H. Hovy. 2016. 양방향 LSTM-CNNs-CRF를 통한 end-to-end 시퀀스 라벨링. ACL에서.

Mitchell P. Marcus, Beatrice Santorini, 그리고 Mary Ann Marcinkiewicz. 1993년. 영어의 큰 주석이 달린 말뭉치 구축: 펜 트리뱅크. 컴퓨터 언어학 19:313–330.

브라이언 맥캔, 제임스 브래드버리, 카이밍 씽, 그리고 리처드 소처. 2017년. 번역에서 배운 것: 맥락화된 단어 벡터. NIPS 2017에서.

오렌 멜라무드, 야콥 골드버거, 이도 다간.
2016년. context2vec: 양방향 lstm을 사용하여 일반적인 문맥 임베딩 학습. CoNLL에서 발표.

G´ abor Melis, Chris Dyer, 그리고 Phil Blunsom. 2017. 신경 언어 모델 평가의 최신 동향에 대하여. CoRR abs/1707.05589.

스티븐 메리티, 니티시 시리쉬 케스카, 그리고 리처드 소처. 2017년. LSTM 언어 모델의 정규화와 최적화. CoRR abs/1708.02182.

토마스 미콜로프, 일리야 숫스케버, 카이 첸, 그레그 S 코라도, 그리고 제프 딘. 2013년. 단어와 구문의 분산 표현과 그들의 조합성. NIPS에서.

조지 A. 밀러, 마틴 코도로우, 샤리 랜드스, 클라우디아 리콕, 그리고 로버트 G. 토마스. 1994년. 의미 식별을 위한 의미적 일치도 사용. HLT에서.

츠엔드수렌 문크다라이와 홍유. 2017. 텍스트 이해를 위한 신경망 트리 인덱서. EACL에서.

아르빈드 니라칸탄, 지반 샨카르, 알렉산드르 파스소스, 그리고 앤드류 맥콜럼. 2014년. 벡터 공간에서 단어당 다중 임베딩의 효율적인 비모수적 추정. EMNLP에서.

마사 파머, 폴 킹스베리, 그리고 다니엘 길데아.
2005년. Thepropositionbank: 의미 역할의 주석이 달린 말뭉치. 계산 언어학 31:71-106.

제프리 페닝턴, 리처드 소처, 그리고 크리스토퍼 D. 매닝. 2014. Glove: 단어 표현을 위한 글로벌 벡터. EMNLP에서.

매튜 E. 피터스, 왈리드 암마르, 찬드라 바가바툴라, 그리고 러셀 파워. 2017년. 양방향 언어 모델을 이용한 준지도 시퀀스 태깅. ACL에서.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Hwee Tou Ng, Anders Björkelund, Olga Uryupina,
Yuchen Zhang, and Zhi Zhong. 2013. 온토노트를 사용한 견고한 언어 분석을 향하여. CoNLL에서.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012년. Conll-2012 공유 작업: 온토노트에서의 다국어 무제한 핵심 참조 모델링. EMNLP-CoNLL 공유 작업에서.

알레산드로 라가나토, 클라우디오 델리 보비, 그리고 로베르토 나비글리. 2017a. 단어 의미 모호성을 위한 신경망 시퀀스 학습 모델. EMNLP에서.

알레산드로 라가나토, 호세 카마초-콜라도스, 그리고 로베르토 나비글리. 2017b. 단어 의미 구분: 통합 평가 프레임워크와 경험적 비교. EACL에서.

PranavRajpurkar, JianZhang, KonstantinLopyrev, and Percy Liang. 2016. Squad: 100, 000+ questions for machine comprehension of text. In EMNLP. 

프라나브 라즈푸르카, 지안 장, 콘스탄틴 로피레프, 퍼시 량. 2016. Squad: 텍스트 기계 이해를 위한 100,000개 이상의 질문. EMNLP에서.

Prajit Ramachandran, Peter Liu, and Quoc Le. 2017년.
레이블이 없는 데이터를 사용하여 시퀀스 학습 개선하기. EMNLP에서.

에릭 F. 통 김 상과 피엔 데 뮐더.
2003년. CoNLL-2003 공유 작업에 대한 소개:
언어 독립적인 명명된 개체 인식. CoNLL에서.

민준서, 아니루다 켐바비, 알리 파르하디, 그리고 한나네 하지시르지. 2017년. 기계 이해를 위한 양방향 주의 흐름. ICLR에서.

리처드 소처, 알렉스 페렐리진, 전 제인 우, 제이슨 차앙, 크리스토퍼 D 매닝, 앤드류 Y 엔지, 그리고 크리스토퍼 포츠. 2013년. 감성 트리뱅크를 통한 의미 합성에 대한 재귀적인 깊은 모델. EMNLP에서.

안데르스 쇼가드와 요아브 골드버그. 2016년. 하위 레이어에서 낮은 수준의 작업을 지도하는 깊은 다중 작업 학습. ACL 2016에서.

니티시 스리바스타바, 제프리 E. 힌튼, 알렉스 크리즈헤브스키, 일리야 수츠케버, 그리고 루슬란 살라후트디노프. 2014년. 과적합을 방지하기 위한 간단한 방법인 드롭아웃. 기계 학습 연구 저널 15:1929-1958.

Rupesh Kumar Srivastava, Klaus Greff, and Jürgen Schmidhuber. 2015. 매우 깊은 신경망 훈련. NIPS에서.

Joseph P. Turian, Lev-Arie Ratinov, and Yoshua Ben-
gio. 2010. 단어 표현: 반지도 학습을 위한 간단하고 일반적인 방법. ACL에서.
Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang,
and Ming Zhou. 2017. 독해와 질문 답변을 위한 게이트 자기 일치 네트워크. ACL에서.

존 위팅, 모히트 반살, 케빈 김펠, 그리고 카렌 리브스쿠. 2016년. Charagram: 문자 n-그램을 통한 단어와 문장 임베딩. EMNLP에서 발표.

Sam Wiseman, Alexander M. Rush, and Stuart M. Shieber. 2016. 핵심 참조 해결을 위한 전역 특징 학습. HLT-NAACL에서.

매튜 D. 제일러. 2012. Adadelta: 적응형 학습률 방법. CoRR abs/1212.5701.

지에 주와 웨이 쉬우. 2015. 재귀 신경망을 사용한 의미 역할 라벨링의 엔드 투 엔드 학습. ACL에서.

펑 주, 젠유 치, 순종 정, 지아밍 쉬,
홍윤 바오, 그리고 보 쉬. 2016년. 이중방향 LSTM과 이차원 최대 풀링을 통합하여 개선된 텍스트 분류. COLING에서 발표.
깊은 문맥화된 단어 표현을 동반하는 부록 자료.

이 보충제에는 모델 ar의 세부 사항이 포함되어 있습니다.

아키텍처, 훈련 루틴 및 하이퍼파라미터

섹션에서 최첨단 모델의 선택지

4. I love to travel and explore new places.

모든 개별 모델들은 공통적인 아르-를 공유합니다.

최하위 계층에서의 아키텍처는 문맥에 독립적입니다.

여러 개의 층 아래에 있는 펜던트 토큰 표현

스택된 RNN - LSTM은 모든 경우에 예외 없이 사용됩니다.

GRU를 사용하는 SQuAD 모델.

미세 조정 biLM

3.4절에서 언급한 대로, 과제에 대한 biLM의 세부 조정을 수행합니다.

구체적인 데이터는 일반적으로 큰 하락으로 이어지곤 합니다.

주어진 작업에 대해 세밀하게 조정하기 위해 혼란 속에서.

감독 라벨은 일시적으로 무시되었습니다.

훈련 데이터셋에서 biLM을 한 epoch 동안 세밀하게 조정했습니다.

개발 분할에 대해 평가되었습니다. 한 번 더 좋아요.

작업 중에는 biLM 가중치가 고정되어 있습니다.

훈련.

테이블 7은 개발 세트의 혼란도를 나열합니다.

고려된 작업들. CoNLL을 제외한 모든 경우에.

2012년, 세밀한 조정 결과로 큰 개선이 이루어졌다.

복잡함, 예를 들어 SNLI의 경우 72.1에서 16.8로 감소했습니다.

미세 조정의 영향은 지도 학습 성능에 있습니다.

맨스는 작업에 따라 다릅니다. SNLI의 경우,

바이어스 언어 모델의 세부 조정은 개발 정확도를 향상시켰다.

우리의 최고의 단일 제품에 대한 점유율은 88.9%에서 89.5%로 0.6% 증가했습니다.

모델. 그러나 감정 분류에 대해서는

개발 세트 정확도는 대략 동일합니다.

미세 조정된 biLM이 사용되었는지 여부에 관계없이.

1번 식에서 γ의 중요성 2가지

표현식 (1)의 γ 매개 변수는 실용적이었습니다.

한국어로 번역해주세요. 번역 외에는 작성하지 마세요.

차이로 인해 최적화에 대한 중요성이 증가합니다.

biLM 내부 표현 사이의 엔트로피 분포-

표현과 과제별 표현.

마지막으로만 있는 경우에는 특히 중요합니다.

5.1절. 이 매개변수 없이는 마지막 것만

성과가 좋지 않았습니다 (기준선 아래로 매우 낮음)

SNLI와 훈련은 완전히 실패했습니다. SRL에 대해서도 실패했습니다.

A. 3 텍스트 함의

우리의 기준 SNLI 모델은 ESIM 시퀀스입니다.

Chen et al. (2017)의 모델을 따라서

원래 구현에서는 300 차원을 사용했습니다.

모든 LSTM 및 피드 포워드 레이어와 사전-

300 차원의 GloVe 임베딩을 훈련시켰습니다.

훈련 중에 수정되었습니다. 정규화를 위해, 우리는

데이터셋

이전에

튜닝
후에

튜닝

SNLI 72.1 16.8

CoNLL 2012 (coref/SRL) 92.3 - 코넬 2012 (공동참조/문법론) 92.3

CoNLL 2003 (NER) 103.2 46.3
코넬 2003 (개체명 인식) 103.2 46.3

SQuAD
맥락    99.1  43.5

질문 158.2 52.0

SST              131.5 78.6

표 7: 다양한 데이터셋에 대한 훈련 세트에서 1 epoch 동안 미세 조정 전후의 개발 세트 퍼플렉서티 (낮을수록 좋음). 보고된 값은 순방향과 역방향 퍼플렉서티의 평균입니다.

50% 변동적 드롭아웃 (Gal and Ghahramani, 2016)을 추가했습니다.

많이, 2016) 각 LSTM 레이어의 입력으로

입력에서 50% 이탈 (Srivastava et al., 2014)

최종 두 개의 완전히 연결된 레이어에 대해. 모든 피드

터를 공유하는 층은 ReLU 활성화 함수를 사용합니다.

터들은 Adam (Kingma와 Ba, 2014)를 사용하여 최적화되었습니다.

2015) 그래디언트 노름이 5.0으로 클리핑된 상태에서 초기화-

학습률은 0.0004로 시작하여 절반씩 감소합니다.

개발 세트에서의 시간 정확도는 증가하지 않았다.

이후 시대에 증가했습니다. 배치 크기는

32. I am going to the store to buy some groceries.

최고의 ELMo 구성은 ELMo 벡터를 추가했습니다.

최하위의 입력과 출력에 대한 토르스

레이어 정규화를 사용한 LSTM 레이어 (1)을 사용합니다.

그리고 λ = 0.001입니다. ELMo 모델의 매개변수 수가 증가하여 (cid:96)2 규제를 추가했습니다.

정규화 계수 0.0001으로 정규화

모든 재발 및 피드 포워드 가중치 행렬에 대해

그리고 어텐션 레이어 이후에는 50%가 중도하차합니다.

표 8은 우리 시스템의 테스트 세트 정확도를 비교합니다.

이전에 출판된 시스템에 대한 평가입니다. 전반적으로,

ELMo를 ESIM 모델에 추가하면 성능이 향상되었습니다.

정확도를 0.7% 향상시켜 새로운 단일 모델을 구축했습니다.

88.7%의 최첨단 기술을 가지고 있으며, 5명의 구성원으로 이루어져 있습니다.

semble는 전체 정확도를 89.3%로 끌어올립니다.

A. 4 질문에 대한 답변

우리의 QA 모델은 모델의 간소화된 버전입니다.

클락과 가드너 (2017)에 따르면, 이것은 내장됩니다.

각 토큰의 대소문자를 유지한 채로 연결하여 kens를 만듭니다.

300 차원의 GloVe 단어 벡터 (펜닝-

톤 외 (2014)는 캐릭터 기반 임베드와 함께했다.

핑은 합성곱 신경망을 사용하여 생성되었습니다.

학습된 문자에 대한 작업 후에 맥스 풀링을 수행합니다.

액터 임베딩. 토큰 임베딩은

양방향 GRU를 통과했고,

그런 다음 양방향 어텐션 메커니즘으로

BiDAF (Seo et al., 2017). 증강된 모델의 정확도.

특징 기반 (Bowman et al., 2015) 78.2

DIIN (Gong et al., 2018) 88.0

BCN+Char+CoVe (McCann et al., 2017) 88.1
BCN+Char+CoVe (McCann et al., 2017) 88.1

ESIM (Chen et al., 2017) 88.0

ESIM+TreeLSTM (Chen et al., 2017) 88.6
ESIM+TreeLSTM (Chen et al., 2017) 88.6

ESIM+ELMo                  88.7 ± 0.17

DIIN 앙상블 (Gong et al., 2018) 88.9

ESIM+ELMo 앙상블         89.3

표 8: SNLI 테스트 세트 정확도. 단일 모델 결과가 상단에 위치하며, 앙상블 결과는 하단에 있습니다.

텍스트 벡터는 그 후에 선형 레이어를 통과합니다.

ReLU 활성화 함수를 사용한 잔차 self-attention

GRU를 사용한 레이어, 그리고 같은 어텐션을 따르는 레이어

문맥 대 문맥 적용된 번역 메커니즘입니다.

ReLU 활성화 함수를 사용한 또 다른 선형 레이어입니다. Fi-

마지막으로, 결과는 선형 레이어를 통해 전달됩니다.

답변의 시작 토큰과 끝 토큰을 예측하십시오.

the neural network.

GRU와 선형 레이어를 0.2의 비율로 업데이트합니다.

GRU에는 90의 차원이 사용됩니다.

선형 레이어에 대해 180을 사용합니다. 모델을 최적화합니다.

테스트에서 배치 크기 45로 Adadelta를 사용합니다.

시간 우리는 지수 이동 평균을 사용합니다.

무게를 제한하고 출력 범위를 최대로 설정합니다.

크기 17. 우리는 단어 벡터를 업데이트하지 않습니다.

훈련.

성능은 ELMo를 추가했을 때 가장 높았다.

입력과 출력 모두에 레이어 정규화를 적용하지 않은 경우

문맥적 GRU 레이어의 출력과 나머지

ELMo 가중치는 정규화되지 않았습니다 (λ = 0).

테이블 9는 테스트 세트 결과를 비교합니다.

2017년 11월 17일 현재 SQuAD 리더보드

시스템을 제출했을 때. 전반적으로, 우리의 하위

임무는 가장 높은 단일 모델과 앙상블을 가졌다.

이전의 단일 모델을 개선하여 더 나은 결과를 얻었습니다.

결과 (SAN)는 F1 기준으로 1.4% 증가하였으며, 기준선은 4.2% 증가하였습니다. 11명의 앙상블은 F1을 87.4%로 끌어올려 이전 앙상블 대비 1.0% 증가하였습니다.

최고.

5. 의미 역할 라벨링

우리의 기준 SRL 모델은 정확한 재구현입니다.

(He et al., 2017)의 표현 방법입니다. 단어는 표현됩니다.

100 차원 벡터의 연결을 사용하여

표현들은 GloVe를 사용하여 초기화되었습니다 (Penning-).

톤 외 (2014)와 이진, 단어별 술어

특징, 100차원 임베딩을 사용하여 표현됩니다.

https://nlp.stanford.edu/projects/snli/에서 포괄적인 비교를 찾을 수 있습니다.

침구. 이 200차원 토큰은

테이션은 그런 다음 8층의 "인터-"를 통해 전달됩니다.

300 차원의 숨겨진 "biLSTM"으로 이동했습니다.

방향이 LSTM 레이어의 크기

각 층마다 번갈아 가며. 이 깊은 LSTM은 High-을 사용합니다.

방법 연결 (Srivastava et al., 2015) 사이

layers와 변량 재귀적 드롭아웃 (Gal and

Ghahramani, 2016). 이 깊은 표현은

그런 다음 최종 밀집층을 사용하여 예측합니다.

소프트맥스 활성화를 통해 분포를 형성합니다.

모든 가능한 태그. 라벨은 의미론적 역할로 구성됩니다.

PropBank (Palmer et al., 2005)을 보완하여

논쟁을 나타내기 위한 BIO 라벨링 체계와 함께

주의 집중력. 훈련 중에는 최소화합니다.

태그 시퀀스의 음의 로그 우도를 사용하여

학습률이 1.0이고 ρ = 0.95인 Adadelta

안녕하세요. 저는 한국어 번역을 담당하는 인공지능입니다. 아래의 문장을 한국어로 번역해드리겠습니다.

(Zeiler, 2012). 테스트 시간에는 Viterbi를 수행합니다.

BIO con-을 사용하여 유효한 범위를 강제로 해독하기

제약. 10%의 변동적 드롭아웃이 추가됩니다.

모든 LSTM 은닉층입니다. 그래디언트는 클리핑됩니다.

그들의 가치는 1.0을 초과합니다. 모델은 500번 훈련되었습니다.

에포크 또는 검증 F1이 향상되지 않을 때까지

200 에포크, 더 빠른 것을 선택합니다. 사전 훈련된

GloVe 벡터는 훈련 중에 세밀하게 조정됩니다.

최종 밀집층과 모든 LSTM의 모든 셀은 초기화됩니다.

직교화되도록 초기화됩니다. 망각 게이트 편향은

모든 LSTMs에 대해 1로 초기화되며, 다른 모든 게이트는 그대로입니다.

0으로 초기화되었습니다, (J´ ozefowicz et al., 2015)에 따라.

테이블 10은 우리의 테스트 세트 F1 점수를 비교합니다.

ELMo의 증강 구현 (He et al.,

2017년) 이전 결과와 함께. 우리의 단일 모델

84.6 F1 점수는 새로운 최첨단 기술을 나타냅니다.

CONLL 2012 의 의미 역할 라벨 결과

ing task, surpassing the previous single model re- 

이전의 단일 모델 결과를 능가하는 작업을 수행하고 있습니다.

2.9 F1로 계산된 모델과 1.2 F1로 계산된 5개 모델 앙상블.

A. 6 핵심 참조 해결

우리의 기준 핵심 참조 모델은 end-to-end입니다.

이상의 모델은 Lee et al. (2017)의 신경망 모델로, 모든 하이퍼파라미터를 사용하였습니다. 

모델                       EM  F1

BiDAF (서 등, 2017)    68.0 77.3

BiDAF + Self Attention      72.1 81.1

DCN+                        75.1 83.1

레그-라소르 75.8 83.3

퓨전넷 76.0 83.9

r-net (Wang et al., 2017) 76.5 84.3

알넷 (왕 등, 2017) 76.5 84.3

SAN (Liu et al., 2017) 76.8 84.4
SAN (Liu et al., 2017) 76.8 84.4

BiDAF + Self Attention + ELMo 78.6 85.8
비다프 + 셀프 어텐션 + ELMo 78.6 85.8

DCN+ 앙상블               78.9 86.0

퓨전넷 앙상블          79.0 86.0

인터랙티브 AoA 리더+ 앙상블 79.1 86.5

BiDAF + Self Attention + ELMo 앙상블 81.0 87.4

테이블 9: SQuAD에 대한 테스트 세트 결과를 보여주는 정확도 (EM)와 F1을 모두 표시합니다. 표의 상단 절반은 단일 모델 결과이며, 하단에 앙상블 결과가 있습니다. 가능한 경우 참고 자료가 제공되었습니다.

모델            F1

Pradhan et al. (2013) 77.5

Zhou와 Xu (2015) 81.3

그는 외. (2017), 단일 81.7

그는 외. (2017), 앙상블 83.4

그는 외. (2017), 우리의 impl. 81.4

그는 외. (2017) + ELMo 84.6

테이블 10: SRL CoNLL 2012 테스트 세트 F1.

모델              평균 F1

더렛과 클라인 (2013) 60.3

Wiseman et al. (2016) 64.2
위즈먼 외 (2016) 64.2

클락과 매닝 (2016) 65.7

이 등. (2017) (단일) 67.2

이 등. (2017) (앙상블) 68.8

이상민 외 (2017) + ELMo 70.4

테이블 11: CoNLL 2012 공유 작업의 테스트 세트에서의 핵심 참조 해결 평균 F1.

원본 이미지를 정확히 따르는 매개변수

구현.

ELMo를 추가한 최상의 구성

가장 낮은 층의 biLSTM을 제외하고 가중치를 부여했다.

biLM 레이어를 사용하여 (1) 어떠한 정규화도 없이

(λ = 0) 또는 레이어 정규화. 50% 드롭아웃이었다.

ELMo 표현에 추가되었습니다.

표 11은 우리의 결과를 이전에 비교합니다.

게시된 결과. 전반적으로, 우리는 단일을 개선합니다.

모델은 평균 F1 기준으로 최신 기술을 3.2% 향상시키며, 우리의 단일 모델 결과는 이전 앙상블보다 개선되었습니다.

BLEU 점수는 1.6% F1로 향상되었습니다. biLSTM 입력에 추가로 biLSTM 출력에 ELMo를 추가하는 것입니다.

약 0.7% 감소한 F1 (표시되지 않음).

7. 명명된 개체 인식

우리의 기준 NER 모델은 50 차원을 연결합니다.

사이너 벡터는 Collobert et al.에 의해 사전 훈련된 벡터입니다.

2011) CNN 캐릭터 기반 표현을 사용하여.

문자 표현은 16 차원을 사용합니다.

문자 임베딩과 128개의 합성곱 필터

세 글자 폭의 텐서, ReLU 활성화

그리고 맥스 풀링을 통해 토큰 표현이 됩니다.

두 개의 biLSTM 레이어를 통과했으며, 첫 번째 레이어는

200개의 숨겨진 유닛과 두 번째는 100개의 숨겨진 유닛입니다.

최종 밀집층과 소프트맥스 이전의 단위 수

훈련 중에는 CRF 손실 함수를 사용합니다.

테스트 시간에는 Viterbi 알고리즘을 사용하여 디코딩을 수행합니다.

출력 태그 시퀀스를 보장하면서 알고리즘을 최적화합니다.

유효합니다.

입력에 변동적 드롭아웃이 추가됩니다.

biLSTM 레이어. 훈련 중 그래디언트는 그들의 제곱 노름이 5.0을 초과하는 경우 재조정됩니다.

Adam을 사용하여 상수 학습을 통해 에터를 업데이트합니다.

0.001의 비율입니다. 사전 훈련된 Senna 임베딩

훈련 중에 세밀하게 조정됩니다. 초기에 채용합니다.

개발 세트에서 중단하고 평균을 보고하십시오.

다섯 번의 다른 실행으로 이루어진 평균 테스트 세트 점수

랜덤 시드.

ELMo는 가장 낮은 층의 입력에 추가되었습니다.

작업 biLSTM. CoNLL 2003 NER 데이터 세트로

비교적 작은데, 우리는 최고의 성능을 발견했습니다.

가중치를 학습 가능한 레이어에 제한을 두어

(1)을 사용하여 λ = 0.1로 설정함으로써 효과적으로 일정하게 유지됩니다.

ous state-of-the-art models.

pared to previous methods, our system outperforms them by a significant margin.

Peter et al. (2017)와 비교하여 표현을 사용한 모델의 F1 ± 표준편차.

Collobert et al. (2011)♣ 89.59
콜로베르 등 (2011)♣ 89.59

램플 등 (2016) 90.94

마와 호비 (2016) 91.2
치우와 니콜스 (2016)♣,♦ 91.62 ± 0.33
피터스 외 (2017)♦ 91.93 ± 0.19
biLSTM-CRF + ELMo 92.22 ± 0.10

표 12: CoNLL 2003 NER 작업의 테스트 세트 F1. 
♣가 포함된 모델은 가젯리스트를 사용하였으며, ♦가 포함된 모델은 훈련에 훈련 및 개발 세트를 모두 사용하였습니다.

모델                     정확도

DMN (Kumar et al., 2016) 52.1

LSTM-CNN (Zhou et al., 2016) 52.4

NTI (Munkhdalai와 Yu, 2017) 53.1

BCN+Char+CoVe (McCann et al., 2017) 53.7
BCN+Char+CoVe (McCann et al., 2017) 53.7

BCN+ELMo                  54.7

테이블 13: SST-5에 대한 테스트 세트 정확도.

모든 레이어의 biLM은 겸손한 성능을 제공합니다.

개선.

A. 8 감정 분류

우리는 거의 동일한 이중주의 분류를 사용합니다.

McCann et al.에서 설명된 네트워크 아키텍처.

(2017)년, 마지막을 제외하고 대체하였습니다.

더 간단한 피드포워드 네트워크로 맥스아웃 네트워크를 최대한 활용하십시오.

드롭아웃이 있는 두 개의 ReLu 레이어로 구성된 작업.

배치 정규화된 맥스아웃을 가진 BCN 모델

네트워크는 상당히 낮은 검증을 달성했습니다.

우리 실험에서의 정확도는 다소 부정확할 수 있습니다.

우리의 실행과의 불일치가 있을 수 있습니다.

McCann et al. (2017)의 것과 일치시키기 위해. CoVe와 일치시키기 위해.

훈련 설정, 우리는 단어들에 대해서만 훈련합니다.

토큰을 4개 이상 사용합니다. 우리는 300차원의 숨겨진 값(hidden)을 사용합니다.

biLSTM와 모델을 최적화하기 위한 상태

Adam (Kingma와 Ba, 2015)을 사용하여 매개변수를 업데이트합니다.

학습률을 0.0001로 설정하고 있는 중입니다. 학습 가능한 biLM입니다.

레이어 가중치는 λ = 0.001로 정규화됩니다. 그리고

우리는 입력과 출력 모두에 ELMo를 추가합니다.

biLSTM; 출력 ELMo 벡터가 계산됩니다.

두 번째 biLSTM과 연결하여

놓다.

