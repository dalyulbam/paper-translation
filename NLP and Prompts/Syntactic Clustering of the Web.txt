SRC 기술 노트

1997-015

1997년 7월 25일

웹의 구문 클러스터링

안드레이 지. 브로더, 스티븐 C. 글래스만, 마크 S. 마나세, 제프리 즈와이그

시스템 연구 센터
130 Lytton Avenue
Palo Alto, CA 94301
http://www.research.digital.com/SRC/

저작권 1997 디지털 장비 회사. 모든 권리 보유.

요약

우리는 파일의 구문적 유사성을 결정하는 효율적인 방법을 개발했으며, 이를 전 세계의 모든 문서에 적용했습니다. 이 메커니즘을 사용하여 구문적으로 유사한 모든 문서의 클러스터링을 구축했습니다. 가능한 응용 분야에는 "분실물 찾기" 서비스, 웹 검색 결과 필터링, 널리 배포된 웹 페이지 업데이트, 지적 재산권 침해 사례 식별 등이 있습니다.


요약
소개
URNs
관련 연구
유사성 정의
유사도와 포함도 추정
알고리즘
클러스터링 알고리즘
쿼리 지원

1 of 13
군집화 성능 문제
일반적인 셔틀
동일한 문서
슈퍼 셔틀
응용 프로그램
웹 기반 응용 프로그램
분실물과 유실물
검색 결과의 군집화
널리 분포된 정보의 업데이트
페이지가 시간에 따라 어떻게 변하는지 특성화
지적 재산과 표절
상태
결론
감사의 말씀
참고 문헌
저자들

소개

웹은 탄생 이후 지수적인 성장을 겪었으며, 이 확장은 여러 문제를 발생시켰습니다. 본 논문에서는 이 중 두 가지 문제에 대해 다루고 있습니다.

1. 동일하거나 거의 동일한 문서들의 증가.
2. URL의 불안정성.

우리 접근 방식의 기초는 두 문서가 "대략 동일한"지를 발견하는 메커니즘입니다. 즉, 서식, 작은 수정, 웹마스터 서명 또는 로고와 같은 수정을 제외하고 동일한 내용을 가지고 있는지를 발견하는 것입니다. 마찬가지로, 한 문서가 다른 문서에 "대략 포함"되어 있는지도 발견할 수 있습니다. AltaVista 스파이더가 찾은 문서 모음에 이 메커니즘을 적용하면 관련된 항목들의 클러스터로 문서들을 그룹화할 수 있습니다. 아래에서 설명한대로, 이 클러스터링은 문서 중복과 URL 불안정성 문제를 해결하는 데 도움이 될 수 있습니다.

중복 문제는 두 가지 방식으로 발생합니다. 첫째, 동일한 형태로 여러 곳에서 발견되는 문서들이 있습니다. 몇 가지 예시는 다음과 같습니다.

자주 묻는 질문 (FAQ) 또는 의견 요청 (RFC) 문서입니다.
인기 있는 프로그램에 대한 온라인 문서입니다.
여러 거울 사이트에 저장된 문서입니다.
법적 문서입니다.

둘째, 거의 동일한 형태로 발견되는 문서들이 있습니다. 이는 다음과 같은 이유로 인해 그렇습니다:

같은 문서의 다른 버전.
다른 서식으로 된 같은 문서.
특정 사이트 링크, 맞춤 설정 또는 연락처 정보가 있는 같은 문서.
다른 출처 자료와 결합하여 큰 문서를 형성함.
작은 문서로 분할함.

2 중 13
특정 URL이 원하지 않는 상태가 되면 불안정성 문제가 발생합니다.

연관 문서는 일시적으로 사용할 수 없거나 이동되었습니다.
URL은 오래된 버전을 가리키고 사용자는 현재 버전을 원합니다.
URL에 접근하는 속도가 느리고 사용자는 더 빠르게 검색할 수 있는 동일하거나 유사한 문서를 원합니다.

모든 경우에, 주어진 문서와 구문적으로 유사한 문서를 찾을 수 있는 능력은 사용자가 원하는 항목의 다른, 수용 가능한 버전을 찾을 수 있게 해줍니다.

URNs

URNs (Uniform Resource Names) [6]은 위에서 설명한 기능과 유사한 기능을 제공하는 방법으로 종종 제안되었습니다. URNs은 URL (Uniform Resource Locators)의 일반화된 형태입니다. 그러나 URL이 리소스를 직접적으로 명명하는 반면에 - 특정 서버, 포트 및 파일 이름을 제공하여 URL이 리소스를 명명하는 방식 - URNs은 명칭 서버를 통해 간접적으로 리소스를 가리킵니다. 명칭 서버는 URN을 리소스의 "최적" (어떤 기준에 따라) URL로 변환할 수 있습니다.

URN의 주요 장점은 위치에 독립적이라는 것입니다. 단일하고 안정적인 URN은 리소스의 이름이 변경되거나 서버에서 서버로 이동하는 경우에도 해당 리소스를 추적할 수 있습니다. URN은 사용자를 가장 가까운 미러 사이트에 있는 복제된 리소스의 인스턴스로 이동시킬 수 있거나 원하는 언어로 제공할 수 있습니다. 유감스럽게도, URN에 대한 진전은 느리게 이루어지고 있습니다. 여기에서 제시하는 메커니즘은 대안적인 해결책을 제공합니다.

관련 작업

우리의 구문 유사성을 결정하는 접근 방식은 Heintze [2]에 의해 개발된 샘플링 접근 방식과 관련이 있지만, 세부 사항과 사용된 측정 항목의 정확한 정의에는 많은 차이가 있습니다. 우리의 관심 영역은 훨씬 더 크기 때문에 (그의 프로토타입 구현은 50,000 배 작은 도메인에 대한 것입니다) 그리고 우리는 표절에 대해 덜 걱정하기 때문에 강조점이 종종 다릅니다. 유사성을 결정하기 위한 관련 샘플링 메커니즘은 Manber [3]와 Stanford SCAM 프로젝트 내에서도 개발되었습니다 [1, 4, 5].

군집화에 관한 연구들 중에서 의미적 군집화와 관련된 많은 문헌이 있다. 이는 다른 개념이다. 또한, 구문적 유사성에 기반한 군집화(규모는 훨씬 작음)는 SCAM 프로젝트의 맥락에서 논의되었다.

문서의 유사성을 정의하는 것

"대략적으로 동일한"과 "대략적으로 포함된" 비형식적인 개념을 엄격하게 포착하기 위해, 우리는 아래에 정의된 유사성과 포함성이라는 수학적 개념을 사용합니다.

문서 A와 B의 유사성은 0과 1 사이의 숫자로 나타내며, 유사성이 1에 가까울수록 문서가 "대략적으로 동일"한 것으로 판단됩니다. 마찬가지로, A가 B에 포함되는 정도는 0과 1 사이의 숫자로 나타내며, 1에 가까울수록 A가 B에 "대략적으로 포함"되어 있는 것을 나타냅니다. 두 문서의 유사성과/또는 포함도를 계산하기 위해서는 각 문서에 대해 몇 백 바이트의 스케치를 유지하는 것이 충분합니다. 스케치는 효율적으로 계산될 수 있으며(문서의 크기에 선형적인 시간으로), 두 개의 스케치가 주어지면 해당 문서의 유사성 또는 포함도를 스케치의 크기에 선형적인 시간으로 계산할 수 있습니다.

13개 중 3개
우리는 각 문서를 단어의 연속으로 보며, 우선적으로 어휘적으로 분석하여 정규화된 토큰의 연속으로 만듭니다. 이 정규화된 형태는 서식, HTML 명령어, 대소문자 등과 같은 작은 세부사항을 무시합니다. 그런 다음, 각 문서 D에 대해 토큰의 부분 연속집합 S(D, w)를 연결합니다.

문서 D에 포함된 연속된 하위 시퀀스를 셔링이라고 합니다. 문서 D가 주어지면, 우리는 그것의 w-셔링 S(D, w)을 정의합니다. 이는 D에 포함된 크기가 w인 모든 고유한 셔링의 집합입니다. 예를 들어, 4-셔링은 다음과 같습니다.

(장미는 장미다)

세트인가요?

(하나, 장미, 하나, 이다)
(장미, 하나, 장미, 이다)
(하나, 이다, 장미, 이다)

주어진 셔링 크기에 대해, 두 문서 A와 B의 유사도 r은 다음과 같이 정의된다.

|A|의 크기가 A 집합의 크기입니다.

A가 B에 포함되는 것으로 정의된다.

따라서 유사도는 0과 1 사이의 숫자이며, 항상 r(A, A) = 1, 즉 문서가 자기 자신과 100% 유사하다는 것이 참입니다. 마찬가지로 포함도는 0과 1 사이의 숫자이며, 그렇다면 c(A, B) = 1입니다.

실험 결과, 이러한 수학적 정의들은 우리의 비공식적인 "대략적으로 같은"과 "대략적으로 포함된" 개념을 효과적으로 포착한다.

유사성은 추이적이지 않다는 것을 알아두세요 (할아버지들이 알려진 사실을 한탄하는 것처럼), 그러나 우리의 비공식적인 "대충 비슷하다"라는 개념도 마찬가지입니다. 예를 들어 연속된 논문 버전은 "대충 비슷할 수 있지만, 100번 버전은 1번 버전과는 아마도 매우 다를 것입니다. 그럼에도 불구하고, 유사성 거리는 다음과 같이 정의됩니다.

메트릭이며 삼각부등식을 따릅니다. (이에 대한 증명 및 여기서 논의된 대부분의 수학적 분석은 별도의 논문 작성 중입니다.)

유사성과 포함 여부를 추정합니다.

크기 w의 단자를 고정하고, U를 크기 w의 모든 단자들의 집합으로 정의하자. 일반성을 잃지 않고 U를 숫자들의 집합으로 볼 수 있다. 이제 매개변수 s를 고정하자. 집합으로 정의된 경우에 대해.

13개 중 4번째, "가장 작은"은 U의 숫자 순서를 의미하며 정의합니다.

정리. U에서 균일하게 무작위로 선택된 U의 순열이라고 하자.

그리고. F(B)와 V(B)를 유사하게 정의하십시오.

그럼

가치

A와 B의 유사성에 대한 편향되지 않은 추정치입니다.

가치

A와 B의 유사성에 대한 편향되지 않은 추정치입니다.

가치

A가 B에 포함되는 것에 대한 편향되지 않은 추정치입니다.

위의 내용을 고려하면, 우리는 임의의 순열을 선택한 후 각 문서 D에 대해 F(D)와/또는 V(D) 집합으로만 구성된 스케치를 유지할 수 있습니다. 이 스케치는 원본 파일이 필요하지 않고 어떤 두 문서 쌍의 유사성이나 포함 여부를 추정하는 데 충분합니다.

세트 F(D)는 고정된 크기를 가지는 장점이 있지만, 유사성의 추정만 허용합니다. V(D)의 크기는 D가 커짐에 따라 증가하지만, 유사성과 포함도의 추정을 허용합니다.

V(D)의 크기를 제한하기 위해 다음과 같이 진행할 수 있습니다: 크기가 (예를 들어)와 사이인 문서에 대해, 집합을 저장합니다. 의 예상 크기는 항상 입니다.

50과 100 사이입니다. 반면에, 우리는 쉽게 계산할 수 있습니다. (우리는 단순히 유지합니다.

.) 따라서, 우리에게 A와 B라는 두 개의 문서가 주어지고 모듈러스가 사용되었다면

5 of 13


더 긴 문서에서는 우리의 추정치를 위해 'V_i(A) and V_i(B)'를 사용합니다. 이 방법의 단점은
매우 짧은 문서를 상당히 큰 문서에 포함시키는 것에 대한 추정은 샘플의 부족으로 인해 오류가 발생하기 쉽습니다.
우리 시스템에서는 스케치를 다음과 같이 구현합니다.

문서를 정규화하기 위해 HTML 형식을 제거하고 모든 단어를 소문자로 변환합니다. Shingle 크기 w는 10입니다.
우리는 Rabin fingerprints [7]를 기반으로 한 40비트 fingerprint 함수를 사용하며, 이는 무작위 순열로 동작하도록 개선되었습니다. 
(이 논문의 나머지 부분에서 shingle 또는 shingle 값이라고 언급할 때 이 fingerprint 값을 의미합니다.)
m이 25인 shingle을 선택하기 위해 "modulus" 방법을 사용합니다.

알고리즘

개념적으로, 이 유사성 알고리즘을 전체 웹에 적용하는 것은 꽤 간단합니다. 우리는:

	- 웹 상의 모든 문서를 검색합니다. (이 데이터는 AltaVista 스파이더 실행으로부터 제공되었습니다),
	- 각 문서에 대한 스케치를 계산합니다. 
	- 각 문서 쌍의 스케치를 비교하여 유사도 임계값을 초과하는지 확인합니다.
	- 유사한 문서 쌍을 결합하여 유사한 문서 클러스터를 만듭니다. 

이 알고리즘은 꽤 간단하지만, 순진한 구현은 비현실적입니다. 우리의 테스트 케이스는 웹에서 검색된 30,000,000개의 HTML 및 텍스트 문서입니다. 쌍으로 비교하면 O(1015) (천조) 개의 비교가 필요합니다. 이는 분명히 실현 불가능합니다.

입력 데이터의 크기는 우리의 데이터 구조와 알고리즘 설계에 심각한 제약을 가하였다.
데이터 구조에서 문서 당 하나의 비트는 4MB를 필요로 한다. 문서 당 800 바이트의 스케치 크기는 24GB를 필요로 한다. 문서 당 1밀리초의 계산은 8시간의 계산으로 변환된다. 임의의 디스크 접근이나 페이지 활동을 유발하는 알고리즘은 완전히 불가능하다.

우리 알고리즘의 설계에서는 많은 양의 데이터를 처리하기 위해 단일하고 간단한 접근 방식을 사용합니다 - 분할, 계산, 병합. 데이터를 가져와서 조각으로 나눈 다음 각 조각을 개별적으로 계산하고 결과를 병합합니다. 계산이 메모리 내에서 완전히 수행될 수 있도록 조각 크기 m을 선택합니다. 결과를 병합하는 것은 간단하지만 시간이 많이 소요되는 프로세스입니다. 각 병합 패스는 선형이지만 log(n/m) 패스가 필요하므로 전체 프로세스의 성능은 O(n log(n/m)) 항에 의해 지배됩니다.

군집화 알고리즘

우리는 4단계로 클러스터링 알고리즘을 수행합니다. 첫 번째 단계에서는 모든 문서에 대해 스케치를 계산합니다.
이 단계는 문서의 총 길이에 선형적입니다.

두 번째 단계에서는 모든 셔인들과 그들이 나타나는 문서들의 목록을 셔인 값에 따라 정렬하여 생성합니다. 이를 위해 각 문서의 스케치는 <셔인 값, 문서 ID> 쌍의 목록으로 확장됩니다. 우리는 위에서 설명한 분할, 정렬, 병합 접근법을 사용하여 이 목록을 정렬합니다.

세 번째 단계에서는 어떤 셔인을 공유하는 모든 문서 쌍의 목록과 함께 숫자를 생성합니다.

13개 중 6개
공통으로 가지고 있는 단추들에 대해. 이를 위해, 정렬된 <단추, ID> 쌍의 파일을 가져와서 목록으로 확장합니다.
여러 문서에 나타나는 각 단추를 가져와 <ID, ID, 공통 단추의 개수> 세트로 완전히 확장합니다. 그런 다음 나누기, 정렬, 병합
절차를 적용하여 일치하는 ID - ID 쌍의 개수를 추가하여 모든 <ID, ID, 개수> 세트가 첫 번째 문서 ID로 정렬된 단일 파일을 생성합니다. 이 단계는 초기
문서 ID 세트의 확장이 단추를 공유하는 문서 수에 대해 이차적으로 이루어지므로 가장 많은 디스크 공간이 필요하며, 초기에는
개수가 1인 많은 세트를 생성합니다.

최종 단계에서 우리는 완전한 클러스터링을 생성합니다. 우리는 각 <ID, ID, count> 쌍을 검사하고 문서 쌍이 유사성 임계값을 초과하는지 여부를 결정합니다. 만약 초과한다면, 우리는 두 문서 사이에 링크를 추가하기 위해 union-find 알고리즘을 사용합니다. union-find 알고리즘이 출력하는 연결된 구성 요소들이 최종 클러스터를 형성합니다. 이 단계는 전체 union-find 데이터 구조를 메모리에 보관해야 하기 때문에 가장 큰 메모리 요구 사항을 가지고 있습니다.

지원 문의

클러스터링을 완료한 후에는 쿼리를 더 편리하게 만들기 위해 여러 보조 데이터 구조가 필요합니다. 우리는 다음을 생성합니다:

URL의 문서 ID에 대한 매핑:
각 URL에 지문을 생성하고 문서 ID와 짝지어 줍니다.
<fingerprint, ID> 쌍을 지문 값에 따라 정렬합니다.
URL이 주어지면, 우리는 지문을 생성하고 정렬된 목록에서 해당 문서 ID를 출력합니다.
문서 ID가 포함된 클러스터에 대한 매핑
이는 문서 ID에 따라 정렬된 클러스터에서 클러스터를 문서 ID에 대한 역매핑입니다.
클러스터에 속한 문서들에 대한 매핑
이는 클러스터링 알고리즘의 출력입니다.
문서 ID에 대한 URL의 매핑
문서 ID 순서로 정렬된 모든 URL의 배열입니다.

클러스터링 성능 문제

일반적인 지붕재료

우리에게는 매우 흔한 셔링(이는 1000개 이상의 문서에서 공유되는 셔링을 의미합니다)은 알고리즘의 세 번째 단계에서 성능 문제가 됩니다. 우리가 논의한 대로, 문서 ID 쌍의 수는 셔링을 공유하는 문서의 수에 대해 이차 방정식입니다. 너무 흔한 셔링은 우리가 다뤄야 하는 문서 ID 쌍의 수를 크게 늘릴 수 있습니다.

가장 흔한 지붕재료를 살펴본 결과, 거의 모두 기계적으로 생성된 것으로 나타났습니다. 이에는 다음이 포함됩니다:

HTML이 생성한 프로그램을 식별하는 HTML 주석 태그
자동으로 생성된 많은 페이지(양식 또는 데이터베이스의 뷰)에서 공유되는 헤더 또는 푸터 정보
매우 흔한 텍스트 시퀀스(숫자 3-12, ...)
인공적으로 다른 URL과 내부 링크를 가진 기계적으로 생성된 페이지

13개 중 7개
이러한 일반적인 단조로운 부분은 문서들의 전반적인 유사성에 영향을 미치지 않거나 오히려 두 개의 기본적으로 다른 문서 사이에 잘못된 유사성을 만들어 낼 수 있습니다. 따라서, 우리는 매우 일반적인 단조로운 부분들을 무시합니다.

동일한 문서

우리 알고리즘에서는 동일한 문서를 특별히 처리할 필요는 없지만, 이는 계산 작업량을 증가시키고 쉽게 제거할 수 있습니다. 동일한 문서는 분명히 동일한 셋의 셔인을 공유하므로, 클러스터링 알고리즘에서는 동일한 문서 그룹에서 하나의 대표만 유지하면 됩니다. 따라서 각 문서마다 전체 내용을 포함하는 지문을 생성합니다. 동일한 지문을 가진 문서를 찾으면, 클러스터링 알고리즘에서 하나만 남기고 나머지를 제거합니다. 클러스터링이 완료된 후에는 다른 동일한 문서들을 유지된 버전을 포함하는 클러스터에 추가합니다.

"단어적으로 동일한" 문서와 "셔인글-동등한" 문서를 사용하여 동일한 문서의 컬렉션을 확장할 수 있습니다. 단어적으로 동일한 문서는 정규 형식으로 변환된 후에 동일합니다. 셔인글-동등한 문서는 셔인글 집합이 선택된 후에 동일한 셔인글 값이 있는 문서입니다. 당연히 모든 동일한 문서는 단어적으로 동일하며, 모든 단어적으로 동일한 문서는 셔인글-동등합니다.

우리는 각 문서 세트를 단일 지문으로 찾을 수 있습니다. 동일한 문서는 전체 원본 내용의 지문으로 찾을 수 있습니다. 어휘적으로 동등한 문서는 전체 표준화된 내용의 지문으로 찾을 수 있습니다. Shingle 동등한 문서는 선택된 Shingle 세트의 지문으로 찾을 수 있습니다.

슈퍼 싱글스

우리 알고리즘의 두 번째와 세 번째 단계는 <shingle, ID> 쌍과 <ID, ID, count> 세트를 위해 많은 디스크 공간이 필요합니다. 우리는 문서 스케치에서 문서 유사성을 더 직접적으로 결정하기 위한 방법을 조사했습니다.

스케치는 두 문서의 유사성을 추정하는 효과적인 방법이다. 왜냐하면 스케치는 문서의 대표적인 표현이며 쉽게 비교할 수 있기 때문이다. 따라서, 우리는 두 문서 사이에 공통으로 가지고 있는 셔잉글의 수를 전체 셔잉글 수로 나누어 유사성을 추정할 수 있다.

비슷하게, 우리는 두 개의 스케치의 유사성을 추정할 수 있습니다. 이를 위해 메타-스케치(스케치의 스케치)를 계산합니다.
우리는 스케치의 셔링들을 정렬하고, 그 셔링들을 다시 셔링하여 슈퍼 셔링을 계산합니다. 문서의 메타-스케치는 슈퍼 셔링들의 집합으로 결정됩니다. 
만약 두 개의 문서가 적어도 하나의 슈퍼 셔링을 공유한다면, 그것은 그들의 스케치가 공통의 셔링 시퀀스를 가지고 있다는 것을 의미합니다.

만약 슈퍼 셔링의 수가 올바르게 선택된다면, 두 개의 유사한 문서는 적어도 하나의 공통된 슈퍼 셔링을 가지고 있을 확률이 매우 높습니다. 또한, 단 하나의 공통된 슈퍼 셔링의 존재는 두 문서가 서로 유사하다는 것을 나타냅니다. 일반 셔링을 사용하여 유사성을 계산하기 위해서는 공통된 셔링을 수집하고 계산해야 합니다. 슈퍼 셔링을 사용하여 유사성을 감지하기 위해서는 단 하나의 공통된 슈퍼 셔링만 찾으면 됩니다. 따라서, 슈퍼 셔링은 유사성을 계산하는 더 간단하고 효율적인 방법입니다.

슈퍼 쉬글을 기반으로 한 클러스터링 알고리즘은:

13 중 8
각 문서에 대한 슈퍼 쉬글 목록을 계산하십시오.
슈퍼 쉬글 목록을 정렬된 <슈퍼 쉬글, ID> 쌍의 목록으로 확장하십시오.
슈퍼 쉬글을 공유하는 문서는 서로 유사하므로 클러스터에 추가됩니다. (더 높은 임계값을 원한다면 실제 유사성을 계산할 수 있습니다.)

그래서, 문서 ID 쌍을 생성하고 병합하는 기본 알고리즘의 전체 세 번째 단계는 필요하지 않습니다.

불행하게도, 슈퍼 셔링은 일반적인 스케치와 비교하여 유연성과 정확성이 부족합니다.
먼저, 슈퍼 셔링은 짧은 문서에는 잘 작동하지 않습니다. 짧은 문서에는 많은 셔링이 포함되어 있지 않으므로, 일반적인 셔링으로도 문서 유사성을 추정하는 오차가 더 큽니다. 슈퍼 셔링은 이 문제를 더 악화시킵니다. 슈퍼 셔링은 셔링의 연속을 나타내므로, 더 적은 슈퍼 셔링을 가진 짧은 문서는 공통 슈퍼 셔링을 생성할 확률이 낮습니다.

둘째, 슈퍼 셔링은 포함을 감지할 수 없습니다. 두 개의 문서가 있고, 더 큰 문서가 작은 문서를 완전히 포함한다고 가정해 봅시다. 그러면 더 큰 문서의 스케치에는 작은 문서의 모든 셔링과 추가적인 셔링이 포함됩니다. 우리가 더 큰 문서의 셔링을 정렬하고 슈퍼 셔링을 계산할 때, 추가 셔링은 공통 셔링과 섞여 있을 것입니다. 따라서 더 큰 문서의 셔링 시퀀스 - 그리고 따라서 슈퍼 셔링 -은 작은 문서와 다를 것입니다.

응용 프로그램

우리는 곧 웹 클러스터링과 관련된 몇 가지 특정 응용 프로그램에 대해 논의할 것이지만, 우리의 유사성 및 클러스터링 기술이 텍스트 문서에만 제한되지 않음을 언급하고 싶습니다. 우리의 일반적인 기술은 객체에서 특징 집합을 추출할 수 있는 능력에만 의존합니다. 각 객체의 특징 집합이 주어지면, 우리는 위에서 설명한 알고리즘을 적용하여 객체들의 유사성을 계산하고 유사한 객체들의 그룹을 클러스터링할 수 있습니다.

텍스트 이외의 문서와 물체에 대해서는 유사성을 계산하기 위한 많은 잠재적인 특징들이 있습니다. 인간의 말 소리 오디오 메시지는 음소의 연속에 기반한 특징을 가질 수 있습니다. 외국어 문서의 경우, 특징은 다국어 콩코드에서의 레이블일 수 있습니다. 음악적 특징은 음표나 코드의 연속에 기반할 수 있습니다. 다른 데이터 유형에서 특징을 식별하기 위한 기술이 개발됨에 따라, 비슷한 점을 비교할 수 있는 물체에는 제한이 없습니다: 이미지, 비디오 시퀀스 또는 데이터베이스.

웹 기반 애플리케이션

지금, 우리는 우리의 방법들의 웹 관련 응용 프로그램을 고려해볼 것입니다. 스케치, 클러스터 및 보조 데이터 구조가 있으면, 우리는 그것들을 여러 흥미로운 응용 프로그램에 사용할 수 있습니다. 우리가 다양한 응용 프로그램을 논의할 때, 그들의 저장 및 성능 특성을 고려할 것입니다. 두 가지 접근 방식이 있습니다.

기본적인 클러스터링

가장 직관적인 응용 프로그램은 주어진 URL에 대한 매우 유사한 대안을 찾는 서비스입니다. 이 경우, 사용자는 문서의 URL을 가지고 있으며 어떤 이유로 인해 비슷한 다른 문서를 찾고 싶어합니다. 이 관계가 바로 클러스터링이 우리에게 제공하는 것입니다.

URLs to cluster IDs, we can easily retrieve the documents in each cluster.

13개 중 9개
문서 ID를 URL로 변환하면, 클러스터 내 문서들의 모든 URL을 매우 효율적으로 계산할 수 있습니다.

불행하게도, 군집화는 닮음에 대한 단일한 고정 임계값으로 수행되어야 하며, 우리는 사전에 군집에 포함될 포함 및 포함 문서를 결정해야 합니다. 우리는 이를 우회하고 다양한 정책에 기반한 군집을 생성하기 위해 군집화 알고리즘의 최종 단계를 각각 다른 정책에 대해 반복함으로써 해결할 수 있습니다. 이 단계는 비교적 비용이 적게 들며, 출력 군집은 비교적 조밀합니다.

또 다른 문제는 기본 클러스터링이 입력의 일부인 URL에 대한 쿼리만 지원하며, 클러스터는 URL의 내용을 검색한 시점을 기준으로 형성됩니다. 우리는 이 문제를 해결하기 위해 새로운 또는 수정된 문서에 대해 필요할 때 스케치를 계산함으로써 해결할 수 있습니다.

2. 즉흥적인 닮음

만약 우리가 모든 문서의 완전한 스케치와 정렬된 <shingle, ID> 쌍 파일을 유지할 수 있다면, 우리는 실시간으로 유사성을 수행할 수 있습니다. 이 경우, 입력은 URL에서 가져온 문서든 로컬에 저장된 문서든 상관없습니다. 초기 클러스터링의 일부인지 여부나 변경되었는지 여부에 상관없이 가능합니다. 알고리즘은 다음과 같습니다.

입력 문서의 스케치를 가져옵니다.
URL의 스케치를 찾거나 문서 자체에서 스케치를 계산합니다.
입력 문서에서 각 셔인글을 정렬된 <셔인글, ID> 파일에서 찾습니다.
셔인글을 공유하는 각 문서에 대해 공통 셔인글의 개수를 유지합니다.
각 문서의 셔인글 수에 따라 유사성과 포함/포함 관계 값을 계산합니다.
결과를 정렬, 임계값 설정하고 제시합니다.

이 방법은 미리 계산된 클러스터보다 더 많은 공간과 시간을 요구하지만, 더 큰 유연성을 제공합니다. 또한 원래 입력에 포함되지 않은 문서라도 비교할 수 있습니다. 우리는 이 방법의 성능이 꽤 좋다는 것을 발견했습니다 (몇 초 내외), 단 입력 문서가 매우 크거나 많은 수의 문서와 유사한 경우는 제외합니다.

잃어버리고 찾아온 것

모두가 URL이 영원히 좋지 않다는 것을 알고 있습니다. 페이지가 이름이 바뀌고, 페이지가 이동하고, 웹 사이트가 재정리되며, 서버가 이름이 바뀌며, 사용자가 인터넷 서비스 제공자를 변경합니다. 모든 좋은 URL은 결국 또 다른 링크가 사라지게 됩니다.

우리의 클러스터링 방법은 자동으로 웹 페이지의 URL이 변경되었음을 알리고 새로운 URL을 찾을 수 있는 전 세계 웹 분실물 찾기를 만들 수 있습니다. 우리는 현재 웹의 내용뿐만 아니라 다양한 시간에 걸친 웹의 내용을 클러스터링합니다. 특정 URL을 발견한 한 번의 스윕이라도 있으면 해당 URL의 최신 위치를 해당 클러스터에서 가장 최근의 URL을 통해 찾을 수 있습니다. 클러스터링 알고리즘은 동일하지만 문서의 URL에 날짜도 태그가 되어 있습니다.

일련의 스윕에서 발견된 문서들을 클러스터링하는 것은 매번 처음부터 전체 클러스터링을 수행할 필요가 없기 때문에 비교적 효율적으로 수행될 수 있습니다. 대신, 우리는 마지막 스윕에서 문서들을 간략하게 스케치하기만 하면 됩니다.

13개 중 10개
기존 클러스터에 통합하여 정리합니다. 또한, 스윕 사이에는 많은 수의 동일한 문서가 있을 것이며, 이들은 알고리즘 초기에 추출될 수 있습니다.

검색 결과의 클러스터링

현재 AltaVista와 같은 검색 엔진은 쿼리에 가장 관련성 높은 답변을 먼저 반환하려고 노력합니다. 이는 종종 문서의 여러 유사한 버전이 별도의 항목으로 반환되는 것을 의미합니다. 클러스터링을 통해 우리는 이 유사성을 사용자에게 보여주고 검색 결과를 더 간결하게 제시할 수 있습니다. 사용자는 선호하는 버전을 선택하여 검색 결과를 검색하고 거의 동일한 사본을 조사하지 않을 수 있습니다.

널리 배포된 정보 업데이트

일부 중요한 정보는 웹 전체에 널리 보급되고 인용되며, 지역적인 변화가 약간 있습니다.
예를 들어, 소비자 신용에 관한 연방거래위원회(FTC)의 판결에 대한 약간의 형식을 바꾼 완전한 또는 부분적인 사본이 많이 있습니다. 이 판결이 변경된다면, FTC가 이 문서의 모든 버전을 가진 사이트에 알림을 하기를 바랄 것입니다. 원본 판결을 포함하는 클러스터는 연락처 목록을 작성하는 데 도움이 될 것입니다. 반면, 검색 엔진을 사용하면 모든 변형을 포함하는 충분히 넓은 쿼리는 관련 없는 많은 결과를 가져와서 걸러내야 합니다.

시간이 지남에 따라 페이지가 어떻게 변화하는지 특징화하는 것

URL을 업데이트하는 것 외에도, 우리는 시간에 따라 스케치를 비교하는 기술을 사용하여 웹 페이지의 동작을 특성화할 수 있습니다. 예를 들어, 우리는 서로 다른 시간에 페이지를 관찰하고 각 버전이 이전 버전과 얼마나 유사한지 볼 수 있습니다. 많은 웹 페이지에 대해 이 정보를 가지고 있을 때, 우리는 웹에 대해 몇 가지 기본적인 질문에 답할 수 있습니다.

페이지는 얼마나 자주 변경되나요?
시간 간격당 얼마나 변경되나요?
페이지는 얼마나 자주 이동하나요? 서버 내에서? 서버 간에?
페이지는 얼마나 오래 존속하나요? 얼마나 많이 생성되나요? 얼마나 많이 소멸되나요?

이러한 문제들에 대한 더 나은 이해는 더 나은 프록시, 검색 엔진, 디렉토리 및 브라우저를 구축할 수 있게 만들 것입니다.

지적 재산권과 표절

한 가지 마지막 응용 분야는 지적 재산의 불법 복제 또는 수정을 감지하는 것입니다. 원본 문서를 기준으로, 우리는 그것의 전체 또는 일부가 실질적으로 복사되었는지 또는 변경되지 않아야 할 문서에 작은 변경 사항이 있는지 감지할 수 있습니다 (예: 라이선스 계약). 그러나 우리의 접근 방식의 보안은 단일하고 정적인 스케치 정책 때문에 제한적입니다. Heintze [2]가 취한 접근 방식은 더 큰 저장된 집합에서 새로운 샘플 세트를 선택하는 것으로, 상당한 저장 비용을 치르지만 더 안전합니다.

상태

우리는 스케치, 클러스터링 및 실시간 클러스터링 알고리즘을 구현하고 작동하는 데모 시스템을 만들었습니다.

13개 중 11개
우리는 1996년 4월에 AltaVista가 수행한 웹 크롤링에서 얻은 30,000,000개의 HTML 및 텍스트 문서 컬렉션에서 알고리즘을 테스트했습니다. 총 입력 데이터는 150 G바이트였으며 (문서당 약 5k의 평균), 문서의 URL만을 담은 파일은 1.8 G바이트였습니다 (URL당 평균 60바이트). 우리는 10단어로 이루어진 셔인글을 사용하여 모든 문서를 스케치하여 40비트 (5바이트) 셔인글 지문을 생성했습니다. 우리는 찾은 셔인글 중 25개 중 1개를 유지했습니다.

약 6억 개의 단청판이 있었기 때문에 원시 스케치 파일은 3 기가바이트를 차지했습니다 (단청판 당 5 바이트). 클러스터링 알고리즘의 첫 단계에서는 이것이 약 5.5 기가바이트로 확장되었습니다 (각 항목 당 9 바이트 - 단청판에 5 바이트, 문서 ID에 4 바이트). 최대로는 병합 작업 중에 데이터의 두 개의 사본이 필요하기 때문에 10 기가바이트의 저장 공간이 필요했습니다.

세 번째 단계에서는 <ID, ID, count> 쌍을 생성하는 과정에서 저장 요구 사항이 약 20 G바이트로 증가했습니다. (한 문서에만 나타나는 셰잉글들이 있기 때문에 일부 공간을 절약하지만, 문서 ID 목록의 이차 확장으로 인해 손해를 입습니다. 최대 저장 용량은 문서 ID 쌍이 처음에는 각 별도의 파일에 중복으로 저장되기 때문에 반영됩니다. 그러나 파일이 병합됨에 따라 점차적으로 결합됩니다.) 세 번째 단계의 끝에서는 정렬된 <ID, ID, count> 쌍 파일이 6 G바이트를 차지했습니다.

최종 클러스터링 단계는 전체 유니온-파인드 데이터 구조가 메모리에 있어야 하기 때문에 가장 메모리 집약적인 단계입니다. 각 클러스터에 있는 문서 목록을 포함한 최종 파일은 100 Mbytes 미만의 공간을 차지했습니다.

우리는 50% 유사도를 기반으로 클러스터를 계산했습니다. 총 3.6백만 개의 문서를 포함한 12.3백만 개의 클러스터를 발견했습니다. 이 중 2.1백만 개의 클러스터에는 동일한 문서만 포함되어 있었고 (5.3백만 개의 문서), 나머지 1.5백만 개의 클러스터에는 7백만 개의 문서가 포함되어 있었습니다 (정확한 중복과 유사한 문서의 혼합). 다음은 다른 작업에 대한 처리 시간 분할입니다 (작업이 병렬화 가능한 경우, 대부분의 작업은 최종 병합을 제외하고 많은 기계에서 동시에 수행될 수 있습니다).

단계     시간 (CPU-일) 병렬화 가능

스케치      4.6        예

중복 제거 0.3

싱글 병합 1.7 예

ID-ID 페어 형성 0.7

ID-ID 병합    2.6        예

클러스터 형성 0.5

총 ~10.5

결론

우리는 우리의 시스템이 웹의 정보 바다를 다루기 위한 새로운 기능을 제공한다고 믿습니다. 이 시스템은 사용자가 전 세계 어디에서나 구문적으로 관련된 문서를 찾을 수 있게 해줍니다. 또한, 검색 엔진은 클라이언트에게 더 나은 결과를 제시할 수 있게 해줍니다. 그리고, 이 시스템은 URL을 시간에 따라 추적하고 이동된 URL에 대한 링크를 감지하고 수정하는 새로운 서비스를 가능하게 합니다.

우리는 또한 우리의 기술이 다른 문제 영역에도 일반화될 수 있다고 믿습니다. 객체에서 특징 집합을 추출하는 어떠한 기술이 주어진 경우, 우리는 어떠한 두 객체의 유사도를 측정하거나 유사한 집합들을 군집화할 수 있습니다.

13개 중 12개
많은 물체들 중에서의 물체들.

감사의 말씀

우리는 유사성 정의와 계산에 대한 아이디어 개발에 도움을 준 Greg Nelson에게 감사의 말씀을 전하고자 합니다.

참고문헌

1. S. Brin, J. Davis, H. Garcia-Molina. 디지털 문서를 위한 복사 감지 메커니즘. ACM SIGMOD 연례 회의 논문집, 샌프란시스코, CA, 1995년 5월. http://www-db.stanford.edu/pub/brin/1995/copy.ps에서 확인 가능
2. Nevin Heintze. 확장 가능한 문서 지문. USENIX 전자상거래 워크샵 논문집, 캘리포니아 오크랜드, 1996년 11월 18-21일. http://www.cs.cmu.edu/afs/cs/user/nch/www/koala/main.html에서 확인 가능
3. U. Manber. 대형 파일 시스템에서 유사한 파일 찾기. 1994년 USENIX 컨퍼런스 논문집, 1-10쪽, 1994년 1월.
4. N. Shivakumar, H. Garcia-Molina. SCAM: 디지털 문서를 위한 복사 감지 메커니즘. 디지털 도서관 이론과 실제에 관한 제2회 국제 컨퍼런스 논문집, 텍사스 오스틴, 1995년. http://www-db.stanford.edu/~shiva/Pubs/scam.ps에서 확인 가능
5. N. Shivakumar and H. Garcia-Molina. 확장 가능하고 정확한 복사 감지 메커니즘 구축. 디지털 도서관 이론과 실제에 관한 제3회 국제 컨퍼런스 논문집, 1996년. http://www-db.stanford.edu/~shiva/Pubs/performance.ps에서 확인 가능
6. URN 자원 이름, IETF 작업 그룹
7. M. O. Rabin, 무작위 다항식에 의한 지문 생성. 하버드 대학교 컴퓨팅 기술 연구 센터, 보고서 TR-15-81, 1981년.

저자들

시스템 연구 센터
디지털 장비 공사

안드레이 지. 브로더, broder@pa.dec.com
스티브 글래스만, steveg@pa.dec.com
마크 S. 마나세, msm@pa.dec.com

컴퓨터 과학 학과
캘리포니아 대학교 버클리

Geoffrey Zweig, zweig@cs.berkeley.edu
제프리 즈와이그, zweig@cs.berkeley.edu

13 중 13

