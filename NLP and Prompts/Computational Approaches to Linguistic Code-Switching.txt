CALCS 2023

언어 코드 스위칭에 대한 계산적 접근 방식

워크샵의 절차

2023년 12월 7일
CALCS 주최자들은 다음과 같은 후원사들의 지원에 감사드립니다.

금

ii
©2023 연산 언어학 협회

이와 다른 ACL 절차의 사본을 주문하려면 다음으로 이동하세요:

협회는 계산 언어학에 대한 협회입니다.
209 N. Eighth Street
Stroudsburg, PA 18360
미국
전화: +1-570-476-8006
팩스: +1-570-476-0860
acl@aclweb.org

ISBN 979-8-89176-053-0

안녕하세요, 저는 iii입니다.

2023년 CALCS 워크샵 제6회 컴퓨터 언어 전환 접근 방식에 대한 절차에 오신 것을 환영합니다! 코드 전환은 다중 언어 사용자들이 다른 다중 언어 사용자들과 의사소통할 때 사용하는 언어들 사이를 왔다갔다 하며 의사소통하는 일반적인 현상입니다. 올해 워크샵은 2023년 12월 7일 싱가포르에서 EMNLP에서 개최됩니다.

이 워크샵 시리즈는 현재 코드 스위칭의 다른 측면에서 작업 중인 전문가와 실무자들을 모아 음성 및 텍스트 연구자들 간의 더 강한 협력을 도모하는 것에 초점을 맞추고 있습니다. 우리는 15개의 정규 워크샵 제출을 받았으며, 그 중 8개를 수락하고 1개는 비보관용으로 받았습니다. 또한, 우리의 워크샵은 새로운 연구를 독려하고 코드 스위칭 데이터가 제기하는 도전에 대응하기 위해 커뮤니티에 활력을 불어넣는 것을 목표로 합니다.

워크샵 프로그램에는 정규 워크샵 제출물과 키노트 스피커의 짧은 강연이 포함되어 있습니다.
또한 Preethi Jyothi와 Haizhou Li의 키노트 강연으로 구성된 훌륭한 초청 연사 프로그램이 있습니다.
워크샵 조직 중 도움을 주신 EMNLP 워크샵 주최자에게 감사드립니다.
싱가포르에서 모두를 직접 만나는 것이 좋았을 텐데, 12월 7일에 함께해주시고 우리가 준비한 프로그램을 즐기시길 바랍니다.

12월에 코드 스위칭에 대해 이야기해봅시다!

워크샵 주최자

조직위원회

주최자

수디프타 카르, 아마존
겐타 인드라 위나타, 블룸버그
마리나 주코바, 캘리포니아 대학교 산타바바라
타마르 솔로리오, 휴스턴 대학교 및 모하마드 빈 자이드 인공지능 대학
모나 디압, 카네기 멜론 대학교
수나야나 시타람, 마이크로소프트 연구소
모노짓 초우드후리, 마이크로소프트 튜링
칼리카 발리, 마이크로소프트 연구소

프로그램 위원회

프로그램 위원회

세자 도
아빈나브 아로라
다마 스라바니
다비드 비라레스
엘레나 알바레스-멜라도
엘스 레페버
홀리 로베니아
프랑수아 이본
가네시 자와하르
구스타보 아길라르
켈런 질레스피
마누엘 마거
파르트 팻와
살림 사즈
세군 아로예훈
슈관 천
수만 도와가르
수라지 마하르잔
타냐 루스타
비베크 스리바스타바
싱지 구오
이홍 타이스

초대 연사

이하이조우 리, 홍콩 중문 대학교 및 싱가포르 국립 대학교
프리디 조티, 인도 공과 대학교 본베이

주요 강연: 코드 스위치 언어 모델링하기

이중언어 병렬 말뭉치

이하이조우 리
홍콩 중국 대학교, 싱가포르 국립 대학교

요약: 언어 모델링은 단어 시퀀스의 확률을 추정하는 기술입니다. 양방향 언어 모델은 언어 간의 단어들의 순차적 종속성을 모델링하는 것을 기대합니다. 그러나 적절한 훈련 데이터의 부족과 언어 간 다양한 문법 구조로 인해 어려움이 있습니다. 우리는 양방향 어텐션 언어 모델 (BALM)을 제안합니다. 이 모델은 단일 언어 및 언어 간 순차적 종속성을 모델링하기 위해 언어 모델링 목적과 준번역 목적을 동시에 수행합니다. 어텐션 메커니즘은 병렬 코퍼스에서 양방향 컨텍스트를 학습합니다. 우리는 동남아시아의 다양한 언어 사용에 대한 연구와 코드 스위치 언어 모델이 언어 처리에 유용할 수 있는 방법에 대해 논의할 것입니다.

바이오: 하이저우 리는 중국 홍콩 중국어 대학 데이터 과학 학부의 X.Q. 덩 대통령 의장 교수입니다. 그는 또한 싱가포르 국립 대학과 싱가포르의 부교수이며 독일 브레멘 대학의 브레멘 우수 의장 교수입니다. CUHK (Shenzhen)에 합류하기 전에 리 교수는 싱가포르의 난양 공과 대학과 싱가포르 국립 대학 (2006-2016), 핀란드의 동부 핀란드 대학 (2009), 호주의 뉴사우스웨일즈 대학 (2011-2016)에서 강의했습니다. 그는 싱가포르 과학 기술 연구 기관 인포컴 연구소 (2003-2016)의 주요 과학자 및 연구 소장이었습니다. 리 교수는 IEEE 펠로우 및 ISCA 펠로우입니다.
그는 IEEE-ACM 오디오 음성 및 언어 처리 트랜잭션 (2015-2018)의 편집장, 컴퓨터 음성 및 언어 (2012-2021)의 부편집장, 스프링거 국제 사회 로봇학 저널 (2008-2021)의 편집위원 및 IEEE 음성 및 언어 처리 기술 위원회 (2013-2015), 수상 위원회 (2021-2023), 및 IEEE 신호 처리 학회의 출판 위원회 (2015-2018)의 회원으로 활동했습니다. 그는 국제 음성 통신 협회 (ISCA, 2015-2017)의 회장, 아시아 태평양 신호 및 정보 처리 협회 (APSIPA, 2015-2016)의 회장, 아시아 자연 언어 처리 연맹 (AFNLP, 2017-2018)의 회장이었습니다. 그는 ACL 2012, INTERSPEECH 2014 및 ICASSP 2022와 같은 주요 과학 회의의 총회장이었습니다.

Keynote Talk: 자원 효율적인 계산 모델에 대한

코드 스위칭된 말과 텍스트

프리티 조티
IIT 보마베이

요약: 코드 스위칭은 언어 간 및 문장 내에서 언어를 전환하는 언어 현상으로, 다양한 언어를 사용하는 사회에서 널리 퍼져 있다. 코드 스위칭된 입력은 기존의 음성 및 NLP 모델에 심각한 도전을 제시한다. 이 도전은 주로 자연스러운 코드 스위칭 데이터의 한정된 가용성과 코드 스위칭의 내재적 다양성으로 인해 발생한다. 이 발표에서는 이러한 이중 도전에 효과적으로 대응하기 위한 기술에 대해 논의할 것이다. 이러한 기술은 코드 스위칭을 위해 단일 언어 음성과 텍스트를 활용하는 방법, 실제 데이터를 보완하기 위해 합성 및 다양한 코드 스위칭 텍스트를 생성하는 방법, 그리고 기존의 실제 코드 스위칭 음성과 텍스트를 다른 언어 자원과 함께 적절하게 사용하는 방법을 다룰 것이다.

바이오: 프리티는 IIT Bombay에서 부교수로 재직 중입니다. 그녀는 2016년 9월에 해당 학과에 합류했습니다. 그 이전에는 University of Illinois at Urbana-Champaign에서 벡만 박사 후 연구원으로 근무했습니다. 그녀는 2013년에 Ohio State University의 CSE 학과에서 박사 학위를 받았습니다. 그녀의 연구 관심사는 주로 음성인식과 음성에 적용된 기계 학습, 그리고 코드 스위칭 분야입니다.

viii
목차

TongueSwitcher: 독일어-영어 코드 스위칭의 세부적인 식별
이고르 스테르너와 시모네 토이펠 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

현실 세계에서의 스트리밍 음성 번역을 위한 코드 스위칭 음성에 대한 연구
Belen Alastruey, Matthias Sperber, Christian Gollan, Dominic Telaar, Tim Ng, Aashish Agarwal. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14

네팔어-영어 이중언어 사용자의 사회적 미디어에서의 감정 표현에 대한 언어 선호도

텍스트 기반 언어 식별을 통한 엔드 투 엔드 코드 스위칭 음성 인식
Qinyi Wang과 Haizhou Li. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .33

다국어 대형 언어 모델을 유도하여 혼합 언어 텍스트를 생성하는 방법: 동남아시아 언어 사례
Zheng Xin Xin Yong, Ruochen Zhang, Jessica Zosa Forde, Skyler Wang, Arjun Subramonian,
Holy Lovenia, Samuel Cahyawijaya, Genta Indra Winata, Lintang Sutawika, Jan Christian Blaise Cruz,
Yin Lin Tan, Long Phan, Long Phan, Rowena Garcia, Thamar Solorio 및 Alham Fikri Aji. . . . . . . .43

CONFLATOR: 코드 혼합 언어 모델링을 위한 스위칭 포인트 기반 회전 위치 인코딩 통합
Mohsin Ali Mohammed, Sai Teja Kandukuri, Neeharika Gupta, Parth Patwa, Anubhab Chatterjee,
Vinija Jain, Aman Chadha, Amitava Das . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64

코드 스위칭 음성 인식 및 언어 식별을 위한 통합 모델: 연결된 토크나이저를 기반으로
쿠날 다완, KDimating 레케시, 보리스 긴즈버그 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

다국어 자가지도 음성 표현은 코드스위칭이 있는 저자원 아프리카 언어의 음성 인식을 개선시킨다. 
Tolulope Ogunremi, Christopher Manning, Dan Jurafsky. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .83

프로그램

2023년 12월 7일 목요일

09:10 - 09:00 개회사

09:05 - 10:35 논문 구두 발표 1

현실 세계에서의 스트리밍 음성 번역을 위한 코드 스위칭 음성에 대한 연구
Belen Alastruey, Matthias Sperber, Christian Gollan, Dominic Telaar, Tim Ng
그리고 Aashish Agarwal

텍스트 기반 언어 식별을 통한 엔드 투 엔드 코드 스위칭
음성 인식
Qinyi Wang과 Haizhou Li

TongueSwitcher: 독일어-영어 코드 스위칭의 세밀한 식별
이고르 스테르너와 시모네 토이펠

CONFLATOR: 스위칭 포인트 기반 회전 위치 부호화를 통합한 코드 혼합 언어 모델링
Mohsin Ali Mohammed, Sai Teja Kandukuri, Neeharika Gupta, Parth Patwa,
Anubhab Chatterjee, Vinija Jain, Aman Chadha 및 Amitava Das

다국어 대형 언어 모델을 유도하여 혼합 언어 텍스트를 생성하는 것:
동남아시아 언어의 경우
Zheng Xin Xin Yong, Ruochen Zhang, Jessica Zosa Forde, Skyler Wang, Ar-
jun Subramonian, Holy Lovenia, Samuel Cahyawijaya, Genta Indra Winata, Lin-
tang Sutawika, Jan Christian Blaise Cruz, Yin Lin Tan, Long Phan, Long Phan,
Rowena Garcia, Thamar Solorio 및 Alham Fikri Aji

10:25 - 11:00 휴식

11:00 - 11:45 초대 강연 - Preethi Jyothi

11시 45분 - 12시 15분: 논문 구두 발표 2

다국어 자가지도 음성 표현은 코드스위칭이 있는 저자원 아프리카 언어의 음성 인식을 개선시킨다.
Tolulope Ogunremi, Christopher Manning, Dan Jurafsky

네팔어-영어 이중언어 사용자의 감정 표현을 위한 언어 선호도
소셜 미디어에서
니라지 파하리와 카즈타카 시마다

12:15 - 12:30 신경망 기계 번역 사전 훈련을 위한 단어 의미와 함께 코드 스위칭을 사용한 연구 결과 논문 찾기

x
목요일, 2023년 12월 7일 (계속)

14:00 - 12:30 점심 휴식

14:00 - 12:15 논문 구두 발표 3

통합된 코드 스위칭 음성 인식 및 언어 식별 모델은 연결된 토크나이저를 기반으로 한다.
쿠날 다완, KDimating 레케시, 보리스 긴즈버그

14:15 - 15:30 패널 토론 - Sudipta Kar, Genta Winata, Marina Zhukova

15:30 - 16:00 커피 시간

16:00 - 16:45 초청 강연 - Haizhou Li

16:45 - 16:50 최우수 논문 발표

16:50 - 16:55 마무리 인사

제6회 언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 논문집, 1-13쪽
2023년 12월 7일 ©2023 계산언어학 협회
TONGUESWITCHER:
독일어-영어 코드 스위칭의 세부적인 식별

이고르 스테르너
공학부
케임브리지 대학교
영국
is473@cam.ac.uk

시몬 토이펠
컴퓨터 과학 및 기술 학과
케임브리지 대학교
영국
sht25@cam.ac.uk

요약

이 논문은 독일어-영어 코드 스위칭 연구에 기여합니다. 우리는 독일어 텍스트에 영어가 포함된 자연스러운 독일어-영어 코드 스위칭의 가장 큰 말뭉치를 제공하며, 코드 스위칭 식별을 위한 두 가지 방법을 제시합니다. 첫 번째 방법은 단어 목록과 형태소 처리를 사용하는 규칙 기반 방법입니다. 우리는 이 방법을 사용하여 독일어-영어 코드 스위칭을 적용한 25.6M개의 트윗 말뭉치를 편집합니다. 두 번째 방법에서는 이 말뭉치에서 신경 언어 모델의 사전 훈련을 계속하고, 이 언어 모델의 임베딩을 기반으로 토큰을 분류합니다. 우리의 시스템은 우리의 새로운 말뭉치와 기존의 독일어-영어 코드 스위칭 벤치마크에서 SoTA를 성립합니다. 특히, 우리는 문맥에서만 해결할 수 있는 언어 모호성 단어와 영어와 독일어 형태소가 혼합된 형태소 혼합 단어에 대해 체계적으로 코드 스위칭을 연구합니다. 우리는 이 두 말뭉치와 시스템을 연구 커뮤니티에 배포합니다.

1 소개

세계 인구의 상당 부분은 다국어를 구사하며, 이는 당연히 세계의 상당 부분이 매일, 자주, 일상적으로 코드 스위칭을 하고 있다는 것을 의미한다 (Harris와 McGhee Nelson, 1992; Grosjean, 2010; Grosjean과 Li, 2013). 코드 스위칭은 화자가 언어를 번갈아 가며 사용하는 것을 의미하며, 이는 문장, 단어 또는 하위 단위에서 발생할 수 있다. 많은 다양한 언어를 구사하는 사람들에게 코드 스위칭은 비형식적인 언어의 자연스러운 부분이며, 편의상이거나 의도한 의미를 더 정확하게 표현할 수 있기 때문에 사용될 수 있다. 코드 스위칭에 대한 여러 심리언어학적 및 사회언어학적 이론들이 존재한다 (Poplack, 1980; Joshi, 1982; Myers-Scotton, 1997; Muysken, 2000; Green and Abutalebi, 2013; Filipović and Hawkins, 2019). 우세한 언어는 매트릭스 언어라고 불리며, 포함된 부차적 언어는

트윗: 나는 정말 다시 보아야 할 것 같아. 나는 정말로 텅 빈 느낌이야. 지금 어떻게 해야 할까요?

그림 1: 독일어-영어 코드 스위칭

내장된 언어라고 불리는 것이다 (Joshi, 1982). 우리는 내장된 언어의 어떤 텍스트 세그먼트를 섬이라고 부른다. Figure 1에 나타난 코드 스위칭의 예시에서, Elike i feel so empty는 섬이다.

많은 NLP 시스템들이 현재 비공식적인 맥락에서의 텍스트를 처리할 수 있는 능력을 갖추도록 개발되고 있습니다. 코드 스위칭은 특히 코드 스위칭 텍스트의 의미를 인식하고 정확하게 추출하거나 심지어 해당 텍스트를 생성하는 애플리케이션에 대해 새로운 압력을 가합니다. 현재 사용 가능한 NLP 도구들은 이 측면에서 뒤쳐지고 있습니다 (Aguilar and Solorio, 2020; Do˘ gruöz et al., 2021); 특히 대규모 언어 모델은 자연스러운 코드 스위칭 데이터로 세밀하게 조정될 때 가장 우수한 성능을 발휘합니다 (Santy et al., 2021). 저희의 연구는 코드 스위칭 언어를 더 잘 이해하고 조작할 수 있는 NLP 도구를 목표로 합니다.

우리는 자연스러운 코드 스위칭을 연구하는 것에 관심이 있습니다. 대부분 비공식적인 대화가 이루어지는 소셜 미디어는 이러한 텍스트의 이상적인 출처입니다. 우리는 영어와 독일어 사이의 코드 스위칭을 연구하고 있으며, 이 두 언어는 밀접한 관련이 있습니다. 우리는 두 언어에서 "was"와 같은 동일한 형태의 고빈도 단어를 많이 마주치게 됩니다. 이 단어는 독일어에서는 WH-대명사이지만, 영어에서는 "to be"의 과거형입니다. 중요한 점은 이 두 의미가 전혀 관련이 없다는 것입니다. 이러한 경우는 코드 스위칭된 텍스트에 대한 흥미로운 예외 사례를 구성하며, 이를 국제어 동형어라고 합니다. 두 번째 흥미로운 현상은 독일어가 형태론적으로 풍부한 언어이기 때문에 그 형태론이 영어 형태에 영향을 미칠 수 있다는 것입니다.

1
페메스는 단어 내 코드스위칭을 생성하는데, 이는 Figure 1의 과거 분사 Mrewatchen과 같은 것이다. 독일어-영어 언어 쌍의 세 번째 특징은 독일어에서 영어 대출어의 높은 빈도이다. 대출어는 외래어로, 주 언어에 완전히 동화된 단어이다. 대출어와 코드스위칭은 언어 변화의 회색 지대를 구성한다. 대출어인지 아니면 섬의 일부인지에 대해서는 언어학에서 논쟁이 많다. (Deuchar, 2020; Treffers-Daller, 2022). 이 연구에서는 대출어 구분을 직접 다루지는 않지만, 우리는 이론 중립적인 방법이 이를 미래에 대한 경험적인 방법으로 기여할 수 있다고 믿는다.
본 논문에서는 섬, 혼합 형태론 및 상호 언어 동형어와 같은 세부 현상에 대한 분석적 관심을 가지고 독일어-영어 코드스위칭을 연구한다. 이는 코드스위칭의 자동 연구에 새로운 측면을 도입한다. 동시에, 우리는 분석에 규모를 가져온다. TONGUESWITCHER 코퍼스에는 자동 코드스위칭 식별이 포함된 2560만 개의 독일어-영어 코드스위칭 트윗이 포함되어 있다. 우리는 우리의 코퍼스와 개발한 두 가지 코드스위칭 식별 방법(규칙 기반, 신경망 기반)을 공개한다.

2 관련 연구

코드 스위칭 식별과 언어 식별은 밀접한 관련이 있는 작업이지만, 전통적인 언어 식별(LI) 도구는 주어진 텍스트에서 어떤 언어가 있는지만 판단할 뿐, 각 섬의 정확한 시작과 끝을 판별할 수는 없습니다. 예를 들어, Chen과 Skiena(2014) 및 Joulin 등(2016b; 2016a)이 제공하는 LI 도구는 문자 기반 n-gram 모델에 의존합니다. FastText(Joulin 등, 2016b,a)는 입력 텍스트의 통계적 특성을 사전 컴파일된 각 언어의 빈도 프로파일과 비교하기 위해 문자 기반 n-gram 방법을 사용합니다. 이는 룩셈부르크어와 아프리칸스어와 같은 유사한 언어와 함께 영어와 독일어를 포함한 176개 언어를 구별합니다. Polyglot은 Riesa와 Giuliani(2013)의 CLD2 도구를 기반으로 구축된 다른 도구로, 문서당 하나 이상의 언어를 식별할 수 있습니다(Chen과 Skiena, 2014). Lingua(Stahl, 2023)는 블랙박스 LI 도구로, 독일어-

1. 코드, 모델(신경 태거 및 코드 스위칭 언어 모델, 데모 포함) 및 말뭉치가 모두 온라인에 있습니다.

한국어. 이것은 언어 모델링 접근 방식과 하드 코딩된 규칙을 결합합니다. 그것의 코드 스위칭 식별 성능은 실험적으로 평가된 적이 없습니다.

Nguyen et al. (2020; 2021)은 베트남어-영어와 힌디어-영어 혼합 텍스트에 대한 규칙 기반의 코드 스위칭 식별 시스템을 제시한다. 이 시스템은 각 언어 쌍을 위해 특별히 생성된 단어 목록에 기반한다. 두 단어 목록에 모두 나타나는 모든 단어는 인간 주석자에 의해 수동으로 명확하게 구분된다. 이는 훈련을 필요로하지 않기 때문에 연구자들이 시스템을 제어할 수 있는 간단한 접근 방식이다.

Osmelak과 Wintner (2023)는 코드 스위칭을 더 세분화된 수준에서 감지합니다. 그들의 Denglisch 시스템에서는 토큰 수준에서 태깅이 진행되며, 다음과 같은 레이블이 사용됩니다: 독일어 토큰에 대한 D와 영어 토큰에 대한 E; 독일어에서 영어로 가져온 대출어에 대한 SD, 영어에서 독일어로 가져온 대출어에 대한 SE, 그리고 다른 언어에서 가져온 대출어에 대한 SO. 또한 구두점과 이모티콘과 같은 분류할 수 없는 항목에 대한 기타 카테고리와 혼합된 형태소의 단어에 대한 혼합 카테고리도 있습니다.

다른 몇 가지 코드 스위칭 접근 방식도 혼합 형태론을 모델링합니다. Nguyen과 Cornips (2016)는 Morphessor 도구를 사용하여 Dutch-Limburgish-English 코드 스위칭을 처리하기 위해 형태론 분석을 수행하며, Mager 등 (2019)은 RNN을 사용하여 German-Turkish 및 Spanish-Wixarika 텍스트에서 단어 내 코드 스위치를 감지합니다. Osme-lak과 Wintner (2023)는 CRF, 지도 학습 기계 학습 프레임워크를 사용하여 철자, n-gram, 형태론, 기능어, 빈도, 어휘 구성 요소 및 단어 목록과 같은 수동으로 관리되는 기능과 결합하여 작동합니다. 훈련 자료는 영어와 독일어가 균형 잡힌 60,000 토큰을 포함하는 950개의 Reddit 댓글로 구성됩니다. 또한 자동으로 태그가 지정된 실버 표준 데이터를 추가로 사용하여 31,500개의 댓글 (5백만 토큰)을 처리합니다. 대조적으로, 우리의 솔루션은 어떠한 인간 주석 훈련 자료도 필요로하지 않습니다.

신경 코드 스위칭 식별을 위해 mBERT (Devlin et al., 2019)와 같은 다국어 언어 모델의 단어 임베딩을 사용하는 것은 한 가지 가능한 접근 방법입니다. mBERT는 각 토큰을 768차원 벡터로 임베딩하는 인코더 전용 트랜스포머 기반 모델입니다. Santy et al. (2021)는 자연스러운 코드 스위칭 자료에서 미세 조정된 경우 가장 적합하다고 발견했습니다. Nayak과 Joshi (2022)

2
힌글리시에서 코드 스위칭 식별을 위해 BERT 기반 모델을 사전 훈련하고 세부 조정합니다. 그들은 기존 도구를 사용하여 트윗의 대규모 말뭉치를 수집하고 자동으로 레이블을 지정합니다.
골드 표준 데이터셋에 관해서는, 코드 스위칭 데이터셋의 대부분은 (1) 인도에서 사용되는 언어와 영어 사이(Gupta 등, 2021; Nguyen 등, 2021; Adda-Decker 등, 2008), (2) 중국어와 영어 사이(Lyu 등, 2010) 및 (3) 스페인어와 영어 사이(Mave 등, 2018; Samih 등, 2016)에 있습니다. 독일어-영어 코드 스위칭의 경우 Osmelak과 Wintner(2023) 이외에 Rijhwani 등(2017)은 99개의 트위터 트윗으로 구성된 미니 말뭉치를 사용하였으며, 이는 공개적으로 이용할 수 없습니다. 우리의 말뭉치는 훨씬 더 큽니다.

3 코퍼스 구축

우리가 입력으로 사용하는 독일어 트윗은 Kratzke (2022, 2023)에 의해 대규모로 수집되었습니다. 트위터 언어 식별 알고리즘은 각 트윗의 작성 시점에 확률적인 언어를 할당합니다. Kratzke는 독일어로 간주된 트윗을 선택했습니다. 이로 인해 2019년 4월부터 2023년 2월까지 작성된 1억 4920만개의 입력 트윗이 있었습니다. 우리는 트윗을 정리하고 (URL은 <URL>로 대체되며, 이모티콘, 이메일, 전화번호 및 언급은 제거됩니다) FastText 언어 감지를 실행하여 독일어 태그가 재할당되거나 영어 언어 태그로 할당된 트윗만 유지합니다. 이 단계에서는 룩셈부르크어 및 독일어와 유사한 다른 언어로 인해 트위터의 언어 식별기가 잡지 못한 많은 트윗이 제거됩니다. 이 단계 이후에는 1억 2370만개의 트윗이 남게 됩니다. 반면에 Osmelak과 Wintner (2023)는 Polyglot의 예측이 영어와 독일어 둘 다가 아닌 경우 해당 예제를 제거하기 위해 입력을 필터링합니다.

테스트 세트를 구축하기 위해 본 논문의 저자들이 1252개의 트윗에 코드 스위칭 주석을 수행했습니다. 우리는 Prodigy 주석 도구 (Montani and Honnibal, 2018)를 사용했습니다. 주석 시간을 효율적으로 사용하기 위해, 우리는 볼 수 있는 경우의 상당 부분이 코드 스위칭이 상당히 높은 경우를 보장하고 싶었습니다. 따라서 트윗은 TONGUESWITCHER의 이전 버전에 의해 처리되고 사전 필터링되었습니다. 이 시스템은 최종 버전과 거의 차이가 없었으며, 규칙의 순서와 다국어 어간 추출 알고리즘의 품질 등에서 약간의 차이가 있었습니다. 그런 다음 두 개의 하위 집합에서 무작위로 샘플링했습니다: 모든 입력 트윗의 25%와 코드 스위칭 비율이 높은 트윗의 75%. 시스템 주석은 인간 주석 이전에 제거되지 않았습니다.

남자 주석. 명확한 지침이 없었습니다.
주석자들은 스위스 독일어와 같은 독일 방언을 제외한 트윗을 버렸으며,
독일어가 실제로 기본 언어로 작용하는지 확인한 후
각 남아있는 트윗에서 섬의 시작과 끝 지점을 표시했습니다.
경우의 63.5%에서 경계가 이동되었습니다. 이는 주석자들이 시스템의 제안을 단순히 수용하지 않았음을 의미합니다.
대출어의 주석에 대해서는, 각 주석자는 대출어로 사용되는 정도가 너무 흔해서 그렇게 사용되는 단어들을 직관적으로 따랐으며, 대출어의 문맥에 민감한 정의를 추가로 사용했습니다.
주석의 일관성을 확립하기 위해, 우리는 1172개의 토큰으로 구성된 36개의 트윗을 무작위로 추출하여 두 주석자가 라벨을 붙였습니다.
주석자 간의 일치도는 κ=0.68 (N=1172, n=3, k=2; Cohen, 1960)로 측정되었습니다.
36개의 트윗 중 15개에서 모든 토큰에 대해 주석자들은 완전히 동의했습니다.
결과적으로 테스트 세트에서 섬의 크기 분포는 그림 2에 나와 있습니다.

1. Can you please help me with this?
2. I am going to the store to buy some groceries.

3

4

5

6 7 8 9
101112141518

그림 2: 테스트 세트에서 섬 크기의 비율. 각 필드는 해당 크기의 섬에 발생하는 토큰의 총 수를 나타냅니다.

4. 텅스위처

우리의 규칙 기반 방법은 독일어 트윗을 입력으로 받아 각 단어 또는 혼합 형태소 단어의 언어를 나타내는 레이블을 생성합니다. 주 알고리즘은 결정을 내리기 위해 여러 단어 목록 기반 필터를 적용합니다. 추가적인 처리는 a) 단어가 실제로 두 언어에서 가능한 단어인 경우 또는 b) 단어 내 코드 스위치인 경우에 적용됩니다. 이 방법에서의 모든 처리는 소문자로 변환된 단어에서 수행됩니다.

4.1 단어 목록 구성

우리는 먼저 영어와 독일어를 위한 공식 및 비공식 단어 목록을 편집합니다. 우리의 전략은 우리가 가지고 있는 자원에 따라, 두 언어 중 하나에만 포함된 단어로 구성된 순수한 단어 목록을 편집하는 것입니다 (예를 들어,

"파서"는 순수한 목록에 있어서는 안 되며, 가능한 한 많은 단어를 포함하는 큰 단어 목록이 있어야 합니다. 이 단어 목록은 독일어 매트릭스 언어에서 가능한 한 많은 단어를 커버합니다. "순수한 영어" 단어 목록에는 WortSchatz Leipzig News Corpora (WL, 15,000 단어, Biemann et al., 2007)와 온라인 Urban Dictionary (UD, 13,000 단어, Bierner, 2022)의 스크랩된 버전을 결합합니다. 이는 영어 슬랭에서 사용되는 많은 비공식적인 단어와 구구절을 포함하고 있습니다. WL 코퍼스에서 5회 이하로 나타나는 단어와 UD에서 10회 이하로 나타나는 단어를 제거합니다.

독일어에 대해서는 WL 말뭉치(65,000 단어)를 사용하며, 스위스어(37,000 단어)와 오스트리아어(34,000 단어)를 추가합니다. 이들 방언으로 작성된 많은 입력 트윗을 자동으로 걸러내지 못했기 때문입니다. 또한, 더 비공식적인 온라인 독일어 사전인 dict.cc(583,000 단어, Hemetsberger, 2023)도 추가합니다. 이 목록은 우리의 "큰 독일어" 단어 목록의 기초입니다. 다국어 어간 추출을 위해 순수한 독일어 어근 단어 목록도 필요합니다. 독일어 WL 말뭉치에서 두 번 이상 나타나는 단어들로 작은 단어 목록을 수집하는 것으로 시작합니다.

영어로 된 외래어는 독일어 목록에서 제거되어야 합니다. 이상적으로는 외래어를 별도로 처리하기 위해 완전한 목록이 있어야 하지만, 실제로는 독일어에서 알려진 영어로 된 외래어 목록 중 작은 목록인 3367개의 목록에만 접근할 수 있습니다. 이 목록은 Seidel (2010)이 독일 잡지 Der Spiegel의 분석을 통해 작성한 것입니다. 우리는 이 목록을 "Big German"에서 제거합니다. 또한, 영어 단어와 그에 해당하는 독일어 번역이 동일한 경우와 그 반대인 경우에는 dict.cc (Hemetsberger, 2023)의 모든 항목을 자동으로 독일어 단어 목록에서 제거합니다. 또한, 우리의 접근 방식에서는 남자, 여자 및 도시 이름의 큰 목록 (Weiss, 2022a,b; OnTheWorldMap, 2023)도 두 목록에서 제거합니다. 우리의 알고리즘의 7단계인 n-gram 처리 단계에서 주변 언어를 기반으로 이름을 처리합니다 (§4.2에서 다룰 예정).

마지막으로, 우리는 또한 단어 목록에서 언어에 구애받지 않는 한 두 글자 단어들 (예: "eh")을 제거하고 싶습니다. 이러한 단어들은 오타, 약어 및 일반적인 처리 문제로 인해 발생할 수 있습니다. 이러한 초단위 단어들은 수동으로 선택된 단어 목록에 포함되지 않았다면 제외하고 싶습니다.

2. 이 대출어들을 제거하는 또 다른 이유는 일부 단어들이 혼합된 형태소를 가지고 있기 때문입니다. 우리의 알고리즘은 이미 "BigGerman"에 전체 단어가 있는 경우 혼합된 형태소를 감지하지 못합니다. 이러한 단어들을 제거함으로써 혼합된 단어 감지 단계에서 자동으로 처리됩니다.

큰 독일어    709,979
순수 독일어    92,099
순수 영어    20,203
언어 간 동형어    120

표 1: 단어 목록 작성, 단어 수와 함께

lists3, 우리는 모든 단어 목록에서 그들을 제거했습니다.
이 모든 단계를 거친 후에도 여전히 단어들이 나타납니다.
(독일어 단어 목록에는 순수한 영어 단어들이 많이 있고 그 반대도 마찬가지입니다).
이 중 많은 단어들은 노이즈입니다. Nguyen과 Bryant (2020)가 하는 것처럼
수작업으로 완전히 줄일 수 있습니다. 대신, 우리는 먼저 대형 언어 모델 (LLM) text-davinci-003 (Brown et al., 2020)에게 각 단어의 주 언어 추측을 요청합니다.
다음 프롬프트로: 한 단어로, 이 단어는 어떤 언어입니까: {}? LLM은 영어에 편향될 수 있습니다. 따라서 LLM의 예측을 맹목적으로 받아들이지 않고 모든 분류를 수동으로 검토합니다. 모델의 선택을 알게 되면 시간을 절약할 수 있습니다. 우리는 영어 단어 목록에서 독일어 단어를 제거하고, 독일어 단어 목록에서 영어 단어를 제거했습니다.
이 목록을 수동으로 검토하는 과정에서 두 언어에서 그래픽적으로 동일하고 동일한 의미를 가진 단어들 (예: '다양한')도 발견됩니다. 이러한 단어가 발견되면 모든 단어 목록에서 제거됩니다. 나중에 주변 언어를 기반으로 이러한 단어들을 처리할 것입니다.
마지막으로, 우리는 IH 목록을 작성했습니다. IH가 두 언어에서 다른 POS를 가지고 있다는 가정하에, 영어와 독일어 WL 말뭉치를 태깅하여 적어도 하나의 다른 POS를 가진 공유 단어를 찾습니다. 대문자화를 제외하고.
결과 단어 목록의 크기는 표 1에 나와 있습니다.

4.2 코드 스위칭 식별 알고리즘

우리의 코드 스위칭 식별 알고리즘은 다음과 같이 정의됩니다. 먼저 Flair upos-multi 다국어 uPOS 태거 (Akbik et al., 2018; Petrov et al., 2012)를 사용하여 각 정제된 트윗을 토큰화하고 POS 태깅합니다. 그런 다음 각 토큰을 분류하기 위해 다음 단계를 적용합니다. 이러한 단계는 또한 그림 3에 플로우 차트로 시각화되며, 각 단계에서 처리되는 토큰의 예시는 부록에 제공됩니다.

3. 선별된 목록에는 28개의 영어 한 글자 또는 두 글자 단어 (예: 'of'와 'if')와 24개의 독일어 한 글자 또는 두 글자 단어 (예: 'zu'와 'um')가 포함되어 있습니다.
4. 이러한 단어들은 IH가 아닙니다, 왜냐하면 IH는 다른 의미를 가지고 있기 때문입니다.

4
단어

lookuppure - 순수 조회
englishwordlist - 영어 단어 목록
lookupinter- - 국제 조회
lingualhomographs - 언어 동형어
EN(1) - 영어(1)
POS - 품사
asEnglish? - 영어로 되어 있나요?
EN(2) - 영어(2)

lookupbig - 큰조회
germanwordlist - 독일어 단어 목록

할 수 있나요?
혼합어로 분석할 수 있나요?
DE(2,3)

믹스(4)

통계 형태소 분석을 할 수 있나요? (lan(stem)==ENand lan(affix)==DE)or len(lans(roots))==2 MIX(5)

1. Can you speak English?
2. I am learning Korean.
3. What is your name?
4. How old are you?
5. Where are you from?

단어에 우물쇠가 있나요? DE(6)
예 아니오 예 예

N

N
Y

네, 저는 한국어로 번역할 수 있습니다. 어떤 문장을 번역해 드릴까요?

N

네
아니요

N

Y Y

그림 3: 단어 수준의 분류 서브루틴

표 9. 우리의 말뭉치에서 각 단계별로 식별된 토큰의 비율이 괄호 안에 제시되어 있습니다.
1 (5.8%) 만약 단어가 우리의 순수한 영어 단어 목록에 있다면, 즉시 영어 태그를 받습니다.
2 (9.3%) 만약 단어가 상호언어 동형어(IH)라면, 단어의 품사 태그를 사용하여 언어 식별을 시도합니다.
3 (74.6%) 그렇지 않으면, 우리의 큰 독일어 단어 목록에서 단어를 찾아 독일어 태그를 할당합니다.
4 (0.2%) 단어가 아직 식별되지 않았다면, 우리가 개발한 다중 언어 어간 추출 시스템을 사용하여 접사를 재귀적으로 제거합니다(Osmelak과 Wintner, 2023에서 가져온 목록). 단어가 순수한 영어 단어 목록에 나타나거나 더 이상의 접사가 발견되지 않을 때까지(또는 간단한 변형: 누락된 'e'를 추가하거나 마지막 글자를 두 번 제거) 단어를 찾습니다. 만약 영어 어간이 순수한 독일어 접사와 함께 발견된다면, 단어에는 혼합 레이블이 지정됩니다.
5 (1.4%) 다음으로, 우리는 HanTa(2019년 Wartena 기반의 통계적 형태론적 분할 부분 시스템)을 사용하여 알려진 하위 단어를 찾습니다. HanTa는 훈련 가능한 2차 자기회귀 모델로, 각 형태소는 이전 두 형태소에 의존하여 가장 가능성 있는 형태소 순서를 예측합니다. 우리는 HanTa를 (a) 독일어를 위해 Tiger Corpus(Brants et al., 2002) (b) 영어를 위해 Brown Corpus(Francis and Kucera, 1964) (c) 둘의 혼합체에 대해 훈련시키고, 이 세 가지 시스템을 차례로 사용하여 단어에서 어근을 찾습니다. 이 부분 시스템은 완전히 단일 언어의 합성어도 감지하므로, 이전 단계의 0.2%에 비해 비율이 증가합니다.

분할 트윗 문장 토큰 영어 토큰

훈련 24.6백만 57.8백만 741.9백만 82.6백만
개발 1.1백만 2.6백만 32.9백만 3.6백만
테스트 1.3천 3.0천 37.5천 2.8천

총 25.6백만 60.4백만 774.8백만 86.2백만

테이블 2: 통스위처 말뭉치 통계

6 (0.5%) 알 수 없는 단어에 우모트가 포함되어 있으면 독일어 태그를 받습니다.
7 (8.2%) 이 단계에서 알 수 없는 단어는 단일 언어 섬 내에서 발생하는 경우 이웃 언어로 할당됩니다. 섬 경계에 있는 단어는 독일어와 영어의 가장 가능성이 높은 10,000개의 바이그램 빈도에 기반하여 양쪽에서 가장 가능성이 높은 언어를 가정합니다. 그렇지 않은 경우, 토큰은 가장 가까운 식별된 토큰의 언어를 가정합니다.
우리는 Lin과 Byrne (2022)의 프레임워크를 사용하여이 알고리즘을 구현하며, 이로 인해 TONGUESWITCHER (TS) 시스템이 생성됩니다. 이 시스템을 사용하여 모든 123.7M 개의 정제된 입력 트윗에 자동으로 레이블을 지정하여 우리의 실버 주석 데이터를 생성했습니다. 실버 레이블을 기반으로 적어도 50%의 독일어 토큰과 적어도 하나의 영어 또는 혼합 토큰을 포함하지 않는 트윗을 제외했습니다. 이 코퍼스를 데이터의 마지막 두 달 (23년 1월, 2월)을 개발 세트로 할당하여 분할했습니다. 실버 표준 훈련/개발 데이터와 함께 코퍼스의 요약은 표 2에 제공됩니다. 우리의 실버 표준 데이터는 11%의 영어 토큰을 가지고 있습니다.
우리는 코퍼스와 실버 표준 데이터를 검증합니다.

5
각각 5개의 트윗을 샘플링하여 다른 섬 크기(1에서 20 토큰)에 대한 표준 주석을 작성했습니다. 100개의 트윗 중 64개는 진짜 코드 스위칭이었습니다. 나머지 중 9개는 번역이었고 27개는 단일 언어였습니다. 대부분의 단일 언어 오류는 단일 토큰 차용어나 명명된 개체의 잘못된 식별로 인해 발생했습니다. 전반적으로, 우리는 현재 사용 가능한 어떤 말뭉치보다도 회수율이 더 높을 것으로 예상되므로 정밀도가 허용 가능하다고 결론지었습니다. 우리의 말뭉치에 선택된 트윗에 대해 더 엄격한 조건을 선택했다면, Nayak과 Joshi (2022)가 하는 것처럼 단일 토큰 섬만 있는 트윗을 제외할 수도 있었을 것입니다. 이렇게 하면 정밀도를 쉽게 높일 수 있었지만, 코드 스위칭 삽입이나 차용어의 흥미로운 경계 사례를 놓칠 수도 있었습니다. 이러한 사례들이 언어학자와 어휘학자들에게 매우 가치 있는 것입니다. 

코드 스위칭 트윗 중에서 우리는 시스템이 예측한 섬 중 몇 개가 올바르게 식별되었는지를 세어보았습니다. 우리는 단일 토큰 영어 섬의 정밀도가 62.5 (예측된 섬 40개), 두 토큰 섬은 87.5 (예측된 섬 8개), 세 토큰 섬은 80.0 (예측된 섬 10개)이었으며, 이보다 큰 모든 섬 크기 (예측된 섬 65개)의 정밀도는 100.0이었습니다. 특히 밀집된 코드 스위칭의 두 가지 예시가 표 3에 나와 있습니다. TS는 예시 (1)을 완벽하게 레이블링하지만, 예시 (2)에서는 'performed', 'pushen', 'Time-to-Market' 및 'Re-Launch'를 잘못된 태그로 독일어로 표시합니다. 'Top-of-mind-Awareness'는 Flair에서 올바르게 분할되지 않아 주변 토큰의 언어로 잘못 식별되었으며, 이는 독일어입니다.

5 BERT 기반 시스템

우리는 또한 독일어-영어 식별을 위해 세밀하게 조정된 신경망 시스템을 원했습니다. 이를 통해 신경 단어 임베딩이 이 작업에 적합한 정도를 조사할 수 있었습니다. 이를 위해 우리는 TONGUESWITCHER 말뭉치에서 신경 언어 모델을 사전 훈련하고 토큰 분류를 위해 세밀하게 조정했습니다. 그런 다음 Denglisch 말뭉치의 인간 레이블 예제를 사용하여 분류 계층을 학습합니다. 이 시스템은 tsBERT라고 합니다.

5 TS 시스템에는 명명된 개체 인식기나 외래어에 대한 특별한 처리를 제외하고는 단어 목록과 주변 언어를 사용합니다.
6 우리는 시스템이 예측한 섬과 실제 섬 사이의 중첩이 충분한 경우에 대해 관대한 경계 정의를 사용했습니다.
7 이는 이러한 단어들이 우리의 "Big German" 단어 목록에 포함되어 있으며 "Pure English" 단어 목록에는 포함되어 있지 않기 때문입니다.

6 실험

시스템, 경쟁자, 기준선 우리는 우리의 시스템, TONGUESWITCHER (TS)와 tsBERT를 문헌에서 가져온 두 경쟁자인 Denglisch CRF (Osmelak and Wintner, 2023)와 Lingua (Stahl, 2023)와 비교평가합니다. Denglisch 시스템은 훈련된 시스템으로 제공되지 않으므로, 우리는 그들의 절차를 따라 훈련시킵니다. Denglisch의 출력을 해석하기 위해, 우리는 Denglisch 레이블을 우리의 축소된 세트에 맞춥니다. 영어, 독일어, 혼합은 직접 사용됩니다. SE는 영어로, SD는 독일어로 변환됩니다. Denglisch의 SO 레이블과 구두점 레이블은 평가에서 무시됩니다.
우리는 GPT-4 LLM (OpenAI, 2023)에 부록 §A.3에서 주어진 프롬프트로 강력한 기준선을 구축합니다. 또한 (영어) BERT (eBERT), 독일어 BERT (gBERT, DeepsetAI, 2019) 및 다중언어 BERT (mBERT) 모델에서 직접 분류 레이어를 학습하여 기준선 신경망 분류 모델을 훈련시킵니다.

데이터셋 우리는 사전 훈련 데이터로 TONGUESWITCHER 코퍼스를 사용하고, Denglisch 코퍼스 (Osmelak과 Wintner, 2023)의 인간이 레이블을 단 예제를 세부 조정 데이터로 사용합니다 (이모티콘을 제거하고, 어휘에 없는 구두점 토큰을 대체하고, 100 토큰보다 긴 항목을 제거한 후).
우리의 주요 평가는 우리 자체 코퍼스 (§3)를 사용하여 1252개의 트윗 테스트 세트로 진행됩니다. 또한 우리의 시스템과 Denglisch CRF 시스템의 결과를 Denglisch 코퍼스의 독일어-영어 하위 부분에 대해 보고합니다 (이전과 동일한 정의를 사용하여 15%의 코퍼스 문장을 사용). BERT 기반 시스템은 교차 검증 설정에서 그들의 데이터로 훈련되지만, TONGUESWITCHER는 훈련될 수 없습니다. 우리는 이 평가를 정상성 검사로 사용합니다: 만약 우리의 시스템이 이 코퍼스에서 Denglisch 시스템보다 훨씬 낮은 성능을 보였다면, 이는 경고의 이유가 될 것입니다.

훈련 우리는 bert-base-multilingual-cased (mBERT) 사전 훈련 모델 (Devlin et al., 2019)로 BERT 기반 모델을 초기화합니다. 우리의 rule-based 시스템과 달리, 이 모델은 대소문자 단어를 구분합니다. 우리는 TS 훈련 말뭉치의 24.6M 개의 코드 스위칭 트윗에 대해 1 에포크 동안 사전 훈련을 계속합니다. 우리는 Denglisch Corpus (Osmelak and Wintner, 2023)에서 우리의 작업을 위해 fine-tuning을 수행합니다. 그들의 말뭉치에 대한 평가를 위해, 우리는 그들이 하는 것과 동일한 10-fold 교차 검증 설정에 대해 모델을 훈련합니다. 우리의 테스트 세트에 대한 평가를 위해, 우리는 그들의 말뭉치의 100%에서 훈련합니다.

6
(1) 대명사: 그/그를 키: 1.83m 별자리: 처녀자리 흡연: 아니요 타투: 3개 피어싱: 귀걸이 (더는 원하지 않아요, 최대로 귀 피어싱 더 많이) 좋아하는 색: 초록 좋아하는 음료: 커피와 우롱 우유 차, 뜨거운 것, 1/4 설탕과 타피오카가 있는 내 버블티 가게에서.

(2) 우리가 우리의 기술을 향상시키고 유닛들을 함께 수행한다면, 우리는 판매를 새로운 수준으로 끌어올릴 수 있습니다. 또한, 이를 통해 리런치의 시장 진입 시간을 단축시킬 수 있습니다. 이는 추가적인 상기도를 가져오고 커뮤니티에서 브랜드를 홍보합니다. 알겠습니까? 출발!

테이블 3: TONGUESWITCHER Corpus의 정상성 검사에서의 예시

실버 표준 자료를 라벨링할 때와 같이 그들이 하는 대로 합니다. 훈련 세부 사항은 부록 §A.2에 제공됩니다.

메트릭은 토큰 기반의 마이크로 평균 F1 측정치 (Ft로 표시)와 개체 기반의 F1 측정치 (Fe로 표시)로 별도로 보고합니다. Fe는 독일어 텍스트 내의 영어 섬의 수에 기반하여 엄격한 경계로 정의됩니다. 우리는 개체 표현을 위해 BIO 형식 (Ramshaw와 Marcus, 1995)을 사용합니다. 코드 스위칭 세그먼트는 텍스트 내에서 일관된 개체이므로, 개체 기반 메트릭을 사용하는 것이 각 토큰의 코드 스위칭 컨텍스트를 무시하는 토큰 기반 메트릭보다 더 유익할 것입니다. 우리는 모든 섬에 대한 성능을 보고하며, 또한 골드 표준에 따라 2-4 토큰으로 구성된 짧은 섬에 대한 시스템의 성능을 측정하는 새로운 메트릭을 도입합니다. 이 논문 전체에서 사용하는 통계적 검정은 양측 페어 퍼뮤테이션 테스트로, R = 10,000로 근사화되며, 유의 수준은 α = 0.05입니다.

7 결과
독일어 영어 혼합 전체
9907 1972 192 12071

Denglisch 97.5 89.1 25.6 95.5 - 덴글리쉬 97.5 89.1 25.6 95.5

TS       96.9  87.7 32.4 94.5
tsBERT   98.9  95.5 60.1 97.8

테이블 4: Denglisch 말뭉치에 대한 결과; Ft로 표시

Table 4는 Denglisch 말뭉치의 G-E 하위 집합에서 Ft로 결과를 제공합니다. 우리가 훈련시킨 tsBERT 모델은 모든 범주에서 훈련시킨 Denglisch를 능가합니다 (차이는 유의미하며, 4배 p<0.01). 이 벤치마크에서 새로운 SoTA를 설정합니다. tsBERT의 우월성은 영어 범주 (95.5 대 89.1)에서 나타납니다. 이는 독일어-영어 코드 스위칭 작업의 핵심입니다.

식별은 특히 만족스럽습니다. 혼합어 감지에서 우리 시스템은 Denglisch보다 135%의 개선을 이루었습니다.
표 3의 예제 (2)를 다시 살펴보면, TONGUESWITCHER (TS)가 여러 번의 실수를 저지르는 경우, tsBERT는 이 모든 실수를 수정하고 코드 스위칭을 완벽하게 식별합니다. Denglisch는 'Skills', 'elevaten', 'Units', 'performen', 'Re-Launch', 'shorten', 'pushed'가 모두 독일어라고 예측하고 'Time-to-Market'은 혼합어라고 잘못 제안합니다. 한편, TS는 규칙 기반으로 작동하기 때문에 Denglisch 데이터에 대해 훈련되지 않았습니다. 영어 및 혼합어 카테고리에서 TS는 Denglisch와 통계적으로 구별할 수 없습니다 (p = 0.19, p = 0.09). 독일어 카테고리에서는 Denglisch에 비해 성능이 크게 뒤쳐집니다.
우리는 두 시스템 모두 정상성 검사를 통과했다고 생각합니다. 이제 우리 자체 말뭉치에서의 주요 결과로 넘어가보겠습니다. 이 말뭉치에는 어떤 시스템에게도 새로운 인간 주석 훈련 자료가 제공되지 않았습니다. 표 5는 우리 말뭉치의 정밀도, 재현율 및 Ft 결과를 보여줍니다.
TONGUESWITCHER (Ft = 97.1 전체)와 tsBERT (Ft = 97.0 전체)는 서로 구별할 수 없으며, 모든 기준선과 경쟁 모델보다 유의하게 우수합니다. 단, 혼합 카테고리에서는 TS가 tsBERT보다 우수합니다 (p <0.01) 그리고 tsBERT는 모든 BERT 기반 기준선과 구별할 수 없습니다. 다른 모든 차이는 유의미하며, 이는 GPT-4 (Ft = 94.3 전체)가 우리의 두 TS 시스템에 비해 열악하다는 것을 의미합니다. 이는 TS가 우리의 말뭉치에서 SoTA를 확립했다는 것을 의미합니다. TS는 혼합 카테고리에서 다른 모든 모델보다 우수한 성능을 보입니다. BERT 기반 모델들이 다음으로 우수합니다.

Denglisch의 골드 표준에 대한 우리의 처리에 주의하세요 (모든 '공유 독일어' 토큰을 독일어로 축소). 이는 오직 TS에만 영향을 미칩니다. 예를 들어, TS는 '베를린'과 같은 명명된 개체가 영어 구성 요소 내에서도 영어로 표시된다고 말할 것입니다.

7
독일어     영어     혼합      전체
29761       2757        129        32647
P   R  Ft   P   R  Ft  P   R  Ft   P   R  Ft

Lingua      95.8 97.3 96.5 66.5 57.6 61.7 0.0 0.0 0.0 93.6 93.6 93.6
GPT-4       99.2 95.2 97.2 66.2 93.7 77.5 12.2 16.3 14.0 94.8 94.8 94.8
Denglisch CRF 98.4 97.4 97.9 75.1 85.5 79.9 19.0 6.2 9.4 96.0 96.0 96.0

eBERT       98.7 97.4 98.0 78.1 86.7 82.2 23.1 38.0 28.7 96.3 96.3 96.3
gBERT       98.8 97.0 97.9 73.9 87.6 80.1 27.7 34.1 30.6 95.9 95.9 95.9
mBERT       98.7 97.5 98.1 78.1 87.3 82.4 24.9 32.6 28.2 96.4 96.4 96.4

텅스위처 99.3 97.6 98.4 79.0 93.8 85.8 48.0 38.0 42.4 97.1 97.1 97.1
츠버트 99.0 97.9 98.5 81.5 89.1 85.1 25.5 38.8 30.8 97.0 97.0 97.0

테이블 5: 우리의 테스트셋 결과

섬   짧은 섬 (2-4)
1192       365
P   R  Fe   P   R  Fe

Lingua 25.4 14.0 18.1 27.8 34.5 30.8
GPT-4 44.5 70.1 54.4 50.7 74.5 60.4
Denglisch 49.0 55.5 52.0 53.2 72.3 61.3

eBERT 54.0 61.5 57.5 63.1 70.7 66.7
gBERT 49.2 58.4 53.4 55.3 71.0 62.2
mBERT 54.8 62.0 58.2 63.4 73.7 68.2

eBERT 54.0 61.5 57.5 63.1 70.7 66.7
gBERT 49.2 58.4 53.4 55.3 71.0 62.2
mBERT 54.8 62.0 58.2 63.4 73.7 68.2

TS 58.9 75.7 66.2 57.3 77.3 65.8
tsBERT 60.5 66.5 63.4 66.7 75.9 71.0

테이블 6: 섬 기반 결과

혼합어 식별은 특정 분야로 간주될 수 있습니다. 혼합어의 발생 빈도가 낮기 때문에 이 결과를 보는 것은 기쁩니다. 우리는 형태소의 혼합이 미연구 현상이라고 생각하기 때문입니다. 경험적 데이터가 필요한 언어학자와 인지과학자는 이와 같은 시스템을 통해 이러한 경우를 상당히 잘 감지할 수 있을 것입니다.
대부분의 범주에서 우리의 tsBERT 시스템이 다른 BERT 기반 모델보다 작지만 유의미한 개선이 있는 것을 보는 것은 좋습니다 (혼합어를 제외한 범주). 이는 TONGUESWITCHER 코드 스위칭 말뭉치로 사전 훈련을 한 것이 도움이 되었다는 것을 보여줍니다. 코드 스위칭 데이터로 훈련된 이 언어 모델은 우리와 관련 없는 독일어-영어 작업에도 다른 연구자들에게 유용할 수 있습니다.

7.1 섬들

지금까지 우리는 토큰 기반의 측정 결과를 제시해왔지만, 이는 코드 스위칭이 문맥에 민감한 현상임을 무시합니다. 우리는 전체적으로 어떤 언어의 토큰이 얼마나 있는지보다는 어떤 텍스트 자료가 섬을 형성하는지에 더 관심이 있습니다.
표 6은 섬과 짧은 섬에 대한 P, R 및 Fe의 결과를 제공합니다. 다시 말하지만, 두 개의 TS 시스템이 우세합니다.

모든 경쟁자와 기준선. Lingua는 멀리 뒤에 떨어져 있다. 섬에서의 TS의 성공은 대다수의 토큰이 문맥 없이 이 시스템에 의해 처리되기 때문에 놀라운 결과이다. 이 알고리즘의 단계 7(§4.2)은 인접한 토큰들의 레이블을 알려지지 않은 토큰에 할당함으로써 문맥적 평활화를 수행하는 것일 수 있다. 이는 일관된 섬을 선호함으로써 맞춤법 오류와 다른 단어 생성을 처리한다.
짧은 섬의 경우, tsBERT와 mBERT는 각각 Fe=71.0과 Fe=68.2로 공동 우승자이며, TS(65.8), GPT-4(60.4)와 Denglisch(61.3)를 이기고 있다. TS는 GPT-4보다 우수하다(p=0.02), 반면 GPT-4와 Denglisch는 구별할 수 없다. 한편, Lingua의 성능은 Fe=30.8로 좋지 않다. 우리는 Polyglot(Chen and Skiena, 2014)이 이 작업에 대해 비슷한 문제를 가질 것으로 의심한다. Denglisch(Osmelak and Wintner, 2023)는 모든 데이터에 대해 Polyglot을 필터링 도구로 사용하고 있으므로, Denglisch 말뭉치가 생성될 때 코드 스위칭의 짧은 섬의 많은 경우가 손실될 수 있다.

7.2 후분석: 언어 간 동음이의어

우리는 다음으로 시스템이 IHs에서 얼마나 잘 작동하는지 분석했습니다. 우리는 실제 IHs를 포함하는 트윗을 위해 별도의 작은 테스트 세트를 작성했습니다. 우리는 두 언어 중 덜 빈번한 언어의 빈도에 따라 이전의 IH 목록을 정렬한 다음, 각 언어의 각 단어에 대해 최대 100개의 트윗을 수동으로 확인했습니다. 다음과 같은 문제가 있는 경우 단어를 삭제했습니다: 단어가 한국어 또는 영어 중 하나 이상에서만 고유명사로만 등장한 경우 (예: 영어 "los").

Lingua의 저자들의 주장에 따라 우리는 Lingua가 Polyglot을 실험적으로 이기는 것으로 기반을 두고 있습니다 (GitHub 참조). 우리는 Polyglot의 성능을 검증하지 않았으며, 토큰 수준의 레이블을 예측할 수 없기 때문에 우리에게는 기준선으로 적합하지 않았습니다.

8
독일어 영어 전체
146   130  276

Lingua 70.9 55.7 64.9
GPT-4 92.8 92.0 92.4
Denglisch 74.9 72.0 73.6

eBERT 80.0 80.3 84.1
gBERT 85.4 81.5 83.7
mBRET 84.4 83.7 84.1

TS       84.5 82.8  83.7
tsBERT  89.3  89.1  88.8

테이블 7: IH 모호성 해소 결과 (Ft로 표시)

(3) 트윗: 나는 이화가 그것으로 어떤 것을 달성하려는지 이해하지 못한다.

문제 없어요. 작년 학기 평균 성적은 1.5였지만 이번 학기는 더 나빠질 거예요. 정신 건강 때문에요, 알잖아요.

테이블 8: 우리의 IH 테스트셋 예시

또는 그 단어는 독일어-영어 코드 스위칭에서 너무 드물어서 상위 100개 트윗에 나타나지 않았습니다 (예: 영어 "stark"). 우리는 적어도 하나의 진짜 영어와 독일어 사용이 있는 29개의 진짜 IH를 찾았습니다. 각 IH마다 2-10개의 트윗이 테스트 세트에 추가되었습니다. 독일어와 영어 발생 사이의 트윗을 균형있게 조정하려고 노력했으며, IH가 섬의 경계에 있는 예제를 우선으로 선택했습니다. 이로 인해 253개의 트윗과 276개의 IH 토큰으로 이루어진 테스트 세트가 생성되었으며, 이 중 47%가 영어로 구성되었습니다.
결과는 표 7에 제시되었습니다. IH의 경우, 우리의 규칙 기반 TS (전체 Ft=83.7)와 신경망 기반 tsBERT (전체 Ft=88.8)는 훈련된 Denglisch (전체 Ft=73.6)와 Lingua (전체 Ft=64.9)보다 우수한 성능을 보였습니다 (모든 Denglisch와 Lingua 결과는 다른 모든 시스템과 유의미하게 다릅니다). BERT 시스템의 경우, 모든 범주에서 eBERT는 mBERT와 구별할 수 없으며, mBERT는 gBERT와 구별할 수 없습니다. TS는 모든 범주에서 eBERT, gBERT 및 mBERT와 구별할 수 없습니다. 전체적으로와 독일어 토큰에 대해서도 tsBERT와 구별할 수 없습니다. GPT-4와 tsBERT는 모든 범주에서 구별할 수 없습니다 (p=0.21, 0.13, 0.08).
"강력한 기준"인 GPT-4와 우리의 신경망 시스템 tsBERT가 어려운 작업에서 가장 우수한 결과를 보여줍니다.

전쟁, 쓰레기통, 나쁜, 보다, 죽다, 남자, 만들어진, 달렸다, 요금,
떨어지다, 모자, 뚱뚱한, 드럼, 왼쪽, 여전히, 이러한, 빠른, 지옥, 편리한, 요새,
긍정적인, 태그, 현자, 보인다, 잃다, 럼, 할 것이다, 아니요

이러한 단어들의 의미를 명확히 하는 것에 대한 표입니다. 표 8은 IH 'was'에 대한 두 가지 예를 보여줍니다. 독일어에서는 이 문자열이 WH 대명사이지만, 영어에서는 'to be'의 과거형입니다. Lingua를 제외한 모든 시스템은 (3)을 독일어로 올바르게 식별합니다. 대조적으로, (4)의 IH를 영어로 식별하는 유일한 시스템은 GPT-4입니다.

8 결론

우리는 독일어-영어 코드 스위칭 식별을 위해 두 가지 방법을 제시했습니다. 우리의 규칙 기반 시스템은 우리에게 자연스러운 코드 스위칭의 가장 큰 말뭉치를 수집할 수 있도록 했습니다. 우리의 BERT 기반 모델은 이 말뭉치로 훈련되고 인간 주석 데이터로 세밀하게 조정되어 기존의 독일어-영어 벤치마크에서 SoTA를 성립했습니다. 우리는 또한 토큰 및 개체 기반 측정을 사용하여 새롭게 형성된 말뭉치에서도 SoTA를 성립했습니다. 상호언어 동형어에 대한 사후 분석에서는 신경 언어 모델이 이러한 단어들을 명확하게 구분하는 데 가장 우수한 시스템임을 확인했습니다. 전반적으로, 우리의 연구는 코드 스위칭의 미래에 중요한 두 가지 측면을 결합하고 있습니다: a) 자연스러운 데이터에서 대규모 경험적 방법의 사용과 b) 세밀한 언어 현상에 대한 분석적 관심.

9. 미래의 일

우리는 언어학, 어휘학 및 인지과학의 논쟁을 고려하여, 진정한 코드 스위칭과 대조되는 대출어의 보다 객관적인 정의를 제공하는 것에 관심이 있습니다. 우리가 이 주제에 대한 미래적인 기여는 구체적으로 섬-문맥에서만 구별이 가능하다는 사실에 중점을 둘 것입니다. 따라서 섬 탐지에 가장 적합한 도구를 사용하는 것이 유용하며, 우리는 여기서 독일어-영어 시스템이 매우 효과적임을 입증했습니다. 또한 빈도도 역할을 합니다. 독일어의 일부로 간주될 수 있는 대출어는 영어 섬에서 자연스럽게 발생하는 영어 단어보다 독일어 매트릭스 텍스트에서 훨씬 더 빈번하게 나타납니다. 우리는 TONGUESWITCHER 코퍼스의 각 섬 길이별 상위 10,000개의 섬에 대한 빈도로 정렬된 데이터를 공개합니다. 이는 이 도전에 대한 경험적 연구의 시작점으로 활용될 수 있습니다.

제한사항

우리의 골드 표준에는 TS에 의해 찾은 트윗의 사전 선택으로 인해 편향이 있을 수 있습니다. 앞으로는 주석 작업이 더 필요하더라도 완전히 새로운 골드 표준을 만들 계획입니다.

노력과 지침. 우리 현재의 정의는 주석 작업자의 직관에 너무 의존하고 있다.
우리와 같은 시스템의 평가는 또한 어렵다. 부분적으로 코드 스위칭 언어 식별은 주관적이기 때문이다. 특히, 주석 작업자와 NLP 시스템은 종종 영어 편향을 도입한다 (Anastasopoulos and Neubig, 2020; Garrido-Muñoz et al., 2021).
우리의 규칙 기반 시스템에서는 명명된 개체 인식기를 구현하지 않는다. 따라서 우리의 말뭉치에서 영어 단어를 포함한 명명된 개체는 종종 잘못된 레이블로 표시된다.
다국어 품사 태거의 품질과 토큰화도 우리의 방법을 제한한다. 이 태거를 사용하여 모든 입력 트윗에 태그를 지정하기 위해서는 고성능 GPU 계산이 필요했다.
혼합 식별 방법에 있어서, 우리의 TONGUESWITCHER 시스템은 단어를 과도하게 분할한다 (예: verrate), 이는 철자가 틀린 단어에 특히 문제가 된다.

윤리 성명

대규모의 소셜 미디어 게시물과 작업하고 공개하는 것은 데이터 개인정보 보호에 대한 우려를 불러일으킵니다. 저희는 트윗 작성자에 대한 개인정보를 수집하지 않습니다. 우리는 우리의 말뭉치를 연구 커뮤니티에만 공개합니다.

감사의 말씀

우리는 Alexander Bleistein과 Constanze Leeb에게 이 작업에 대한 초기 지원에 감사드립니다. 또한 Louis Cotgrove, Chris Bryant, Li Nguyen 및 우리의 세 명의 심사위원들께도 통찰력 있는 의견에 대해 감사드립니다.

참고문헌

마르틴 아다-데커, 토마스 펠레그리니, 에릭 비린스키,
그리고 질레스 아다. 2008. 자동 음성 처리 및 언어 연구를 위한 "Lëtze-
buergesch" 자원의 개발. 제6회 국제 언어 자원 및 평가 컨퍼런스 (LREC'08) 논문집, 마라케시, 모로코. 유럽 언어 자원 협회 (ELRA).

구스타보 아길라르와 타마르 솔로리오. 2020. 영어에서 코드 스위칭으로: 강력한 형태소 단서를 활용한 전이 학습. 제58회 연례 컴퓨터 언어학 협회 회의 논문집, 8033-8044쪽, 온라인. 컴퓨터 언어학 협회.

알란 악빅, 던컨 블라이스, 롤랜드 폴그라프. 2018년.
시퀀스 레이블링을 위한 문맥적 문자열 임베딩.

COLING 2018에서는 27번째 국제 컴퓨터 언어학 회의에서 1638-1649페이지를 발표하였습니다.

안토니오스 아나스타소푸로스와 그레이엄 뉴빅. 2020년.
모든 교차언어 임베딩은 영어로 말해야 할까요? 
계산언어학 협회 제58차 연례 회의 논문집, 8658-8679쪽, 온라인. 
계산언어학 협회.

크리스 비만, 게르하르트 헤이어, 우베 크바스트호프, 그리고 마티아스 리히터. 2007년. 라이프치히 코퍼스 컬렉션 - 표준 크기의 단일 언어 코퍼스. 코퍼스 언어학 프로시딩, 2007.

매트 비어너. 2022년. 어반 사전 목록. 원본 날짜: 2016-03-10T07:51:42Z.

Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The tiger treebank. In Proceedings of the workshop on treebanks and linguistic theories, volume 168, pages 24–41.

사비네 브란츠, 스테파니 딥퍼, 실비아 한센, 볼프강 레지우스, 그리고 조지 스미스. 2002년. 타이거 트리뱅크. 트리뱅크와 언어학 이론 워크샵 논문집, 168권, 24-41쪽.

톰 B. 브라운, 벤자민 맨, 닉 라이더, 멜라니 서비아, 제어드 카플란, 프라풀라 다리왈, 아르빈드 니라칸탄, 프라나브 샴, 기리쉬 사스트리, 아만다 애스켈, 산디니 아가르왈, 아리엘 허버트-보스, 그레첸 크루거, 톰 헤니건, 리원 차일드, 아디티아 라메시, 다니엘 M. 지글러, 제프리 우, 클레멘스 윈터, 크리스토퍼 헤세, 마크 첸, 에릭 시글러, 마테우시 리트빈, 스콧 그레이, 벤자민 체스, 잭 클락, 크리스토퍼 버너, 샘 맥캔디시, 알렉 라드포드, 일리야 숫크베르, 다리오 아모데이. 2020. 언어 모델은 페우-샷 학습자입니다. ArXiv:2005.14165 [cs].

Yanqing Chen과 Steven Skiena. 2014. 모든 주요 언어에 대한 감성 어휘집 구축. 연례 컴퓨터 언어학 협회 52차 대회 논문집(단문), 383-389쪽.

제이콥 코헨. 1960년. 명목 척도에 대한 일치 계수. 교육 및 심리 측정, 20(1):37-46.

딥셋AI. 2019. bert-base-german-cased · 허깅페이스.

마가렛 듀차. 2020. 언어학에서의 코드 스위칭: 위치 논문. 언어, 5(2):22. 번호: 2 출판사: 다학제 디지털 출판 기관.

제이콥 데블린, 민위 창, 켄튼 리, 그리고 크리스티나 투타노바. 2019년. BERT: 언어 이해를 위한 깊은 양방향 트랜스포머의 사전 훈련. 2019년 북미 협회 컴퓨터 언어학 회의 논문집: 인간 언어 기술, 1권 (장문과 단문), 페이지 4171-4186, 미니애폴리스, 미네소타. 컴퓨터 언어학 협회.

10
Ton Dijkstra, Jonathan Grainger, and Walter JB
Van Heuven. 1999. 동음이의어와 상호언어 동형어의 인식: 음운론의 간과된 역할. 기억과 언어, 41(4):496–518.

A. 세자 도, 스루즈, 수나야나 시타람, 바바라 E. 블록, 알메이다 자클린 토리비오. 2021. 코드 스위칭에 대한 조사: 언어 기술을 위한 언어 및 사회적 관점. 제59회 연례 협회 컴퓨터 언어학 및 제11회 국제 공동 자연 언어 처리 학회 논문집 (1권: 장문), 페이지 1654-1666, 온라인. 협회 컴퓨터 언어학.

루나 필리포비치와 존 A. 호킨스. 2019. 이중언어주의를 위한 복잡한 적응 시스템 원리 모델: 이중언어 주의자의 언어 상호작용. 이중언어 국제저널, 23(6):1223-1248.

W Nelson Francis와 Henry Kucera. 1964년. 디지털 컴퓨터와 함께 사용하기 위한 현대 편집된 미국 영어의 표준 말뭉치. 브라운 대학교, 프로비던스, 2.

이스마엘 가리도-무뇌스, 아르투로 몬테호-라에스, 페르난도 마르티네스-산티아고, 그리고 L. 알폰소 우레나-로페스. 2021년. 딥 NLP에서의 편향에 관한 조사. 응용 과학, 11(7):3184. 번호: 7 출판사: 다학제 디지털 출판 기관.

데이비드 W 그린과 주빈 아부탈레비. 2013. 이중언어 사용자의 언어 제어: 적응 제어 가설. 인지 심리학 저널, 25(5):515–530.

프랑수아 그로장과 핑 리. 2013. 이중언어의 심리언어학. 존 와일리 앤드 썬스.

프랑수아 그로장. 2010년. 이중언어: 삶과 현실.
하버드 대학 출판사.

요게시 구프타, 간샤얌 라구완시, 그리고 아프나 트리파티. 2021년. 소셜 미디어 코드믹스트 텍스트에서 언어 식별을 위한 새로운 방법론. AMLTA 2020의 고급 기계 학습 기술과 응용: 243-254쪽. 스프링거.

리처드 잭슨 해리스와 엘리자베스 마리 맥기 넬슨. 1992. 이중언어: 더 이상 예외가 아니다. 리처드 잭슨 해리스 편집, 이중언어 사용자의 인지 처리, 심리학 진전 시리즈 83권, 3-14쪽. 북홀랜드.

폴 헤메츠베르거. 2023년. dict.cc | 독일어-영어 사전.

아라빈드 K. 조시. 1982. 문장 내 코드 스위칭 처리. Coling 1982: 컴퓨터 언어학 국제 학회 제9회 회의록.

아르망 주랭, 에두아르 그라브, 피오트르 보야노프스키,
마티스 두제, 에르베 제고, 토마스 미코로프.
2016a. FastText.zip: 텍스트 분류 모델 압축.
arXiv 사전 인쇄 arXiv:1612.03651.

아르망 주랭, 에두아르 그라브, 피오트르 보야노프스키, 토마스 미코로프. 2016b. 효율적인 텍스트 분류를 위한 기교의 가방. arXiv 사전 인쇄 arXiv:1607.01759.

나네 크라츠케. 2022년. 독일어 월간 샘플 트윗. 10.5281/zenodo.7528718.

나네 크라츠케. 2023년. 독일어 월간 트윗 샘플. 10.5281/zenodo.7708787.

위저 린과 빌 번. 2022. 외부 지식을 활용한 검색 보강 시각적 질문 응답. ArXiv:2210.03809 [cs].

다우-청 류, 티엔-핑 탄, 엥 셩 청, 그리고 하이저우 리. 2010년. 동남아시아에서의 중국어-영어 코드 스위칭 음성 말뭉치인 Seame. 국제 음성 의사소통 협회 제11회 연례 회의에서 발표.

마누엘 마거, 오즐렘 체티노글루, 그리고 카타리나 칸.
2019년. 단어 내 코드 스위칭을 위한 서브워드 수준 언어 식별. ArXiv:1904.01989 [cs].

딥티 마베, 수라지 마하르잔, 그리고 타마르 솔로리오.
2018년. 언어 식별 및 코드 스위칭된 소셜 미디어 텍스트의 분석. 
제3회 언어 코드 스위칭에 대한 계산적 접근 방법 워크샵 논문집, 51-61쪽, 멜버른, 호주. 
계산언어학 협회.

이네스 몬타니와 매튜 혼니발. 2018. Prodigy: 극도로 효율적인 기계 교육을 위한 새로운 주석 도구. 인공지능.

P. Muysken. 2000. 이중 언어 발화: 코드 혼용의 유형학. 케임브리지 대학 출판사.

C. Myers-Scotton. 1997. 언어 대결: 코드스위칭에서의 문법 구조. 클라렌던 프레스.

라빈드라 나야크와 라비라지 조시. 2022. L3Cube-HingCorpus와 HingBERT: 코드 혼합된 힌디어-영어 데이터셋과 BERT 언어 모델. 제13회 언어 자원 및 평가 컨퍼런스 내 WILDRE-6 워크샵 논문집, 7-12쪽, 프랑스 마르세유. 유럽 언어 자원 협회.

동 너옌과 레오니 코르닙스. 2016. 단어 내 코드 스위칭의 자동 감지. 음성학, 음운학 및 형태론에 대한 컴퓨터 연구에 관한 14번째 SIGMORPHON 워크샵 논문집, 82-86쪽, 독일 베를린. 계산언어학 협회.

11
LiNguyenandChristopherBryant.2020. 캔베라 베트남어-영어 코드 스위칭 자연어 음성 말뭉치. 제12회 언어 자원 및 평가 컨퍼런스 논문집, 4121-4129쪽, 프랑스 마르세유. 유럽 언어 자원 협회.

리 누옌, 크리스토퍼 브라이언트, 사나 키드와이, 그리고 테레사 비베로. 2021년. 코드 스위치된 힌디어-영어 소셜 미디어 텍스트에서의 자동 언어 식별. 개방형 인문학 데이터 저널, 7:7.

온더월드맵. 2023년. 전 세계 도시 지도
| 전 세계 도시 목록을 알파벳 순으로 나열합니다.

OpenAI. 2023년. GPT-4 기술 보고서. _eprint: 2303.08774.

도린 오스멜락(Doreen Osmelak)과 쉬리 윈트너(Shuly Wintner). 2023년. 독일어-영어 코드 스위칭의 덴글리쉬 말뭉치. 5차 연구 워크샵 논문집: 계산 언어학적 유형학과 다국어 처리에 대한 연구, 42-51쪽, 크로아티아 두브로브니크. 계산 언어학 협회.

슬라브 페트로프, 디판잔 다스, 그리고 라이언 맥도널드. 2012년.
일반적인 품사 태그셋. 제8회 언어 자원 및 평가 국제 학회 (LREC'12) 논문집, 2089-2096쪽, 터키 이스탄불. 유럽 언어 자원 협회 (ELRA).

샤나 팝락. 1980년. 가끔 나는 문장을 스페인어로 시작하고 스페인어로 끝냅니다: 코드 스위칭에 대한 유형론을 향하여. 언어학, 18(7-8):581–618.

랜스 램쇼와 미치 마르커스. 1995년. 변환 기반 학습을 사용한 텍스트 청크 분석. 제3회 매우 큰 말뭉치 워크샵에서.

제이슨 리에사와 이반 주리아니. 2013년. 컴팩트 언어 감지기 2.

Shruti Rijhwani, Royal Sequiera, Monojit Choudhury, Kalika Bali, and Chandra Shekhar Maddila. 2017. 트위터에서의 코드 스위칭 추정에 대한 새로운 일반화된 단어 수준 언어 감지 기술. 2017년 협회 연구 논문집 55회 연례 회의, 1권, 1971-1982쪽, 캐나다 밴쿠버. 협회 연구 논문집.

유네스 사미, 수라지 마하르잔, 모하메드 아티아, 로라 칼메이어, 그리고 타마르 솔로리오. 2016년. LSTM 순환 신경망을 통한 다국어 코드 스위칭 식별. 제2회 코드 스위칭에 대한 계산적 접근 방법 워크샵 논문집, 50-59쪽, 텍사스 오스틴. 협회 계산언어학.

세바스티안 산티, 아니루드 스리니바산, 그리고 모노짓 초우드리. 2021. BERTologiCoMix: 코드믹싱이 다국어 BERT와 상호작용하는 방식은 어떻게 되는가? 제2회 자연어처리를 위한 도메인 적응 워크샵 논문집, 111-121쪽, 키예프, 우크라이나. Association for Computational Linguistics.

우베 자이델. 2010. 독일어에서의 영어 대출어의 사용과 통합: 1990년부터 2010년까지의 Der Spiegel 잡지를 기반으로 한 말뭉치 연구. 석사 논문, 앨라배마 대학교, 미국 - 앨라배마. ISBN: 9781124456560 출판물 제목: ProQuest Dissertations and Theses.

피터 M. 스타일. 2023년. pemistahl/lingua-py. 원본 날짜: 2021-07-13T09:52:34Z.

Jeanine Treffers-Daller. 2022. 대출과 코드 스위칭에 대한 단순한 관점. 이중언어학 국제저널. 출판사: 세이지.

크리스천 바르테나. 2019. 독일어 원형화를 위한 확률적 형태론 모델. 제15회 자연어처리 학회(KONVENS 2019) 논문집, 40-49쪽.

로빈 엘리스 와이스. 2022a. 상위 1,000개의 남자 아기 이름.
섹션: Verywell.

로빈 엘리스 와이스. 2022b. 상위 1,000개 여아 이름.
섹션: Verywell.

12
A  부록

알고리즘 단계별 코퍼스 예시

1 연구 책임자가 말합니다! 좀 더 연구해 보세요.
2 어떤 사람과 경기를 했는데, 난 그냥 무능해서 너의 a
모자를 쓴 남자, 전 해충

PR 매니저를 위한 3가지 승인 워크플로우입니다.

인스타그램과 트위터를 위한 다음 제품 강조.

4. 나는 지금 매우 플라토닉한 친구와 채팅 중이다.
5. 이사회는 지난 주말에 연례 업무 워크샵을 툰에서 개최했다.
6. 고마워, 나는 신경 뿌리 염증으로 세 번째 주를 견디고 있다. 강한 약물을 먹고 있지만 여전히 고통스럽다. 일부는 지옥에서 온 것 같은데, 물리치료는 괜찮다.
7. 요코는 아직도 축구에 대한 열정으로 무료로 살고 있다.

내 마음 속에는 얼마나 아름다운지

테이블 9: 각 단계별로 분류된 토큰의 예시

아무도 와서 나를 도와주지 않았다.
나는 한국 음식을 좋아한다.
나는 한국어를 배우고 싶다.
나는 한국에 가고 싶다.
나는 한국 문화에 관심이 많다.

2. 훈련 하이퍼파라미터

우리는 Devlin et al. (2019)에 의해 제시된 가려진 언어 모델링 목적을 사용합니다. 우리는 4개의 NVIDIA A100 GPU를 사용하여 약 30시간 동안 훈련합니다. 배치 크기는 32이며, 이는 191,950 단계에 해당합니다. 학습률은 1e-4를 사용하며, 10,000 단계의 워마업 후 선형 감소, β = (0.9, 0.999) 및 가중치 감소 = 0.01을 사용합니다.
분류를 학습하기 위해 우리는 학습률이 3e-5이고 배치 크기가 16이며 가중치 감소 = 0.01인 3개의 에포크 동안 훈련합니다.

A. 3 GPT-4 프롬프트

문장: {tweet} 작업: 다음 단어 목록과 레이블을 채워넣으세요. 문장의 각 단어를 영어('E'), 혼합어('M') 또는 독일어('G')로 식별하여 레이블을 지정하세요. 구두점은 주변 관련 단어와 동일한 언어여야 합니다. 혼합어는 단어 내에서 영어와 독일어를 전환합니다. 'E', 'M' 또는 'G' 태그만 사용하세요. 채워넣기: {token_1: '', token_2: '', ...}

우리는 출력된 JSON이 종종 잘못되거나 입력 토큰과 길이가 다른 것을 발견했습니다. 그러나 그런 경우에는 우리가 프롬프트를 반복했습니다.

13
언어 전환에 대한 계산적 접근 방식 워크샵 제6회 절차, 14-22페이지
2023년 12월 7일 ©2023 계산언어학 협회
혼용된 코드에 대한 실제 세계 스트리밍 음성 번역을 향하여

연설

벨렌 알라스트루이1 ∗, 마티아스 스퍼버2, 크리스티안 골란2,
도미닉 텔라르2, 팀 엔지2, 아시쉬 아가르과르2
1카탈루냐 공과대학교 TALP 연구센터, 바르셀로나

2사과
belen.alastruey@upc.edu, sperber@apple.com

요약

코드 스위칭 (CS)은 한 문장에서 다른 언어를 혼합하는 것으로, 커뮤니케이션에서 흔한 현상이며 자연어 처리(NLP) 설정에서 도전적일 수 있습니다. 이전의 CS 연구는 ST(음성 번역)에 대해 유망한 결과를 보여주었지만 오프라인 시나리오와 소스 언어 중 하나로의 번역에 한정되었습니다.

이 논문에서는 실제 세계의 CS 음성 번역에 대해 아직 탐구되지 않은 두 가지 중요한 영역에 초점을 맞추고 있습니다: 스트리밍 설정 및 제3 언어로의 번역 (즉, 원본에 포함되지 않은 언어). 이를 위해 Fisher 및 Miami 테스트 및 검증 데이터셋을 확장하여 스페인어와 독일어의 새로운 대상을 포함시켰습니다. 이 데이터를 사용하여 오프라인 및 스트리밍 ST 모델을 훈련시키고, 이전에 언급한 두 가지 설정에 대한 기준 결과를 수립합니다.

1 소개

음성 기술은 기계 학습의 주요 응용 분야 중 하나이며 현재 많은 실제 시나리오에서 사용되고 있습니다. 적절한 사용자 경험을 보장하기 위해 정확도 외에도 다른 요소들을 고려해야 합니다. 그 중 하나는 실시간으로 출력물을 생성할 수 있는 능력(스트리밍 설정)과 낮은 지연 시간을 가지는 것이고, 또 다른 하나는 코드 스위칭과 같은 말하기 언어의 독특한 특성을 효과적으로 처리하는 것입니다.
코드 스위칭(Code-switching)은 한 발화 내에서 여러 언어를 번갈아 가며 사용하는 현상입니다. 세계화로 인해 이는 이중언어 사용자뿐만 아니라 단일 언어 사용자들 사이에서도 점점 더 흔해지고 있습니다.
코드 스위칭은 자동 음성 인식(ASR), 기계 번역(MT), 음성 번역(ST)과 같은 다양한 자연 언어 처리(NLP) 설정에서 도전을 제공합니다.

애플 인턴십 기간 동안 수행한 업무.

두 개의 원본 언어를 다루는 내재적 복잡성과 CS 교육 및 테스트 데이터의 부족으로 인해 (Jose et al., 2020).
CS 음성 작업에 대한 ST의 관련성에도 불구하고, 해당 주제에 대한 기존 문헌은 상당히 제한적이다. Nakayama et al. (2019)은 단일 언어 전사라는 작업을 조사한다. 즉, 한 언어의 단어만을 사용하여 CS 발화를 전사하는 것이다. 따라서 CS인 단어를 번역한다. 그들의 연구는 일본어-영어 CS에서 명시된 작업을 평가하기 위해 다양한 접근 방식을 제안하고 비교한다. 다른 후속 연구들도 비슷한 접근 방식을 취한다 (2장 참조).
그러나 오늘날까지도 CS 원본에 없는 언어로의 번역이나 스트리밍 ST와 같은 일부 중요한 주제들은 탐구되지 않았다. 이는 실제 사용에 있어서 매우 중요하지만, 이러한 특성을 가진 데이터셋의 부재로 인해 그렇다. 또한, 스트리밍 환경에서는 지연 시간, 안정성 및 정확성 사이의 균형을 달성하는 것이 매우 중요하며, 이는 모든 스트리밍 작업과 마찬가지로 원활한 사용자 경험을 제공하기 위해 필수적이다. 게다가, 언어 혼합의 복잡성으로 인해 CS 작업은 단일 언어 작업보다 더 많은 문맥을 요구할 수 있다. 따라서 CS 스트리밍 ST에서 이러한 지표 사이의 트레이드오프를 다루는 것은 단일 언어 데이터와 비교하여 더 복잡할 수 있다.
우리의 연구에서는 두 가지 언급된 도전 과제를 해결한다. 첫째, 제3 언어로의 번역을 위한 데이터 및 결과의 부족함, 그리고 둘째, 스트리밍 CS ST에 대한 기준선의 부재. CS 작업에서 데이터 부족을 완화하기 위해, 우리는 Fisher (Cieri et al., 2004)와 Bangor Miami CS (Deuchar et al., 2014) 데이터셋을 확장한다 (영어와 스페인어 원본 및 영어 대상을 결합). 이러한 추가는 테스트 및 검증 세트에서 스페인어와 독일어 대상을 포함시킴으로써 가능하다.

https://github.com/apple/ml-codeswitching-translations에서 사용 가능한 데이터입니다.

14
우리의 모델의 성능을 평가하기 위해 우리에게는 단일 언어 전사 (영어 또는 스페인어로의 번역)뿐만 아니라 CS ST에서 세 번째 언어 (독일어)로의 번역도 포함되어 있습니다. 또한, 이 연구는 CS 음성에 대한 스트리밍 ST에 대한 첫 번째 연구이며, 오프라인 및 스트리밍 모델에 의해 생성된 전사에서의 오류를 고려하여 다른 지연 시간 및 깜박임 제약 조건 및 접두사 샘플링과 같은 다양한 훈련 기술을 고려합니다. 우리는 접두사 샘플링이 모델의 성능을 향상시키지 않으며, CS 포인트의 오류가 스트리밍 및 오프라인 ST에서 동일한 비율로 발생한다는 것을 보여줍니다. 우리의 연구는 기준 결과를 설정하고 CS의 영향을 다른 모델의 성능에 대한 통찰력을 제공하며, 분야의 발전에 기여할 수 있는 잠재적인 연구 포인트를 식별하는 데 도움이 됩니다. 요약하면, 우리의 연구의 주요 기여는 다음과 같습니다:

우리는 오프라인 설정에 초점을 맞춘 이전 연구와는 달리, CS 음성에 대한 스트리밍 ST의 기준 결과를 제공합니다.

우리는 이전 연구와는 달리, 단일 언어 전사에 초점을 맞춘 것과는 달리, CS ST를 제3 언어로 기준 결과를 제공합니다. 이를 위해 Fisher-Miami CS 데이터셋을 확장하여 스페인어와 독일어 대상을 추가합니다.

2 관련 연구

지난 몇 년 동안 CS 작업에 대한 관심이 증가하고 있습니다. 이전 연구는 MT에 초점을 맞추었습니다 (Sinha and Thakur, 2005; Winata et al., 2021; Zhang et al., 2021; Yang et al., 2020) 그리고 ASR에 초점을 맞추었습니다 (Lyu et al., 2006; Ahmed and Tan, 2012; Vu et al., 2012; Johnson et al., 2017; Yue et al., 2019). 그러나 ST에서의 CS 주제는 상대적으로 미개척되었으며 일반적으로 단일 언어 전사에만 집중하고 있습니다 (Nakayama et al., 2019; Hamed et al., 2022; Weller et al., 2022) 그리고 합성 생성 데이터에 의존하고 있습니다 (Nakayama et al., 2019; Huber et al., 2022).
CS ST에 대한 첫 번째 연구는 Nakayama et al. (2019)에 의해 수행되었습니다. 저자들은 일본어-영어 CS에서 영어 단일 언어 전사를 위한 다양한 아키텍처와 훈련 구성을 분석합니다.
Weller et al. (2022)은 다른 언어 쌍에서 유사한 작업을 제시합니다. 저자들은 자연스러운 영어-스페인어 CS 텍스트와 음성 소스, 그리고 영어 텍스트 대상을 가진 CS 데이터셋을 제시하며 Fisher 및 Bangor Miami 데이터셋에서 CS 문장을 수집합니다. 이러한 데이터를 사용하여 ASR과 평가할 수 있습니다.

트랜스포머
인코더

트랜스포머
디코더

또는

임베디드 텍스트 & 소스 태그

<src> +
<src> <한국어> <스페인어> <독일어>

말하기
인코더

그림 1: 제안된 모델 아키텍처. 다중 모달 인코더는 음성 번역 및 텍스트 번역 데이터에 대한 훈련을 지원합니다. 태깅 체계는 (코드 스위칭된) 대본 또는 (단일 언어의) 번역 중 하나를 생성할 수 있도록 설계되었습니다.

ST, 비록 ST 설정은 사실 단일 언어 전사입니다. 저자들은 두 단계의 훈련을 통해 다른 아키텍처를 탐구합니다: 비 CS 데이터에 대한 사전 훈련 및 CS 데이터에 대한 세밀 조정. 저자들은 엔드 투 엔드 ST 모델이 연속된 모델보다 더 높은 정확도를 얻으며, 세밀 조정 단계 후 CS 테스트 세트의 정확도가 비 CS 세트의 성능에 미치는 영향이 미미하다는 것을 발견합니다. 나중에 Hamed 등 (2022)은 이집트 아랍어-영어 CS 작업을 위한 말뭉치를 제시합니다. 이 데이터셋에는 텍스트 및 음성 CS 소스, 그리고 단일 언어로 된 영어와 이집트 아랍어의 대상이 포함되어 있습니다. 이러한 세트를 결합함으로써 저자들은 CS 음성에서 CS 텍스트로의 ASR (자동 음성 인식)뿐만 아니라 MT (기계 번역) 및 ST를 연구할 수 있습니다. 그러나 대상 언어 때문에 ST 및 MT 설정은 사실상 단일 언어 전사 및 이 작업의 텍스트 대 텍스트 변형입니다. 마지막으로, Huber 등 (2022)은 ST 및 ASR을 위한 언어 중립적인 모델인 LAST를 제시합니다. 이 모델은 음향 언어 ID 게이트 파이프라인을 고유한 CS 모델로 대체하기 위한 것입니다. 그러나 그들의 연구는 합성 데이터를 사용하여 문장 경계에서 CS가 발생하는 문장 간 CS에 초점을 맞추고 있습니다.

3 모델

학습에는 Ye et al. (2021)이 제안한 다중 모달 모델 디자인을 채택합니다 (그림 1). 이 모델은 음성 전사, 음성 번역 및 텍스트 번역을 지원하며, 다중 작업을 통해 세 가지 작업의 페어 데이터를 활용합니다.

15
훈련. Ye et al. (2021)과 유사하게, 우리는 사전 훈련된 wav2vec 2.0 BASE 모델 (Baevski et al., 2020)을 사용하여 음성 표현을 추출합니다. 이는 프레임당 20ms의 결과를 가져옵니다. 다운샘플된 음성 표현을 계산하기 위해 wav2vec 2.0은 3개의 합성곱 레이어로 구성된 스택을 적용하여 프레임당 160ms의 결과를 얻습니다. 각 레이어는 3의 커널과 2의 스트라이드를 가지고 있습니다. 다중 작업 텍스트 대 텍스트 훈련을 위해 텍스트 표현을 추출하기 위해 1024차원의 임베딩 레이어를 사용합니다. 그 다음으로, 사전 정규화, 1024의 숨겨진 차원, 0.1의 드롭아웃, 5개의 인코더 레이어와 3개의 디코더 레이어를 가진 인코더-디코더 트랜스포머 (Vaswani et al., 2017)를 연결합니다. 인코더의 입력은 다운샘플된 음성 표현 또는 임베딩된 소스 텍스트입니다. 디코더에서는 자기 어텐션 대신 1024차원의 LSTM (Hochreiter and Schmidhuber, 1997)을 사용하여 초기 조사에서 더 좋은 결과를 얻었습니다.
모델은 다중 작업 방식으로 훈련되며, 전사 작업, 텍스트 번역 작업, 음성 번역 작업의 손실과 전체 인코더 위에 적용된 CTC 손실 (Graves et al., 2006)을 합산합니다. 작업은 동등하게 가중치가 부여됩니다.
우리의 작업에 중요한 점은 번역 또는 전사를 수행하기 위해 공유된 디코더를 사용하며, 원하는 ST 출력 언어를 나타내는 언어 태그 또는 <src> 태그를 사용하여 전사를 생성합니다. 전사는 단일 언어 문장의 번역과 동등하지만, CS 문장을 고려하기 위해 전사에 대한 특수 토큰이 필요합니다.
스트리밍 환경에서 모델을 사용하기 위해 재번역 기술 (Niehues et al., 2018; Weller et al., 2021)을 사용합니다. 이 기술은 추가 정보가 수신됨에 따라 이전 예측을 업데이트하기 위해 문장을 재번역합니다. 지연 시간, 깜빡임 및 정확도 사이의 균형을 조절하기 위해 이전 예측의 마지막 k개의 하위 단어에 마스크를 설정하여 모델이 출력의 해당 부분만 다시 작성할 수 있도록 합니다. 따라서, 높은 k는 모델이 전체 예측을 다시 작성할 수 있게 하여 높은 정확도를 얻지만 지연 시간과 깜빡임 점수가 낮아지게 합니다. 반대로, k = 0으로 설정하면 모델은 이전 예측에 집중하여 정확도가 저하되지만 깜빡임이 없고 가능한 최소의 지연 시간을 가집니다. Section 5에는 적절한 k를 얻기 위한 실험이 포함되어 있습니다.

구체적으로, 페이스북/wav2vec2-base-960h
Hugging Face Transformers를 통해 (Wolf et al., 2020).

4 데이터 세트

사전 훈련

데이터셋 언어 출처 #샘플

MuST-C
한국어로 번역해주세요.

원래 234,000입니다.

CoVoST
Es-En  원본 64,351

De-Ko  Original 71 831

En-Ko  Original 232 958

Es-De 합성 64 351

De-Es 합성 71 831

피셔 Es-En 오리지널 130 600

마이애미 Es-En 오리지널 6,489

세밀한 조정

데이터셋 언어 출처 #샘플

피셔

En/Es-Es 합성 7 398

인공 합성 7 398

표 1: 우리의 두 단계 훈련 중 사용된 훈련 데이터 요약.

주요 대상은 CS 연설이지만, 후자의 부족으로 인해 우리는 단일 언어 및 CS 데이터 모두에서 모델을 훈련시킵니다. 특히, 우리는 다음 데이터셋을 사용합니다.

방고르 마이애미 (Deuchar et al., 2014): 이 데이터셋은 비공식적인 환경에서 양언어 사용자들 간의 기록된 대화를 포함하고 있으며, 자연스러운 코드 스위칭 발화의 높은 비율을 가지고 있습니다. 녹음은 벨트에 착용된 작은 디지털 녹음기를 사용하여 이루어졌으며, 이로 인해 배경 소음과 함께 낮은 오디오 품질을 가지고 있습니다. 우리는 Weller et al. (2022)에 의해 정의된 CS ST 분할을 사용합니다.

피셔 (Cieri et al., 2004): 이 데이터셋은 미국과 캐나다에 거주하는 스페인어 사용자들을 전화 통화를 통해 짝지어 ASR을 위해 수집되었습니다. 이는 CS에 초점을 맞춘 데이터셋은 아니지만, 영어를 사용하는 맥락에서 발화되어 CS 발화의 상당한 양을 포함하고 있습니다. 녹음은 2004년에 전화 녹음을 통해 이루어졌으며, 이는 노이즈가 있는 ASR 데이터셋이지만, 마이애미보다는 덜 노이즈가 있습니다. 우리는 Weller et al. (2022)에 의해 정의된 CS ST를 위해 분할을 사용합니다.

16
CoVoST (Wang et al., 2020): 공통 음성 프로젝트 (Ardila et al., 2020)를 기반으로 한 다국어 및 다양한 ST 데이터셋입니다. 이 데이터셋은 여러 언어에서 영어로의 언어 쌍을 포함하며, 저자원 언어도 포함됩니다.

MuST-C (Di Gangi et al., 2019): ST 연구를 위한 데이터셋입니다. 이는 영어 TED Talks에서의 음성 녹음과 해당하는 인간의 전사 및 번역을 포함한 대규모, 다국어 데이터셋입니다. 이 데이터셋은 영어에서 여러 언어로의 번역을 다룹니다. 녹음 컨텍스트 (TED Talks)로 인해 품질이 좋은 깨끗한 데이터셋입니다.

4.1 데이터 수집

마이애미와 피셔 CS 세트는 CS En/Es에서 소스로 구성되어 있으며, CS 대본과 단일 언어 영어 대본을 대상으로 합니다. 포함되는 언어의 범위를 확장하기 위해, 우리는 단일 언어 스페인어 대본과 소스에서 사용되지 않은 새로운 언어인 독일어를 포함합니다. 이 새로운 언어를 포함함으로써, 우리는 모델의 성능을 순수한 음성 번역에서 이전의 단일 언어 대본 작업과 대조하여 평가할 수 있게 됩니다. 따라서, 우리는 마이애미와 피셔 CS 테스트 및 검증 세트의 데이터를 독일어와 스페인어로 수집합니다. 해당 데이터는 각각의 대상 언어의 모국어를 사용하는 전문 번역가에 의해 번역되었습니다.

4.2 데이터 사용 및 준비

(Weller et al., 2022)에 따르면, 우리는 실험을 두 단계로 나눕니다: (1) 단일 언어 데이터에 대한 사전 훈련, 그리고 (2) 코드 스위칭 데이터에 대한 세밀 조정.
사전 훈련 단계에서는 CoVoST (Es-En, De-En, En-De 분할), MuST-C (En-Es, En-De 분할) 및 Fisher 및 Miami 데이터 세트의 비 코드 스위칭 세트 (Es-En)를 사용합니다. 추가로, 우리는 Hugging Face Transformers 패키지의 MarianMT 3 모델 (Wolf et al., 2020)을 사용하여 CoVoST De-En 세트를 스페인어로 번역하고, Es-En 세트를 독일어로 번역하여 Es-De 및 De-Es 쌍의 데이터를 얻습니다. 세밀 조정 단계에서는 Fisher의 코드 스위칭 (Es/En-En) 훈련 세트 (7389개 샘플)에 초점을 맞추고, MarianMT 모델을 사용하여 영어 대상을 독일어와 스페인어로 번역하여 Es/En-Es 및 Es/En-De 번역을 확장합니다.
사전 훈련 단계에는 200 에포크를 사용하고, 세밀 조정에는 100 에포크를 사용합니다. Adam을 사용합니다.

우리는 번역을 수동으로 정리합니다.

(Kingma와 Ba, 2015) 옵티마이저 α = 5e −4, β1=0.9, β2=0.98를 사용합니다. 사전 훈련에는 500개의 웜업 단계를 가진 역 제곱근 학습 일정을 사용합니다. 세부 조정에는 12.5%의 웜업 단계, 12.5%의 유지 단계 및 75%의 감소 단계를 가진 삼단계 일정을 사용합니다.

접두사 샘플링 실험을 위해 우리는 동일한 훈련 세트를 사용하지만 Niehues 등이 제시한 방법을 따라 절반의 인스턴스를 접두사 샘플링합니다. 각 단계에서 사용된 데이터에 대한 요약은 표 1을 참조하십시오.

5 실험

우리의 실험은 네 가지 주요 방향을 따릅니다: (1) 다시 번역의 깜빡임과 지연을 제어하기 위한 합리적인 k 찾기, (2) CS 전환 지점 주변에서의 오류 발생 연구, (3) 접두사 샘플링의 유용성 분석, (4) 제3 언어로의 번역 및 CS 음성에 대한 스트리밍 작업을 위한 기준 숫자 설정, 이는 전사, 단일 언어 번역 및 번역을 포함합니다.

우리의 모델을 평가하기 위해 세 가지 다른 지표를 사용할 것입니다. 모델의 정확도를 측정하기 위해 BLEU (Papineni et al., 2002)와 SACREBLEU (Post, 2018)를 사용하며, 빔 크기는 5로 설정합니다. 모델 입력과 출력 사이의 지연을 평가하기 위해 평균 지연 (AL, Ma et al. (2019))을 사용하고, 깜빡임을 측정하기 위해 정규화된 삭제 (NE, Arivazhagan et al. (2020))을 사용합니다. 추가적으로, ASR 성능을 평가하기 위해 WER을 사용합니다.

5.1 메트릭 트레이드오프와 k 분석

물리 2장에서 설명한 대로, 우리의 모델은 재번역(Niehues et al., 2018)을 사용하여 스트리밍 출력을 생성합니다. 재번역 접근 방식을 따라서, 우리는 다음 단어를 예측할 때 출력의 마지막 k개의 하위 단어를 가리고(mask) 있습니다. 우리는 k∈{0,5,10,15,20,25,30,+ ∞}에 대한 지연 시간, 깜빡임(flickering) 및 정확도 지표를 평가합니다. 그림 2에서 보여지듯이, 결과는 Fisher와 Miami 데이터셋에서 일관성이 있으며, 다른 언어 쌍에서도 동일합니다. 모든 지표는 k와 함께 증가합니다. 그러나 30과 + 사이의 간격은

∞
AL과 NE에서는 BLEU보다 훨씬 높습니다. BLEU는 k가 높을수록 개선되지만 다른 지표보다 안정적입니다. 이러한 이유로 우리는 앞으로 k = 15를 사용합니다. BLEU 점수는 최적에 가깝지만 NE와 AL은 아직 낮기 때문입니다.

17
그림 2: 다른 스트리밍 제약 조건에서의 BLEU, 정규화된 삭제 및 평균 지연 점수. 각 예측 단계에서 모델은 마지막 k개의 토큰 (하위 단어)을 제외한 이전 예측에 대해 확정해야 합니다. 우리는 모델의 성능을 k에 대해 평가합니다.

∈
{0,5,10,15,20,25,30,+ ∞}.

∈
{0,5,10,15,20,25,30,+ ∞}.

피셔            마이애미
컴퓨터 과학      모노.     컴퓨터 과학      모노.
모델              영어 스페인어 독일어   영어 독일어  영어  스페인어 독일어  영어  독일어

BLEU( ↑)
피셔 CS     23.3 30.3 12.2 22.9 12.8 19.7 16.0 6.4 11.9 5.9
피셔 CS 접두사 포함 23.7 30.9 12.2 22.0 13.0 22.1 18.3 7.0 13.9 6.7
(웰러 외, 2022)

25.6 - 26.1 - 14.7 - 17.6 -

AL( ↓)
피셔 CS      0.6 0.5 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3
접두사가 있는 피셔 CS 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.4 0.4

NE( ↓)
피셔 CS      1.2 1.2 1.3 1.1 1.4 1.2 1.2 1.4 1.0 1.2
접두사가 있는 피셔 CS 1.2 1.0 1.2 1.2 1.0 1.0 1.0 1.1 1.6 0.8

표 2: 스트리밍 음성 번역에서의 BLEU, 평균 지연 시간(초) 및 정규화된 삭제 점수, 접두사 샘플링을 사용한 훈련과 그렇지 않은 훈련에 대한 결과입니다. 모든 실험에서 k = 15로 설정했습니다. †: Weller 등이 (2022)에서 오프라인 ST에서 보고한 최상의 결과입니다.

5.2 코드 스위치와 예측 오류

우리는 CS 포인트가 언어적 불확실성이 높은 포인트라고 가정하며, 따라서 예측하거나 번역하기가 상대적으로 어렵다고 가정합니다. 따라서, CS 스위치 포인트 주변의 단어들은 잘못 예측될 가능성이 높을 것입니다. 이러한 현상을 ASR 작업에서 오프라인 및 스트리밍 모델을 비교하여 분석하고, (1) CS 포인트 주변에서 더 많은 잘못된 예측이 발생하는지 확인하거나 부정하는 것, (2) 오프라인 또는 스트리밍 ST가 (1)의 결론에 어떤 영향을 미칠 수 있는지 연구합니다.
우리는 Fisher CS 테스트 세트에서 ASR 4 작업의 예측된 트랜스크립트를 세 가지 다른 추론 제약 조건으로 분석합니다: 플리커링이 없는 k = 0의 스트리밍 모델과 오프라인 모델.

이는 ASR에서만 평가할 수 있으며(ST가 아닌), CS 대상의 필요성 때문입니다.

가장 낮은 가능한 지연 시간을 가진 스트리밍 모델로 k = 15를 선택하였으며, 이는 깜빡임과 지연에 큰 영향을 주지 않으면서 더 나은 정확도를 얻기 위한 합리적인 선택으로 판단되었습니다. 또한 오프라인 모델도 고려하였는데, 이는 k = + ∞인 스트리밍 모델과 동등합니다. 우리는 리콜 기반 지표를 설정하고, 참조 트랜스크립트에서 단어를 세어 예측된 트랜스크립트에 해당 단어가 나타나면 정확하게 예측된 것으로 간주하고, 그렇지 않으면 잘못 예측된 것으로 간주합니다. 우리는 정확하게 예측된 단어의 비율과 해당 단어들이 CS 지점과의 거리(단어로 측정)를 연구합니다. 따라서 거리가 1인 단어는 CS의 바로 앞이나 뒤에 위치한 것이며, 이와 같은 식으로 계속해서 거리를 측정합니다. 이를 위해 우리는 거리 d에서의 리콜을 다음과 같이 정의합니다:

R(d) = R(d) =

올바른 예측(d)
올바른 예측(d) + 잘못된 예측(d)

(1) 저는 한국에 살고 있어요.

18
피셔             마이애미
컴퓨터 과학       단일.     컴퓨터 과학       단일.
모델             영어  스페인어 독일어  영어 독일어  영어  스페인어 독일어  영어  독일어

BLEU( ↑)
피셔 CS     41.8 45.8 24.27 35.5 23.7 49.4 41.8 19.9 31.7 19.5
피셔 CS 접두사 포함 41.8 44.1 22.9 35.7 22.5 48.1 38.7 19.1 32.2 18.9

AL( ↓)
피셔 CS      0.4 0.4 0.4 0.4 0.4 0.2 0.2 0.2 0.2 0.2
접두사가 있는 피셔 CS 0.4 0.4 0.4 0.4 0.4 0.2 0.2 0.2 0.2 0.2

NE( ↓)
피셔 CS     0.06 0.04 0.06 0.04 0.04 0.00 0.00 0.00 0.00 0.00
접두사가 있는 피셔 CS     0.04 0.04 0.06 0.04 0.04 0.00 0.00 0.00 0.00 0.00

테이블 3: 프리픽스 샘플링을 사용한 훈련과 사용하지 않은 훈련에서의 스트리밍 텍스트 번역의 BLEU, 평균 지연 시간(초) 및 정규화된 삭제 점수입니다. 모든 실험에서 k = 15로 설정했습니다.

1 2 3 4 5 6 7 8 9 10
단어로 된 CS까지의 거리
0.0
0.2
0.4
0.6

리콜

스트리밍 k = 0

스트리밍 k = 15

오프라인 (k = 무한대)

그림 3: 다른 추론 제약 조건 하에서 CS 지점과의 거리에 따른 단어 예측 오류 분석.

그림 3의 결과는 CS 포인트가 모델의 정확도에 영향을 미친다는 것을 보여줍니다. 모든 모델에서 거리가 1인 단어들은 가장 높은 비율로 잘못 예측됩니다. 그러나 d = 2부터는 재현율이 약간만 증가하거나 거의 일정한 수준을 유지하므로 CS의 영향은 오래 지속되지 않습니다. 둘째로, 우리는 k = 0인 스트리밍 설정이 전반적으로 재현율이 더 낮지만, 예측을 할 때 사용 가능한 문맥이 가까운 CS 포인트에 더 큰 영향을 미치지 않는다는 것을 알 수 있습니다. 특히, k = 0인 스트리밍 모델에서 d = 2와 d = 1 사이의 감소가 더 낮다는 것을 볼 수 있습니다. 이는 우리가 예상한 것과는 달리, 스트리밍 ST에서 문맥의 부족이 CS 포인트에 부정적인 영향을 미치지 않으며, 따라서 모델은 CS 또는 CS가 아닌 단어를 올바르게 예측하기 위해 동일한 문맥이 필요하다는 것을 나타냅니다.

5.3 접두사 샘플링의 유용성

기술적으로 스트리밍 모델을 훈련시키기 위해 자주 사용되는 기법은 훈련 데이터의 일부에서 접두사를 샘플링하는 것이다. 우리는 이를 사용하는 것이 어떤 영향을 미치는지 연구한다.

1 2 3 4 5 6 7 8 9 10
단어로 된 CS까지의 거리
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7

리콜

표준 훈련

접두사 훈련

그림 4: CS 지점과의 거리에 따른 단어 예측 오류 분석, 훈련 세트에 접두사 샘플링을 사용한 경우와 그렇지 않은 경우.

정확도, 지연 시간 및 깜빡임 측정에서의 기술과 그것이 CS 포인트 주변의 오류에 미치는 영향.

이 훈련 전략의 유용성을 분석하기 위해, 우리는 Fisher CS 세트로 훈련된 모델과 동일한 세트에서 절반의 완전한 발화를 접두사로 대체한 모델을 비교합니다. 표 2에서 보여지듯이, 접두사 샘플링은 BLEU 점수를 향상시켰으며, 특히 Miami 테스트 세트에서 (+2.4까지) 큰 향상을 보였습니다. 놀랍게도, 이 지연 또는 깜박임 성능을 향상시키기 위한 훈련 전략은 평균 지연 점수를 악화시키고, 정규화된 지움에는 유의미한 영향을 미치지 않습니다.

뿐만 아니라, 우리는 접두사 샘플링이 CS 포인트 주변의 예측 정확도에 영향을 미치는지에 대해 연구합니다. 그림 4에서는 섹션 5.2에서와 같은 리콜 지표를 사용하여 두 모델을 비교합니다. 우리는 접두사 훈련이 CS 포인트 주변의 예측 정확도를 저하시킨다는 것을 알 수 있습니다. 특히 거리가 1인 단어들에서는 표준 훈련의 리콜이 0.51에서 접두사 훈련의 0.45로 떨어집니다.

19
피셔 마이애미
모델          CS 모노  CS 모노

WER( ↓)
피셔 CS     34.9 29.8 63.3 63.5
접두사가 있는 피셔 CS 35.4 29.9 60.6 58.1

AL( ↓)
피셔 CS      1.0  0.8 0.8 0.6
접두사가 있는 피셔 CS 0.5 0.4 0.5 0.3

NE( ↓)
피셔 CS      1.2  1.0 1.2 1.1
접두사가 있는 피셔 CS 1.1 0.8 1.2 0.6

테이블 4: 스트리밍 자동 음성 인식에서 WER, 평균 지연 시간(초) 및 정규화된 삭제 점수,
접두사 샘플링을 사용한 훈련과 사용하지 않은 훈련에 대한 결과입니다. 모든 실험에서 k = 15로 설정했습니다.

5.4 성능 분석

이전 섹션에서 설명한 실험 후에 접두사 샘플링을 사용하는 것은 성능 향상을 가져오지 않는 것으로 발견되었습니다. 또한, 문장 번역 중 각 단계에서 마지막 15개의 하위 단어를 가리는 것이 다양한 평가 지표 간에 최적의 균형을 보여준다는 것을 확인했습니다. CS 스트리밍 ST에 대한 이전 연구가 없기 때문에 우리의 결과를 이전 연구와 공정하게 비교할 수 없으므로 기준 숫자를 설정하기 위해 노력하고 있습니다. 그러나 우리는 오프라인 ST에서 영어로의 BLEU 점수를 (Weller et al., 2022)의 점수와 비교하여 오프라인과 스트리밍 ST 간의 성능 하락이 합리적인지 분석합니다. 예상대로, 우리의 스트리밍 모델은 이전 연구의 오프라인 모델과 비교하여 대부분의 테스트 세트에서 성능 저하가 있습니다. 그러나 Miami 데이터셋의 CS ST에서 영어로의 번역은 최대 +7.4 BLEU의 개선을 얻습니다. 

독일어 번역의 성능을 분석할 때, 영어와 스페인어 번역과 비교하여 중요한 성능 하락이 있음을 알 수 있습니다 (원문에 모두 포함되어 있음). CS 음성 번역은 일반적으로 원본에 포함된 언어로만 번역하여 연구되고 평가되므로 독일어에서의 성능 하락은 CS ST에서 단일 언어 전사에만 의존하지 않는 것의 중요성을 보여주는 중요한 발견이라고 생각합니다. 또한, 이는 제3 언어로의 번역을 위한 추가 연구를 위한 기준 결과를 설정합니다. 평균 지연과 정규화된 삭제에 대한 성능은 Fisher 및 Miami 데이터셋을 사용한 이전 작업에서 기준으로 제시합니다. 그러나 이러한 지표에서 우리 모델의 품질을 추정하기 위해 MuST-C 데이터에서 Weller et al. (2021)의 점수와 비교합니다. 표 2에서 우리는 유사한 점수를 얻는 것을 볼 수 있으므로, 우리는 우리 모델의 성능이 충분히 좋다고 결론지을 수 있습니다.

모델은 깜빡임과 지연에 대해 합리적입니다.

5.5 기계 번역 및 자동 음성 인식 결과

이 작업의 주요 범위는 음성 번역이지만, 우리는 기계 번역과 자동 음성 인식에 대한 모델을 평가합니다. 우리는 모델이 멀티태스크이며 입력 유형을 전환하고 출력을 생성하기 위해 태그를 적절하게 정의할 수 있기 때문에 이를 쉽게 수행할 수 있습니다.

표 3에서는 MT에 대한 결과를 확인할 수 있습니다. 우리는 ST와 마찬가지로 접두사 샘플링이 AL과 NE 점수를 향상시키지 않는 것을 알 수 있습니다. 게다가, MT의 경우 접두사를 사용하면 대부분의 모델의 성능이 저하됩니다. BLEU 점수에 관해서는, 우리는 ST와 마찬가지로 소스 언어로 번역하는 작업이 독일어로 번역하는 작업보다 훨씬 높은 정확도를 얻는 것을 관찰합니다.

표 4에서는 ASR 설정에 대한 결과를 볼 수 있습니다.
이 경우, 접두사 샘플링은 AL과 NE 점수에 대해 예상대로 작동합니다.
접두사를 가진 모델들이 점수가 낮은 모델들입니다. 그러나 여전히 모델의 성능에 부정적인 영향을 미칩니다.
특히 Miami 테스트 세트에서 그 영향이 큽니다.
WER에 대해서는 Miami 데이터셋의 점수가 Fisher 데이터셋의 점수보다 훨씬 나쁩니다.
번역 작업에서는 이러한 패턴을 관찰하지 못했습니다.
이는 사전 훈련 중 번역 작업에 사용된 데이터가 여러 다른 데이터셋에서 나온 것이기 때문에 모델이 적절하게 일반화를 학습할 수 있었기 때문일 수 있습니다.
그러나 CS 타겟을 가진 사용 가능한 데이터는 주로 Fisher 데이터셋(130,600개 샘플)에 해당하며, Miami 데이터셋에서는 단지 6,487개의 샘플만 사용할 수 있습니다.
데이터 분포에 대한 자세한 내용은 표 1을 참조하십시오.

20
6 결론

이 작업에서는 CS ST에서 두 가지 개방된 문제를 다루었습니다: 제3 언어로의 번역과 스트리밍 설정. 이를 위해 우리는 CS 음성의 직접 번역과 전사를 위해 오프라인 및 스트리밍 모델을 훈련시켰습니다. 또한, 우리는 Fisher 및 Miami 테스트 및 검증 세트를 새로운 스페인어 및 독일어 대상으로 확장했습니다. 이를 통해 우리는 단일 언어 전사뿐만 아니라 순수 번역도 분석할 수 있었습니다. 우리는 두 가지 설정 사이에서 최대 18 BLEU 점의 하락을 관찰했으며, 이는 이전 연구에서 일반적으로 수행되던 단일 언어 전사에 의존하지 않는 것의 중요성을 보여줍니다. 제3 언어로의 번역은 단일 언어 번역에 비해 더 복잡하기 때문에 정확도 하락을 해결하기 위해 추가 데이터를 통합하는 것이 필요하다고 생각합니다. 그러나 자연스러운 코드 스위칭 데이터는 제한적이며, 합성 데이터 생성은 이 연구의 범위를 벗어나므로 이를 향후 연구에 남겨둡니다.
요약하면, 우리의 작업은 CS의 영향에 대한 깊은 분석과 스트리밍 CS 음성 번역 및 제3 언어로의 번역에 대한 결과를 제시하며, 이는 아직 해결되지 않은 분야에서 향후 작업의 기준이 될 수 있습니다.

제한사항

우리의 작업은 영어, 독일어, 스페인어와 같은 고자원 언어에 한정되어 있습니다. 따라서 실제 세계의 컴퓨터 과학 번역을 달성하기 위해 저자원 언어에 대한 추가 작업이 필요합니다.

참고문헌

Basem HA Ahmed와 Tien-Ping Tan. 2012. 1-최상의 재점수화를 사용한 코드 스위칭 음성의 자동 음성 인식. 2012 국제 아시아 언어 처리 학회에서 발표된 논문, 137-140쪽. IEEE.

로자나 아디라, 메간 브랜슨, 켈리 데이비스, 마이클 코러, 조시 메이어, 마이클 헨레티, 루벤 모라이스, 린지 산더스, 프란시스 타이어스, 그레고르 베버. 2020년. Common voice: 대규모 다국어 음성 말뭉치. 제12회 언어 자원 및 평가 컨퍼런스 논문집, 4218-4222쪽, 프랑스 마르세유. 유럽 언어 자원 협회.

나비인 아리바자간, 콜린 체리, 볼프강 마헤리, 그리고 조지 포스터. 2020년. 재번역

동시 번역을 위한 스트리밍 대비. arXiv
미리 인쇄된 논문 arXiv:2004.03643.

알렉세이 바예프스키, 유하오 조우, 압델라만 모하메드, 그리고 마이클 아울. 2020. wav2vec 2.0: 음성 표현의 자기 지도 학습을 위한 프레임워크. Advances in Neural Information Processing Systems에서 발표된 논문, 33권, 12449-12460쪽. Curran Associates, Inc.

크리스토퍼 시에리, 데이비드 밀러, 그리고 케빈 워커.
2004년. 피셔 말뭉치: 다음 세대의 음성 인식을 위한 자원. 제4회 언어 자원 및 평가 국제 학회 (LREC 2004) 논문집, 4권, 69-71쪽.

마가렛 듀차, 페레더 데이비스, 존 러셀 헤링, M 카르멘 파라피타 쿠토, 그리고 다이애나 카터. 2014년. 이중언어 말뭉치 구축. 이중언어 연구의 진전, 93-110쪽. 멀티링구얼 매터스.

마티아 A. 디 강기, 롤다노 카토니, 루이사 벤티보글리, 마테오 네그리, 그리고 마르코 투르키. 2019년. MuST-C: 다국어 음성 번역 말뭉치. 2019년 북미 협회 컨퍼런스 논문집: 인간 언어 기술, 제1권 (장문 및 단문 논문), 페이지 2012-2017, 미네소타 주 미니애폴리스. 컴퓨터 언어학 협회.

알렉스 그레이브스, 산티아고 페르난데스, 그리고 유르겐 슈미트휴버. 2006. 연결주의 시간 분류: 순환 신경망을 사용하여 세분화되지 않은 순차 데이터에 레이블 지정하기. 제23회 국제 기계 학습 컨퍼런스 논문집, 369-376쪽. ACM.

인지 하메드, 니자르 하바시, 슬림 압덴나더, 그리고
옹 통 부. 2022. Arzen-st: 코드 스위칭된 이집트 아라비아어-영어를 위한 삼방향 음성 번역 말뭉치. arXiv 사전 인쇄 arXiv:2211.12000.

셉 호크라이터와 유르겐 슈미트후버. 1997년. 장단기기억. 신경계산, 9(8):1735-1780.

크리스천 후버, 에네스 야부즈 우간, 알렉산더 와이벨. 2022년. 스위칭 없는 코드 스위칭: 언어 중립적인 엔드 투 엔드 음성 번역.

멜빈 존슨, 마이크 슈스터, 꽉 브이 레, 막심 크리쿤, 용희 우, 지펑 천, 니킬 토랏, 페르난다 비에가스, 마틴 와텐버그, 그렉 코라도, 맥더프 휴즈, 그리고 제프리 딘. 2017년. 구글의 다국어 신경망 기계 번역 시스템: 제로샷 번역 가능하게 함. 연구논문, 5:339-351.

네이비아 호세, 바라티 라자 차크라바르티, 샤르둘 수리완시, 엘리자베스 셜리, 그리고 존 P 맥크레이. 2020년. 코드 스위칭 연구를 위한 현재 데이터셋 조사. 2020년 제6회 국제 고급 컴퓨팅 및 통신 시스템 컨퍼런스(ICACCS) 논문집, 136-141쪽. IEEE.

21
디에더릭 P. 킹마와 지미 바. 2015. Adam: 확률적 최적화를 위한 방법. 학습 표현에 대한 국제 학회.

대우 청, 렌 위안 청, 유앙친 치앙, 그리고 춘난 슈. 2006. 중국어 방언 간의 코드 스위칭에 대한 음성 인식. 2006년 IEEE 국제 음향, 음성 및 신호 처리 학회 논문집, 1권, I-I쪽. IEEE.

Mingbo Ma, Liang Huang, Hao Xiong, Renjie Zheng,
Kaibo Liu, Baigong Zheng, Chuanqiang Zhang,
Zhongjun He, Hairong Liu, Xing Li, 그리고 기타. 2019년.
Stacl: 접두사-접두사 프레임워크를 사용한 암시적 예측과 제어 가능한 지연을 가진 동시 번역. 
계산언어학 협회 제57차 연례 회의 논문집, 3025-3036쪽.

사호코 나카야마, 타카토모 카노, 안드로스 티안드라, 사크리아니 사크티, 사토시 나카무라. 2019. 코드 스위칭 음성 발화의 인식과 번역. 2019년 오리엔탈 COCOSDA 국제 음성 데이터베이스 및 평가 기술 (O-COCOSDA) 제22회 컨퍼런스, 1-6쪽. IEEE.

Jan Niehues, Ngoc-Quan Pham, Thanh-Le Ha, Matthias Sperber, and Alex Waibel. 2018. 저지연 신경망 음성 번역. Interspeech 2018 논문집, 1293-1297쪽.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: 기계 번역의 자동 평가를 위한 방법. 40회 연례 컴퓨터 언어학 협회 회의 논문집, 311-318쪽, 미국 펜실베이니아 필라델피아. 컴퓨터 언어학 협회.

맷 포스트. 2018. BLEU 점수 보고에 대한 명확성 요구. 제3회 기계 번역 컨퍼런스 논문집, 186-191쪽, 벨기에 브뤼셀. Association for Computational Linguistics.

R Mahesh K Sinha와 Anil Thakur. 2005. 이중 언어 힌디어-영어 (힌글리쉬) 텍스트의 기계 번역. 10th Machine Translation Summit (MT Summit X)에서, 149-156쪽.

아시쉬 바스와니, 노암 샤지어, 니키 파마르, 야코브 우스코레이트, 리온 존스, 에이단 엔 고메즈, 우카시 카이저, 그리고 일리아 폴로수킨. 2017년. 주의는 당신이 필요한 모든 것이다. 신경 정보 처리 시스템에서의 진보, 30권. Curran Associates, Inc.

Ngoc Thang Vu, Dau-Cheng Lyu, Jochen Weiner, Do-
minik Telaar, Tim Schlippe, Fabian Blaicher, Eng-
Siong Chng, Tanja Schultz, and Haizhou Li. 2012. A
first speech recognition system for mandarin-english
code-switch conversational speech. In 2012 IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing (ICASSP), pages 4889–4892. IEEE.

Ngoc Thang Vu, Dau-Cheng Lyu, Jochen Weiner, Do-
minik Telaar, Tim Schlippe, Fabian Blaicher, Eng-
Siong Chng, Tanja Schultz, and Haizhou Li. 2012. A
first speech recognition system for mandarin-english
code-switch conversational speech. In 2012 IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing (ICASSP), pages 4889–4892. IEEE.

창한 왕, 앤 월, 후안 피노. 2020. Covost 2: 대규모 다국어 음성-텍스트 번역 말뭉치.

오리온 웰러, 마티아스 스페버, 크리스티안 골란, 그리고 조리스 클리버스. 2021년. 공동 음성 인식 및 번역을 위한 스트리밍 모델. 유럽 자연어처리학회 16회 컨퍼런스: 주요 논문집, 2533-2539쪽, 온라인. 자연어처리학회.

오리온 웰러, 마티아스 스페버, 텔모 피레스, 헨드라 세티아완, 크리스티안 골란, 도미닉 텔라르, 그리고 마티아스 파울릭. 2022년. 코드 스위치된 음성에 대한 엔드 투 엔드 음성 번역.

Genta Indra Winata, Alham Fikri Aji, Zheng-Xin Yong,
그리고 Thamar Solorio. 2022년. NLP에서 코드 스위칭 연구의
수십 년 진전: 동향과 도전에 대한 체계적인 조사. arXiv 사전 인쇄
arXiv:2212.09660.

Genta Indra Winata, Samuel Cahyawijaya, Zihan Liu,
Zhaojiang Lin, Andrea Madotto, and Pascale Fung.
2021. 코드 스위칭에서 다국어 모델은 효과적인가요? arXiv 사전 인쇄 arXiv:2103.13309.

토마스 울프, 리산드르 드뷔, 빅터 산, 줄리앙 쇼몽, 클레멘 들랑, 안토니 모이, 피에리크 시스탁, 팀 롤트, 레미 루프, 모건 펀토위츠, 조 데이비슨, 샘 쉴라이퍼, 패트릭 폰 플라텐, 클라라 마, 야신 제르니트, 줄리앙 플루, 캔웬 쉬, 테븐 르 스카오, 실바앙 구거, 마리아마 드라메, 쿠엔틴 로에스트, 그리고 알렉산더 러쉬. 2020. 트랜스포머: 최첨단 자연어 처리. 2020 논문집: 시스템 데모, 38-45쪽, 온라인. 계산언어학회.

Zhen Yang, Bojie Hu, Ambyera Han, Shen Huang, and
Qi Ju. 2020. Csp: Code-switching pre-training for
neural machine translation. In Proceedings of the
2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 2624–2636.

Zhen Yang, Bojie Hu, Ambyera Han, Shen Huang, 그리고
Qi Ju. 2020. Csp: 코드 스위칭 사전 훈련을 위한
신경망 기계 번역. 2020 자연어 처리에 대한
경험적 방법 컨퍼런스 (EMNLP) 논문집, 2624–2636쪽.

Rong Ye, Mingxuan Wang, and Lei Li. 2021. 교차 모달 점진적 훈련을 통한 엔드 투 엔드 음성 번역. Interspeech에서.




Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, 그리고 Ye Bai. 2021. 언어 편향을 가진 Rnn-transducer를 사용한 엔드 투 엔드 중영 코드 스위칭 음성 인식. 2021년 제12회 국제 중국어 말하기 언어 처리 심포지엄(ISCSLP)에서 발표된 논문, 1-5쪽. IEEE.

22
언어 전환에 대한 계산적 접근 방식 워크샵 제6회 절차, 23-32쪽
2023년 12월 7일 ©2023 계산언어학 협회
네팔어-영어 감정 표현을 위한 언어 선호도

사회적인 매체에서의 이중언어 사용자

니라지 파하리와 카즈타카 시마다
일본 후쿠오카 이즈카 카와즈 680-4
경상기술대학교
pahari.niraj828@mail.kyutech.jp 및 shimada@ai.kyutech.ac.jp

요약

네팔어-영어 코드 스위칭(CS)은 네팔 사회에서 특히 소셜 미디어에서 점점 더 늘어나는 현상이다. 코드 스위칭 텍스트는 다중 언어 사용자의 사회언어적 행동을 이해하는 데 활용될 수 있다. 기존 연구들은 다른 언어 쌍을 사용하여 다양한 감정을 표현하는 다중 언어 사용자의 언어 선호도를 파악하려고 시도해왔다. 본 연구에서는 소셜 미디어에서 감정을 표현하는 동안 다중 언어 사용자의 언어 선호도를 연구하고자 한다. 우리는 YouTube에서 공개된 네팔어-영어 코드 스위칭 댓글을 사용하여 감성 분석을 위한 새로운 데이터셋을 생성한다. 데이터셋에 대한 통계적 연구를 수행한 후, 우리는 부정적인 댓글에서 네팔어 사용 비율이 긍정적인 댓글과 비교했을 때 더 높다는 것을 발견하였으며, 이로써 부정적인 감정을 표현할 때 모국어 사용을 선호한다는 결론을 도출한다. 감성 분류를 위해 기계 학습 및 트랜스포머 기반 모델을 데이터셋의 기준 모델로 사용한다. 데이터셋은 공개적으로 공개되었다.

1 소개

최근 몇 년 동안, 소셜 미디어와 컴퓨터 중재 의사소통의 사용이 매일 수백만 명의 사용자와 함께 증가했습니다. 이러한 소셜 미디어의 증가로 인해 코드 스위칭(CS) 또는 코드 혼용 콘텐츠의 사용도 증가했습니다. CS는 언어적 행동으로 정의될 수 있으며, 이는 상대방이나 주제를 변경하지 않고 두 개 이상의 언어로 구성된 어휘 항목과 문법 구조를 이해하는 것입니다. 이 논문에서는 '코드 스위칭'과 '코드 혼용'이라는 용어를 사용하여 단일 담론 내에서 두 개 이상의 언어를 번갈아 사용하는 현상을 가리킨다는 입장을 취합니다. 언어적 맥락에서 사용법에는 미묘한 차이가 있을 수 있지만, 우리 연구의 목적을 위해 이 용어들은 상호 교환 가능하게 사용됩니다.

두 용어는 동의어로 취급되며, 같은 언어적 행동을 묘사합니다.

CS는 이전에는 구어 언어와 관련이 있었지만, 소셜 미디어의 비공식적인 특성으로 인해 CS는 쓰여진 형태로도 발견된다 (Bali et al., 2014). 다양한 언어를 구사하는 개인이 사용하는 언어는 감정과 밀접한 관련이 있다 (Rajagopalan, 2004). 마찬가지로, 감정은 CS 행동의 주요 요인이다 (Ndubuisi-Obi et al., 2019). 언어학 연구자들은 다중 언어 사용자들이 감정을 표현하는 데 특정한 언어를 선호한다는 것을 발견했다 (Dewaele, 2010; Rudra et al., 2016). 따라서, 다중 언어 사용자의 감정에 기반한 감성 분석과 사회 언어학 연구는 자연어 처리(NLP) 분야에서 많은 관심을 받고 있다. 이러한 연구들은 사회의 다양한 특성에 대해 새로운 통찰력을 제공하고 있다. 다양한 연구들은 다중 언어 사회에서의 언어 선호도를 분석하고, 다중 언어 사용자들이 실제로 자신들의 감정을 전달할 때 첫 번째 언어(L1)를 선호한다는 결론을 내렸다 (Agarwal et al., 2017; Rudra et al., 2019). 반면, 코드 스위칭 분야의 대부분의 연구는 고자원 언어 쌍에만 초점을 맞추고 있다. 지금까지 네팔어-영어 CS 텍스트의 증가하는 양을 활용하고, 네팔 다중 언어 커뮤니티의 감정 감성을 분석하는 데는 너무나도 적은 관심이 기울여졌다.

감성 분석은 텍스트에서 전달되는 감정이나 감정적 태도를 결정하는 컴퓨팅 기술입니다. 감성 분석은 사용자의 의견으로부터 특정 제품이나 주제에 대한 통찰력을 얻는 데 도움이 되며 비즈니스 전략을 계획하는 데 도움이 될 수 있습니다 (Balage Filho et al., 2012). 감성 분석을 위한 응용 프로그램과 자원은 주로 단일 언어 설정에서 고자원 언어에 대해 생성됩니다. 그러나 단일 언어 데이터에 대한 주석 처리된 데이터는 코드 스위칭 시나리오를 처리할 수 없으며 좋은 결과를 얻지 못합니다 (Al-

23
Ghamdi et al., 2016). 몇몇 연구자들은 코드-스위치 시나리오를 위한 감성 분석 데이터셋을 구축했습니다 (Chakravarthi et al., 2020b; Hegde et al., 2022). 그러나 우리의 지식으로는 네팔어-영어 혼용 언어에 대한 기존의 감성 분석 데이터셋은 없습니다. 네팔어 대화에서 영어 요소의 사용이 증가함에 따라 네팔레스 커뮤니티에서 네팔어-영어 혼용 언어가 한 방언으로 등장했음에도 불구하고 (Gurung, 2019).
이 연구에서는 유튜브 플랫폼에서 코드-스위치된 네팔어-영어로 된 공개 댓글을 수집하고 감성 주석을 달았습니다. 우리는 댓글에서 사용된 언어와 댓글의 감성, 그리고 부정적 또는 긍정적 감정 표현을 위한 선호 언어 간의 관계를 분석하기 위해 두 가지 가설을 세웠습니다. 이 연구의 기여는 다음과 같습니다:

우리는 감정 분석을 위한 첫 번째 표준 코드 스위칭된 네팔어-영어 데이터셋을 제공합니다.

우리는 사회적 미디어에서 네팔어-영어 다중언어 사용자의 언어 선호도를 파악하기 위해 통계 연구를 수행합니다.

3. 우리는 감정 분석을 위한 코드 스위칭 데이터셋에서 기계 학습 및 딥 러닝 기반 모델의 실험적 분석을 제공합니다.

2 관련 연구

의견 표현을 위한 선호 언어는
다국어 사용자들에 의해 오랜 시간 동안 언어학자들에 의해 연구되었습니다. Fishman (1970)은 영어-스페인어 이중언어 사용자들의 행동을 연구하고, 영어를 전문적인 목적으로 사용하고 채팅과 같은 비공식적인 목적으로 스페인어를 사용한다고 보고했습니다. Barredo (1997)은 바스크-스페인어 코드 스위칭의 화용 기능을 연구하고, 바스크-스페인어 다중언어 사용자들은 일반적으로 유머와 아이러니를 전달하기 위해 스페인어로 전환한다는 결론을 내렸습니다. Dewaele (2004)은 다중언어 사용자들이 욕설과 금기어를 사용하는 데에 첫 번째 언어를 높은 비율로 사용한다는 것을 확인했습니다. 저자들은 다중언어 사용자들이 코드 스위칭/믹싱을 사용할 때에도 상대방이 언어를 이해하지 못해도 욕설에 첫 번째 언어를 사용하는 경향이 있다고 보고했습니다. 힌디어와 네팔어는 서로 밀접한 관련이 있으며 같은 언어 패밀리에 속합니다.

사랑해. 힌디어-영어 코드 스위칭 데이터에 대해 Agarwal 등 (2017)은 소셜 네트워크에서의 영어-힌디어 코드 스위칭과 욕설 패턴을 분석하고, 다중 언어 사용자들이 우세한 언어에서 욕설을 선호한다는 결론을 내린다. Rudra 등 (2019)은 트위터에서의 영어-힌디어 코드 스위칭의 다양한 측면을 연구하고, 힌디어를 사용하여 부정적인 감정을 표현하는 선호도가 영어의 두 배라는 것을 확인한다. 네팔어-영어 코드 스위칭의 맥락에서 Gurung (2019)의 연구는 네팔 사람들 간의 대화에서 코드 스위칭 현상에 대한 상세한 사회 언어학적 연구를 제시한다. 이 연구는 네팔어-영어 언어 혼용의 범위, 미디어의 역할 및 혼합의 이유를 연구한다. 우리의 지식으로는 네팔어-영어 코드 스위칭 시나리오에서 언어 선호를 연구한 기존의 연구는 없다.

계산 언어학자들은 상당한 기간 동안 코드 스위칭을 연구해왔다. 코드 스위칭 연구를 지원하기 위해 여러 데이터 자원이 생성되었다. Solorio 등 (2014)는 네팔어-영어를 포함한 네 가지 언어 쌍에 대한 언어 식별 작업을 위한 코드 스위칭 데이터셋을 공개한다. 그들은 트위터와 페이스북과 같은 소셜 미디어 플랫폼에서 문장을 추출한다. 마찬가지로, Patwa 등 (2020)는 코드 스위칭된 힌디어-영어와 스페인어-영어 언어 쌍을 위한 감성 데이터셋을 공개한다. 이 데이터셋은 긍정, 중립, 부정 세 가지 클래스 중 하나로 감성 주석이 달린 코드 스위칭된 트윗으로 구성된다. 유튜브 댓글은 저자들이 영어와 혼합된 저자들의 감성 (또는 의견) 텍스트의 소스로 활용되어 낮은 자원 언어에 대한 상당한 양의 문헌이 출판되었다 (Chakravarthi 등, 2020a,b; Ravikiran 및 Annamalai, 2021; Hegde 등, 2022). 네팔어-영어 코드 스위칭은 특히 소셜 미디어에서 네팔 사회에서 계속해서 증가하는 현상이지만, 코드 혼합된 시나리오에 초점을 맞춘 감성 분석 데이터셋은 없다. 따라서 네팔어-영어 코드 스위칭에서 감정 표현을 위한 언어 선호를 연구하기 위해 감성 분석 데이터셋을 생성하고 가설을 검증한다.

3 가설

이 연구에서는 다음과 같은 연구 질문에 대해 시도해보려고 합니다: "네팔어-영어 사용자는 소셜 미디어에서 부정적인 감정을 표현할 때 모국어 사용을 선호하는 경향이 있을까요?" 우리는 이를 조사하고자 합니다.

24
이 현상을 조사하기 위해 특정 감정을 표현하는 데 사용되는 언어의 비율을 사용합니다.
이 연구에서 검증할 두 개의 가설을 정의합니다.

가설 I: 감정과 언어 비율 사이에 연관성이 있다.

가설 II: 부정문에서 네팔어 사용 비율이 긍정문보다 높다.

첫 번째 가설은 소셜 미디어에서 감정을 표현하는 데 사용되는 언어의 비율과 관련이 있는지 여부를 검증하려고 합니다. 두 가지 사이에 연관성이 있다면, 다음 가설은 부정적인 문장에 대해 네팔어 사용 비율이 긍정적인 문장보다 높은지 확인할 것입니다. 두 번째 가설은 소셜 미디어에서 네팔어-영어 다중 언어 사용자의 실용적인 행동을 검증하려고 합니다.

4 데이터셋

4.1 데이터 수집

유튜브는 가장 인기 있는 소셜 미디어 플랫폼 중 하나입니다. 플랫폼 내 네팔 대상 비디오의 수도 증가하고 있습니다. 이 비디오에 대한 댓글은 대부분 댓글 작성자의 감정을 표현합니다. Ndubuisi-Obi 등의 연구(2019)에 따르면, 사회적 긴장과 관련된 주제(예: 정치 및 사회경제)는 코드 스위칭에 강한 영향을 미칩니다. 따라서 유튜브에서 댓글을 수집하기 위해, "뉴스 및 정치" 카테고리에서 네팔의 상위 10개 유튜브 채널이 나열되었습니다. 각 채널의 상위 50개 비디오에서 모든 댓글과 그 스레드가 유튜브 API를 사용하여 추출되었습니다. 댓글 작성자에 대한 정보는 수집되지 않았습니다. 4개 이하의 토큰을 가진 댓글과 데바나가리 문자를 포함하는 댓글은 걸러졌습니다. 비 코드믹스 댓글을 걸러내기 위해, (Pahari and Shimada, 2023)의 최고 성능 언어 식별 모델인 F1-점수 94.66을 사용했습니다. 이 모델은 문장의 각 토큰에 대해 영어, 네팔어, 명명된 개체, 기타 및 모호한 다섯 가지 태그 중 하나를 예측합니다. 영어와 네팔어 토큰 수를 사용하여 식(1)을 이용하여 각 문장의 코드믹싱 지수(CMI)를 계산했습니다.

표 1: 각 분할별 댓글 수와 총합을 보여주는 데이터셋 통계.

긍정적 중립적 부정적 합계
훈련 2,768 2,918 2,875 8,561
개발 346 365 360 1,071
테스트 346 365 359 1,070
합계 3,460 3,648 3,594 10,702

CMI = (100 * (1 - max(wi) / n - u), if n > u

0, 만약 n = u 이면

(1) 저는 한국에 살고 있어요.

어디에서, wi는 언어 i의 단어 수이고,
n은 총 토큰 수이며, u는 언어 독립적인 토큰의 수입니다. CMI는 말뭉치 내에서 언어 간 혼합 수준을 측정합니다. 이 연구에서는 이 측정치를 사용하여 댓글 내에서 언어 간 혼합 수준을 얻습니다. CMI가 20보다 작은 댓글은 영어와 네팔어 토큰의 혼합을 보장하기 위해 걸러집니다. 또한, 댓글에는 종종 개인 식별 가능한 정보인 사람 이름이 포함되어 있습니다. 이러한 이름은 임의의 실제 사람 이름으로 대체하여 익명화되었습니다. 대체 과정에서 이름의 성별은 유지되었습니다.

4.2 데이터 주석

필터링된 댓글 풀은 주석을 위해 무작위로 섞였다. Patwa et al. (2020)와 유사하게, 주석 작업자들은 각 댓글을 긍정, 중립, 부정 세 가지 범주로 주석을 달 것을 요청받았다. 두 명의 주석 작업자가 처음에는 모든 댓글에 주석을 달도록 지정되었다. 두 주석 작업자 간의 상호 평가자 신뢰도는 Cohen의 카파 (k) (Cohen, 1960)를 사용하여 계산되었으며 0.55로 나타났다. 이는 주석 작업자들 간에 중간 정도의 일치를 시사한다. 세 번째 주석 작업자는 주석 작업자들 간의 불일치를 검토하고 합의를 통해 해결했다. 대부분의 불일치는 중립과 다른 두 범주 사이의 경계선 케이스에서 관찰되었다. 예를 들어, "Background sound ali low garna paryo." (영어 번역: "배경 소리를 낮추어야 한다.")는 한 명에게는 부정적으로 표시되었지만, 다른 한 명에게는 중립적으로 표시되었다. 이 리뷰는 배경 볼륨을 낮추는 제안으로 해석될 수 있으며, 따라서 '중립' 범주에 속할 수 있지만, 이는 배경 소리에 괴로움을 느낀 주석 작업자에게는 '부정적' 감정으로 해석될 수도 있다.

25
주석 작업자들은 총 10,702개의 댓글에 주석을 달았습니다. 주석이 달린 데이터셋의 통계는 표 1에 제공되었습니다. 이 데이터셋은 네팔어-영어 언어 쌍에서 코드 혼용 감성 분석 연구를 촉진하기 위해 공개되었습니다.

5개의 기준선 분류기

전통적인 기계 학습 모델과 트랜스포머 기반 모델은 YouTube 댓글에서 감정을 판단하기 위해 간단한 기준선으로 사용됩니다. 이 연구에서 사용된 모델은 이 섹션에 나열되어 있습니다.

5.1 기계 학습 기반 모델

우리는 전통적인 기계 학습 기법을 고려합니다.
특히, 서포트 벡터 머신(SVM)과 다층 퍼셉트론(MLP)을 다양한 임베딩과 함께 사용합니다.
이러한 모델들은 sklearn 라이브러리를 사용하여 구현되었습니다(Pedregosa et al., 2011).
SVM에는 '선형' 커널을 사용합니다.
MLP의 경우, 은닉층 크기는 2로 설정됩니다.
다음 임베딩들이 이러한 전통적인 기법들과 함께 사용됩니다:

5.1.1 TFIDF
5.1.1 TFIDF

단어 빈도 역 문서 빈도(TFIDF)는 텍스트 데이터를 숫자로 변환하는 일반적인 알고리즘입니다. 이 방법은 댓글 내에서 단어의 중요성을 양적으로 측정하면서 전체 댓글에서의 빈도를 고려합니다. 이 방법은 간단함, 해석 가능성 및 계산 효율성으로 인해 다양한 NLP 작업에서 사용됩니다.

5.1.2 레이저

언어에 중립적인 문장 표현 (LASER) (Artetxe and Schwenk, 2019)은
BiLSTM 인코더를 기반으로 한 문맥화된 언어 모델로, 번역 목적을 사용하여
공개적으로 사용 가능한 병렬 코퍼스의 여러 출처를 사용하여 훈련되었습니다. LASER 모델은
30개 이상의 다른 언어 가족에 속하는 93개 언어의 숫자 표현을 생성하기 위해 훈련되었으며,
28개 다른 문자로 쓰여진 언어입니다. 다양한 언어로의 공동 훈련은
이 모델이 저자원 언어에서 경쟁력 있는 성능을 발휘할 수 있게 합니다.

5.1.3 LaBSE
5.1.3 라브스

언어에 구애받지 않는 BERT 문장 임베딩 (LaBSE) (Feng et al., 2022)은 BERT 기반의 교차 언어 문장 임베딩 모델로, 훈련되었습니다.

마스크된 언어 모델링과 번역 언어 모델링은 번역 순위 작업에 대한 목표입니다. LaBSE 모델은 109개 언어를 지원합니다. LaBSE는 서로 다른 언어로 된 병렬 문장에 대해 유사한 표현을 생성합니다. 이 모델은 훈련되지 않은 언어에서도 강력한 성능을 보여주었습니다.

5.2 변압기 기반 모델

클래식한 머신 러닝 모델 이외에도, 우리는 다양한 트랜스포머 기반 모델들과 실험을 진행합니다. 트랜스포머 기반 모델들은 고성능으로 인해 NLP 분야에서 현재 기본적인 방법론입니다. 다국어 트랜스포머 기반 모델들은 여러 언어의 정렬된 표현을 생성하는 능력으로 코드믹스 텍스트 처리에 유용합니다 (Winata et al., 2021). 분류 모델은 사전 훈련된 언어 모델과 드롭아웃이 적용된 선형 레이어로 구성됩니다. 실험은 transformers 라이브러리를 사용하여 실행됩니다 (Wolf et al., 2020). AdamW 옵티마이저가 사용되며 학습률은 1e로 설정됩니다.

−
5. 훈련은 5 에포크 동안 실행되며 검증 세트에서 가장 성능이 우수한 모델이 테스트에 사용됩니다.

5.2.1 mBERT (엠버트)

멀티링구얼 BERT (mBERT) (Devlin et al., 2019)은 BERT의 다국어 버전입니다. mBERT는 104개 언어의 위키피디아 데이터로 사전 훈련되었습니다. mBERT 모델은 가려진 언어 모델링과 다음 문장 예측 목적으로 사전 훈련되었습니다. 이 모델은 다국어 작업에 사용할 수 있는 교차 언어 표현을 생성할 수 있습니다.

5.2.2 XLM-R
5.2.2 XLM-R

XLM-RoBERTa (XLM-R) (Conneau et al., 2020)은 100개 언어의 단일 언어 데이터를 사용하여 가려진 언어 모델링을 위해 훈련된 트랜스포머 모델입니다. 이 모델은 2.5 TB의 텍스트를 사용하여 훈련되었습니다. XLM-R 모델은 XLM (Lample and Conneau, 2019)의 수정 버전으로, 번역 언어 모델링을 피하고 BERT 대신 RoBERTa (Liu et al., 2019)를 사용합니다. XLM-R의 성능은 저자원 언어에서 mBERT에 비해 정확도가 23% 향상되었습니다.

5.2.3 뮤릴

인도어 다국어 표현 (MuRIL) (Khanuja et al., 2021)은 사전 훈련된 인도 하위 대륙 언어 패밀리 모델입니다.

26
인도 하위 대륙의 다양한 언어들에 대한 대규모 말뭉치를 기반으로 한 모델입니다. 이 모델은 인도 하위 대륙 언어 16개와 영어로 사전 훈련되었습니다. 이 모델의 사전 훈련에는 가려진 언어 모델링과 번역 언어 모델링 목표가 사용되었습니다. 이 모델은 인도 하위 대륙 언어를 포함한 작업에서 다른 다국어 모델보다 우수한 성능을 보였습니다. 이 모델은 훈련 과정에서 데바나가리 문자와 그의 영문 표기를 모두 포함하고 있습니다.

6 결과 및 토의

6.1 가설 검정

문장 수: 각 댓글의 주요 언어를 식별하기 위해, 우리는 섹션 4.1에서 논의한 언어 식별 모델을 사용합니다. 각 댓글마다, 댓글의 모든 토큰에 대해 언어 태그를 식별합니다. 댓글의 특정 언어 토큰의 수를 이용하여 댓글의 주요 언어를 구분합니다. 영어 언어 토큰의 수가 네팔어 언어 토큰의 수보다 많으면, 댓글을 영어 댓글로 간주하고 그 반대의 경우도 마찬가지입니다. 영어 언어 토큰과 네팔어 언어 토큰의 수가 동일한 경우, 댓글에는 구별되는 언어가 없다고 간주합니다. 그림 1의 모자이크 차트는 문장의 주요 언어에 대한 감정 클래스에 속하는 문장 수에 대한 통계를 보여줍니다. 이 통계를 사용하여 섹션 3에서 설명한 가설에 대한 통계적 검정을 실행합니다.

통계적 검정: 섹션 3에서 논의한 가설을 검정하기 위해 카이제곱 검정을 사용합니다. 이 검정은 두 범주형 변수 간의 독립성을 확인하는 데 사용됩니다. 우리의 경우, 변수는 우세한 언어와 감정 클래스입니다. 이 검정의 귀무가설은 "감정과 언어 간에 연관성이 없다"이며, 대립가설은 가설 I입니다. 유의수준은 1%로 설정되었습니다. 검정에서 얻은 p-값은 유의수준보다 훨씬 낮았습니다. 따라서, 우리는 귀무가설을 기각하고 대립가설을 받아들입니다. 다시 말해, 이 결과는 우리의 가설 I를 지지하며, 감정과 언어 간에 연관성이 있다는 것을 의미합니다.
댓글의 감정 클래스와 우세한 언어 간에 연관성이 있기 때문에, 우리는 두 번째 가설을 검정하여 확인합니다.

감정

언어

없음.
네팔어
영어

중립적인 부정적인

1034

2197

229 이백 이십 구
601 육백 일

2873

174 - 일칠사
469 - 사륙구

2971

154

그림 1: 인간 주석이 달린 댓글의 감정 클래스별로 각 언어의 문장 빈도를 보여주는 모자이크 차트.

만약 다른 감정 그룹에서 네팔어 사용 비율에 통계적으로 유의한 차이가 있다면. 우리는 비율에 대한 z-검정을 사용하여 두 가지 가설을 검정합니다. 비율에 대한 z-검정은 두 개의 표본 비율 사이의 차이에 대한 가설을 검정하는 데 사용됩니다. 우리의 경우, 우리는 긍정적인 클래스와 부정적인 클래스에서 네팔어 댓글의 비율을 취합니다. 이 검정의 귀무 가설은 다음과 같습니다: '부정적인 감정과 긍정적인 감정 댓글에 대한 네팔어 사용 비율은 동일하다', 반면 대립 가설은 가설 II입니다. 비율에 대한 z-검정을 계산한 후, 우리는 우리의 z-값이 -4보다 유의하게 낮다는 것을 발견했습니다. 따라서 우리는 귀무 가설을 기각하고 대립 가설을 받아들일 수 있습니다. 따라서 통계적으로 우리는 네팔어 사용 비율이 긍정적인 댓글과 비교했을 때 부정적인 댓글에서 더 높다고 결론지을 수 있습니다. 또한, 긍정적인 댓글과 부정적인 댓글에서 영어 사용 비율에 대해 동일한 검정을 수행한 결과, 우리의 데이터셋에서 영어 사용 비율이 긍정적인 댓글에서 부정적인 댓글보다 더 높았음을 알 수 있었습니다.

사람들은 (Agarwal et al., 2017; Rudra et al., 2019)의 결과와 일치하며, 이들은 다국어 사용자들이 감정을 표현할 때 주로 자신의 모국어를 사용한다는 것을 발견했다. 네팔의 대부분의 다국어 사용자들은 모국어인 네팔어를 집에서 배우며, 학교에서는 두 번째 언어로 영어를 배운다 (Gurung, 2019). 따라서, 다국어 사용자들의 대부분은 모국어를 선호한다.

27
(a) 긍정적인          (b) 중립적인           (c) 부정적인

그림 2: 감정 클래스별로 나뉜 댓글의 워드클라우드.

화자들은 영어를 교육받은 언어로서의 지식을 얻습니다. 따라서 이 연구 결과는 Dewaele (2004)의 연구 결과와 일치합니다. Dewaele은 교육받은 언어 학습자들이 부정적인 단어에 대한 일반적인 지식이 제한적이라고 논의하고 있습니다. 결과적으로, 화자들은 교육받은 언어(이 연구의 맥락에서는 영어)를 부정적인 감정을 표현하는 데 자주 사용하지 않습니다. Figure 2는 데이터셋의 각 감정 클래스에 대한 댓글의 워드클라우드를 보여줍니다. 그림에서 볼 수 있듯이, 긍정적인 워드클라우드에는 더 많은 비율의 영어 단어가 보이고, 부정적인 워드클라우드에는 네팔어 단어의 비율이 더 많이 보입니다.

6.2 CS에 대한 감성 분석

표 2와 3은 각각 기계 학습 및 트랜스포머 기반 모델의 F1-점수에 대한 실험 결과를 보여줍니다. 실험은 섹션 4.2에서 설명한 데이터 분할에서 수행되었습니다. 두 표 모두 세 번의 실행 평균이 보고되었습니다.
TFIDF 임베딩을 사용한 SVM 모델이 실험에서 기계 학습 방법 중에서 가장 좋은 결과를 나타냅니다(매크로-, 가중치-F1 및 정확도에 대해 0.68). SVM 모델은 LASER 임베딩을 제외한 모든 임베딩에 대해 MLP보다 우수한 성능을 보입니다. LASER 임베딩의 경우 MLP와 유사한 성능을 보입니다. LaBSE 및 LASER 임베딩은 신경망과 교차 언어 훈련을 활용하여 의미 있는 문장 표현을 생성하기 위해 훈련된 다국어 문장 임베딩입니다. 반면, TFIDF는 문서 내 단어의 중요성과 전체 말뭉치를 기반으로 수치적 표현을 계산하는 간단한 모델입니다. 이 간단한 방법에 의한 더 나은 성능은 모델에 추가된 복잡성을 보여줍니다.

다국어 데이터에서 단일 언어 데이터로 훈련받았습니다.
데이터셋 내에서 언어가 혼합되었기 때문입니다.
저희 데이터셋은 혼합된 네팔어-영어 데이터로 구성되어 있습니다.
데이터셋에서는 네팔어의 로마자 표기법이 사용되었습니다.
이러한 모델의 훈련 중에는 사용되지 않았습니다.
따라서 언어의 혼합과 네팔어에 대한 로마자 표기법 사용으로 인해
다국어 문장 임베딩에서는 TFIDF보다 성능이 낮게 나타납니다.

트랜스포머 기반 모델의 경우, 세 가지 모델 모두 유사한 성능을 보입니다. 가장 높은 성능을 보이는 것은 MuRIL입니다. 이러한 모델들은 우리 연구에 참여한 언어인 네팔어와 영어와 함께 여러 언어로 훈련되었습니다. mBERT와 XLM-R은 이러한 언어의 단일 언어 데이터로 훈련되었지만, MuRIL은 단일 언어 데이터, 병렬 번역 데이터, 그리고 음역 데이터로 훈련되었습니다. 이전에 논의한 대로, 음역 형태는 소셜 미디어 플랫폼과 같은 비공식적인 환경에서 많이 사용되며, 우리의 데이터셋에는 네팔어의 음역 형태가 포함되어 있습니다. 따라서 MuRIL 어휘는 mBERT와 XLM-R에 비해 우리의 데이터셋에서 더 많은 토큰을 고려하므로 성능이 더 우수합니다. 몇몇 이전 연구들(Adhikari et al., 2022; Pahari and Shimada, 2023)은 언어 패밀리별 모델이 훈련 데이터셋 크기가 일정한 최소한의 수일 때 상당한 이점을 제공할 수 있다는 것을 보여주었으며, 이는 데이터 증강과 같은 기술을 사용하여 더 많은 훈련 데이터셋을 도입함으로써 성능을 개선할 여지가 있다는 것을 시사합니다.

테이블을 더 자세히 살펴보면 기계 학습과 트랜스포머 기반 모델 모두 중립적인 경우에 대해 긍정적인 경우와 부정적인 경우에 비해 낮은 점수를 보였습니다.

28
표 2: 기계 학습 기반 모델을 사용한 실험 결과.

임베딩 모델 부정적 중립적 긍정적 매크로 F1 가중치 F1 정확도

TFIDF
SVM   0.67   0.61  0.76   0.68     0.68    0.68
MLP   0.68   0.56  0.74   0.66     0.66    0.66

LaBSE
SVM   0.62   0.55  0.72   0.63     0.63    0.63
MLP   0.61   0.53  0.73   0.62     0.62    0.62

레이저
SVM   0.64   0.55  0.70   0.63     0.63    0.63
MLP   0.62   0.54  0.73   0.63     0.63    0.63

테이블 3: 트랜스포머 기반 모델을 사용한 실험 결과.

모델 부정적 중립적 긍정적 매크로 F1 가중치 F1 정확도
mBERT   0.68  0.59  0.76   0.68     0.68    0.68
XLM-R   0.67  0.54  0.75   0.65     0.65    0.66
MuRIL   0.72  0.60  0.80   0.70     0.70    0.70

부정적인
중립적인
긍정적인
예측된 레이블
부정적인

중립적인

긍정적인
트루레이블
205    135   19

59 241 65

2     54    290    50 100

둘     오십사     이백구십     오십     백

150 - 150
200 - 200
250 - 250

그림 3: MuRIL 모델의 결과에 대한 혼동 행렬.

인간에게도 어려운 경계선 코멘트 때문에 발생합니다. 이는 4.2절에서 논의된 것과 같습니다. MuRIL 모델의 한 번의 실행에 대한 혼동 행렬에서 시각화할 수 있습니다. 부정 클래스의 잘못된 예측 중 89.2%는 중립 클래스이고, 긍정 클래스의 예측 중 83.1%는 중립 클래스입니다.

6.3 자동으로 분류된 댓글들에 대한 가설 검정

섹션 6.1에서는 제한된 인간 주석 데이터에 대한 가설 검정에 대해 논의했습니다. 섹션 6.2에서 논의된 자동 감성 분류기의 가용성으로 인해 대규모 댓글 풀에 대한 추가 테스트가 수행됩니다. MuRIL 기반 분류기를 사용하여 섹션 4.1에서 수집된 27,252개의 주석되지 않은 댓글을 자동으로 분류합니다. 각 댓글의 우세 언어는 동일한 언어 식별 모델을 사용하여 결정됩니다.

감정

언어

없음.
네팔어
영어

중립적인 부정적인

4824

6521

1372 - 천삼백칠십이
1477 - 천사백칠십칠

5655

543 - 오백 사십 삼
1015 - 천 십 오

5521

324 삼백 이십 사

그림 4: 자동으로 주석이 달린 댓글들의 큰 풀에 대한 감정 클래스별 언어별 문장 빈도를 보여주는 모자이크 차트.

6.1절. 그림 4의 모자이크 차트는 댓글의 주요 언어에 대한 감정 클래스별 댓글 수에 대한 통계를 보여줍니다. 차트에서 시각화된 것처럼, 부정적인 댓글에는 주로 네팔어가 주요 언어로 사용되는 댓글의 비율이 긍정적인 댓글보다 높습니다. 인간 주석 데이터에 대한 통계적 검정과 유사하게, 이 자동 주석 데이터에 대한 통계적 검정도 우리의 두 가지 가설을 모두 검증합니다.

6.4 결론

help of machine learning algorithms, we analyzed the sentiment of the comments and identified patterns. The results showed that the majority of the comments were positive.

29
새로 생성된 데이터셋의 도움으로, 우리는 두 개의 가설을 테스트하고 확인합니다. 첫 번째 가설은 댓글에 사용된 언어와 댓글의 감정 사이의 의존성을 확인합니다. 두 번째 가설은 부정적인 감정을 표현하는 네팔어 댓글의 비율이 긍정적인 감정을 표현하는 것보다 높음을 확인합니다. 마찬가지로, 영어의 비율은 부정적인 감정보다 긍정적인 감정에서 높습니다. 이 결과는 이전 연구들의 결론 (Agarwal et al., 2017; Rudra et al., 2019)과 일치하며, 감정 표현이나 욕설에 사용하는 사용자의 모국어 선호도를 보여줍니다. 기계 학습 방법의 결과는 다중 언어 문장 임베더가 코드 스위칭 언어에 대해 적절한 표현을 생성하지 못한다는 것을 보여줍니다. 혼합 언어의 의미를 포착할 수 있는 다중 언어 임베딩을 생성하기 위해 더 많은 작업이 필요합니다. 트위터에서 코드 스위칭 데이터로 훈련된 언어 식별 모델이 분석에 사용되었습니다. 그러나 유튜브 도메인의 테스트 데이터가 없어 언어 식별 모델의 정확도를 평가하지 못했습니다. 향후 연구에서는 이 도메인에서 모델의 정확도를 평가하고 분석에 대한 영향을 확인해야 합니다. 또한, 이 연구 결과는 네팔 사회에서 영어 언어의 영향과 네팔어 언어에 대한 영향에 대해 몇 가지 사회 언어학적 질문을 제기하며, 더 많은 연구를 위한 유익한 영역이 될 것입니다.

제한사항

댓글의 우세 언어는 언어 토큰의 수를 기반으로 식별됩니다. 이 언어 토큰은 자동 언어 식별 모델을 사용하여 식별되며, 이 모델은 무시할 수 없는 오류를 가질 수 있습니다. 우리는 이러한 데이터를 기술적 통계 및 위에서 언급한 가설을 분석하는 데 사용합니다.

참고문헌

라빈 아디카리, 사팔 타팔리야, 니라잔 바스넷, 사믹 푸델, 아만 샤키야, 비세시 카날. 2022년. 저자: "저자: COVID-19와 관련된 네팔어 트윗의 분류에 대한 연구"는 자원이 제한된 환경에서 진행되었습니다. "건강 응용을 위한 소셜 미디어 마이닝" 워크샵 및 공유 작업에서 209-215쪽에 게재되었습니다. "계산 언어학 협회"에서 발행되었습니다.

프라바트 아가르왈, 아시쉬 샤르마, 지누 그로버,
마양크 식카, 코우스타브 루드라, 그리고 모노짓 초우드리. 2017년. 나는 영어로 말할지라도 욕은 힌디어로 할 것이다: 소셜 네트워크에서의 영어-힌디어 코드 스위칭과 욕설 패턴에 대한 연구.

2017년 9번째 국제 커뮤니케이션 시스템 및 네트워크 컨퍼런스(comsnets)에서, 554-557쪽. IEEE.

파하드 알가미디, 조반니 몰리나, 모나 디압, 타마르 솔로리오, 압델라티 하와리, 빅터 소토, 그리고 줄리아 히르슈베르그. 2016년. 코드 스위칭 데이터에 대한 품사 태깅. 제2회 코드 스위칭에 대한 계산적 접근 방법 워크샵 논문집, 98-107쪽, 텍사스 오스틴. 계산언어학 협회.

미켈 아르테체와 홀거 슈벵. 2019. 제로샷 크로스-언어 전이 및 그 이상을 위한 대규모 다국어 문장 임베딩. 계산언어학회 트랜잭션, 7:597-610.

페드로 파울로 발라지 필로, 캐롤린 브룬, 그리고 길버 론도. 2012. 특징 기반 의견 분석을 위한 그래픽 사용자 인터페이스. 북미 협회 컴퓨터 언어학 연구회 컨퍼런스의 시연 세션 논문집, 5-8쪽, 캐나다 몬트리올. 컴퓨터 언어학 협회.

칼리카 바리, 자틴 샤르마, 모노짓 초우드후리, 요가르시 비아스. 2014. 페이스북에서의 영어-힌디어 코드믹싱 분석 "나는 빌려오거나 섞어 쓰고 있어?" 제1회 코드스위칭에 대한 컴퓨터적 접근 워크샵 논문집, 116-126쪽, 카타르 도하. 계산언어학회.

이나마쿨라다 무노아 바레도. 1997년. 바스크-스페인어 이중언어 사용자들의 코드 스위칭의 실용적 기능. 바이링구아에 대한 제1회 국제 심포지엄 논문집, 528-541쪽, 스페인 갈리시아. 출판 서비스.

바라티 라자 차크라바르티, 나비아 호세, 샤르둘 수리완시, 엘리자베스 셜리, 그리고 존 필립 맥크레이. 2020년. 혼합된 말라얄람어-영어에 대한 감성 분석 데이터셋. 미리암, 프랑스에서 열린 제1회 저자원 언어를 위한 구어 언어 기술(SLTU)과 저자원 언어를 위한 협업과 컴퓨팅(CCURL) 합동 워크샵 논문집, 177-184쪽. 유럽 언어 자원 협회.

바라티 라자 차크라바르티, 비그네쉬와란 무랄리다란, 루바 프리야다르시니, 그리고 존 필립 맥크레이. 2020b. 혼합된 타밀어-영어 텍스트에서 감성 분석을 위한 말뭉치 생성. 저자들. 1차 공동 워크샵에서 발표된 논문. 언어 자원 협회.

제이콥 코헨. 1960년. 명목 척도에 대한 일치 계수. 교육 및 심리 측정, 20(1):37-46.

30
알렉시스 코너, 카르티케이 캔델왈, 나만 고얼,
비샤브 초다리, 기욤 웬젝, 프란시스코
구즈만, 에두아르 그레이브, 마일 오토, 루크 제틀-
모이어, 그리고 베셀린 스토야노프. 2020년. 비지도
크로스-언어 표현 학습의 규모. 제 58회 연례 회의
자연어처리 협회 논문집, 페이지 8440–
8451.

아미타바 다스와 비욘 감백. 2014. 혼합된 코드로 된 인도 소셜 미디어 텍스트에서 단어 수준에서 언어 식별하기. 제11회 자연어 처리 국제 학회 논문집, 378-387쪽, 인도 고아. 인도 NLP 협회.

제이콥 데블린, 민위 창, 켄튼 리, 그리고 크리스티나 투타노바. 2019년. BERT: 언어 이해를 위한 깊은 양방향 트랜스포머의 사전 훈련. 2019년 북미 협회 컴퓨터 언어학 회의 논문집: 인간 언어 기술, 제1권 (장문과 단문), 페이지 4171-4186, 미네소타 주 미니애폴리스. 컴퓨터 언어학 협회.

장-마르크 드와엘. 2004. 불타는 닭장! 다국어 사용자들은 어떤 언어로 욕을 할까요?! 사회언어학 연구, 83-105쪽.

장-마르크 드와엘. 2010. 다중 언어에서의 감정. 스프링거.

Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022. 언어에 구애받지 않는 BERT 문장 임베딩. 제60회 연례 계산언어학 협회 학술대회 논문집 (1권: 장문), 페이지 878-891.

조슈아 A 피쉬만. 1970년. 사회언어학: 간략한 소개. ERIC.

디네시 구룽. 2019. 네팔 사람들의 대화에서의 네팔어-영어 코드 스위칭: 사회언어학적 연구. 박사학위 논문, 로햄튼 대학교.

아샤 헤그데, 무두어 데바다스 아누샤, 샤랄 코엘로, 호사할리 락슈마이아 샤시레카, 그리고 바라티 라자 차크라바르티. 2022년. 혼합 코드 툴루어 텍스트의 감성 분석을 위한 말뭉치 생성. ELRA/ISCA 특별 관심 그룹 연례 회의 논문집, 33-40쪽, 프랑스 마르세유. 유럽 언어 자원 협회.

심란 카누자, 딕샤 반살, 사르베시 메타니,
사비야 코슬라, 아트리 디, 바라지 고팔란,
딜립 쿠마르 마르감, 푸자 아가르왈, 라지브 테자
나기포구, 샤치 데이브 등. 2021년. Muril: 인도어
언어를 위한 다중 언어 표현. arXiv
사전 인쇄물 arXiv:2103.10730.

Guillaume Lample과 Alexis Conneau. 2019. 교차언어 언어 모델 사전 훈련. arXiv 사전 인쇄 arXiv:1901.07291.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692.

이인한, 마일 오티, 나만 고얼, 주인페이 두, 만다르 조시, 단치 첸, 오머 레비, 마이크 루이스, 루크 제틀레모이어, 그리고 베셀린 스토야노프. 2019년.
Roberta: 견고하게 최적화된 bert 사전 훈련 접근 방식. arXiv 사전 인쇄물 arXiv:1907.11692.

Innocent Ndubuisi-Obi, Sayan Ghosh, and David Jur-
gens. 2019. 이 댓글들은 무슨 일이야? 나이지리아 온라인 토론에서 코드 스위칭 행동에 영향을 미치는 사회언어학적 요인 모델링. 제57회 연례 협회를 위한 계산언어학 대회 논문집, 6204-6214쪽, 이탈리아 피렌체. 계산언어학 협회.

니라지 파하리와 카즈타카 시마다. 2023. 학습 기반 접근법을 사용하여 코드 혼용에서 데이터 부족 다루기. 2023년 제13회 국제 응용 정보학 대회 (IIAI-AAI). IEEE.

파르트 팟와, 구스타보 아귈라, 수디타 카르, 수라지 판데이, 스리니바스 PYKL, 비욘 감백, 탄모이 차크라보르티, 타마르 솔로리오, 그리고 아미타바 다스.
2020년. SemEval-2020 과제 9: 코드 혼합 트윗의 감성 분석 개요. 제14회 의미 평가 워크샵 논문집, 774-790쪽, 바르셀로나 (온라인). 국제 계산 언어학 위원회.

파비안 페드레고사, 가엘 바로코, 알렉산드르 그람포, 빈센트 미셸, 베르트랑 티리옹, 올리비에 그리셀, 매튜 블론델, 피터 프레튼호퍼, 론 와이스, 빈센트 디부르그 외. 2011. Scikit-learn: 파이썬에서의 머신 러닝. 기계 학습 연구 저널, 12:2825-2830.

카나빌릴 라자고팔란. 2004. 감정과 언어 정치: 브라질 사례. 다중언어 및 다문화 발전 저널 - J MULTILING MULTICULT DEVELOP, 25:105–123.

마니칸단 라비키란과 수비아 아나말라이. 2021년.
DOSA: 드라비디언 코드믹스 공격적인 구간 식별 데이터셋. 제1회 드라비디언 언어를 위한 음성 및 언어 기술 워크샵 논문집, 10-17쪽, 키예프. 계산언어학 협회.

코우스타브 루드라, 슈루티 리즈와니, 라피야 베구, 칼리카 바리, 모노짓 초우드후리, 그리고 닐로이 강구리. 2016년. 의견과 감정 표현을 위한 언어 선호도 이해: 트위터에서 힌디어-영어 사용자는 무엇을 하는가? 2016년 자연어 처리에 대한 경험적 방법에 관한 학회 논문집, 1131-1141쪽.

Koustav Rudra, Ashish Sharma, Kalika Bali, Monojit Choudhury, and Niloy Ganguly. 2019. 트위터에서 영어-힌디어 코드 스위칭의 다양한 측면을 식별하고 분석하기. ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP), 18(3):1–28.

31
타마르 솔로리오, 엘리자베스 블레어, 수라지 마하르잔, 스티븐 베서드, 모나 디압, 마흐무드 곤임, 압델라티 하와리, 파하드 알가미디, 줄리아 히어츠버그, 앨리슨 창 등. 2014. 코드 스위칭 데이터에서 언어 식별에 대한 첫 번째 공유 작업 개요. 코드 스위칭에 대한 계산적 접근 방식에 대한 첫 번째 워크샵 논문집, 62-72쪽.

Genta Indra Winata, Samuel Cahyawijaya, Zihan Liu, Zhaojiang Lin, Anfrea Madotto, and Pascale Ngan Fung. 2021. 코드 스위칭에서 다국어 모델은 효과적인가? 제5회 언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 논문집, 142-153쪽.

토마스 울프, 리산드르 드뷔, 빅토르 산, 줄리앙 쇼몽, 클레멘 들랑, 안토니 모이, 피에리크 시스탁, 팀 롤트, 레미 루프, 모건 펀토위츠 등. 2020년. 트랜스포머: 최첨단 자연어 처리. 2020년 자연어 처리에 대한 경험적인 방법에 관한 컨퍼런스 논문집: 시스템 데모, 38-45쪽.

32
언어 전환에 대한 계산적 접근 방식 워크샵 제6회 절차, 33-42 페이지
2023년 12월 7일 ©2023 계산언어학 협회
최종 결과를 위한 텍스트 기반 언어 식별 통합

코드-스위칭 음성 인식

Qinyi Wang
싱가포르 국립대학교
qinyi@u.nus.edu

하이저우 리
싱가포르 국립대학교
홍콩 중국 대학교, 심천
haizhouli@cuhk.edu.cn

요약

코드 스위칭(CS) 말의 인식은 자동 음성 인식 시스템(ASR)에 대해 종종 도전을 제기합니다. 이는 짧은 단일 언어 세그먼트에서 언어적 맥락이 제한되어 언어 혼동을 초래하기 때문입니다. 이 문제를 완화하기 위해 언어 식별(LID)은 종종 음성 인식 시스템에 통합되어 추가적인 언어적 맥락을 제공합니다. 그러나 이전 연구들은 주로 음성 신호에서 언어 식별을 추출하는 데 초점을 맞추었습니다. 우리는 순수 텍스트 데이터에서 언어 식별을 학습하기 위한 새로운 접근법을 소개합니다. 이를 위해 언어 식별-언어 모델을 통해 언어 식별을 학습합니다. 또한, LID 상태 퓨전과 언어 후방 편향 두 가지 전략을 탐구하여 텍스트에서 유도된 언어 식별을 end-to-end ASR 시스템에 통합합니다. 가설적인 언어 식별을 통합함으로써, 우리의 ASR 시스템은 중요한 문맥적 단서를 얻어 코드 스위칭 발화 내에서 언어 전환과 패턴을 효과적으로 포착합니다. 우리는 SEAME 말뭉치에서 음성 인식 실험을 수행하고 제안한 방법의 효과를 입증합니다. 결과는 코드 스위칭 시나리오에서 크게 향상된 전사를 보여주며, 텍스트에서 유도된 LID가 코드 스위칭 음성 인식을 향상시키는 잠재력을 강조합니다.

1 소개

자동 음성 인식 (ASR) 시스템은 특히 코드 스위칭 (CS)이라고 알려진 현상이 포함된 다국어 음성을 정확하게 전사하는 복잡한 작업에 오랜 기간 동안 고민해 왔습니다. 코드 스위칭 또는 코드 혼용은 단일 대화 내에서 두 개 이상의 언어 또는 방언을 번갈아 사용하는 것을 말합니다. 이러한 복잡한 언어 혼합물 내에서 매우 짧은 단일 언어 세그먼트의 존재는 도전을 더욱 어렵게 만듭니다. 이러한 세그먼트 내에서의 제한된 문맥 정보는 종종 다른 언어의 음성적으로 유사한 단어를 인식하는 데 혼란을 야기하며, 이는 큰 어려움을 야기합니다.

다중 언어 ASR 시스템의 전반적인 성능에 영향을 미칩니다 (Amazouz et al., 2017; Yılmaz et al., 2018; Wang et al., 2019). 코드 스위칭 ASR에 대한 전통적인 접근 방식은 언어 식별 또는 코드 스위칭 감지 시스템을 별도의 전처리 또는 후처리 단계로 사용해 왔습니다. 이러한 방법은 언어 컨텍스트를 추가로 제공하는 데 효과적이었지만 (Weiner et al., 2012a; Vu et al., 2012; Zhang, 2013), ASR 파이프라인에 추가 복잡성을 도입하고 처리 시간을 증가시킵니다.

딥러닝의 발전은 다국어 및 코드 스위칭 ASR 시스템에서 혁명적인 패러다임 변화를 가져왔다. 엔드 투 엔드 (E2E) 접근 방식은 고급 신경망 아키텍처 (예: Transformer)를 활용하여 코드 스위칭 음성을 직접 전사하는 데 중요한 관심을 받았다. 이러한 E2E CS ASR 시스템은 코드 스위칭 음성의 음향 및 언어적 특성을 자동으로 포착하여 명시적인 음향 및 언어 모델링이 필요하지 않다. E2E CS ASR 시스템에서 언어 혼동을 줄이기 위해 연구자들은 언어 신원 (LID) 정보를 연결된 음성-텍스트 데이터와 비연결 음성 데이터에서 학습하는 방법을 연구했다. 그러나 이전 접근 방식은 주로 음성 데이터에서 언어 신원을 학습하는 데 초점을 맞추었으며 순수 텍스트 데이터의 잠재력을 간과했다. 주석이 달린 음성 데이터와 비교하여 텍스트 데이터는 더 접근 가능하고 즉시 사용 가능한 자원을 제공한다.

이 논문은 말 데이터에 의존하지 않고 순수 텍스트 데이터로부터 언어 전환 패턴을 학습하는 가능성을 탐구한다. 품사 태그와 구문 특징과 같은 텍스트 기반 특징은 코드 전환 언어 모델의 성능을 향상시키는 것으로 입증되었다. (Adel)

33
et al., 2013, 2015; Winata et al., 2018). 이러한 성과에 영감을 받아, 우리는 텍스트 데이터에서 언어 신원을 추론하고 이러한 텍스트 기반 언어 신원을 end-to-end CS ASR 시스템에 통합하는 것을 제안합니다. 우리의 목표는 언어 전환 구문과 패턴을 언어 신원의 형태로 텍스트 데이터에서 습득하고, 이러한 언어 신원을 활용하여 코드 스위칭 음성 인식에서 언어 혼동을 완화하는 것입니다. 우리는 도메인 내 텍스트가 본질적으로 풍부한 언어 정보를 포함하고 있으며, 이를 효과적으로 활용하여 코드 스위칭 음성 인식을 발전시킬 수 있다고 믿습니다.

텍스트 데이터로부터 코드 스위칭 패턴을 획득하기 위해 우리는 언어 식별-언어 모델이라고 불리는 새로운 언어 모델링 방법을 제안합니다. 이 모델은 이전 텍스트와 언어 식별 토큰의 결합된 이력을 기반으로 다음 텍스트 토큰의 언어 식별을 예측합니다. 제안된 언어 식별-언어 모델은 Transformer 기반 ASR 모델과 함께 공동으로 훈련됩니다. 또한, 우리는 두 가지 전략을 탐구하여 예측된 언어 식별을 E2E ASR 시스템에 통합합니다: LID 상태 퓨전과 언어 사후 확률 편향. LID 상태 퓨전 전략에서는 학습된 가중치를 사용하여 토큰 수준의 언어 식별 숨겨진 상태와 ASR 숨겨진 상태를 결합합니다. 반면, 언어 사후 확률 편향 전략은 가설된 언어 식별과 언어 사후 확률에 기반하여 ASR 사후 확률을 직접 조정합니다. 우리는 Mandarin-English 음성 데이터 세트인 SEAME 코퍼스에서 이러한 제안된 방법들의 효과를 평가합니다. 결과는 코드 스위칭 음성 인식 중 언어 혼동을 줄이는 우리의 접근 방식의 효능을 강조하며, 코드 스위칭 음성의 보다 정확한 전사를 이끌어냅니다.

이 논문의 나머지는 다음과 같이 구성되어 있습니다. 섹션 2에서는 병렬 음성-텍스트 디코더를 사용한 Transformer 기반 ASR의 배경을 검토합니다. 섹션 3에서는 다국어 및 코드 스위칭 음성 인식에서 언어 식별을 활용하는 관련 연구를 제시합니다. 섹션 4에서는 순수 텍스트 데이터에서 언어 식별을 생성하기 위한 제안된 LID-LM과 LID 통합 전략을 제시합니다. 섹션 5에서는 제안된 방법의 성능을 평가하기 위해 사용된 데이터셋, 모델 및 평가 지표를 설명합니다. 섹션 6에서는 실험의 결과와 분석을 제시합니다. 마지막으로, 섹션 7에서는 기여 내용을 요약하고 향후 연구 방향을 개괄합니다.

그림 1: 병렬 음성-텍스트 디코더를 가진 Transformer 기반 ASR의 아키텍처.

2 배경

이 섹션에서는 우리가 우리의 방법을 구현하는 데 사용한 병렬 음성-텍스트 디코더와 함께 Transformer 기반 ASR 아키텍처를 간단히 검토합니다.

2.1 병렬 음성-텍스트 디코더를 갖춘 트랜스포머

음성-텍스트 변환기 기반의 ASR을 기준 모델로 사용합니다. 이 모델은 그림 1에 나와 있는 것과 같이 병렬 음성-텍스트 디코더 아키텍처를 사용합니다. 이 디코더 아키텍처는 음성-텍스트 변환기(Wang et al., 2023)의 디코더 아키텍처의 변형입니다. 예비 연구 결과, 이 디코더 아키텍처는 단일 언어 및 코드 스위칭 영어와 중국어 음성 인식 작업에서 바닐라 트랜스포머 디코더 아키텍처보다 우수한 성능을 보입니다.
병렬 음성-텍스트 디코더는 K개의 동일한 디코더 블록으로 구성됩니다. 각 디코더 블록은 두 개의 병렬 분기로 구성되어 있습니다: 깊은 음향 분기와 음성 디코딩 분기입니다. 깊은 음향 분기의 포함은 음향 표현을 텍스트 표현과 비교 가능한 추상 수준으로 변환하여 음성-텍스트 정렬의 학습을 용이하게 합니다.
깊은 음향 분기는 새로운 깊은 음향 표현을 생성합니다.

34
그림 2: (왼쪽) 이중 모달리티 주의 모듈
이중 모달리티 스케일드 닷-프로덕트 주의를 채택한 모듈입니다.
(오른쪽) 이중 모달리티 스케일드 닷-프로덕트 주의입니다.

다음과 같이 이전 블록의 깊은 음향 상태를 고려하여 음향 상태 H(k)를 결정합니다.

H(k) = STDecBlock(H(k −1)). (1)
H(k) = STDecBlock(H(k −1)). (1)

한편, 음성 해독 분기는 다음과 같이 이전 블록의 디코더 상태와 깊은 음향 상태에 주목하여 디코더 상태 Y(k)를 생성합니다.

Y (k) = STDecBlock(Y (k −1),H(k −1)). (2)
Y (k) = STDecBlock(Y (k −1),H(k −1)). (2)

마지막으로, 완전한 음향 특성 시퀀스와 이전 텍스트 토큰 기록이 주어졌을 때, 다음 텍스트 토큰의 확률은 마지막 디코더 블록에서 생성된 디코더 상태를 사용하여 다음과 같이 계산됩니다.

P(yn|X,y1:n −1) = 소프트맥스(선형(레이어 정규화(Y(K)))).

(3) 

1. Can you please help me with this?
2. I am sorry, I don't understand.
3. Where is the nearest bus stop?
4. How much does this cost?
5. What time does the movie start?
6. Do you have any recommendations?
7. Can I pay with credit card?
8. Excuse me, where is the restroom?
9. Is there a pharmacy nearby?
10. Can you speak English?

2.2 이중 모달 어텐션

병렬 음성-텍스트 디코더의 또 다른 주요 기능은 이용되는 이중 모달리티 어텐션 메커니즘입니다. 이는 우리의 음성-텍스트 트랜스포머 프레임워크에서 제안된 온디맨드 이중 모달리티 어텐션의 변형입니다. 그림 2에 나타난 것처럼, 이 메커니즘은 쿼리와 두 개의 키-값 쌍을 출력 표현으로 매핑함으로써 텍스트-텍스트 표현과 텍스트-음성 표현 간의 의존성을 설정합니다. 이중 모달리티 어텐션은 다음과 같이 정의됩니다.

듀얼 모달리티 어텐션(Qt,Kt,Vt,Ks,Vs)

소프트맥스
(cid:18)QtKT
c
√d
(cid:19)Vc.
(4)
이 다중 헤드 어텐션 메커니즘은 다섯 개의 입력 벡터를 가지고 있습니다 - 쿼리와 두 개의 키-값 쌍 세트: 대상 쿼리 Qt, 대상 키 Kt, 대상 값 Vt, 소스 키 Ks 및 소스 값 Vs. 여기서 Kc는 Kt와 Ks의 연결이고, Vc는 Vt와 Vs의 연결입니다.

3 관련 연구

언어 식별은 다양한 다국어 음성 처리 응용 프로그램에서 중요한 역할을 합니다. 특히, 다국어 또는 코드 스위칭 음성 인식 시스템에서 중요한 역할을 합니다. 이는 음성 인식기를 조절하고 언어 혼동을 줄이는 가치 있는 문맥 정보를 제공합니다. 초기 다국어 ASR 시스템은 두 단계 접근법을 채택했습니다. 언어 식별 구성 요소가 전단에 통합되어 다른 언어의 음성을 구별하고, 그 후에 단일 언어 인식기를 사용하여 특정 언어의 음성을 전사합니다. 이후, 전용 언어 식별 모듈에 의해 예측된 프레임 수준의 언어 식별이 ASR 디코딩 프로세스에 통합되어 빠른 언어 변경을 처리합니다.
딥러닝의 발전으로 인해, 언어 식별을 보조 작업으로 포함시키는 방향으로 전환되었습니다. 이는 end-to-end 다국어 및 코드 스위칭 음성 인식 시스템과 함께 공동으로 학습됩니다. 또한, Seki et al. (2018)는 언어 식별 모듈의 필요성을 없애기 위해 음성 전사에서 코드 스위칭 지점 앞에 언어 식별 토큰을 추가하여 코드 스위칭 발화에서 언어 식별을 동적으로 추적합니다. 이 LID 토큰 증강 방법은 (Zhang et al., 2021)에서도 사용되며, 텍스트의 단어 임베딩과 다른 언어의 언어 임베딩을 연결하여 단어 임베딩 간의 구별성을 더욱 향상시킵니다.
그러나 기존 연구는 주로 음성 신호에서 언어 식별을 추출하는 데 집중되어 있습니다. 대조적으로, 우리의 연구는 새로운 접근법을 취하여 원시 텍스트 데이터에서 언어 식별을 직접 학습하는 가능성을 탐구합니다. 텍스트 데이터 내의 풍부한 언어 정보를 활용하여 end-to-end 코드 스위칭 음성 인식에서 언어 혼동을 줄이는 것을 목표로 합니다.

35
(a) LM (엘엠)
(b) LID-LM (리드-엘엠)

그림 3: LM과 LID-LM의 설명. LM은 이전 텍스트 토큰 기록을 바탕으로 다음 텍스트 토큰을 예측하며, LID-LM은 이전 보강된 언어 식별 및 텍스트 토큰 기록을 바탕으로 다음 언어 식별 토큰 또는 다음 텍스트 토큰을 예측한다.

시스템은 더 정확한 전사를 이끌어냅니다.

4 제안된 방법

4.1 언어 정체성-언어 모델

언어 모델의 목표는 단어 시퀀스에 확률을 할당하는 것입니다. N 길이의 텍스트 토큰 시퀀스 Y = {y1,...,yn,...,yN}를 고려해 봅시다. 신경 언어 모델의 목표는 이전 텍스트 토큰 이력 y1:n-1이 주어졌을 때 어휘 V에 대한 확률 분포 P(yn|y1:n-1)를 예측하는 것입니다. 언어 모델에 언어 식별 정보를 명시적으로 통합하기 위해, 우리는 언어 식별 언어 모델(LID-LM)이라는 새로운 언어 모델 체계를 소개합니다. 이 모델은 각 텍스트 토큰 앞에 삽입된 언어 식별 정보가 포함된 토큰 시퀀스를 입력으로 사용합니다. 그림 3은 원래의 언어 모델과 제안된 LID-LM을 비교한 것입니다. 언어 식별 정보를 출력 토큰 집합에 통합함으로써 언어 모델을 보강하여 텍스트 데이터에서 미묘한 언어별 특성과 코드 스위칭 패턴을 포착할 수 있게 됩니다. 이 LID 토큰 증강 기술은 ASR 시스템에서 언어 혼동을 줄이는 데 효과적임이 입증되었습니다 (Seki et al., 2018; Zhang et al., 2021). 텍스트 토큰 시퀀스에 언어 식별 정보를 추가함으로써 LID-LM은 음성 데이터에 의존하지 않고 언어 식별을 예측하는 혁신적인 방법을 제공합니다.
LID-LM 내에서 언어 식별 정보를 수용하기 위해, 우리는 확장된 어휘 V' = V ∪ Vlid를 사용합니다. 여기서 Vlid는 언어 식별 토큰의 집합을 나타냅니다. 확장된 2N 길이의 시퀀스 Z = {z1,...,zn,...,z2N}는 언어 식별 토큰과 텍스트 토큰이 번갈아 배열된 것에 해당합니다.

언어 식별 토큰과 텍스트 토큰으로 이루어진 시퀀스입니다. 홀수 인덱스 토큰은 언어 식별 토큰을 나타내고, 짝수 인덱스 토큰은 텍스트 토큰을 나타냅니다. LID-LM은 언어 식별 및 텍스트 토큰의 이전 시퀀스 z1:2n-1 또는 z1:2n-2에 기반하여 다음 텍스트 토큰 z2n 또는 다음 언어 식별 토큰 z2n-1의 확률을 예측하는 것을 목표로 합니다.
최적화를 위해, 우리는 LID-LM의 손실 함수로 교차 엔트로피 손실을 채택합니다. 이 손실 함수는 예측된 토큰 분포와 실제 레이블 분포 사이의 차이를 측정하며, 훈련 데이터의 총 토큰 수로 정규화됩니다. 이 손실을 Llid-lm으로 표기합니다. LID 통합 방법을 설명하는 후속 하위 섹션에서는 다음 공식을 사용하여 LID-LM이 ASR 모델과 함께 공동으로 훈련됩니다.

Ljoint = α Lctc + (1 − α) Latt + β Llid −lm, (5)
여기서 Lctc와 Latt는 CTC 손실과 하이브리드 CTC/어텐션 ASR 모델의 라벨 스무딩 손실을 나타내며, Llid −lm은 LID-LM의 교차 엔트로피 손실을 나타냅니다. 가중치 α와 β는 각 손실 요소의 기여도를 제어하여 ASR 및 LID-LM 구성 요소에 대한 균형 잡힌 최적화를 가능하게 합니다.
훈련 과정에서는 랭귀지 식별자가 포함된 음성 전사를 입력 텍스트로 사용하여 랭귀지 식별자-랭귀지 모델을 훈련시킵니다. 이를 통해 LID-LM이 올바른 랭귀지 식별자를 해당 텍스트 토큰과 연관시키는 방법을 학습하게 됩니다.
디코딩 과정에서는 ASR 모델의 이전 디코딩된 텍스트 토큰과 해당하는 랭귀지 식별자를 LID-LM의 이전 토큰 히스토리로 포함시킵니다. 이로써 LID-LM은 ASR 모델의 이전 출력 전사에 기반하여 랭귀지 식별자 예측을 생성하도록 제한됩니다. 또한, ASR과 LID-LM 모델 사이의 텍스트 임베딩 가중치를 공유합니다. 이 매개변수 공유는 ASR 모델이 LID-LM이 제공하는 랭귀지 식별자를 이후 하위 섹션에서 설명하는 통합 전략에 활용하고 이해할 수 있도록 합니다.

4.2 LID 상태 퓨전

이전 연구에서는 다국어 음성 인식에서 언어별 게이팅 메커니즘의 효과가 입증되었습니다 (Kim and Seltzer, 2018). 그들의 접근 방식에서 ASR 시스템은 사용합니다.

36
도표 4: LID 상태 융합 방법의 개략적인 표현.

한 레이어에서 각각의 숨겨진 상태를 변조하기 위해 언어 표시자로서의 원-핫 벡터를 사용합니다. 이 동기에 기반하여, 우리는 LID 상태 융합에 대한 새로운 접근 방식을 제안합니다. 이 접근 방식은 LID-LM에 의해 생성된 언어별 정보를 이용하여 ASR을 가이드하기 위해 게이팅 메커니즘을 사용합니다. 구체적으로, ASR 시스템은 언어 식별 상태를 자신의 디코더 출력 상태에 융합함으로써 언어 식별 정보를 통합합니다. LID-LM이 제공하는 언어별 정보를 활용하여 ASR 시스템은 언어 식별 상태에 내재된 언어 지식과 신뢰 수준에 따라 코드 스위칭 시나리오에서 예측을 효과적으로 적응시킬 수 있습니다.
LID 상태 융합 방법은 그림 4에 설명되어 있습니다. 우리는 LID-LM에서 언어 식별 및 텍스트 토큰의 과거 토큰 시퀀스 z1:2n-2를 이용하여 토큰 수준의 LID 숨겨진 상태 ZLID를 생성합니다. 동시에, 음성-텍스트 디코더의 마지막 디코더 블록에서 숨겨진 상태 Y(K)에 레이어 정규화를 적용하여 정규화된 디코더 숨겨진 상태를 생성합니다.

YDEC = 레이어 정규화(Y (K)). (6)

다음으로, 우리는 토큰 수준의 LID 표현을 정규화된 디코더의 은닉 상태와 융합하여 상태 융합 게이트를 생성합니다. 이를 통해 결합된 표현 YFUS가 생성됩니다. 상태 융합 게이트는 Sriram et al. (2018)의 연구에서 영감을 받은 게이팅 메커니즘을 사용하여 계산됩니다.

G = 시그모이드(선형(연결(YDEC,ZLID))),

(7) 

Please give me a glass of water.

ZGATED = MatMul(G,ZLID), (8) 
ZGATED = G와 ZLID의 행렬곱, (8)

테이블 1: CS 실험에 사용된 SEAME 코퍼스의 데이터셋 통계.

시간
말
중국어 영어 CS 총계
훈련 96 20,313 20,283 48,342 88,938
개발 5 1,163 1,152 2,685 5,000
평가(남성) 7 1,420 808 4,303 6,531
평가(여성) 4 500 2,656 2,165 5,321

YFUS = 선형(연결(YDEC,ZGATED)).

(9)
마지막으로, 완전한 음향 특성 시퀀스, 이전 텍스트 토큰 기록 및 이전 텍스트 및 LID 토큰 기록이 주어졌을 때, 다음 텍스트 토큰의 출력 확률을 다음과 같이 계산합니다.

P(yn|X,y1:n −1,z1:2n −1) = 소프트맥스(선형(YFUS)).

(10)

4.3 언어 후방 편향화

ASR 시스템의 사후 확률을 언어 식별 구성 요소에 의해 생성된 외부 또는 내부 언어 사후 확률을 사용하여 조정하는 것은 코드 스위칭 ASR 시스템의 성능을 향상시키는 것으로 입증되었습니다 (Liu et al., 2023; Tseng et al., 2021; Li et al., 2019). 본 연구에서는 언어 식별-언어 모델에서 얻은 토큰 수준의 언어 사후 편향 방법의 효과를 조사합니다.
언어 사후 편향 방법에서는 먼저 LID-LM을 사용하여 토큰 수준의 언어 사후 확률 P(z2n −1|zz1:2n −2)을 생성합니다. 그런 다음 다음 공식을 기반으로 ASR의 사후 확률을 해당 언어 사후 확률에 따라 조정합니다.

Pbias(yn|X,y1:n −1) = P(yn|X,y1:n −1) × P(z2n −1|z1:2n −2)

(11) 
나는 한국 음식을 좋아해요.

여기서 P(yn|X,y1:n −1)은 텍스트 토큰 yn에 대한 원래 ASR 사후 확률을 나타냅니다. P(z2n −1|z1:2n −2) 용어는 언어 식별 토큰 z2n −1에 대한 언어 사후 확률을 나타내며, 이는 언어 식별-언어 모델에서 얻어집니다.

5 실험 설정

5.1 데이터셋

제안된 방법의 효과를 평가하기 위해, 우리는 언어 식별 및 코드 스위칭 음성 인식 실험을 진행합니다.

37
SEAME Mandarin-English 연설 말뭉치 (Lyu et al., 2010). 이 말뭉치는 싱가포르와 말레이시아 대학생 및 직원들로부터 수집된 약 110시간의 자발적 코드 스위칭 말을 포함하고 있습니다. 녹음은 인터뷰 및 대화 상황에서 근거리 마이크로폰을 사용하여 수집되었습니다. 이 말뭉치에는 문장 간 및 문장 내 코드 혼용 발화뿐만 아니라 단일 언어 발화도 포함되어 있습니다.
ASR 실험에서는 SEAME 훈련 세트를 개발 세트 dev.와 훈련 세트 train으로 분할했습니다. 구체적으로, 5,000개의 발화를 임의로 선택하여 dev. 세트를 구성하였으며, 나머지 쌍 데이터는 train 세트로 사용되었습니다.
평가 세트인 evalman과 evalsge는 표 1에 요약된 대로 단일 언어의 만다린어, 영어 및 만다린어-영어 코드 스위칭 발화의 분포가 다양합니다. evalman 세트는 주로 단일 언어의 만다린어와 코드 스위칭 발화로 구성되어 있으며, evalsge 세트는 단일 언어의 영어 발화의 비율이 더 높습니다.
LID 실험에서는 위의 세트의 전사를 수동으로 보강하여 각 텍스트 토큰의 시작에 해당하는 언어 식별 토큰을 삽입했습니다. 만다린어-영어 언어 쌍을 사용하고 있기 때문에 중국어 문자와 영어 알파벳의 구별은 쉽게 알아볼 수 있습니다. 일관성과 표준화를 보장하기 위해, 우리는 ESPnet (Watanabe et al., 2018)에서 제공하는 기본 SEAME 레시피를 사용하여 중국어와 영어 토큰을 구별했습니다. 따라서 실험 설정 내에서는 상호 평가자 일치가 필요하지 않았습니다.

5.2 구현 세부사항

사전. 영어와 중국어 언어 및 해당 언어 식별을 효과적으로 모델링하기 위해, 우리는 추가적인 언어 식별 토큰을 포함한 이중 언어 사전을 구축합니다. 영어의 경우, 우리는 SEAME 훈련 세트의 영어 전용 전사에 바이트-페어 인코딩(BPE)을 적용하여 서브워드 유닛을 생성하고, 모델링 단위로 3,000개의 어휘 크기를 얻습니다. 중국어의 경우, 우리는 세 개의 비대칭 텍스트 데이터셋에서 추출한 5,103개의 자주 사용되는 중국어 문자를 선택합니다. 언어를 표현하기 위해

텍스트 토큰의 신원을 확인하기 위해, 우리는 출력 단위에 LID 토큰을 도입합니다. 구체적으로, 우리는 ⟨en⟩, ⟨man⟩, 그리고 ⟨na⟩를 포함시킵니다.

⟩ to represent unknown words, the start of a sentence, and the end of a sentence, respectively.

⟩
알 수 없는 단어, 문장의 시작, 문장의 끝을 처리하기 위해 각각 다음과 같은 방법을 사용합니다.
모델. 우리 실험에서 사용한 Transformer 기반 ASR 모델은 8개의 인코더 레이어와 6개의 병렬 음성-텍스트 디코더 레이어로 구성됩니다. 얕은 융합을 위해 사용된 LID-LM과 외부 LM은 모두 6개의 Transformer 디코더 레이어 모델입니다. 모든 모델은 출력 차원이 256이고, 내부 레이어 차원이 2,048이며, 4개의 어텐션 헤드를 가지고 있습니다. 제안된 두 가지 LID 통합 방법에 대해서는 LID-LM이 ASR 모델과 함께 처음부터 공동으로 훈련됩니다. ASR 모델에는 초기 학습률이 1.0인 Adam 최적화 알고리즘을 사용하고, 언어 모델에는 초기 학습률이 1.0 × 10^(-4)인 Adam 최적화 알고리즘을 사용합니다. 학습률을 조정하기 위해 ASR 모델에는 Noam 학습률 스케줄러(Vaswani et al., 2017)를 사용하며, 25,000개의 웜업 스텝을 사용합니다. 언어 모델에는 코사인 감소 스케줄러(Loshchilov and Hutter, 2016)를 사용하며, 초기 스텝은 1,000개이고 총 스텝은 100,000개입니다. 과적합을 방지하기 위해 모든 모델에 대해 드롭아웃 정규화를 0.1의 비율로 적용합니다. 모든 모델은 50 에포크 동안 훈련됩니다. CTC 가중치 α는 훈련 중 모든 모델에 대해 0.3으로 설정되고, 디코딩 중에는 0.5로 설정됩니다. LID-LM 가중치 β는 훈련 중 0.7로 설정됩니다. 추론을 위해 최적의 모델을 선택하기 위해 검증 세트에서 성능에 기반하여 상위 10개 에포크의 매개변수를 평균화합니다.
평가. LID-LM의 토큰 수준 언어 식별 정확도를 보고합니다. ASR 평가에는 Mix Error Rate (MER)를 성능 지표로 사용합니다. MER은 영어 토큰의 단어 오류율 (WER)과 중국어 토큰의 문자 오류율 (CER)을 결합합니다. 이 평가 지표는 만다린-영어 코드 스위칭 문맥에서 영어와 중국어 언어를 모두 전사하는 ASR 모델의 정확도를 포괄적으로 평가합니다.

6 결과 및 토론

6.1 언어 식별 정확도

on a large multilingual corpus, is a language
identification model that uses a language model
approach. We evaluate its performance on a
benchmark dataset consisting of audio samples
from various languages. The results show that
the LID-LM achieves high accuracy in correctly
identifying the languages in the dataset.

38
표 2: SEAME: evalman 및 evalsge 세트에서의 MER. 상단 섹션: LID 통합 방법에 대한 E2E ASR 시스템 (IV 절에서 논의됨). 하단 섹션: 우리가 제안한 LID 통합 방법을 사용한 Transformer 기반 ASR 모델.

모델                방법

MER%
Evalman Evalsge
GRU 기반 인코더-디코더 (Luo et al., 2018)

기준선 35.4 37.8
LID 공동 학습 34.1 36.5
BLSTM 기반 인코더-디코더 (Zeng et al., 2018)

기준선 26.4 36.1
LID 공동 학습 26.0 35.8
LSTM 기반 변환기 (Zhang et al.,
2021)

기준선          33.3  44.9
CS 포인트 태그된 텍스트 30.2 41.5

트랜스포머 기반
인코더-디코더와
병렬 음성-텍스트 디코더

기준선          21.4  29.5
얕은 퓨전    21.0  29.0
LID 상태 퓨전  20.4  28.2
언어 사후 편향 21.3 29.2

SEAME 훈련 세트의 증강된 전사를 사용하여, evalman 및 evalsge 세트에서 토큰 수준의 LID 정확도가 각각 78.7%와 80.1%를 달성합니다. 이 정확도는 음향 특성을 사용하여 프레임 수준의 LID 예측을 생성하는 (Weiner et al., 2012b)의 70.6%에 이르는 이전에 보고된 LID 정확도를 능가합니다. 이 결과는 텍스트 데이터에 포함된 언어 정보의 풍부함을 강조하며, 문법 및 언어 전환 패턴과 관련된 가치 있는 언어적 단서를 제공할 수 있는 능력을 나타냅니다. 따라서, 우리의 연구 결과는 코드 스위칭 음성 인식 시스템에서 정확하고 견고한 언어 식별을 위해 LID-LM을 활용하는 잠재력을 강조합니다.

6.2 ASR 결과

우리는 SEAME 평가 세트인 evalman과 evalsge에서 다양한 방법의 음성 인식 성능을 평가합니다. 표 2의 상단 부분은 엔드 투 엔드 ASR 시스템에 대한 이전 LID 통합 방법의 성능을 보여줍니다. 이러한 방법들은 SEAME 평가 세트에서 약간부터 중간 정도의 개선을 보입니다. 그 중에서도 Zhang et al. (2021)이 제안한 CS 포인트 태깅 텍스트 방법은 evalman 및 evalsge 세트에서 상대적인 MER 감소율이 각각 9.3%와 7.6%로 가장 큰 개선을 이루어 냅니다.
표 2의 하단 부분은 우리의 Transformer 기반 ASR 시스템과 우리가 제안한 LID 통합 방법의 성능을 요약합니다. Transformer 기반 ASR 기준선은 각각 evalman과 evalsge 세트에서 21.4%와 29.5%의 MER를 달성합니다. 훈련 트랜스크립트에서 훈련된 외부 언어 모델과의 얕은 퓨전은 추가 개선을 이루어 냅니다.

위의 결과는 LID 상태 퓨전에서 학습된 게이팅 매개변수가 ASR 시스템이 언어 식별-언어 모델에서 제공되는 문맥적 단서를 효과적으로 통합하고 활용할 수 있도록 하는 데 중요한 역할을 한다는 것을 시사합니다. LID 숨겨진 상태의 기여를 동적으로 조정함으로써 ASR 시스템은 언어별 패턴과 전이를 더 잘 포착하여 코드 스위칭 음성 인식 성능을 향상시킵니다. 반면, LID 후방 퓨전 방법은 이러한 자동 조정 메커니즘을 가지고 있지 않아 언어 식별 모듈에서 오류 전파에 취약한 시스템이 됩니다. 결과적으로, 언어 식별을 활용하여 음성 인식 성능을 향상시키는 효과는 이 접근 방식에서 방해받습니다.

6.3 오류 분석

상태 퓨전 방법을 사용한 ASR 모델과 Transformer 기반 ASR 모델의 음성 인식 성능을 파악하기 위해, 우리는 세 가지 다른 발화 유형(단일 언어의 만다린어, 단일 언어의 영어, 코드 스위칭 만다린어-영어)에 대한 인식 오류 분석을 수행했습니다. 그림 5는 devman과 devsge 세트에서 이러한 카테고리의 오류 횟수를 보여줍니다.
이 그림은 LID 상태 퓨전의 채용을 보여줍니다.

39
(a) 개발자 세트에서의 오류 횟수

(b) 개발자 세트에서의 오류 횟수

그림 5: devman 및 devsge 세트에서의 오류 횟수
세 가지 발화 범주에 걸친 것입니다. 만다린 발화의 경우, 오류 횟수는 문자 오류 횟수를 의미합니다.
영어 발화의 경우, 오류 횟수는 단어 오류 횟수를 의미합니다.
코드 스위칭 발화의 경우, 오류 횟수는 혼합 오류 횟수를 의미합니다.

상태 퓨전 방법은 코드 스위칭 발화의 오류 수를 상당히 줄입니다. 특히, 우리는 devman 및 devsge 세트에서 각각 4.9%와 5.6%의 오류 수 감소를 관찰했습니다. 이는 LID 상태 퓨전 방법이 언어 혼동을 효과적으로 완화하고 전체 시스템 성능을 향상시킨다는 것을 나타냅니다. 더욱이, 분석 결과 LID 상태 퓨전 방법은 코드 스위칭 발화보다는 적지만 단일 언어의 만다린 발화 및 영어 발화의 오류 수도 감소시킵니다. 이 관찰은 언어 식별 정보의 통합이 ASR 시스템이 언어별 패턴과 전환을 더 잘 포착하여 단일 언어 상황에서도 인식 정확도를 향상시킨다는 것을 시사합니다.
또한, 우리는 두 개의 ASR 모델인 Transformer 기반 ASR 모델(기준 모델이라고 함)과 LID 상태 퓨전 방법을 사용한 Transformer 기반 ASR 모델(퓨전 모델이라고 함)에 의해 생성된 코드 스위칭 전사 예제를 분석합니다. 결과는 표 3에 제시되었습니다. 전반적으로, 전사는

표 3: 기준선 및 퓨전 모델에 의해 생성된 참고문과 전사의 예시. 인식 오류(****는 삭제를 의미)는 빨간색으로 표시되었습니다.

Transcription
참고 자료 대강 그 치즈는 대강 25정도야
Baseline 대강이라고 그 치즈는 대강 25정도야
Fusion 대강 그 치즈는 대강 25정도야
참고 자료 크리스마스가 다가오고 있어서 준비는 했어?
Baseline 크리스마스가 다가오고 있어서 **** 준비는 했어?
Fusion 크리스마스가 다가오고 있어서 준비는 했어?
참고 자료 나는 당연히 좋은 걸 사야지, 맞지?
Baseline 나는 다들 좋은 걸 사야지, 맞지?
Fusion 나는 당연히 좋은 걸 사야지, 맞지?
참고 자료 20%인지 2%인지 1000이 아니라 200이야
Baseline 그럼 20%인지 2%인지
Fusion 20%인지 2%인지 1000이 아니라 200이야
참고 자료 너는 너 자신이 매우 맞아? 
Baseline 너는 너 자신이 매우 뚱뚱해? 
Fusion 너는 너 자신이 매우 맞아?

융합 모델에 의해 생성된 문장은 기준 모델로 생성된 것과 비교하여 우수한 의미론적 및 문법적 정확성을 보였으며, 특히 단일 언어 세그먼트 문맥이 짧을 때 더욱 두드러졌다. 이러한 결과는 LID 상태 융합 방법이 코드 스위칭 음성 인식과 관련된 문제에 대처하는 데 효과적임을 강조한다. 언어 식별 정보가 제공하는 문맥적 단서를 활용함으로써 ASR 시스템은 언어 간 구별과 정확한 전사를 더욱 능숙하게 수행할 수 있다. 코드 스위칭 발화의 성공적인 전사는 LID 상태 융합 방법이 언어 혼동을 완화하고 복잡한 언어 환경에서 시스템의 성능을 향상시킬 수 있는 능력을 강조한다.

7 결론

이 논문에서는 순수 텍스트 데이터로부터 언어 식별을 예측하기 위한 새로운 언어 식별-언어 모델 체계를 제안했습니다. 이를 통해 음성 데이터에 의존하지 않고 언어 식별을 할 수 있습니다. 또한 텍스트 기반 언어 식별 단서를 ASR 모델에 효과적으로 통합하기 위해 두 가지 혁신적인 방법을 탐구했습니다. SEAME 말뭉치에서의 코드 스위칭 음성 인식 실험 평가는 우리의 방법의 효과를 입증했습니다. 언어 식별 정보를 통합함으로써, 우리의 ASR 시스템은 코드 스위칭 발화의 언어 혼동을 크게 줄이고, 단일 언어 및 코드 스위칭 발화에 대해 보다 정확한 전사를 제공합니다. 향후 연구에는 LID-LM 아키텍처의 추가 개선이 포함됩니다.

40
건축 및 추가 통합 전략 조사
ASR 시스템에서 언어 신원 정보를 더 효과적으로 활용하기 위해. 또한, LID-LM에 대한 사전 훈련 및 세부 조정 기술을 탐색함으로써 텍스트 데이터를 효율적으로 활용하여 언어 신원을 예측하는 더 많은 가능성을 열 수 있습니다.

제한사항

우리의 연구는 텍스트 기반 언어 식별 기술의 혁신적인 활용을 통해 코드 스위칭 ASR 시스템의 발전에 상당한 진전을 이루었지만, 고려해야 할 몇 가지 제한 사항이 있습니다. 첫째, 우리의 접근 방식은 텍스트 데이터가 언어 식별 정보를 충분히 포착한다는 가정에 의존합니다. 이 가정은 많은 맥락에서는 성립하지만, 특정 코드 스위칭 환경에서의 언어 다양성의 풍부함을 완전히 포괄하지 못할 수도 있습니다. 둘째, 우리의 방법의 성능은 다른 언어 쌍, 방언 또는 도메인에 따라 다를 수 있습니다. 이러한 변동에 대한 접근 방식의 견고성은 다양한 언어 환경에서의 추가적인 검토와 검증을 통해 개선될 수 있습니다. 마지막으로, 우리의 연구는 텍스트 기반 언어 식별 단서를 ASR 모델에 통합하기 위한 특정 통합 전략 (LID 상태 퓨전 및 언어 사후 편향)을 탐구합니다. 앞으로의 연구에서는 대안적인 전략이나 혼합 접근 방식이 더욱 발전된 코드 스위칭 ASR 시스템을 위해 탐구되어야 할 것입니다. 이러한 제한 사항은 인정되었지만, 이 연구에서 마련한 기반을 확장하기 위한 미래 연구의 기회로 간주되어야 합니다.

참고문헌

HeikeAdel, NgocThangVu, KatrinKirchhoff, Dominic Telaar, and Tanja Schultz. 2015. 코드 스위칭 팩터드 언어 모델을 위한 구문 및 의미적 특징. IEEE/ACM 오디오, 음성 및 언어 처리 트랜잭션, 23(3):431–440.

헤이케 아델, 응 탁 부, 프란치스카 크라우스, 팀 슐리페, 하이조우 리, 탄야 슐츠. 2013. 코드 스위칭 대화 음성을 위한 재귀 신경망 언어 모델링. 2013 IEEE 국제 음향, 음성 및 신호 처리 학회 논문집, 8411-8415쪽. IEEE.

Djegdjiga Amazouz, Martine Adda-Decker, 그리고 Lori Lamel. 2017. 프랑스어/알제리 아라비아어 말에서 코드 스위칭 다루기. Interspeech 2017에서, 페이지 62-66.

키란 부바나기리와 수닐 코파라푸. 2010년. 혼합 언어 자동 음성 인식에 대한 접근 방식. 오리엔탈 코코스다, 카트만두, 네팔.

실다르트 달미아, 유종 리우, 스리칸트 로난키, 그리고 카트린 키르훌프. 2021. 코드 스위칭 음성 인식을 위한 트랜스포머-트랜스듀서. ICASSP 2021-2021 IEEE 국제 음향, 음성 및 신호 처리 컨퍼런스(ICASSP), 페이지 5859-5863. IEEE.

수연 김과 마이클 L 셀처. 2018. 언어-보편적인 엔드 투 엔드 음성 인식을 향하여. 2018년 IEEE 국제 음향, 음성 및 신호 처리 학회(ICASSP)에서 발표된 논문, 4914-4918쪽. IEEE.

Chia-Yu Li와 Ngoc Thang Vu. 2019. 중국어-영어 코드 스위칭을 위한 엔드 투 엔드 자동 음성 인식에서 지식 통합. 2019 아시아 언어 처리 국제 컨퍼런스 (IALP)에서 160-165쪽. IEEE.

Ke Li, Jinyu Li, Guoli Ye, Rui Zhao, and Yifan Gong.
2019년. 엔드 투 엔드 CTC 모델을 위한 코드 스위칭 ASR을 향하여.
ICASSP 2019-2019 IEEE 국제 음향, 음성 및 신호 처리 컨퍼런스(ICASSP)에서, 페이지 6076-6080.
IEEE.

헉신 리우, 하이화 쉬, 레이브니 파올라 가르시아, 앤디 WH
콩, 이 희, 그리고 산지브 쿠다푸르. 2023년. 토큰 수준 언어 다이어라이제이션을 사용한 코드 스위칭 음성 인식을 위한 언어 혼동 감소. ICASSP 2023-2023 IEEE 국제 음향, 음성 및 신호 처리 컨퍼런스(ICASSP), 1-5쪽. IEEE.

이리야 로슈칼로프와 프랭크 허터. 2016. Sgdr: 따뜻한 재시작을 통한 확률적 경사 하강법. 학습 표현에 대한 국제 학회에서 발표.

네 루오, 동웨이 장, 쇼지앙 조, 카이샤 공,
웨이 조우, 그리고 샹강 리. 2018년. 엔드-투-엔드 코드 스위칭 음성 인식을 향하여. arXiv 사전 인쇄 arXiv:1810.13091.

대우 청, 렌 위안 청, 유앙친 치앙, 그리고 춘난 슈. 2006. 중국어 방언 간의 코드 스위칭에 대한 음성 인식. 2006년 IEEE 국제 음향, 음성 및 신호 처리 학회 논문집, 1권, I-I쪽. IEEE.

다우-청 류, 티엔-핑 탄, 엥 산 총, 그리고 하이저우 리. 2010년. 동남아시아에서의 중국어-영어 코드 스위칭 음성 말뭉치인 Seame. 국제 음성 의사소통 협회 제11회 연례 회의에서 발표.

수라비 푼자비, 하리시 아르시케레, 제이납 라이시, 찬더 찬닥, 니킬 브하베, 안키시 반살, 마르쿠스 뮐러, 세르지오 무릴로, 아리야 라스트로우, 스리 가리멜라 등. 2020년. 언어 식별과 함께하는 스트리밍 엔드 투 엔드 이중 언어 asr 시스템. arXiv 사전 인쇄 arXiv:2007.03900.

지멍 취, 이이유안 리, 신지안 리, 플로리안 메츠, 윌리엄 M 캠벨, 그리고 아마존 알렉사 AI. 2020. 
맥락에 따른 end-to-end 코드 스위칭 음성 인식을 향하여. INTERSPEECH에서, 페이지 4776-4780.

히로시 세키, 신지 와타나베, 타카아키 호리, 조나단 르 루, 그리고 존 R 허시. 2018. 혼합 언어 음성을 위한 종단 간 언어 추적 음성 인식기. 2018년 IEEE 국제 음향, 음성 및 신호 처리 학회(ICASSP) 논문집, 페이지 4919-4923. IEEE.

창하오 산, 차오 웡, 광센 왕, 단 수,
민 루오, 동 유, 레이 셰. 2019. 중국어-영어 코드 스위칭을 위한 엔드 투 엔드 음성 인식 연구. ICASSP 2019-2019 IEEE 국제 음향, 음성 및 신호 처리 학회 (ICASSP)에서 발표된 논문, 6056-6060쪽. IEEE.

아누룹 스리람, 희우 준, 산지브 사티쉬, 그리고 아담 코츠. 2018년. Cold fusion: 언어 모델과 함께 seq2seq 모델을 훈련시키기. In Proc. Interspeech 2018, 페이지 387-391.

Liang-Hsuan Tseng, Yu-Kuan Fu, Heng-Jui Chang, 그리고 Hung-yi Lee. 2021. 자기 지도 학습 음성 표현 모델을 사용한 중국어-영어 코드 스위칭 음성 인식. arXiv 사전 인쇄 arXiv:2110.03504.

아시쉬 바스와니, 노암 샤지어, 니키 파마르, 야코브 우스코레이트, 리온 존스, 에이단 엔 고메즈, 우카시 카이저, 그리고 일리아 폴로수킨. 2017년. 주의력은 당신이 필요한 모든 것이다. 신경 정보 처리 시스템의 발전, 30.

Ngoc Thang Vu, Dau-Cheng Lyu, Jochen Weiner, Do-
minic Telaar, Tim Schlippe, Fabian Blaicher, Eng-
Siong Chng, Tanja Schultz, and Haizhou Li. 2012. A
first speech recognition system for mandarin-english
code-switch conversational speech. In 2012 IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing (ICASSP), pages 4889–4892. IEEE.

Ngoc Thang Vu, Dau-Cheng Lyu, Jochen Weiner, Do-
minic Telaar, Tim Schlippe, Fabian Blaicher, Eng-
Siong Chng, Tanja Schultz, and Haizhou Li. 2012. A
first speech recognition system for mandarin-english
code-switch conversational speech. In 2012 IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing (ICASSP), pages 4889–4892. IEEE.

Qinyi Wang, Emre Yılmaz, Adem Derinel, and Haizhou Li. 2019. ASR-생성 언어 Posteriors를 사용한 코드 스위칭 감지. Interspeech 2019, 페이지 3740-3744에서 발표.

Qinyi Wang, Xinyuan Zhou, Haizhou Li 등. 2023년.
음성 및 텍스트 트랜스포머: 짝이 맞지 않는 텍스트를 활용한 end-to-end 음성 인식. APSIPA
신호 및 정보 처리에 대한 거래, 12(1).

신지 와타나베, 타카아키 호리, 시게키 카리타, 토모키 하야시, 지로 니시토바, 유야 우노, 넬슨-엔리크 야타 솝린, 얀 헤이만, 매튜 위스너, 난신 천 등. 2018. Espnet: 엔드 투 엔드 음성 처리 툴킷. Interspeech 2018 논문집, 페이지 2207-2211.

요헨 바이너, 응 탁 부, 도미닉 텔라르, 플로리안 메체, 탄야 슐츠, 라우 다우 청, 엉 산 청, 하이조우 리. 2012a. 코드 스위치를 포함한 말하는 대화를 위한 인식 시스템에 언어 식별 통합. 저자 미상. 저자 미상.

요헨 바이너, 응 탁 부, 도미닉 텔라르, 플로리안 메체, 탄야 슐츠, 라우 다우 청, 엉 산 청, 하이조우 리. 2012b. 코드 스위치를 포함한 말소리 대화를 위한 인식 시스템에 언어 식별 통합. 저자 미지정 언어에 대한 말소리 기술.

Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, 그리고 Pascale Fung. 2018. 구문 인식 멀티태스크 학습을 이용한 코드 스위칭 언어 모델링. arXiv 사전 인쇄 arXiv:1805.12070.

엠레 윌마즈, 헨크 반 덴 허벨, 그리고 다비드 A. 반 리우언. 2018. 데이터 증강 음향 및 언어 모델을 사용한 코드 스위칭 감지. SLTU 학회 논문집, 페이지 127-131.

헝신 인, 광위 후, 페이 왕, 그리고 펑페이 렌.
2022년. 중국어-영어 코드 스위칭 ASR을 위한 하이브리드 CTC 언어 식별 구조. 2022년 제13회 중국어 말하기 언어 처리 국제 심포지엄(ISCSLP) 논문집, 537-541쪽. IEEE.

징 지핑, 예르볼라트 하산노프, 반 퉁 팜,
하이화 쉬, 엥 셩 청, 하이저우 리. 2018.
중영 코드 스위칭 음성 인식에 대한 엔드 투 엔드 솔루션에 관하여. arXiv 사전 인쇄
arXiv:1811.00241.

홍지장. 2013. 언어와 음향 정보의 조합을 통한 코드 스위칭 말 감지 방법. Advanced Materials Research, 756권, 3622-3627쪽. Trans Tech Publ.

Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, 그리고 Ye Bai. 2021. 언어 편향을 가진 Rnn-transducer를 사용한 엔드 투 엔드 중영 코드 스위칭 음성 인식. 2021년 제12회 국제 중국어 말하기 언어 처리 심포지엄(ISCSLP)에서 발표된 논문, 1-5쪽. IEEE.

신유안 주, 엠레 윌마즈, 롱 얀화, 이 이지에, 그리고 하이조우 리. 2020. 코드 스위칭 음성 인식을 위한 멀티 인코더-디코더 트랜스포머. Interspeech 2020 논문집, 1042-1046쪽.

42
6차 언어 전환에 대한 계산적 접근 방식 워크샵 논문집, 43-63쪽
2023년 12월 7일 ©2023 협회 for 계산 언어학
다국어 대형 언어 모델에 코드 혼합 생성을 유도하기

남동아시아 언어 사례
Zheng-Xin Yong1 Ruochen Zhang1 Jessica Zosa Forde1 Skyler Wang2
Arjun Subramonian3 Holy Lovenia4 Samuel Cahyawijaya4 Genta Indra Winata5
Lintang Sutawika6 Jan Christian Blaise Cruz7 Yin Lin Tan8,9 Long Phan10
Rowena Garcia11 Thamar Solorio12 Alham Fikri Aji12
1브라운 대학교 2UC 버클리 3캘리포니아 대학교, 로스앤젤레스
4HKUST 5블룸버그 6EleutherAI 7삼성 R&D 인스티튜트 필리핀
8스탠포드 대학교 9싱가포르 국립대학교 10베트남 인공지능 연구소

11포츠담 대학교 12MBZUAI

요약

코드믹싱은 세계 여러 지역에서 흔히 사용되는 언어적인 실천이지만, 고품질과 저비용의 코드믹싱 데이터 수집은 자연어 처리(NLP) 연구에 있어서 여전히 도전입니다. 대형 언어 모델(LLM)의 최근 확산은 다음과 같은 질문을 던지게 합니다: 이러한 시스템은 코드믹싱 데이터 생성에 얼마나 능력이 있는가? 본 논문에서는 남동아시아(SEA)의 7개 언어(인도네시아어, 말레이어, 중국어, 타갈로그어, 베트남어, 타밀어, 싱글리시)에 대해 다국어 LLM을 제로샷 방식으로 프롬프팅하여 코드믹싱 데이터를 생성하는 방법을 탐구합니다. 우리는 BLOOMZ와 Flan-T5-XXL과 같은 공개적으로 사용 가능한 다국어 인스트럭션 튜닝 모델은 서로 다른 언어의 구절이나 절을 포함한 텍스트를 생성하는 능력이 없다는 것을 발견했습니다. ChatGPT는 코드믹싱 텍스트 생성에 일관성 없는 능력을 보여주며, 프롬프트 템플릿과 언어 페어링에 따라 성능이 달라집니다. 예를 들어, ChatGPT는 유창하고 자연스러운 싱글리시 텍스트(싱가포르에서 사용되는 영어 기반 크리올어)를 생성하지만, 영어-타밀어 언어 페어의 경우 시스템은 대부분 문법적으로 부정확하거나 의미 없는 발언을 생성합니다. 더욱이, 프롬프트에서 지정되지 않은 언어를 잘못 도입할 수도 있습니다. 우리의 조사에 따르면, 기존의 다국어 LLM은 SEA 언어에 대한 코드믹싱 데이터 생성에서 다양한 능력을 보입니다. 따라서 우리는 광범위한 인간의 확인 없이 이러한 맥락에서 LLM 사용을 권장하지 않습니다.

1 소개

코드믹싱 또는 코드스위칭은 말이나 대화에서 두 개 이상의 언어를 번갈아 사용하는 언어적인 실천이다 (Poplack, 1978). 이는 개인들이 문화적인 아이디어를 표현하고 상대방과 연결하거나 구별하며 자신의 정체성을 구체화하는 데 도움을 준다 (Bhatia and Ritchie, 2004; Grosjean,

해양 국가들
선택된 해양 국가들

그림 1: 동남아시아 지역을 나타내는 것으로, 총 11개 국가로 구성되어 있습니다. 우리는 LLMs에게 동남아시아 6개 국가(브루나이, 인도네시아, 말레이시아, 필리핀, 싱가포르, 베트남)에서 사용되는 혼합 언어 데이터를 생성하도록 요청합니다.

1982; Toribio, 2002; Chen, 1996; Do˘ gru¨ oz et al., 2021). 전 세계 여러 지역에서 흔하게 나타나지만, 이 분야에 대한 컴퓨팅 연구는 여전히 연구가 부족하다 (Diab et al., 2014; Aguilar et al., 2020; Winata et al., 2021, 2022; Zhang et al., 2023).

이 분야에서 오랜 기간 동안 직면한 과제 중 하나는 고품질 저비용의 코드믹스 데이터를 확보하는 것이다. 일단, 코드믹싱은 구어체 환경과 말로 된 의사소통에서 더 자주 관찰되므로 광범위한 데이터셋을 조달하고 정리하는 것은 논리적으로 요구되며 비용이 많이 든다 (Chan et al., 2009; Winata et al., 2021). 게다가, 소셜 미디어와 디지털 메시징 플랫폼에서 코드믹싱이 흔하게 나타나더라도, 이러한 데이터를 통합하는 것은 법적 제약과 확장성 문제로 인해 제한될 수 있다. 이러한 도전을 인식하여, 우리는 생성형 대형 언어 모델 (LLM)을 사용하여 코드믹싱 연구에서 데이터 부족 문제를 완화하는 가능성을 탐구한다.

43
CM

Anggapkan anda seorang penutur dwibahasa Inggeris-Melayu,
bagaimana anda akan menulis ayat campuran kod Inggeris-Melayu
yang semula jadi tentang trafik?

(ChatGPT) 저는 교통이 매우 혼잡한 것 같아요. 모든 차선을 막고 있는 차들이 많기 때문이에요.

3

(다빈치-003) "긴 시간이 걸리는 일은 길에서 오래 기다리는 것처럼 지루하게 만들어요!"

0

오늘 교통 정말 혼잡해.

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 음식에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT) 발화자 1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어?
발화자 2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너는 먹어봤니?
발화자 1: 네, 먹어봤어. 맛들의 조합이 정말 좋아. 새테 아얌도 먹어봤어?
발화자 2: 오, 네. 새테 아얌을 정말 좋아해! ..<truncated>

2

(Davinci-003) "영어 사용자: 저는 저녁으로 가장 놀라운 나시 고렝을 먹었어요! 인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요? 영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요.

2

(다빈치-002) "A: 당신이 가장 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식, 특히 나시 고렝을 좋아해요. A: 네, 저도 나시 고렝을 좋아해요!"

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어?
M: 오! 기대했던 대로 정말 재미있었어요.
W: 다행이네요. 다음에 어디 가면 같이 가자고 했던 거 아니었어요?
M: 응... 그래요 그럼"

0

(Flan-T5-XXL) M: 파티 음식 어떻게 생각하세요? 맛있어요? W: 파티 음식은 괜찮은데, 먹을 필요 없어요. 0

(b) 템플릿: 두 명의 양언자

가족에 관한 한 문장을 싱글리쉬로 말할 수 있는 사람의 말투를 모방하세요.

(ChatGPT) 응, 알지, 가족은 아주 중요하다니까, 항상 오직 오직 함께해야 돼, 오징어랑 고추장처럼 말야, 되겠지?

3

(다빈치-003) "우리 가족은, 우리 정말 가까워서 어디든 함께 갈 수 있어!"

(다빈치-002) 우리 가족은 최고야! 0

(c) 템플릿: 말하는 스타일 모방하기

CM

코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 영어-중국어 코드믹싱 문장을 생성해볼 수 있을까요?
(ChatGPT) 물론, 예를 들어 "점심에는 ∏ !(짜지) 후라이드 치킨을 먹는 걸 좋아해요."라고 할 수 있습니다. 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 좋아해요! 0 (Davinci-002) "FPFP  }}⇤⇤ÑÑ⇥⇥ 두부, 두부, 먹기에는 좋지 않아요." 0
(BLOOMZ) fliÔÂ⇤ F Å⇤*⇢⇥ 0

(Flan-T5-XXL) 한 요리사가 음료를 준비합니다. 0

(d) 템플릿: CM을 명확하게 정의하다.

CM 생각해보세요, 당신이 베트남어를 사용하는 사람이라고 상상해봅시다. 영어와 베트남어를 동시에 사용하여 날씨에 대해 어떻게 말할 것인가요?

(ChatGPT) "오늘은 날씨가 꽤 더워서, 나는 반바지와 티셔츠를 입고 나갈 것 같아요."

(Davinci-003) 오늘 날씨는 분명히 아름답겠어요.

(Davinci-002) 난 여기 날씨가 좋아. 너무 더우지도 않고 너무 추지도 않아.

(BLOOMZ) 한국어를 할 수 있는 사람이라고 말하고, 두 가지 언어로 날씨를 설명해주세요: 0

(Flan-T5-XXL) V 고객님께서는 티셔츠를 찾으시는데 이엔 브랜드의 옷을 찾으실 수 있습니다.

0

(e) 템플릿: 원어민

CM

"인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다."

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 우리가 살고, 일하고, 지금 살아가는 방식을 혁신하고 있습니다. 이는 프로젝트에 현대적인 솔루션을 제공하고 자동화를 기다리는 몇 가지 작업을 수행함으로써 이루어집니다.

3

(다빈치-002) 인공지능은 우리가 감사해야 할 것이다.
(블룸즈) 인공지능 전문가가 동료의 도움으로 양 언어를 구사하는 학생에게 자신의 전문 분야를 설명한다.

0

(Flan-T5-XXL) 더 많은 헤어 드라이어의 결함을 조사하는 것은 차량의 연구를 통해 열의 전도성을 연구하고, 한 남성의 명예를 위해 모임을 개최합니다.

0

(f) 템플릿: CM 문장을 작성하세요.

그림 17: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비코드 혼용 문장을 포함한 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다.

23
(a) 템플릿: 이중언어 사용자로 가정하다.

CM

Anggapkan anda seorang penutur dwibahasa Inggeris-Melayu,
bagaimana anda akan menulis ayat campuran kod Inggeris-Melayu
yang semula jadi tentang trafik?

나는 이 도로가 차들로 인해 매우 혼잡하다고 생각합니다. 모든 차선이 막혀 있기 때문입니다.

이 문장에서는 영어와 말레이어 단어를 섞어서 코드믹스 문장을 만들었습니다. 이 문장은 말레이어로 시작해서...

3

(Davinci-003) "오래 걸리는 작업은
긴 도로에서 오래 기다리는 것처럼
지루하게 만들어요!"

0

오늘 교통 정말 혼잡해.

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 음식에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT) 발화자 1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어?
발화자 2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너는 먹어봤니?
발화자 1: 네, 먹어봤어. 맛들의 조합이 정말 좋아. 새테 아얌도 먹어봤어?
발화자 2: 오, 네. 새테 아얌을 정말 좋아해! ..<truncated>

2

(Davinci-003) "영어 사용자: 저는 저녁으로 가장 놀라운 나시 고렝을 먹었어요!
인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요?
영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요.
..<중략>

2

(다빈치-002) "A: 당신이 가장 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식을 좋아해요, 특히 나시 고렝이요.
A: 네, 저도 나시 고렝을 좋아해요!"

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어?
M: 오! 기대했던 대로 정말 재미있었어요.
W: 다행이네요. 다음에 어디 가면 같이 가자고 했던 거 아니었어요?
M: 응... 그래요 그럼"

0

(Flan-T5-XXL) M: 파티 음식 어때? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어.

0

(b) 템플릿: 두 개의 양언자

CM

가족에 관한 한 문장으로 싱글리쉬를 구사할 수 있는 사람의 말투를 모방해 보세요. (ChatGPT) 에이, 알지 랏, 가족은 아주 중요한 거야 레, 항상 오징어와 고추장처럼 붙어있어야 돼, 될거야?

3

(다빈치-003) "우리 가족은, 우리 정말 가까워서 어디든 함께 갈 수 있어!"

(다빈치-002) 우리 가족은 최고야! 0

(c) 템플릿: 말하는 스타일 모방하기

CM

코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹싱된 영어-중국어 문장을 생성할 수 있나요?

(ChatGPT) 그럼, 예를 들어보겠습니다: "점심에 ∏ !(zhá j¯ı) 치킨을 먹는 것을 좋아해요." 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 좋아해요! 0

(다빈치-002) "두부, 두부, 먹기에 좋지 않아요, 좋지 않아요." 0

(BLOOMZ) 플라워 배송 서비스 제로

(Flan-T5-XXL) 한 요리사가 음료를 준비합니다. 0

(d) 템플릿: CM을 명확하게 정의하다.

CM

상상해보세요. 당신이 베트남어를 사용하는 사람이라고 가정해봅시다. 영어와 베트남어를 동시에 사용하여 날씨에 대해 어떻게 이야기할까요?

(ChatGPT) "오늘은 날씨가 꽤 더워서 나는 반바지와 티셔츠를 입을 거 같아."

3

(Davinci-003) 오늘 날씨는 분명히 아름다울 거야.

(Davinci-002) 난 여기 날씨가 좋아. 너무 더우지도 않고 너무 추지도 않아.

(BLOOMZ) 블룸즈에 오신 것을 환영합니다. 저희는 베트남어를 구사하며, 날씨에 대해 두 가지 언어로 설명할 수 있습니다: 0 (Flan-T5-XXL) 고객님은 옷을 찾으시는데, 다양한 옷 종류를 찾으실 수 있습니다.

0

(e) 템플릿: 원어민

CM

인공지능에 관한 영어와 타갈로그어 혼용 문장을 작성하세요.

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI가 현대적인 솔루션을 제공하고 자동화되기를 기다리는 몇 가지 작업을 처리함으로써, 우리가 살고 일하고 살아가는 방식을 혁신하고 있습니다.
(Davinci-002) 인공지능은 우리가 감사해야 할 것입니다.
(BLOOMZ) 인공지능 전문가가 양 언어를 구사하는 동료의 도움을 받아 학생에게 자신의 전문 분야를 설명합니다.
(Flan-T5-XXL) 더 많은 자동차의 결함을 분석하기 위해, 남성의 영광을 위한 연구를 수행하고, 녹슬음을 연구하기 위해 모임을 개최합니다.

0

(f) 템플릿: CM 문장을 작성하세요.

그림 17: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비 코드 혼용 문장을 포함한 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다. 23
(b) 템플릿: 말하는 스타일 모방

그림 2: 다양한 언어와 주제 분야를 가진 예시 프롬프트 템플릿 및 LLM의 코드믹스 / 비코드믹스 문장을 포함한 응답 예시. 설명은 ChatGPT의 원래 생성물의 일부입니다. "CM"은 코드믹싱 수준을 나타냅니다 (2.2절 참조). 다른 LLM인 BLOOMZ와 Flan-T5-XXL의 모든 프롬프트 템플릿 및 응답은 부록의 그림 15를 참조하십시오.

최근 연구에 따르면 LLM은 합성 데이터를 성공적으로 생성할 수 있다는 것을 보여줍니다 (Taori et al., 2023; He et al., 2023; Tang et al., 2023; Whitehouse et al., 2023). 여기서 우리는 다국어 LLM이 원어민에게 자연스러운 코드믹스 데이터를 생성할 수 있는지 (그렇다면 어느 정도인지) 평가합니다. 이를 위해 우리는 남동아시아 (SEA)의 언어에 초점을 맞춥니다. 6억 8천만 명 이상의 인구와 1200개 이상의 언어를 보유한 SEA는 언어와 문화적 교배 및 식민지주의의 오랜 역사로 인해 코드믹싱이 특히 흔한 지역입니다 (Figure 1) (Goddard, 2005; Bautista and Gonzalez, 2006; Reid et al., 2022). 특징적인 다양한 언어와 다인종적 구성을 가진 SEA는 NLP 연구에서 여러 언어와 언어적 실천을 연구하기 위한 기회를 제공합니다 (Migliazza, 1996; Goddard, 2005; Joshi et al., 2020; Aji et al., 2022; Winata et al., 2023; Cahyawijaya et al., 2022). 그러나 SEA 커뮤니티와 관련된 코드믹스 데이터셋은 여전히 제한적으로 공개되어 있습니다 (Lyu et al., 2010; Winata et al., 2022).
우리는 다섯 개의 다국어 LLM, 즉 Chat-GPT, InstructGPT (davinci-002 및 davinci-003) (Ouyang et al., 2022), BLOOMZ (Muennighoff et al., 2022) 및 Flan-T5-XXL (Chung et al., 2022)을 코드믹스 텍스트를 생성하도록 유도합니다.

1. 동남아시아 국가들의 주요 언어들은 인도유럽어, 태국어, 오스트로네시아어, 중국-티베트어, 드라비다어, 그리고 오스트로아시아어와 같은 다른 언어 가족에 속합니다. 게다가, 적어도 수천 개의 주요 및 부수적인 동남아시아 언어가 있습니다.

영어와 말레이어, 인도네시아어, 중국어, 타갈로그어, 베트남어 또는 타밀어를 혼합합니다. 이 여섯 개의 동남아 언어(영어와 함께)는 싱가포르, 말레이시아, 브루나이, 필리핀, 인도네시아 및 베트남이라는 여섯 개의 동남아 국가에서 사용됩니다. 또한, 이들은 서로 다른 언어 가족에 속합니다 - 인도유럽어, 오스트로네시아어, 중국어-티베트어, 오스트로아시아어 및 드라비다어. 우리가 사용한 프롬프트의 예는 "인공지능에 대한 영어와 타밀어 코드 혼합 문장을 작성하십시오."입니다. 또한, 우리는 이러한 LLM들에게 말레이어, 중국어 및 타밀어와 같은 여러 동남아 언어를 결합한 싱글리시(싱가포르에서 널리 사용되는 영어 기반 크리올어)로 텍스트를 생성하도록 요청합니다. 우리는 원어민들에게 출력물의 자연스러움(즉, 원어민이 그렇게 말할 것인지 여부)과 코드 혼합의 수준을 주석으로 달라고 요청합니다.

우리의 지식으로는, 우리의 작업은 LLMs를 사용하여 어떠한 단일 언어 참조 텍스트나 명시적 언어 제약 없이 제로샷 방식으로 합성 코드믹스 데이터 생성을 연구하는 첫 번째 시도임을 나타냅니다 (Solorio and Liu, 2008; Tarunesh et al., 2021; Rizvi et al., 2021; Mondal et al., 2022). 우리는 BLOOMZ와 Flan-T5-XXL과 같은 공개적으로 이용 가능한 다국어 언어 모델이 대부분 대출어나 주제 관련 명사와 함께 코드믹스를 할 수 있다는 것을 발견했습니다. 그러나 대부분의 경우, 그들은 코드믹스를 실패합니다 (다국어로 광고되었음에도 불구하고). ChatGPT는 코드믹스 텍스트를 생성하는 능력에서 뛰어나지만, 프롬프트 템플릿에 극도로 민감하며 자연스러운 코드믹스를 생성하는 데 있어서 상당한 성공률의 변동성을 보입니다.

44
그림 3: 제로샷 프롬프팅을 통해 코드믹스 데이터를 생성하는 다른 LLM의 성능 비교.
우리는 결과를 다른 코드믹싱 레벨로 분배합니다: (0) 코드믹싱 없음 (비-CM), (1) 외래어, (2) 주제 관련 명사, 그리고 (3) 언어적 요소.

다른 언어 쌍을 통한 텍스트. 게다가, 이는 잘못된 언어를 추가로 도입하고 텍스트의 코드 혼합을 잘못 설명할 수 있습니다.
우리의 결과는 오늘날을 기준으로 코드 혼합이 많은 다중 언어 LLM의 필수 구성 요소로 간주되지 않는다는 결론을 내리게 합니다. 게다가, ChatGPT와 같은 모델의 불투명한 생성은 코드 혼합을 가능하게 하는 메커니즘을 확인하기 어렵게 만듭니다. 저희는 LLM의 한 형태인 저자원 데이터 생성에 대한 제한된 약속을 강조함으로써 기존 시스템을 사용하여 철저한 인간 평가 없이 합성 코드 혼합 데이터를 생성하는 것에 대해 NLP 연구자들에게 권고합니다.

2 방법론

2.1 언어 모델 유도

우리는 두 가지 축을 따라 LLMs에게 요청을 통해 합성 코드 혼합 데이터를 수집합니다: 언어와 주제 (음식, 가족, 교통, 인공 지능 및 날씨). 다른 프롬프트 템플릿 예시는 그림 2를 참조하십시오. 구체적으로, 우리는 ChatGPT, InstructGPT (davinci-002 및 davinci-003) (Ouyang et al., 2022), 176B-파라미터 BLOOMZ (Muennighoff et al., 2022) 및 Flan-T5-XXL (Chung et al., 2022)을 탐색합니다. 우리는 OpenAI와 HuggingFace의 API를 프롬프팅에 사용합니다 (부록 B 참조), 단 ChatGPT의 경우 웹 인터페이스를 통해 수동으로 쿼리했습니다. 우리의 프롬프트에서는 영어와 인도네시아어, 말레이어, 중국어, 타갈로그어, 베트남어 또는 타밀어 사이의 코드 혼합을 명시합니다. 우리는 두 가지 이유로 SEA 언어와 영어의 코드 혼합에 초점을 맞추었습니다: (1) 코드 혼합된 영어에 대한 광범위한 문헌은 관련 비교점을 제공합니다.

이 연구를 진행할 때 2ChatGPT의 API는 공개적으로 출시되지 않았습니다.

그리고 (2) 영어는 동남아시아 국가들 사이에서 코드믹싱에 가장 널리 사용되는 언어 중 하나입니다 (Kirkpatrick, 2014). 우리는 또한 크리올어인 싱글리시로 된 문장들을 사용하여 LLMs가 동남아시아 지역의 언어 다양성에 얼마나 민감한지 평가합니다. 총 210개의 고유한 프롬프트를 각 언어 모델에 제출했습니다.

2.2 평가

코드 혼용 수준

출력물을 평가하기 위해, 우리는 LLMs가 문장 내 코드믹스 텍스트를 생성할 수 있는지 여부를 확인합니다. 우리는 Berk-Seligson (1986)의 문장 내 코드믹싱 정의를 채택합니다. 이 정의는 명사구와 동사구와 같은 작은 구성요소와 병렬 절과 전치구와 같은 큰 구성요소를 혼합하는 것을 포함합니다. 그런 다음 원어민은 수집된 응답을 0부터 3까지의 척도로 수동으로 주석을 달도록 지시됩니다. 코드믹스 정도를 나타내기 위해 다음 코딩 가이드라인을 사용합니다.

的车才到公司。”
• 3 - Code-switching: The generated text
exhibits intrasentential code-switching, where
words or phrases from another language are
inserted within a sentence. For example: In the
sentence, “I need to buy some 고기 for dinner,”
“고기” is a code-switched word.
• 4 - Mixed script: The generated text uses a
mixture of scripts from different languages.
For example: In the sentence, “我喜欢 eating
sushi,” the word “sushi” is written in Latin
script while the rest of the sentence is in
Chinese characters.
• 5 - Mixed language: The generated text
combines multiple languages within a sentence
or across sentences. For example: In the
sentence, “I went to the boulangerie to buy
some bread,” “boulangerie” is in French while
the rest of the sentence is in English.

3https://en.wiktionary.org
3https://en.wiktionary.org

45
1
대출어
2
주제와 관련된 명사
3
언어적 요소
0
20 40
60 80
100

언어 (a) 프롬프트의 백분율

중국어

인도네시아어 말레이어 타갈로그어 타밀어
베트남어

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(b) 주제

인공지능

가족 음식 교통 날씨

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(c) 템플릿

아무리 어려워도 포기하지 마세요.
너무 슬퍼하지 마세요.
당신은 훌륭한 사람입니다.
오늘 하루도 힘내세요.
사랑해요.

CM 스타일을 명확하게 정의하다. 원어민처럼 말하는 스타일을 모방하다. 양언어 사용자 두 명. CM 문장을 작성하다.

그림 4: ChatGPT에 의해 생성된 코드 혼용 데이터의 분석.

"오늘 교통 정말 심각해요. 사무실에 도착하기 위해 한 시간을 운전했어요."
"우리 가족은 이번 주말에 공원에서 큰 가족 모임을 계획했어요."
"교통이 혼잡할 때 사고를 피하기 위해 운전할 때 조심하세요."

우리는 CMI (Gamb¨ ack and Das, 2014)와 같은 인기있는 단어 수준의 측정치 대신에 이 척도를 사용합니다. 왜냐하면 우리의 척도는 LLMs의 코드믹싱 능력을 보다 종합적으로 평가하기 때문입니다. 이 척도의 하단은 코드믹싱의 복잡성이 낮음을 반영합니다. 대출어를 사용한 코드믹싱은 언어적으로 단일 언어 맥락에서 자주 사용되기 때문에 아마도 덜 도전적이라고 볼 수 있습니다. 마찬가지로, 주제와 관련된 명사를 코드믹싱하는 것은 두 언어의 명사 간에 대응이 있고 프롬프트에 의해 사전에 준비되기 때문에 그리 복잡하지 않습니다.

한편, 코드 혼용 접두사/접미사, 구문 및 절을 혼용하는 것은 두 언어의 복잡한 형태-문법 구조를 잘 이해해야 하며, 문법적으로 다양한 코드 혼용 데이터를 생성할 수 있습니다. 따라서, 우리는 해당 텍스트가 이 범주에 속한다면 LLM이 성공적으로 코드 혼용 텍스트를 생성한 것으로 간주합니다.

4. 타갈로그어에서 "pag-" 접두사는 영어 단어 "drive"에 붙여지며 "pagda-drive"라는 단어를 만듭니다 (운전하는 행위). 이 예시는 타갈로그어의 굴절 규칙을 영어 단어에 적용하는 것을 보여줍니다.

자연스러움

우리는 원어민들에게 생성된 텍스트의 자연스러움을 1부터 3까지의 등급 척도로 주석을 달아달라고 요청했습니다. 1은 전혀 자연스럽지 않다는 것을 의미하고, 2는 주석 작성자가 다른 지역/문화에서 온 사람이 말하는 것처럼 보일 수 있다는 것을 의미하며, 3은 주석 작성자가 자신이 말하는 것처럼 보일 수 있다는 것을 의미합니다. 텍스트가 자연스럽지 않다고 판단된 경우 (1등급), 우리는 주석 작성자가 순조 문제, 문법 오류 및 의미적 오류를 포함하여 그 이유를 기록하도록 요청했습니다.

코드 혼용 실천은 인종, 성별, 계급 및 지리 등 다양한 축을 통해 다양합니다. 따라서 사회언어학 연구에 따라, 우리는 코드 혼용 텍스트의 "자연스러움" (주석자가 인식하는 대로)은 주관적이며, 주석자의 배경과 사회적 위치에 따라 달라진다고 강조합니다. 모든 주석자는 인공지능 연구원이며, 각각의 동남아시아 언어의 모국어 사용자입니다. 주석자 및 주석자 간 합의 점수에 대한 자세한 정보는 부록 G를 참조하십시오.

정확성

우리는 작업 실패 또는 잘못된 설명을 고려하여 세대의 정확성을 추가로 주석으로 달았습니다. 부정확한 출력은 다음과 같이 정의되었습니다:

• 지시에 따르지 않음: 일부 LLM은 정확하게 지시사항을 수행하지 못합니다 (예: 단일 언어 문장 생성). 또한, 일부 코드 혼용된 출력물에서는 지시사항에 명시되지 않은 추가 언어가 포함되어 있습니다.
• 부정확한 설명: ChatGPT를 포함한 다른 LLM들은 코드 혼용된 구문을 설명하는 경향이 있지만, 가끔 잘못된 설명을 제공하기도 합니다 (Figure 10 참조).

상상해보세요. 두 명의 영어-베트남어 이중언어 사용자가 서로 대화를 나누고 있다고 상상해보세요. 가족에 대해 이야기하는 그들의 대화를 상상할 수 있나요?

안녕, 너네 가족은 어떻게 지내?
안녕, 우리 가족은 건강해. 너네 가족은 어때?
그들은 잘 지내, 물어봐줘서 고마워. 너네는 어때?
우리 가족도 건강해, 고마워. 최근에 할아버지, 할머니와 내 동생들과 놀았어.

상상해보세요. 두 명의 영어-중국어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 날씨에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT)KoreanSpeaker1: 얘,오늘 밖에 나왔어?
너무 더워!
ChineseSpeaker1: 是啊，今天天气真的很热。
KoreanSpeaker2: 응, 하루 종일 맑았어.
ChineseSpeaker2: 是啊，今天一整天都很晴朗.

그림 5: ChatGPT에게 두 개의 양언자가 특정 주제에 대해 대화하는 것을 상상하도록 요청할 때 실패한 경우들.

3 결과

3.1 영어-동남아시아 언어

그림 3은 ChatGPT가 여섯 가지 다른 언어 쌍에서 코드믹스 데이터를 생성하는 데 있어 다른 언어 모델보다 우수한 성능을 보여주며, 특히 언어적 표현을 코드믹스하는 데 능숙함을 보여줍니다. InstructGPT의 경우, davinci-003 모델은 구문적으로 다양한 코드믹스 텍스트를 생성하는 능력을 일부 보여주며, davinci-002는 대부분 외래어와 코드믹스합니다. 반대로, 다른 두 개의 공개적으로 사용 가능한 다국어 언어 모델은 코드믹스 능력이 매우 제한적입니다. 더 구체적으로, Flan-T5-XXL은 인도네시아어-영어 언어 쌍에 대해서만 외래어와 코드믹스할 수 있으며, 그 외의 영어가 아닌 단일 언어 출력은 유창성 문제가 심각합니다 (부록 D 참조). BLOOMZ는 타밀어-영어에 대해서만 주제 관련 명사를 코드믹스할 수 있으며, 다국어 사전 훈련 데이터 ROOTS (Laurenc¸on et al., 2022) 및 지시어 튜닝 데이터 xP3 (Muennighoff et al., 2022)는 인도네시아어, 중국어, 타밀어 및 베트남어를 다룹니다. BLOOMZ의 코드믹스 능력에는 이러한 언어들의 훈련 세트 내 비율의 직접적인 영향을 관찰하지 못했습니다 (부록 E 참조).
그림 45에서 ChatGPT의 성능을 더 자세히 살펴보겠습니다. 그림 4(a)에서는 ChatGPT의 성능이 나타납니다.

다빈치-002, 다빈치-003, Flan-T5-XXL 및 BLOOMZ에 대한 상세 분석은 부록에서 찾을 수 있습니다 (그림 11, 그림 12, 그림 13 및 그림 14).

ChatGPT는 영어-타갈로그어의 언어 요소를 혼합하는 데 가장 능숙하지 않습니다. 이는 두 언어 간의 문법적 차이 때문일 수 있습니다. 예를 들어, 영어는 주어-동사-목적어 (SVO)의 어순을 가지고 있지만, 타갈로그어는 동사-주어의 구조를 가지고 있습니다. 게다가, 영어는 주격-목적격 정렬을 보여주지만, 타갈로그어는 대칭 활용 언어로서, "오스트로네시아 언어학자들 사이에서 여전히 논란이 되고 있다"는 언어 분류 체계를 사용합니다 (Aldridge, 2012, 192). 이에 반해, ChatGPT는 영어-인도네시아어 코드 혼용에 대해 가장 우수한 성능을 발휘합니다. 이는 훈련 데이터 분포와 두 언어 간의 어순 및 형태-문법적 정렬에 대한 유사성 때문일 수 있습니다. 또한, ChatGPT는 영어나 동남아시아 언어 중 하나를 주 언어로 사용할 수 있는 능력을 갖추고 있으며, 이는 Matrix Language Frame 모델 (Myers-Scotton, 1997)에 따라 문장의 주 언어로 사용됩니다.

그림 4(b)는 주제에 기반한 ChatGPT의 코드믹싱 능력을 보여줍니다. ChatGPT는 "AI"에 대한 주제일 때 "Artificial Intelligence" 또는 "AI"라는 영어로 된 외래어를 혼용하여 코드믹싱하는 경향이 있습니다. 음식에 대해서는 "bánh mì" (베트남 샌드위치)와 같은 SEA 언어의 음식 관련 용어와 코드믹싱하는 경향이 있습니다. 또한 특정 언어-주제 쌍에서 표현 편향을 관찰할 수 있습니다. 예를 들어, 음식에 관한 경우, ChatGPT는 모든 영어-인도네시아어 응답에 대해 "nasi goreng" (볶은 밥)이라는 단어를 사용합니다. 교통과 날씨와 같은 다른 주제에 대해서는 교통 혼잡과 더운 날씨와 관련된 구문을 코드믹싱하는 경향이 있습니다.

그림 4(c)에서는 우리가 가장 품질이 높은 결과를 얻은 프롬프트 템플릿이 코드믹싱이 명시적으로 정의된 것임을 알 수 있습니다. 그에 반해, 성능이 가장 나쁜 템플릿은 코드믹싱이 언급되지 않은 이중언어 사용자 간 대화를 생성하도록 모델에 요청하는 것으로 구성되어 있습니다. 그림 5에서는 ChatGPT가 대화의 일반적이지 않은 패턴을 생성하는 것을 볼 수 있습니다. 여기서 한 참여자는 영어로 말하고 다른 참여자는 완전히 다른 언어로 말합니다 (상단 예시). 또한, ChatGPT는 프롬프트가 두 명의 참여자 간 대화를 요청하더라도 네 명의 참여자가 있는 것으로 가정할 수 있습니다 (하단 예시).

자연스러움 측면에서, ChatGPT의 출력물에서 상당한 변동성을 관찰할 수 있으며, 영어-타밀어가 가장 자연스럽지 않음 (그림 6). 더 나아가

47
중국어 인도네시아어 말레이어 타갈로그어 타밀어 베트남어 싱가포르어
0.0
0.2
0.4
0.6
0.8
1.0

퍼센트
오브
프롬프트
논-CM

자연스럽지 않음
반자연적

자연적인

그림 6: ChatGPT에서 생성된 코드 혼용(CM) 텍스트의 자연스러움. "반자연적"은 주석 작성자가 다른 지역/문화에서 온 다른 사람이 말하는 것으로 보는 것을 의미하며, "자연스러움"은 주석 작성자가 자신이 말하는 것으로 보는 것을 의미합니다.

ChatGPT InstructGPT
(davinci-003)
InstructGPT
(davinci-002)
Flan-T5-XXL BLOOMZ 0
20 40
60
80
100

퍼센트
오브
프롬프트

그림 7: 제로샷 프롬프팅을 통한 싱글리시 표현 생성에서 모델의 성능.

분석 결과, ChatGPT는 쉼표 분리 및 중복과 같은 문법적 오류를 저지르거나 의미적으로 혼란스러운 문장을 생성합니다. 또한, 동일한 언어의 두 가지 다른 문자 체계를 혼합한 비자연스러운 텍스트 패턴도 관찰됩니다 (예: 타밀 문자와 그의 로마자 표기법). 이러한 자연스러움과 유창성 문제를 표 4 (부록 F)에 기록하고, 평가자 간 일치 점수를 부록 G에 보고합니다.

3.2 싱글리시

상상해봐, 너가 싱가포르 사투리로 음식에 대해 이야기한다면 어떻게 할 거야?

와, 호커 센터에는 치킨 라이스, 라크사, 로작과 같이 맛있는 음식이 정말 많아서 죽을 것 같아!

그림 8: ChatGPT에 의해 생성된 싱글리시 문장과 표준 영어로의 번역.

싱글리시는 말레이어, 중국어, 타밀어, 광둥어, 홍커어 등 다양한 언어로부터 많은 단어를 어휘화한 영어 기반 크리올 언어이기 때문에 대여어와 언어적 요소를 명확히 구분하기 어렵습니다. 따라서, 우리는 생성된 문장에 싱글리시 표현 (예: 감탄사, 표준화되지 않은 언어의 어휘화된 구)이 포함되어 있는지 여부에 따라 모델의 성공을 이진 척도로 분류합니다. 그림 7에서 ChatGPT와 InstructGPT (davinci-003)는 싱글리시 문장을 생성하는 데 최대 96%의 성공률을 보이는 반면, Flan-T5-XXL과 BLOOMZ는 거의 성공률이 없습니다. 또한, ChatGPT는 싱글리시 표현을 표준 미국 영어로 번역할 수 있는 능력도 갖추고 있음을 발견했습니다.

ChatGPT는 유창하고 자연스러운 싱글리시를 생성할 수 있지만 (그림 6), 원어민들에 의해 식별 가능한 단어 선택에서 의미적인 부정확성을 관찰할 수 있습니다. 그림 2(b)에서 ChatGPT는 "sotong and chilli sauce"라는 영어-말레이어 혼용 구문을 생성하는데, "sotong"은 "오징어"를 의미하는 말레이어 단어입니다. 처음 검토할 때, 문장은 문법적으로 올바른 것처럼 보이지만 원어민들은 가족적 연결과 요리 (오징어와 칠리 소스) 사이의 유사성을 의미적으로 혼란스러워합니다.

OpenAI의 모델 차이에 대한 문서7 - 특히 davinci-003이 davinci-002보다 더 높은 품질의 글쓰기를 생성하고, 더 복잡한 지시사항을 처리하며, 더 긴 콘텐츠를 생성할 수 있다는 사실 -은 ChatGPT와 davinci-003이 싱글리시 텍스트 생성에서 davinci-002와 다른 다국어 LLM보다 우수한 성능을 보이는 이유를 충분히 설명하지 못합니다. 우리는 성능 차이가 OpenAI의 훈련 데이터에 싱글리시가 더 많이 포함되어 있기 때문일 수 있다고 가설을 세웁니다. 싱글리시는 영어의 가장 잘 연구된 방언 중 하나이며 (Sin, 2017), 영어 알파벳과 라틴 문자 체계를 사용하기 때문에 (다른 많은 동남아시아 언어와 달리), LLM이 이 언어에서 데이터를 스크래핑하고 구문 분석하기가 더 쉬울 수 있습니다.

3.3 ChatGPT의 실패들

우리는 ChatGPT가 화자의 국적이 언급될 때 코드 혼합 텍스트를 올바르게 생성하지 못할 수 있다는 것을 알아차렸습니다. 국적을 언급하는 것은

6A 참고 목록은 https://en.wikipedia.org/wiki/Singlish_vocabulary에서 찾을 수 있습니다.
7https://help.openai.com/en/articles/6779149-how-do-text-davinci-002-and-text-davinci-003-differ

48
말레이시아어로 말하는 상상을 해보세요. 영어와 중국어를 모두 사용하여 교통에 대해 어떻게 이야기할까요?

"오늘 traffic 정말 teruk이야, KLCC로 미팅하러 급하게 가야 해."

그림 9: ChatGPT가 프롬프트를 따르지 못한 실패. 밑줄 친 텍스트는 언어 분류 오류를 보여줍니다.

국가의 추가 언어와 함께 ChatGPT가 코드믹스 텍스트를 생성하도록 유도합니다. 그림 9의 예에서 말레이시아의 국가 언어가 말레이어이기 때문에 말레이시아 사람에게 영어-중국어 발화를 요청할 때 ChatGPT는 말레이어 단어 "teruk"을 포함한 코드믹스 응답을 반환할 뿐만 아니라 "teruk"을 중국어로 잘못 분류합니다.
ChatGPT는 생성된 텍스트가 코드믹스인 방식을 설명할 수 있지만(그림 2(a) 참조), 두 가지 이유로 그 정당성이 믿을 수 없다는 것을 발견했습니다. 첫째, 코드믹스 텍스트에 존재하지 않는 단어를 환각할 수 있습니다. 예를 들어, 그림 10의 상위 예에서 영어 단어 "cold"는 코드믹스 텍스트에 존재하지 않습니다. 둘째, 단어나 구문을 잘못된 언어로 할당할 수 있습니다. 그림 10의 하위 예에서 구문 "nak minum air sejuk je"은 영어가 아닌 말레이어입니다. 이 관찰은 Bang 등의 (2023) 연구 결과와 일치하여 ChatGPT가 저자원 언어에 대한 언어 식별 작업에서 성능이 좋지 않다는 것을 시사합니다.

LLMs에 대한 4가지 함의와 전진 방법

이 섹션에서는 저희의 연구가 저자원 환경에서 합성 데이터 생성을 위한 LLMs의 배치 이해, LLMs의 다국어성, 생성 LLMs에서의 코드 혼용 능력의 중요성, 그리고 연구 투명성에 대한 다양한 함의를 살펴봅니다.

저비용 데이터 생성을 위해 LLMs를 배치함으로써, 우리는 이 연구에서 LLMs의 생성 능력을 시험해보고, 그들이 고품질이면서도 저비용의 코드 혼합 텍스트를 생성할 수 있는지 묻습니다.

중국어는 그 나라에서 널리 사용되는 언어입니다.

상상해보세요, 당신이 인도네시아어를 사용하는 사람이라고 가정하면, 영어와 인도네시아어를 혼용하여 날씨에 대해 어떻게 이야기할 것인가요?

(ChatGPT) 날씨에 대해 영어와 인도네시아어를 함께 사용하여 한 문장으로 이야기한다면, 다음과 같이 말할 수 있습니다: "Hari ini sangat panas dan panas sekali, saya rasa aku butuh minum air dingin." 이 문장에는 날씨를 설명하기 위해 영어 단어 "hot"과 "cold"가 포함되어 있으며, 비슷한 의미를 가진 인도네시아어 단어 "panas"와 "dingin"도 포함되어 있습니다. 또한, 이 문장에는 "sayarasaakubutuh minumairdingin"라는 인도네시아어로 된 개인적인 진술도 포함되어 있으며, 이는 "차가운 물을 마셔야 할 것 같아요"라는 뜻입니다.

코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 날씨에 관한 영어-말레이어 코드믹스 문장을 생성할 수 있을까요?

"오늘 날씨는 매우 덥네요, 차가운 물 마시고 싶어요."

그림 10: 밑줄 친 텍스트는 코드 혼용 텍스트에 대한 잘못된 설명을 보여줍니다. 코드 혼용 문장을 이탤릭체로 표시하여 독자에게 명확하게 보여줍니다.

한정된 데이터의 가용성으로 괴로움을 겪는 주제에 대해 연구하는 연구자들. 우리는 Chat-GPT가 일부 동남아시아 언어에 대해 코드 혼합 텍스트를 생성하는 데 상대적인 성공을 보였지만, 이 데이터 생성 기술을 사용할 때 신중함을 요구한다고 결론을 내립니다. 다른 언어들을 조사한 결과 Singlish에서는 다른 언어들보다 우수한 성과를 보이지만, 문법적으로 올바른 응답에도 비네이티브 스피커들이 감지하기 어려운 의미적 부정확성이 포함될 수 있다는 것을 발견했습니다. 더욱이, 그 설명은 오해를 불러일으킬 수 있습니다. 신뢰성의 부족으로 인해, 이 데이터 생성 방법을 추구하려는 연구자들에게는 원어민과의 철저한 인간적 검증을 시행할 것을 강력히 권장합니다.

다중언어 ≠ 코드믹스 호환 가능 우리의 BLOOMZ와 Flan-T5-XXL과의 결과는 LLMs가 사전 훈련 및/또는 다중언어 데이터로 세밀 조정한 후에도 코드믹스 능력을 습득하지 못한다는 것을 보여줍니다 (Laurenc¸on et al., 2022; Muennighoff et al., 2022; Chung et al., 2022). 다른 말로, 대부분의 NLP 모델에 대해 다중언어는 단순히 동일한 시스템이 여러 언어로 작업을 처리하고 출력을 생성할 수 있다는 것을 의미하지만, 반드시 동일한 문장에서는 그렇지 않다는 것입니다. 이 한계를 강조함으로써, 우리는 이전 연구를 반영하여 NLP 모델에 코드믹싱 능력을 포함시키는 것을 독려합니다. 이를 위해서는 NLP 모델이 서로 다른 정도의 언어를 결합하는 동적을 포착해야 합니다.

49
형태론적 유사성뿐만 아니라 어조, 정형성 및
기타 문화적 미묘함과 같은 실용적 및 문맥적 특징에 대한
(Winata et al., 2020; Lai and Nissim, 2022; Kabra et al., 2023)의 연구에 따르면.

더 포용적인 언어 기술을 향하여
인공지능 대화 에이전트와 음성 기술의 발전의 주된 원동력인 생성적 LLM을 인식함에 따라 (Thoppilan 등, 2022; SambaNova Systems, 2023; Pratap 등, 2023), 우리는 LLM에 코드 혼용 출력 인식 및 생성 기능을 통합하는 것의 중요성을 강조하여 언어 기술의 포용성과 인간성을 향상시킬 필요성을 강조합니다. 대화 에이전트가 사용자의 언어 혼용 패턴을 반영할 수 있도록 함으로써 사람들은 언어적 정체성에 더 편안하고 진정성 있는 방식으로 의사소통할 수 있습니다. 실제로, Bawa 등의 최근 연구 (2020)에 따르면, 다중 언어 사용자들은 코드 혼용이 가능한 챗봇을 강력히 선호한다는 것을 보여주었습니다. 기계에게 읽을 수 있도록 말 패턴을 조정하는 필요성을 없애는 것은 언어학적 프로파일링 (Baugh, 2005; Dingemanse와 Liesenfeld, 2022)과 헤게모닉한 서양 중심의 기술적 설계의 영향을 완화시킬 뿐만 아니라, 자연스러운 대화 상호작용을 통해 언어 기술에 대한 사용자의 신뢰를 더욱 발전시킬 수 있습니다.

연구 투명성은 ChatGPT와 InstructGPT가 코드 혼용을 할 수 있다는 것을 보여주는 것 외에는, 이러한 시스템이 어떻게 코드 혼용을 하는지 자신있게 확인할 수 없는 이유로 인해 투명성이 부족합니다. ChatGPT와 같은 모델이 개발되는 과정과 엔지니어링 프로세스에 대한 정보가 없기 때문에, 우리는 그들의 훈련 데이터에 상당한 양의 코드 혼용 텍스트가 포함되어 있다고 추측할 뿐입니다. 더 큰 수준의 투명성과 책임을 돕기 위해, 우리는 앞으로 나올 LLMs가 모델이 어떻게 개발되었는지에 대해 더 개방적으로 이야기하고, 사용된 훈련 데이터를 정확하고 포괄적으로 문서화하기를 촉구합니다.

5 관련 연구

코드 혼합 데이터는 SEA에서 모노링구얼 데이터와 달리 인간이 정리한 코드 혼합 데이터셋은 제한적입니다. 이 자원 제한은 SEA에서 NLP 연구의 주요한 이슈입니다 (Winata et al., 2022). 인기 있는 현재의 코드 혼합 평가 벤치마크 (Aguilar et al., 2020; Khanuja et al., 2020)에는 SEA 언어가 포함되어 있지 않습니다.

동남아시아에서의 코드믹싱 연구는 언어 쌍과 크리올에 대해서만 한정적으로 다루고 있습니다. 예를 들어, 영어-타갈로그어 (Oco와 Roxas, 2012), 영어-인도네시아어 (Barik 등, 2019; Yulianti 등, 2021), 자바어-인도네시아어 (Tho 등, 2021), 중국어-영어 (Lyu 등, 2010; Love-nia 등, 2022; Zhang과 Eickhoff, 2023) 그리고 싱글리시 (Chen과 Min-Yen, 2015; Lent 등, 2021)9. 현재의 말뭉치는 동남아시아의 코드믹싱의 양적 측면을 전혀 다루지 못하고 있으며, 실제로 사용 가능한 데이터는 거의 없습니다 (Redmond 등, 2009). 이 연구에서는 LLMs를 활용하여 동남아시아 지역을 위한 합성 코드믹싱 데이터의 잠재력을 탐색하여 이러한 공백을 메우려고 합니다.

합성 코드 혼용 합성 데이터 생성은 데이터 부족 문제를 해결하기 위해 이전에 연구되었습니다. Solorio와 Liu (2008), Winata 등 (2019) 및 Tan과 Joty (2021)는 병렬 말뭉치에서 단어 정렬 및 후보 선택을 통해 합성 코드 혼용 문장을 생성하려고 시도했습니다. Liu 등 (2020)과 Adilazuarda 등 (2022)는 단일 언어 문장에서 기계 번역된 대응어로 단어를 대체하여 합성 코드 혼용 문장을 생성했으며, Pratapa 등 (2018), Rizvi 등 (2021) 및 Santy 등 (2021)는 이러한 대체를 위해 구문 분석 트리 구조를 활용했습니다. 또 다른 접근 방식은 단일 언어 문장을 코드 혼용 문장으로 번역하기 위해 신경 기계 번역을 수행하는 것입니다 (Appicharla 등, 2021; Gautam 등, 2021; Jawahar 등, 2021; Dowlagar 및 Mamidi, 2021). 이 연구에서는 다국어 LLM을 활용하여 합성 코드 혼용 문장을 생성하는 새로운 방법을 평가합니다.

6 결론

남동아시아 언어의 코드 혼용 데이터 부족을 개선하기 위해, 우리는 최첨단 다국어 대형 언어 모델 (LLM)을 사용하여 합성 코드 혼용 데이터를 생성하는 것을 탐구합니다. 한편으로는, BLOOMZ와 Flan-T5-XXL과 같은 공개적으로 사용 가능한 LLM은 구문적으로 다양한 코드 혼용 데이터를 생성하는 능력이 제한적임을 발견합니다. 반면에, ChatGPT와 InstructGPT와 같은 폐쇄 소스 모델은 자연스러운 코드 혼용 텍스트를 생성하는 데 더 우수하지만, 그 성능은 상당히 다양합니다.

상황을 악화시키기 위해, 일부 SEA 코드 혼용 데이터셋은 더 이상 공개되지 않습니다.

50
프롬프트 템플릿과 언어 페어링입니다. 더욱이, 많은 출력물들은 문법적, 의미론적, 신뢰성 문제로 고통받습니다. 따라서, 우리는 원어민의 참여 없이 LLM으로 생성된 합성 코드믹스 데이터를 주석 및 편집하는 데 사용하는 것에 대해 주의를 당부합니다.

7 제한사항

7.1 합성 혼합 코드 데이터의 효과성에 대한 하류 작업의 영향

우리의 연구에서는 합성으로 생성된 코드 혼용 데이터가 언어 모델의 코드 혼용 텍스트 처리 능력을 향상시키는 정도를 평가하지 않았습니다. 이전 연구 결과에 따르면, 합성 코드 혼용 데이터로 모델을 fine-tuning하는 것은 자연적으로 발생한 코드 혼용 데이터보다 성능 향상이 적다는 것을 보여주었습니다(Santy et al., 2021). 그러나 우리는 합성 데이터 생성의 품질이 미래의 다국어 LLMs와 함께 개선됨에 따라 이 성능 차이가 줄어들 것이라고 믿습니다.

7.2 인간이 생성한 데이터의 부족

우리는 코드 혼용성과 자연스러움의 정도를 주석으로 달았지만, 우리는 인간이 생성한 자연스러운 코드 혼용 문장이 주제에 대한 응답으로 존재하지 않았습니다. 따라서 우리는 합성 데이터의 데이터 분포를 인간이 생성한 데이터와 체계적으로 비교할 수 없었습니다. 그러나 문장이 코드 혼용될 수 있는 여러 가지 방법이 있기 때문에, 우리의 주요 관심은 문장이 얼마나 인간과 유사한지에 있으며, 이는 우리의 평가에서 충분히 포착되었다고 믿습니다.

7.3 단일 언어 미지시 제로샷 프롬프팅

우리의 연구는 영어로 작성된 프롬프트 템플릿만을 사용하여 언어 모델을 제로샷 방식으로 유도합니다. 향후 추가 조사에서는 (1) "영어-바하사 문장 생성" 대신 "영어-말레이 문장 생성"과 같은 코드믹스 프롬프트 템플릿을 사용하고 (2) 문맥 내 소수샷 예제로 코드믹스 데이터 생성 능력을 조사할 것입니다.

7.4 지시에 맞춰진 언어 모델

우리의 작업은 지시에 맞춰진 언어 모델만 다룹니다. 향후 작업에서는 지시에 맞춰지지 않은 다국어 모델들 간의 비교를 포함할 것입니다. 예를 들어, GPT3 (davinci) (Brown et al., 2020)와 BLOOM (Scao)입니다.

et al., 2022) - 지시 조정이 코드 혼용 데이터 생성에 미치는 영향을 탐구하기 위해.

7.5 영어 중심의 코드믹싱

우리의 연구는 코드믹스 데이터를 생성하는 데 초점을 맞추고 있습니다.
영어-동남아시아 언어 쌍에 대해서만입니다. 
향후 연구에서는 동남아시아 국가에서 흔히 사용되는 비영어 언어 쌍에 대한 코드믹스 데이터 생성을 조사할 계획입니다. (예: 말레이-중국어 및 인도네시아-자바어)

7.6 BLOOM과 Flan-T5-XXL의 실패

주어진 연구 투명성의 부족으로 인해 ChatGPT가 코드 혼합 텍스트 생성에서 더 나은 성능을 보이는 이유에 대한 연구가 부족하다고 가정합니다. 따라서 BLOOM과 Flan-T5-XXL과 같은 공개 모델은 사전 훈련 말뭉치와 지시 튜닝 데이터셋에서 코드 혼합 텍스트가 부족하여 코드 혼합을 수행할 수 없다고 가정합니다. 코드 혼합 텍스트의 사전 훈련 및 지시 튜닝 데이터에 대한 효과를 이해하기 위해 추가적인 조사가 필요합니다.

미래의 사전 훈련 데이터에는 합성 혼합 코드 데이터가 존재합니다.

우리가 LLM의 향후 세대에서 코드 혼용 능력을 지지함에 따라, 우리는 데이터 피드백의 잠재적인 위험을 인식하고 있습니다. 이는 이전 세대가 생성한 데이터로 재귀적으로 훈련하는 생성 모델이 편향을 증폭시키고 원래 분포의 꼬리에 대한 정보를 잃을 수 있다는 것을 의미합니다 (Shumailov et al., 2023; Taori and Hashimoto, 2022). 이러한 부정적인 영향은 인간이 생성한 콘텐츠를 통해 완화될 수 있으므로 (Shumailov et al., 2023), NLP 커뮤니티는 저자원 언어에 대한 자연스러운 코드 혼용 데이터를 수집하는 것이 필수적입니다.

8 윤리적 고려사항

코드믹싱은 다중언어 사용 커뮤니티의 언어적, 사회적, 문화적 정체성을 반영합니다. 연구자와 실무자들은 합성 코드믹싱에 대해 민감하고 존중하는 태도로 접근해야 하며, LLMs를 사용하여 코드믹싱 데이터를 생성할 때 문화적 도용이나 잘못된 표현의 잠재적 위험을 인식해야 합니다. LLMs는 웹 데이터로 훈련되기 때문에 특정 언어나 커뮤니티의 편견, 차별 또는 주변화를 지속시킬 수 있는 편향을 인코딩할 수 있습니다. 이전 연구에서도 합성 데이터가 피드백 루프에서 역할을 하는 방식이 어떻게 특정 언어나 커뮤니티의 편견을 강화시킬 수 있는지 문서화되어 있습니다.

51
편향된 언어 생성의 존재 (타오리와 하시모토, 2022). 따라서, 언어학자, 언어 전문가 및 지역사회 대표와의 협력은 편견과 문화적 민감성을 의도하지 않게 지속시키는 것을 피하기 위해 필요하다.

참고문헌

무함마드 파리드 아디라주아르다, 사무엘 차야위자야, 겐타 인드라 위나타, 파스칼 펑, 그리고 아유 푸르와리-안티. 2022년. IndoRobusta: 다양한 코드믹스된 인도네시아 지역 언어에 대한 견고성을 향해. 제1회 다국어 평가 확장 워크샵 논문집, 25-34쪽, 온라인. 계산언어학 협회.

구스타보 아길라르, 수디프타 카르, 타마르 솔로리오.
2020년. LinCE: 언어 코드 스위칭 평가를 위한 중앙 집중식 벤치마크. 제12회 언어 자원 및 평가 컨퍼런스 논문집, 1803-1813쪽, 프랑스 마르세유. 유럽 언어 자원 협회.

알함 피크리 아지, 겐타 인드라 위나타, 파지리 코토,
사무엘 차야위자야, 아데 로마돈니, 라흐마드 마헨드라, 케말 쿠르니아완, 다비드 모엘자디, 라디티오 에코 프라소조, 티모시 볼드윈, 제이 한 라우,
그리고 세바스찬 루더. 2022년. 한 나라, 700개 이상의 언어: 인도네시아에서 소외된 언어와 방언에 대한 NLP 도전. 제60회 연례 컴퓨터언어학회 논문집 (1권: 장문), 페이지 7226-7249, 아일랜드 더블린. 컴퓨터언어학회.

에디스 알드리지. 2012. 타갈로그어에서의 안티패시브와 에르가티비티. Lingua, 122:192–203.

Douglas G Altman. 1990. 의학 연구를 위한 실용적인 통계학. CRC 출판사.

라마크리슈나 아피차를라, 카말 쿠마르 구프타, 아시프 에크발, 푸시팍 바타차르야. 2021. IITP-MT at CALCS2021: 영어에서 힌글리시로의 신경망 기계 번역을 위한 비지도 합성 코드믹스 병렬 말뭉치 사용. 제5회 언어 전환에 대한 계산적 접근 방식 워크샵 논문집, 31-35쪽, 온라인. 계산언어학 협회.

에릭 암스트롱. 타밀어와 타밀어-영어 악센트.

예진 방, 사무엘 카히야와야, 나연 이, 웬리앙 다이, 단 수, 브라이언 윌리, 홀리 로베니아, 지위 지, 티에정 유, 윌리 청 등. 2023년. 추론, 환각 및 상호작용에 대한 ChatGPT의 다중작업, 다국어, 다중모달 평가. arXiv 사전인쇄 arXiv:2302.04023.

Anab Maulana Barik, Rahmad Mahendra, 그리고 Mirna
Adriani. 2019. 인도네시아어-영어 코드믹스 트위터 데이터의 정규화. 제5회 회의록에서.

노이즈가 있는 사용자 생성 텍스트 워크샵 (W-NUT 2019), 417-424쪽, 홍콩, 중국. 계산 언어학 협회.

존 보우. 2005. 언어적 프로파일링. 《블랙 언어학》, 167-180쪽. 라우트리지.

마리아 로우르데스 S 바우티스타와 앤드류 곤잘레스.
2006년. 동남아시아 영어. 세계 영어 핸드북, 130-144쪽.

안슬 바와, 프라나브 카드페, 프라틱 조시, 칼리카 발리,
그리고 모노짓 총두리. 2020. 다국어 사용자는 코드믹스하는 챗봇을 선호할까요? 자극을 주고 알아봅시다! ACM 인간-컴퓨터 상호작용 논문집, 4(CSCW1):1–23.

수잔 버크-셀릭슨. 1986. 문장 내 코드 스위칭에 대한 언어적 제약: 스페인어/히브리어 이중언어 연구. 사회 언어학, 15(3):313–348.

T. K. Bhatia와 W. C. Ritchie. 2004. 언어 혼용에 대한 사회적 및 심리적 요인. W. C. Ritchie와 T. K. Bhatia 편집, 이중언어에 대한 핸드북, 336-352쪽. Blackwell Publishing.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell 등. 2020. 언어 모델은 소수의 학습 데이터로도 학습할 수 있습니다. 신경 정보 처리 시스템의 발전, 33:1877-1901.

사무엘 카히야와야, 홀리 로베니아, 알함 피크리
아지, 겐타 인드라 위나타, 브라이언 윌리, 라마드 마헨드라, 크리스천 위비소노, 아데 로마도니, 카리사 빈센티오, 파지리 코토, 제니퍼 산토소, 다비드 모엘야디, 차야 위라완, 프레데리쿠스 후디, 이반 할림 파르모난간, 이카 알피나, 무함마드 사트리오 위차크소노, 일함 피르다우시 푸트라, 삼술 라마다니, 율리안티 외낭, 알리 아크바르 세피안드리, 제임스 자야, 카우스투브 D. 돌, 아리 아르디얀티 수리아니, 리프키 아피나 푸트리, 단 수, 키스 스티븐스, 마데 닌디야타마 니티아샤, 무함마드 파리드 아디라주아르다, 라이언 이그나티우스, 라이언디토 디안다루, 티에정 유, 비토 기파리, 웬량 다이, 얀 슈, 디야 다마푸스피타, 츠크 토, 이치완울 무슬림 카로 카로, 티라나 누르 파티아노사, 지웨이 지, 파스칼 펑, 그레이엄 뉴빅, 티모시 볼드윈, 세바스찬 루더, 헤리 수자이니, 사크리아니 사크티, 아유 푸르와리안티.
2022년. Nusacrowd: 인도네시아 자연어처리 자원을 위한 오픈 소스 이니셔티브.

조이스 YC 찬, 후웨이 카오, PC 칭, 탄 리.
2009. 광동어-영어 코드믹싱 말의 자동 인식. 국제 컴퓨터 언어학 및 중국어 처리 학술지, 제14권, 제3호, 2009년 9월.

수-챠오 천. 1996. 대만 캠퍼스 환경에서 중국인들 사이의 언어 전환을 언어 전략으로서의 코드 스위칭. 월드 잉글리시, 15(3):267–280.

T Chen과 Kan Min-Yen. 2015. 싱가포르 국립대학교 SMS 말뭉치.

52
정형원, 류 후, 셰인 롱프레, 바렛 조프, 이 태, 윌리엄 페더스, 에릭 리, 쉐지 왕, 모스타파 데흐가니, 싯다르타 브라마 등. 2022. 지시어 세부 조정 언어 모델의 확장. arXiv 사전 인쇄 arXiv:2210.11416.

필리핀 연방. 1936년. 연방법령 제184호: Govph.

모나디압, 줄리아히르스버그, 파스칼펑, 타마르 솔로리오 편집. 2014년. 코드 스위칭에 대한 계산적 접근 방식에 관한 첫 번째 워크샵 논문집. 계산언어학 협회, 도하, 카타르.

마크 딩게만스와 안드레아스 리젠펠트. 2022. 텍스트에서 대화로: 인간적이고 다양성을 인식하는 언어 기술을 위한 대화 말뭉치의 활용. 제60회 연례 컴퓨터 언어학 협회 학술대회 논문집 (1권: 장문), 5614-5633쪽, 아일랜드 더블린. 컴퓨터 언어학 협회.

A. 세자 도, 그루 오즈, 수나야나 시타라, 바바라 E. 불록, 알메이다 자클린 토리비오. 2021. 코드 스위칭에 대한 조사: 언어 기술을 위한 언어 및 사회적 관점. 제 59회 연례 협회 컴퓨터 언어학 및 제 11회 국제 공동 언어 처리 학회 논문집 (1권: 장문), 페이지 1654-1666, 온라인. 협회 컴퓨터 언어학.

수만 도와가르와 라디카 마미디. 2021. 영어-힌디어 코드 스위칭 기계 번역을 위한 게이트 컨볼루션 시퀀스 투 시퀀스 기반 학습. 제5회 언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 논문집, 26-30쪽, 온라인. 계산언어학 협회.

조셉 L 플라이스. 1971. 많은 평가자들 사이의 명목 척도 일치 측정. 심리학 보고서, 76(5):378.

Björn Gambäck과 Amitava Das. 2014. 코드믹싱의 복잡성 측정에 관하여. 제11회 국제 자연어 처리 학회 논문집, 인도 고아, 1-7쪽.

데반시 고탐, 프란샨트 코달리, 크시티지 구프타, 안몰 고엘, 마니시 스리바스타바, 그리고 포누랑감 쿠마라구루. 2021년. CoMeT: 병렬 단일 언어 문장을 사용한 코드믹스 번역을 향하여. 제5회 언어 코드스위칭에 대한 계산적 접근 방법 워크샵 논문집, 47-55쪽, 온라인. 계산언어학 협회.

클리프 고다드. 2005. 동아시아와 동남아시아의 언어: 소개. 옥스포드 대학 출판사.

F. Grosjean. 1982. 두 언어로 살아가는 삶: 이중언어에 대한 소개. 하버드 대학 출판사.

허싱웨이, 임정하오, 공예윤, 아 진, 장항, 임천, 조지안, 유시우밍, 단난, 천웨주 등. 2023. Annollm: 대규모 언어 모델을 더 나은 크라우드소싱 주석 작업자로 만들기. arXiv 사전 인쇄 arXiv:2303.16854.

인도네시아 공화국. 2002년. 1945년 인도네시아 공화국 헌법. 인도네시아 인민회의 사무총장.

가네시 자와하르, 엘 모아테즈 빌라 나구디, 무함마드 압둘-마지드, 그리고 락스 락슈마난, V.S. 2021. 합성 코드믹싱을 이용한 영어에서 힌글리시 기계 번역을 위한 텍스트-텍스트 트랜스포머 탐색. 제5회 언어 전환에 대한 계산적 접근 방법 워크샵 논문집, 36-46쪽, 온라인. 계산언어학 협회.

Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, 그리고 Monojit Choudhury. 2020. NLP 세계에서 언어 다양성과 포용성의 상태와 운명. 제 58회 연례 협회 컴퓨터 언어학 대회 논문집, 6282-6293쪽, 온라인. 협회 컴퓨터 언어학.

아누바 카브라, 엠미 리우, 심란 카누자, 알함 피크리 아지, 겐타 인드라 위나타, 사무엘 카하와지야, 아누올루와포 아레무, 페레즈 오가요, 그레이엄 뉴빅. 2023년. 다국어 및 다문화적 비유 언어 이해.

심란 카누자, 산디판 단다팟, 아니루드 스리니바산, 수나야나 시타람, 그리고 모노짓 초우드후리.
2020년. GLUECoS: 코드 스위칭 NLP를 위한 평가 기준. 연례 컴퓨터 언어학 협회 58차 회의 논문집, 3575-3585쪽, 온라인. 컴퓨터 언어학 협회.

앤디 커크패트릭. 2014. 동남아시아의 영어: 교육적 및 정책적 함의. 월드 잉글리쉬, 33(4):426–438.

폴 크로거. 1993. 타갈로그어의 구문 구조와 문법적 관계. 언어 연구 센터 (CSLI).

후이유안 라이와 말비나 니심. 2022. 다중 은유 언어 생성. 제29회 국제 계산 언어학 회의 논문집, 5939-5954쪽, 경주, 대한민국. 국제 계산 언어학 위원회.

J Richard Landis와 Gary G Koch. 1977. 범주형 데이터에 대한 관찰자 일치도의 측정. 생물통계학, 159-174쪽.

휴고 로랑송, 루실 소니에, 토마스 왕,
크리스토퍼 아키키, 알베르트 빌라노바 델 모랄,
테벤 르 스카오, 레안드로 폰 베라, 청하오 모우,
에드와르도 곤잘레스 폰페라다, 후우 뉴얀, 요르그
프로베르그, 마리오 사스코, 콴텐 로에스트, 안젤리나

53
맥밀란-메이저, 제라르 듀퐁, 스텔라 비더만,
안나 로저스, 루브나 벤 알랄, 프란체스코 데 토니,
지아다 피스틸리, 올리비에 능근, 소마이에 닉푸어,
마라임 마수드, 피에르 콜롬보, 하비에르 데 라 로사,
파울로 빌레가스, 트리스탄 트러시, 셰인 롱프레, 세바스찬 나겔,
레온 베버, 마누엘 로메로 무뇌, 지안 주, 다니엘 반 스트리엔, 자이드 알리아페이, 할리드
알무바라크, 부 민 치엔, 이치아르 곤잘레스-디오스,
아이토르 소로아, 카일 로, 마난 데이, 페드로 오르티스
수아레스, 아론 고카슬란, 샤믹 보스, 다비드 이펄
루와 아델라니, 롱 판, 히우 트란, 이안 유, 수하스
파이, 제니 침, 비올레트 르페르크, 수자나 일리치, 마
가렛 미첼, 사샤 루치오니, 야신 제르니트.
2022년. The bigscience ROOTS corpus: A 1.6TB
다국어 복합 데이터셋. Neural Information Processing Systems
Datasets and Benchmarks Track에서 열린 36회 컨퍼런스에서 발표된 논문.

헤더 렌트, 에마누엘레 부글리아렐로, 미리엄 드 로너, 첸 치우, 그리고 안데르스 쇼가드. 2021년. 크리올어를 위한 언어 모델에 관하여. 제25회 컴퓨터 자연 언어 학습 학회 논문집, 58-71쪽, 온라인. 컴퓨터 언어학 협회.

지한 리우, 겐타 인드라 위나타, 조장 린, 펑 쉬, 그리고 파스칼 펑. 2020. 제로샷 크로스-언어 작업 지향 대화 시스템을 위한 주의력 정보를 활용한 혼합 언어 훈련. 인공지능 AAAI 학회 논문집, 34권, 8433-8440쪽.

홀리 로베니아, 사무엘 카히아와야, 겐타 위나타,
펑 쉬, 얀 쉬, 지한 리우, 리타 프리스케, 티에정
유, 웬량 다이, 엘함 J. 바레지, 치펑 천,
샤오후안 마, 버트람 시, 그리고 파스칼 펑. 2022년.
ASCEND: 다중 대화에서의 코드 스위칭을 위한
중국어-영어 자발적 데이터셋. 제13회 언어 자원
및 평가 컨퍼런스 논문집, 7259-7268쪽, 마르세유,
프랑스. 유럽 언어 자원 협회.

다우-청 류, 티엔-핑 탄, 엥 셩 청, 그리고 하이저우 리. 2010년. 동남아시아에서의 중국어-영어 코드 스위칭 음성 말뭉치인 Seame. 국제 음성 의사소통 협회 제11회 연례 회의에서 발표.

로울 말리와트. 2021. 동남아시아의 언어 정책과 교육.

브라이언 미글리아자. 1996년. 동남아시아 대륙: 독특한 언어 지역. 언어학 논문, 75:17-25.

스네하 몬달, 리티카, 쉬레야 파타크, 프리티 조티, 그리고 아라빈단 라구비어. 2022년. CoCoa: 제어 가능한 코드 스위칭 생성을 위한 인코더-디코더 모델. 2022년 자연어 처리에 대한 경험적 방법 회의 논문집, 2466-2479쪽, 아부다비, 아랍에미리트 연합. 컴퓨터 언어학 협회.

니클라스 뮈니호프, 토마스 왕, 린탕 수타위카,
아담 로버츠, 스텔라 비더만, 테븐 르 스카오,
엠 사이풀 바리, 샹 셴, 정신 용, 하이-
리 슈콥프, 샹루 탕, 드라고미르 라데브,
알함 피크리 아지, 칼리드 알무바라크, 사무엘 알-
바니, 자이드 알 알리, 알버트 웹슨, 에드워드 라프,
그리고 콜린 라펠. 2022. 다국어 일반화를 통한
멀티태스크 파인튜닝.

캐롤 마이어스-스코튼. 1997. 언어 대결: 코드스위칭에서의 문법 구조. 옥스퍼드 대학 출판사.

나닐 오코와 라첼 에디타 로사스. 2012. 사전 기반 코드 스위칭 포인트 감지를 위한 패턴 매칭 개선. 언어, 정보 및 계산에 관한 26회 태평양 아시아 학회 논문집, 229-236쪽, 발리, 인도네시아. 인도네시아 대학 컴퓨터 과학 학부.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray 등. 2022. 인간의 피드백을 통해 언어 모델에게 지시를 따르도록 훈련시키기. arXiv 사전 인쇄 arXiv:2203.02155.

펨피 피스셀도, 라마드 마헨드라, 룰리 마누룽,
그리고 아르카 이와얀. 2008년. 인도네시아어를 위한 이중 수준 형태론 분석기. 2008년 호바트, 오스트레일리아에서 개최된 오스트레일라시안 언어 기술 협회 워크샵 논문집, 142-150쪽.

샤나 팝락. 1978년. 코드 스위칭의 문법 구조와 사회적 기능, 2권. 푸에르토리코 연구 센터, [뉴욕 시립 대학교].

Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi 등. 2023년. 1,000개 이상의 언어로 음성 기술 확장. arXiv 사전 인쇄 arXiv:2305.13516.

아디티야 프라타파, 가야트리 바트, 모노짓 총두리, 수나야나 시타람, 산디판 단다팟, 그리고 칼리카 바리. 2018년. 코드믹싱을 위한 언어 모델링: 언어학 이론 기반의 합성 데이터의 역할. 제56회 연례 협회 컴퓨터 언어학 대회 논문집 (1권: 장문), 1543-1553쪽, 멜버른, 호주. 협회 컴퓨터 언어학.

몬트 레드몬드, 킴모 코소넨, 그리고 캐서린 영. 2009. 모국어를 중간 언어로 사용한 교육: 동남아시아의 정책과 경험. 세계은행.

마셀 리드, 빅터 종, 수친 구루랑간, 그리고 루크 제틀모이어. 2022년. M2D2: 대규모 다중 도메인 언어 모델링 데이터셋. 2022년 자연어 처리에 대한 실험적 방법 회의록, 964-975쪽, 아부다비, 아랍에미리트 연합. 계산언어학 협회.

54
모하메드 사나드 자키 리즈비, 아니루드 스리니바산, 타누자 가누, 모노짓 초우드후리, 그리고 수나야나 시타람.
2021년. GCM: 합성 코드믹스 텍스트를 생성하기 위한 도구킷. 16회 유럽 지부 협회 컴퓨터 언어학 컨퍼런스: 시스템 데모, 205-211쪽, 온라인. 컴퓨터 언어학 협회.

함께 컴퓨터 삼바노바 시스템. 2023년.
BLOOMChat: 새로운 오픈 멀티언어 채팅 LLM.

데이비드 산코프, 샤나 팝락, 그리고 스와티 반니아라잔.
1990년. 타밀어에서의 임시 대출 사례. 언어 변이와 변화, 2(1):71-101.

세바스티안 산티, 아니루드 스리니바산, 그리고 모노짓 초우드후리. 2021. BERTologiCoMix: 코드믹싱이 다국어 BERT와 상호작용하는 방식은 어떤가요? 제2회 NLP 도메인 적응 워크샵 논문집, 111-121쪽, 키예프, 우크라이나. 계산언어학회.

테븐 르 스카오, 안젤라 팬, 크리스토퍼 아키키, 엘리 파블릭, 수자나 일리치, 다니엘 헤슬로우, 로만 카스타뉴, 알렉산드라 사샤 루치오니, 프랑수아 이본, 마티아스 갈레 등. 2022년. Bloom: 176b-파라미터 오픈 액세스 다국어 언어 모델. arXiv 사전 인쇄 arXiv:2211.05100.

할롤드 F. 쉬프만. 1998. 말레이시아 타밀인과 타밀 언어 문화.

일리야 슈마일로프, 자카르 슈마일로프, 이렌 조,
야린 갈, 니콜라스 파퍼노트, 그리고 로스 앤더슨.
2023년. 재귀의 저주: 생성된 데이터로 훈련하는 것은 모델이 기억을 잊게 만든다. arXiv 사전인쇄 arxiv:2305.17493.

유엔 신. 2017년. 놀지마, 놀아 - 싱글리시는 전 세계에서 연구되고 있다.

싱가포르 통계부. 2020년. 주요 결과. 2020년.

제임스 닐 스네든. 2003. 인도네시아어:
역사와 현대 사회에서의 역할. UNSW 출판사,
시드니.

타마르 솔로리오와 양 리우. 2008. 코드 스위칭 지점을 예측하는 방법 배우기. 2008년 자연어 처리에 대한 경험적인 방법에 관한 컨퍼런스 논문집에서, 973-981쪽, 호놀룰루, 하와이. 계산언어학 협회.

샘슨 탄과 샤피크 조티. 2021. 코드믹싱 on sesame street: 적대적 다국어 사용자의 도래. 2021년 북미 협회 컴퓨터 언어학 회의 논문집: 인간 언어 기술, 3596-3616쪽, 온라인. 컴퓨터 언어학 협회.

Ruixiang Tang, Xiaotian Han, Xiaoqian Jiang, 그리고 Xia Hu. 2023. llms의 합성 데이터 생성이 임상 텍스트 마이닝에 도움이 되는가? arXiv 사전 인쇄 arXiv:2303.04360.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, 그리고 Tatsunori B. Hashimoto. 2023년. Stanford 알파카: 지시 따르기 라마 모델. https://github.com/tatsu-lab/stanford_alpaca.

로한 타오리와 타츠노리 B 하시모토. 2022. 데이터 피드백 루프: 모델 기반 데이터셋 편향의 증폭. arXiv 사전 인쇄 arXiv:2209.03942.

이샨 타루네시, 샴안탁 쿠마르, 그리고 프리티 조티.
2021년. 기계 번역에서 코드 스위칭으로:
고품질의 코드 스위칭 텍스트 생성. 협회
계산 언어학 연례 회의 및 제 11 회
자연 언어 처리 국제 합동 회의 (1 권: 장문)에서 발표된 논문, 3154-3169 페이지, 온라인. 협회
계산 언어학.

C Tho, Y Heryadi, L Lukas, and A Wibowo. 2021.
인도네시아어와 자바어의 코드 혼합 감성 분석을 위한 어휘 기반 접근 방식. 
물리학 저널: 컨퍼런스 시리즈, 1869(1):012084.

로말 토피란, 다니엘 데 프라이타스, 제이미 홀, 노암 샤지어, 아푸르브 쿨슈레슈타, 헝-제 청, 알리샤 진, 테일러 보스, 레슬리 베이커, 유 두 등. 2022. Lamda: 대화 응용을 위한 언어 모델. arXiv 사전 인쇄 arXiv:2201.08239.

A. J. Toribio. 2002. 스페인어-영어 코드 스위칭
미국 라틴계 사이에서. 언어 사회학 국제 저널, 2002:89-119.

첸시 화이트하우스, 모노짓 초우드후리, 알함 피크리 아지. 2023년. 향상된 다국어 성능을 위한 Llm 기반 데이터 증강. arXiv 사전 인쇄 arXiv:2305.14288.

겐타 인드라 위나타, 알함 피크리 아지, 사무엘 카히아위-
자야, 라마드 마헨드라, 파지리 코토, 아데 로마드-
호니, 케말 쿠르니아완, 다비드 모엘자디, 라디-
티오 에코 프라소조, 파스칼 펑, 티모시 볼드윈,
제이 한 라우, 리코 센릭, 그리고 세바스찬 루더.
2023년. NusaX: 10개의 인도네시아 지방 언어를 위한
다국어 병렬 감성 데이터셋. 유럽 자연어처리 협회
제17회 컨퍼런스 논문집, 815-834쪽, 크로아티아 두브로브니크.
자연어처리 협회.

Genta Indra Winata, Alham Fikri Aji, Zheng-Xin Yong,
그리고 Thamar Solorio. 2022년. NLP에서 코드 스위칭 연구의
수십 년 진전: 동향과 도전에 대한 체계적인 조사. arXiv 사전 인쇄
arXiv:2212.09660.

Genta Indra Winata, Samuel Cahyawijaya, Zihan Liu,
Zhaojiang Lin, Andrea Madotto, and Pascale Fung.
2021. 코드 스위칭에서 다국어 모델은 효과적인가요? 제5회 언어 코드 스위칭에 대한 계산적 접근 방법 워크샵 논문집, 142-153쪽, 온라인. 계산언어학 협회.

55
Genta Indra Winata, Samuel Cahyawijaya, Zihan Liu,
Zhaojiang Lin, Andrea Madotto, Peng Xu, and Pascale Fung. 2020. 크로스 액센트 음성 인식에서 빠른 적응 학습. Interspeech 2020. ISCA.

Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, 그리고 Pascale Fung. 2019. 병렬 문장으로부터 신경망 기반 합성 데이터를 사용한 코드 스위칭 언어 모델. 제23회 계산언어학 컨퍼런스 (CoNLL) 논문집, 271-280쪽.

에비 율리안티, 아즈말 쿠르니아, 미르나 아드리아니, 그리고 요피 세토 두토. 2021년. 인도네시아어-영어 코드믹스 텍스트의 정규화 및 감정 분류에 미치는 영향. 국제 고급 컴퓨터 과학 및 응용지, 12(11).

Ruochen Zhang, Samuel Cahyawijaya, Jan Christian Blaise Cruz, 그리고 Alham Fikri Aji. 2023년. 다국어 대형 언어 모델은 아직 코드 스위처가 아닙니다.

Ruochen Zhang와 Carsten Eickhoff. 2023. Crocosum: 교차언어 코드 스위칭 요약을 위한 벤치마크 데이터셋. arXiv 사전 인쇄 arXiv:2303.04092.

56
동남아시아에서 사용되는 언어들

SEA에서는 1,200개 이상의 언어가 사용되고 있습니다 (Redmond et al., 2009; Maliwat, 2021). 이 중 700개는 인도네시아에서 사용되고 있습니다 (Aji et al., 2022; Cahyawijaya et al., 2022). 우리는 다음 단락에서 연구에 사용된 SEA 언어들에 대해 설명합니다.

중국어(간체)는 중국어(간체)로 표기되며, 중국어는 중국어-티베트어 언어 가족에 속하며 한자 문자를 사용합니다. 중국 동남부의 해안성 지방인 후난, 광동, 하이난 등에서 중국인들이 이주함에 따라 중국어(간체)는 동남아시아에서 널리 사용됩니다. 동남아시아의 중국계 사람들은 종족적인 문화적 정체성을 나타내기 위해 "화인"이라는 용어를 자주 사용합니다. 이 용어는 "중국인"이라는 용어와는 달리 국적과 주로 관련이 있는데, 두 용어 모두 "중국인"이라고 번역될 수 있습니다. 싱가포르는 동남아시아 국가 중에서 가장 많은 중국계 인구를 가지고 있으며, 중국어는 싱가포르의 공식 언어 중 하나로 간주됩니다.
중국어는 각 중국 문자가 하나의 형태소에 해당하고, 문법적 변화가 거의 없는 언어로 "고립된" 언어로 특징지어집니다. 중국어는 의미를 나타내기 위해 상형 문자(한자)를 사용하는 로고그래픽 쓰기 체계를 사용합니다. 중국어는 또한 4개의 음조와 하나의 중립음조를 가진 음조 언어입니다. 일반적으로 기본적인 주어-동사-목적어의 어순을 가지며, 동사를 변형하여 시제를 나타내는 대신 了(le)와 着(zhe)와 같은 양상 입자를 사용하여 문장의 시간적 위치를 나타냅니다.

인도네시아어는 인도네시아의 국어입니다. 전 세계에서 약 3억 명이 사용합니다. 인도네시아어는 리아우-조호르 스울탄국의 문학적인 '고전 말레이어'에서 발전되었으며 지역별로 다양한 변형이 있습니다. 인도네시아어는 라틴 문자로 쓰여지며 표준 말레이어와 80% 이상의 어휘적 유사성을 가지고 있습니다. 인도네시아어는 음조가 없으며 19개의 자음, 6개의 모음, 3개의 이중모음을 가지고 있습니다. 강세는 마지막에서 두 번째 음절에 있으며 단어 순서는 주어-동사-목적어입니다. 선택적으로 명사 분류기가 세 가지 있습니다. 인도네시아어에는 두 가지 사회적 등록이 있으며 다양한 접두사, 접미사, 양쪽접사, 중복을 포함한 풍부한 접사 체계가 있습니다. 인도네시아어의 대부분의 접사는 파생적입니다.

표준 말레이어 표준 말레이어 (msa)는 말레이시아, 브루나이, 싱가포르의 국가 언어이며 전 세계에서 약 2억 9천만 명이 사용합니다. 표준 말레이어의 어순은 SVO이며 접두사 (awalan), 접미사 (akhiran), 양쪽 접사 (apitan) 및 중간 접사 (sisipan)의 네 가지 유형의 접사가 있습니다. 표준 말레이어와 인도네시아어는 동일한 말레이어 언어에서 비롯되었으며 상호 이해가 가능하지만 철자와 어휘에서 차이가 있을 수 있습니다. 대출어가 한 예입니다. 네덜란드어와 영어의 서로 다른 식민지 영향으로 인도네시아어는 주로 네덜란드어 대출어를 흡수하고 말레이어는 영어 대출어를 흡수합니다. 두 언어는 또한 동일한 쓰여진 단어의 의미에서 차이가 있을 수 있으며 이를 일반적으로 상호 언어 동형어라고 합니다. 예를 들어, "polisi"는 인도네시아어에서 "경찰"을 의미하지만 표준 말레이어에서는 "정책"을 의미합니다.

타갈로그어 (tgl)는 약 8200만 명의 원어민에 의해 필리핀에서 사용되는 오스트로네시아어입니다. 이 언어는 접착성과 음절 강조를 가지고 있어 풍부하고 복잡한 형태론을 가지고 있습니다 (Kroeger, 1993). 타갈로그어의 표준형인 필리핀어는 국가의 공식 언어입니다. 필리핀어와 타갈로그어의 차이는 사회정치적인 면보다는 사회언어학적인 면에서 더 큽니다: 1936년의 공화국 법령 제184호는 "국가 언어 개발"을 목적으로 한 국가위원회를 설립했습니다. 이로 인해 타갈로그어가 필리핀어로 표준화되었습니다. 실제로 필리핀어는 타갈로그어와 구별할 수 없으며, 다만 f, j, c, x, z와 대여어가 추가되었습니다 (필리핀 공화국, 1936).

베트남어(Vie)는 베트남의 국어로 전 세계 약 8,500만 명이 사용합니다. 이 언어는 오스트로아시아어 언어 가족에 속하며 6개의 독특한 음조를 나타내기 위해 강세를 사용합니다. 베트남어의 문장 구조는 SVO(주어-동사-목적어) 순서를 따르며 중국어의 강한 영향으로 인해 양화사의 존재에서 필수적으로 분류사를 사용합니다. 예를 들어, "bốn gà"라고 쓰는 대신에 "bốn con gà"라고 써야 합니다. 여기서 "con"은 비인간적인 생물에 대한 분류사입니다.

타밀어 (tam)은 타밀나두와 스리랑카에서 기원한 드라비다어입니다. 싱가포르의 상당한 타밀인 이민자들에 의해 사용되고 있습니다 (2.5%의 인구 비율).

인구의 57% (싱가포르, 2020)와 말레이시아의 9% (인구, Schiffman, 1998)는 무역, 이주, 계약 노예, 시민 불안정성의 역사로 인해 발생한 것이다. 싱가포르는 타밀어를 공식 언어로 채택하였으며, 이는 인도에서 기원한 유일한 언어이다. 타밀어는 형식적인 문학 시스템을 가지고 있으며, 어휘적으로 독특한 강세가 없으며, 비-롯틱한 특징을 가지고 있다 (Armstrong). 타밀어는 SOV 문장 구조를 사용한다. 타밀어-영어 코드믹싱은 임시 대여어(nonce loan)와 같은 흥미로운 언어 현상을 보여준다. 이는 영어에서 유래한 많은 임시 대여어가 타밀어 동사에 해당하는 목적어를 차지하거나 그 반대로 이루어진다 (Sankoff et al., 1990).

싱글리시 싱글리시는 싱가포르에서 널리 사용되는 대화용 언어입니다. 이는 싱가포르에서 많은 다른 언어를 사용하는 사람들 간의 오랜 언어 접촉으로 생겨난 영어 기반의 크리올 언어입니다. 이 언어는 화씨, 말레이어, 테처어, 광둥어, 타밀어를 포함한 많은 언어를 사용하는 사람들 사이에서 사용됩니다. 싱글리시는 약 400만 명의 사용자가 있으며, 이 언어의 독특한 특징 중 하나는 남중국 방언에서 빌린 실용적인 입자의 많은 사용입니다. 이에 대한 한 예로는 "라"가 있으며, "그녀의 드레스가 너무 짧아 라"라는 문장에서는 주장을 강조합니다.

B HuggingFace 추론 API

우리는 HuggingFace의 추론 API를 사용하여 다국어 LLMs를 프롬프트합니다. 왜냐하면 우리는 176B-파라미터 BLOOMZ 모델 (Muennighoff et al., 2022)과 같은 수백억 개의 파라미터를 가진 모델을 호스팅하기에 충분한 로컬 컴퓨팅 자원이 없기 때문입니다. 텍스트 대 텍스트 작업은 텍스트 생성 작업과 동일하게 처리되며, max_new_tokens (생성할 새로운 토큰의 양)을 100으로 설정하고, temperature를 0.7로 설정하고, repetition_penalty를 1.2로 설정합니다.

C OpenAI 추론 API

우리는 OpenAI의 공식 API를 사용하여 davinci-003과 davinci-002를 모두 프롬프트합니다. 특히, 최대 생성 길이가 128인 openai.Completion.create를 사용합니다. 다른 모든 매개변수에 대해서는 기본값을 사용합니다.

D  Flan-T5-XXL 비영어 출력

Flan-T5-XXL이 비영어 출력을 생성할 때 대부분은 무의미한 것으로 관찰됩니다.

이것은 기름 치료를 위한 공기이며 주변 생활입니다.
인공 지능은 내부에 아이를 가진 주민을 식별하기 위해 사용되는 보안 사무실입니다.
그는 그의 날씨를 수행하기 시작한 그의 날씨를 가지고 있었습니다.
예술가는 재능 있는 사람들의 분야에서 뛰어난 재능을 창조했습니다.

E BLOOMZ의 교육 언어
유통

BLOOMZ는 ROOTS corpus (Laurenc¸on et al., 2022)에서 사전 훈련된 다국어 176B-parameter 언어 모델 BLOOM (Scao et al., 2022)을 finetuning하여 만들어졌으며, 이는 xP3 (Muennighoff et al., 2022)라고 알려진 프롬프트 지침 모음에 대해 수행되었습니다. 표 1과 표 2는 우리 논문에서 조사한 SEA 언어의 비율을 ROOTS 및 xP3 데이터셋에서 보여줍니다. 인도네시아어와 중국어는 타밀어보다 비율이 높지만, BLOOMZ는 타밀어에 대해 이전 두 언어보다 약 20% 성능 차이로 더 잘 코드믹스합니다.

언어  백분율 분포 (%)

영어  25%
스페인어  20%
중국어  15%
한국어  10%
프랑스어  8%
독일어  7%
이탈리아어  5%
일본어  4%
기타  6%

영어         30.04
중국어 (간체) 16.2
베트남어        2.7
인도네시아어        1.2
타밀어           0.2

테이블 1: ROOTS 말뭉치에서의 언어 비율
(Laurenc¸on et al., 2022).

ChatGPT의 생성에 있어서 자연스러움과 유창성 문제

우리는 문법적 및 의미론적 오류의 완전하지 않은 목록과 부자연스러움의 이유를 문서화합니다.

58
1
대출어
2
주제와 관련된 명사
3
언어적 요소
0
20 40
60 80
100

언어 (a) 프롬프트의 백분율

중국어

인도네시아어 말레이어 타갈로그어 타밀어
베트남어

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(b) 주제

인공지능

가족 음식 교통 날씨

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(c) 템플릿

아무리 어려워도 포기하지 마세요.
너무 슬퍼하지 마세요.
당신은 훌륭한 사람입니다.
오늘 하루도 힘내세요.
사랑해요.

CM 스타일을 명확하게 정의하다. 원어민처럼 말하는 스타일을 모방하다. 양언어 사용자 두 명. CM 문장을 작성하다.

그림 11: 다빈치-002의 코드 혼합 데이터 생성 능력 분석.

1
대출어
2
주제와 관련된 명사
3
언어적 요소
0
20 40
60 80
100

언어 (a) 프롬프트의 백분율

중국어

인도네시아어 말레이어 타갈로그어 타밀어
베트남어

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(b) 주제

인공지능

가족 음식 교통 날씨

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(c) 템플릿

아무리 어려워도 포기하지 마세요.
너무 슬퍼하지 마세요.
당신은 훌륭한 사람입니다.
오늘 하루도 힘내세요.
사랑해요.

CM 스타일을 명확하게 정의하다. 원어민처럼 말하는 스타일을 모방하다. 양언어 사용자 두 명. CM 문장을 작성하다.

그림 12: 다빈치-003의 코드믹스 데이터 생성 능력 분석.

1
대출어
2
주제와 관련된 명사
3
언어적 요소
0
20 40 60 80
100

프롬프트의 백분율
(a) 언어

중국어

인도네시아어 말레이어 타갈로그어 타밀어 베트남어

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(b) 주제

인공지능

가족 음식 교통 날씨

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(c) 템플릿

말하는 스타일을 모방하다.

이 문장을 한국어로 번역해주세요.

그림 13: BLOOMZ의 코드 혼합 데이터 생성 능력 분석.

1
대출어
2
주제와 관련된 명사
3
언어적 요소
0
20 40
60 80
100

언어 (a) 프롬프트의 백분율

중국어

인도네시아어 말레이어 타갈로그어 타밀어
베트남어

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(b) 주제

인공지능

가족 음식 교통 날씨

1
대출어
2
주제와 관련된 명사
3
언어적 요소
(c) 템플릿

아무리 어려워도 포기하지 마세요.
너무 슬퍼하지 마세요.
당신은 훌륭한 사람입니다.
오늘 하루도 힘내세요.
사랑해요.

CM 스타일을 명확하게 정의하다. 원어민처럼 말하는 스타일을 모방하다. 양언어 사용자 두 명. CM 문장을 작성하다.

그림 14: Flan-T5-XXL의 코드 혼합 데이터 생성 능력 분석.

59
언어  퍼센트 분포 (%)


영어         39.25
인도네시아어       4.85
중국어 (간체)  4.83
베트남어        3.27
타밀어          0.97

표 2: xP3 데이터셋에서의 언어 비율
(Muennighoff et al., 2022).

표 4에서 ChatGPT의 생성 과정에서.

G  주석 작성자와 상호 주석자 동의

우리는 총 13명의 주석가를 보유하고 있으며, 그 중 일부는 두 개 이상의 동남아시아 언어를 구사합니다. 모두가 자신의 동남아시아 언어를 모국어로 사용하며, 대부분은 동남아에서 자랐습니다. 주석가 중 많은 사람들이 인공지능 연구자이며, 북반구에 거주하고 있습니다. 모든 주석가는 논문의 저자입니다. 표 3에서는 Fleiss의 Kappa κ (Fleiss, 1971)를 사용하여 자연스러움 주석에 대한 주석가 간 일치 점수를 보고합니다. 이는 항목에 대해 범주형 등급을 할당할 때 고정된 주석가 수 사이의 일치도를 측정합니다. 이는 다중 주석가 설정에 적용될 수 있으며, 모든 주석가가 모든 항목에 주석을 달 필요는 없습니다. 1에 가까울수록 주석가 간 일치도가 높습니다.
지침에 따르면 (Landis and Koch, 1977; Altman, 1990), 영어-인도네시아어 주석은 공정한 일치도를 가지고 있으며, 영어-중국어와 싱글리시 주석은 상당한 일치도를 가지고 있으며, 영어-타갈로그어 주석은 주석가들 사이에 거의 완벽한 일치도를 가지고 있습니다.

언어 N(주석자) κ

영어-중국어 3      0.6431
영어-인도네시아어 3    0.2165
영어-말레이어   1       -
영어-타갈로그어 2      0.8268
영어-타밀어  1       -
영어-베트남어 1     -
싱글리시      3      0.6199

표 3: ChatGPT가 생성한 혼합 언어 텍스트의 자연스러움에 대한 주석자 간 일치 점수.
N(주석자)는 주석자의 총 수를 나타내며, κ는 Fleiss의 Kappa 일치 점수를 나타냅니다.

60
센티미터

가정하에, 당신이 영어-말레이어 이중언어 사용자라고 가정한다면, 교통에 관한 자연스러운 영어-말레이어 코드믹스 문장을 어떻게 작성하겠습니까? (ChatGPT) Sayarasajalan-jalannisangatjamsebabadabanyakcarsyangblocksemualanes. (교통이 매우 혼잡한 것 같아요. 모든 차선을 막고 있는 차량들이 많기 때문입니다.) 이 문장에서는 영어와 말레이어 단어를 섞어 코드믹스 문장을 만들었습니다. 문장은 말레이어로 시작하며...

3

(다빈치-003) "오랜 시간이 걸리는 작업은 지루하게 만들어요!"

0

오늘 교통 정말 혼잡해요.

(BLOOMZ) 고속도로 교통 체증. 0

(Flan-T5-XXL) 지난 일년 동안 도로 상의 차량 수가 32% 감소했습니다. 0

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 음식에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT) 발화자1: 안녕, 너는 인도네시아 요리인 나시 고렝을 먹어봤니?
발화자2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너는 이전에 먹어봤니?
발화자1: 네, 먹어봤어. 맛의 조합이 정말 좋아. 너는 새테 아얌을 먹어봤니?
발화자2: 오, 네, 나는 새테 아얌을 정말 좋아해!

2

(Davinci-003)"영어 사용자: 저는 저녁으로 정말 놀라운 나시 고렝을 먹었어요! 인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요? 영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요.

2

(다빈치-002) "A: 당신이 가장 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식을 좋아해요, 특히 나시고렝이죠. A: 네, 저도 나시고렝을 좋아해요!"

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어? M: 오! 기대했던 대로 정말 재미있었어. W: 다행이다. 다음에 어디 가면 나도 같이 갈 거라고 말했지 않았어? M: 응... 그래 그럼."

0

(Flan-T5-XXL) M: 파티 음식 어때? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어. 0

(b) 템플릿: 두 명의 양언어 사용자 CM이 싱글리시를 구사할 수 있는 사람의 말투를 모방하여 가족에 관한 한 문장을 말한다. (ChatGPT) 에이, 알지 뭐, 가족은 아주 중요하다니까, 항상 오징어와 고추장처럼 붙어다녀야지, 될거야? 3
(Davinci-003) "우리 가족이야, 우린 너무 친해, 어디든지 함께 갈 수 있어!" 3
(Davinci-002) 우리 가족이 최고야! 0
(BLOOMZ) 0
(Flan-T5-XXL) 집에 가서 가족을 만나러 갈 거야. 0

(c) 말투를 모방해보세요.

CM Code-mixing은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹스된 영어-중국어 문장을 생성할 수 있을까요? (ChatGPT) 물론, 예를 들어 "점심에는 ∏ !(짜지) 후라이드 치킨을 먹는 걸 좋아해요."라고 할 수 있습니다. 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 좋아해요! 0 (Davinci-002) "FPFP  }}⇤⇤ÑÑ⇥⇥ 두부, 두부, 먹기에는 좋지 않아요." 0 (BLOOMZ) fliÔÂ⇤ F Å⇤*⇢⇥ 0 (Flan-T5-XXL) 요리사가 음료를 준비합니다. 0
(d) 템플릿: CM을 명확히 정의하세요.

CM 상상해보세요. 당신이 베트남어를 사용하는 사람이라고 가정해봅시다. 영어와 베트남어를 함께 사용하여 날씨에 대해 어떻게 이야기할까요?

(ChatGPT) "오늘은 날씨가 덥지 않으니까, 나는 반바지와 티셔츠를 입을 생각이야."

(Davinci-003) 오늘 날씨가 아마도 아름다울 거야, 그리고 이따가는 구름이 조금씩 덮을 거야.

(Davinci-002) 난 여기 날씨가 너무 덥지도 않고 너무 추지도 않아서 좋아요.
(BLOOMZ) 한 통 번역을 이용하여, 그리고 두 번째 통역으로 한국어로 번역해주세요.
(Flan-T5-XXL) 고객님은 항상 정중하게 통신하시고, 또한 높은 반응률을 유지해주셔서 감사합니다.
(e) 템플릿: 원어민 스피커

CM

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 우리가 살고 있는 방식, 일하는 방식, 그리고 지금 살아가는 방식을 혁신하고 있습니다. 이는 프로젝트에 현대적인 솔루션을 제공하고 일부 자동화된 작업을 처리함으로써 기다리고 있는 몇 가지 작업을 자동화합니다.

3

(Davinci-002) 인공지능은 우리가 감사해야 할 것이다.
(BLOOMZ) 인공지능 전문가가 양 언어를 구사하는 동료의 도움으로 학생에게 자신의 전문 분야를 설명한다.
(Flan-T5-XXL) 학교에서 차량 학습을 하는 학생은 부드러운 학습 경험을 위해 몇 가지 문제를 해결하고 명예로운 남성의 지도를 받는다.
(f) CM 문장을 작성하는 템플릿: 다양한 언어와 주제 분야를 가진 프롬프트 템플릿 및 다른 LLM의 응답을 포함한 코드 혼합 / 비 코드 혼합 문장. 화자의 국적을 지정하는 템플릿도 포함한다. ChatGPT의 원래 생성물에 설명이 포함되어 있다는 점을 참고하십시오.

23
(a) 템플릿: 이중언어 사용자로 가정하다.

CM

가정하에 당신이 영어-말레이어 이중언어 사용자라고 가정한다면, 교통에 관한 자연스러운 영어-말레이어 혼합 문장을 어떻게 작성하겠습니까?

차트GPT) 사야라사자란-자나니상잣잠세바바다
바냐크카르스양블록세무알라네스. (아이싱크더트래픽이
베리컨제스티드베커스어아레알로트오브카즈댓아
블로킹올레인스.)

이 문장에서는 영어와 말레이어 단어를 섞어서 코드믹스 문장을 만들었습니다. 이 문장은 말레이어로 시작하여...

3

(Davinci-003) "오래 걸리는 작업은 지루하게 만들어요!"

0

오늘 교통 정말 혼잡해요.

(BLOOMZ) 고속도로에서 교통 체증이 발생했습니다. 0

(Flan-T5-XXL) 지난 일년 동안 도로 상의 차량 수가 32% 감소했습니다. 0

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 음식에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT) 발화자1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어?
발화자2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너도 먹어봤어?
발화자1: 네, 먹어봤어. 맛의 조합이 정말 좋아. 새테 아얌도 먹어봤어?
발화자2: 아, 네. 새테 아얌을 정말 좋아해! ..<중략>

2

(Davinci-003)"영어 사용자: 저는 방금 저녁으로 정말 놀라운 나시 고렝을 먹었어요!
인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요?
영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요.

2

(다빈치-002) "A: 당신이 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식, 특히 나시고렝을 좋아해요.
A: 네, 저도 나시고렝을 좋아해요!"

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어요?
M: 오! 기대했던 대로 정말 재미있었어요. W: 다행이네요. 다음에 어디 가면 저도 데려가줄 거라고 말한 적 있잖아요?
M: 응... 그럼 좋아요."

0

(Flan-T5-XXL) M: 파티 음식 어때? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어. 0

(b) 템플릿: 두 개의 양언자

CM 한 문장으로 싱글리쉬를 구사할 수 있는 사람의 말투를 모방해 가족에 대해 이야기해봐.
(ChatGPT) 에이, 알지 랏, 가족은 엄청 중요하다니까, 항상 오징어와 고추장처럼 붙어다녀야지, 될거야? 3
(Davinci-003) "우리 가족이야, 우린 너무 가까워서 어디든지 함께 갈 수 있어!" 3

(다빈치-002) 우리 가족은 최고야! 0

(BLOOMZ) 0 (Flan-T5-XXL) 가족을 보러 집에 갈 거야. 0
(c) 템플릿: 말하는 스타일 모방하기

CM 코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹싱된 영어-중국어 문장을 생성해볼 수 있을까요?
(ChatGPT) 물론, 예를 들어보겠습니다: "점심에는 ∏ !(짜지) 후라이드 치킨을 먹는 걸 좋아해요." 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 사랑해요! 0

(다빈치-002) "두부, 두부, 먹기에 좋지 않아요, 좋지 않아요." 0

(BLOOMZ) 플라워 배송 서비스 제로

(Flan-T5-XXL) 한 요리사가 음료를 준비합니다. 0

(d) 템플릿: CM을 명확하게 정의하다.

CM 상상해보세요. 당신이 베트남어를 사용하는 사람이라고 가정해봅시다. 영어와 베트남어를 함께 사용하여 날씨에 대해 어떻게 말할 것인가요?

(ChatGPT) "오늘은 날씨가 덥지 않으니까, 반바지와 티셔츠를 입을 거야." 
(Davinci-003) "나는 오늘 날씨가 아름다울 거라고 확신해, 지금은 날씨가 좋아 보여." 
(Davinci-002) "여기 날씨가 너무 덥지도 않고 너무 추지도 않아서 좋아. 날씨가 좋아서 좋아." 
(BLOOMZ) "해당 문장을 한국어로 번역하고, 두 번째 문장에는 한 가지 단어를 추가해주세요." 
(Flan-T5-XXL) "고객님은 항상 정중하고 인내심이 많으며, 물건을 사기 전에 잘 생각하고 결정하십니다." 
(e) 템플릿: 원어민 스피커

CM

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 현대적인 솔루션을 제공하고 일부 자동화된 작업을 처리함으로써 우리가 살고 일하는 방식을 혁신하고 있습니다. (Davinci-002) 인공지능은 우리가 감사해야 할 것입니다. (BLOOMZ) 인공지능 전문가가 동료의 도움으로 양 언어를 구사하는 학생에게 자신의 전문 분야를 설명합니다. (Flan-T5-XXL) 학교에서 차량을 연구하는 학생들을 위해 명예를 위한 작업을 수행하는 남성을 통해 더 많은 파괴력을 조사합니다. (f) CM 문장을 작성하세요.

그림 16: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비 코드 혼용 문장을 포함하는 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다. 23
(b) 템플릿: 말하는 스타일 모방

CM 가정하에 당신이 영어-말레이어 이중언어 사용자라고 가정한다면, 교통에 관한 자연스러운 영어-말레이어 혼합 문장을 어떻게 작성하겠습니까? (ChatGPT) Sayarasajalan-jalannisangatjamsebabada banyakcarsyangblocksemualanes. (교통이 매우 혼잡한 것 같아요. 모든 차선을 막고 있는 차량들이 많기 때문에.) 이 문장에서는 영어와 말레이어 단어를 혼합하여 코드-믹스 문장을 만들었습니다. 문장은 말레이어로 시작하여... <중략> 3 (Davinci-003) "Kerja yang mengambil masa yang lama seperti menunggu lamadilaluanrayamembuatkansaya bosan!"

0

오늘 교통 정말 혼잡해요.

(BLOOMZ) 고속도로 교통 체증. 0

(Flan-T5-XXL) 지난 일년 동안 도로 상의 차량 수가 32% 감소했습니다.

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해 볼 수 있나요? 그들이 음식에 대해 이야기하는 대화를 상상해 볼 수 있나요? (ChatGPT) 발화자1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어? 발화자2: 네, 먹어봤어요. 제가 가장 좋아하는 음식 중 하나에요. 이전에 먹어봤어요? 발화자1: 네, 먹어봤어요. 맛의 조합이 정말 좋아요. 새테 아얌을 먹어봤어요? 발화자2: 네, 새테 아얌을 정말 좋아해요! ..<중략> 2
(Davinci-003) 영어 사용자: 저는 방금 저녁으로 정말 놀라운 나시 고렝을 먹었어요! 인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요? 영어 사용자: 저는 가도 가도와 아얌 페네트를 정말 좋아해요. ..<중략> 2 (Davinci-002) A: 당신의 가장 좋아하는 음식은 무엇인가요? B: 저는 인도네시아 음식, 특히 나시 고렝을 좋아해요. A: 네, 저도 나시 고렝을 좋아해요!" 1

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어? M: 오! 기대했던 대로 정말 재미있었어. W: 다행이다. 다음에 어디 가면 나도 같이 갈 거라고 말했지 않았어? M: 응... 그래 그럼."

0

(Flan-T5-XXL) M: 파티 음식 어떻게 생각해? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어.

0

(b) 템플릿: 두 개의 양언자

CM Singlish로 말할 수 있는 사람의 말투를 모방하여 가족에 관한 한 문장을 만들어보세요. (ChatGPT) 에이, 알지 라, 가족은 아주 중요한 거야, 항상 오징어와 고추소스처럼 붙어있어야 돼, 될거야? 3
(Davinci-003) "우리 가족이야, 우린 너무 가까워서 어디든 함께 갈 수 있어!" 3
(Davinci-002) 우리 가족이 최고야! 0
(BLOOMZ) 0
(Flan-T5-XXL) 집에 가서 가족을 만나러 갈 거야. 0
(c) 템플릿: 말투 모방

CM

코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹싱된 영어-중국어 문장을 생성해볼 수 있을까요? (ChatGPT) 물론, 예를 들어보겠습니다: "점심에는 ∏ !(짜지) 후라이드 치킨을 먹는 걸 좋아해요." 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 사랑해요! 0 (Davinci-002) "FPFP  }}⇤⇤ÑÑ⇥⇥ 두부, 두부, 먹기에는 좋지 않아요." 0 (BLOOMZ) fliÔÂ⇤ F Å⇤*⇢⇥ 0 (Flan-T5-XXL) 요리사가 음료를 준비합니다. 0
(d) 템플릿: 코드믹싱을 명확하게 정의하세요.

CM

상상해보세요, 당신이 베트남어를 사용하는 사람이라고 가정하면, 영어와 베트남어를 혼용하여 날씨에 대해 어떻게 이야기할 것인가요?

(ChatGPT) "오늘은 날씨가 덥지 않아서 나는 반바지와 티셔츠를 입을 생각이야."

3

(Davinci-003) 오늘 날씨가 아마도 아름다울 거야, 그리고 이따가는 구름이 조금씩 덮을 거야.

(Davinci-002) 난 여기 날씨가 좋아. 너무 더우지도 않고 너무 추지도 않아.

0

(BLOOMZ) 한국어로 번역되지 않은 이메일은 이해할 수 없으며, 또한 두 번째 이메일을 보내지 않을 것입니다: 0

(Flan-T5-XXL) 고객님께서는 티셔츠를 착용하고 계시지만, 랭크 번호에 따라 상품의 재고가 0개입니다. (e) 템플릿: 원어민 스피커

CM

인공지능에 관한 영어와 타갈로그어 혼합 문장을 작성하십시오.

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 우리가 살고 일하고 살아가는 방식을 혁신하고 있습니다. 현대적인 솔루션을 제공하고 일부 자동화된 작업을 처리함으로써 기다리고 있는 몇 가지 프로젝트를 수행합니다.

3

(다빈치-002) 인공지능은 우리가 감사해야 할 것이다.

0

(BLOOMZ)인공지능 전문가가 동료의 도움으로 양 언어를 구사하는 학생에게 자신의 전문 분야를 설명합니다.

0

(Flan-T5-XXL) 차량의 학습을 위한 학습을 하는 학생들은 더 많은 고장을 경험하고, 한 남자의 명예를 위한 행사를 위해 모이는 것입니다.
(f) 템플릿: CM 문장을 작성하세요.

그림 16: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비 코드 혼용 문장을 포함한 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다.

23
(c) 템플릿: 두 개의 양언어 사용자
CM 만약 당신이 영어-말레이양언어 사용자라고 가정한다면, 교통에 관한 자연스러운 영어-말레이 혼합 문장을 어떻게 작성하겠습니까?
(ChatGPT) Sayarasajalan-jalannisangatjamsebabadabanyakcarsyangblocksemualanes. (교통이 매우 혼잡한 것 같아요. 모든 차선을 막고 있는 차량들이 많아서입니다.)

이 문장에서는 영어와 말레이어 단어를 섞어서 코드믹스 문장을 만들었습니다. 이 문장은 말레이어로 시작하여...

3

(Davinci-003) "오래 걸리는 작업은 지루하게 만들어요!"

0

오늘 교통 정말 혼잡해요.

(BLOOMZ) 고속도로 교통 체증. 0

(Flan-T5-XXL) 지난 일년 동안 도로 상의 차량 수가 32% 감소했습니다.

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해 볼 수 있나요? 그들이 음식에 대해 이야기하는 대화를 상상해 볼 수 있나요?

(ChatGPT) 발화자1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어? 발화자2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너는 먹어봤니? 발화자1: 네, 먹어봤어. 맛의 조합이 정말 좋아. 새테 아얌을 먹어봤니? 발화자2: 오 네, 새테 아얌을 정말 좋아해!

2

(Davinci-003)"영어 사용자: 저는 방금 저녁으로 정말 놀라운 나시 고렝을 먹었어요!
인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요?
영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요. .."

2

(다빈치-002) "A: 당신이 가장 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식을 좋아해요, 특히 나시고렝이죠. A: 네, 저도 나시고렝을 좋아해요!"

(BLOOMZ) "여기 예시가 있어요: W: 안녕, 마리암. 어제 여행은 어땠어? M: 오! 기대했던 대로 정말 재미있었어. W: 다행이다. 다음에 어디 가면 나도 데려갈 거라고 말했지 않았어? M: 응... 그래, 그럼 알았어."

0

(Flan-T5-XXL) M: 파티 음식 어때? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어. 0
(ChatGPT) 에이, 알지 라, 가족은 아주 중요하다니까, 항상 오징어와 고추장처럼 붙어있어야 돼, 될거야? 3 (Davinci-003) "우리 가족이야, 우리는 너무 가까워서 어디든지 함께 갈 수 있어!" 3 (Davinci-002) 우리 가족이 최고야! 0
(BLOOMZ) 0 (Flan-T5-XXL) 집에 가서 가족 보러 갈 거야. 0
(c) 말하는 스타일 모방하기

CM Code-mixing은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹스된 영어-중국어 문장을 생성할 수 있을까요? (ChatGPT) 네, 예를 들어 "점심에 ∏ !(짜지) 후라이드 치킨을 먹는 걸 좋아해요."라고 할 수 있습니다. 2 (Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 사랑해요! 0 (Davinci-002) "FPFP  }}⇤⇤ÑÑ⇥⇥ 두부, 두부, 먹기에는 좋지 않아요." 0 (BLOOMZ) fliÔÂ⇤ F Å⇤*⇢⇥ 0

(Flan-T5-XXL) 한 요리사가 음료를 준비합니다. 0

(d) 템플릿: CM을 명확하게 정의하다.

CM

상상해보세요. 당신이 베트남어를 사용하는 사람이라고 가정하면, 영어와 베트남어를 함께 사용하여 날씨에 대해 어떻게 이야기할까요?

(ChatGPT) "오늘은 날씨가 덥지 않아서 나는 반바지와 티셔츠를 입을 생각이야."

3

(Davinci-003)오늘 날씨가 아마도 아주 좋을 것 같아요.
(Davinci-002)여기 날씨가 너무 더워도 너무 추워도 아니라서 좋아요.
(BLOOMZ)한 텍스트를 한국어로 번역하고, 또한 두 가지 다른 언어로도 번역해주세요.
(Flan-T5-XXL)고객님은 항상 정중하게 통신하시고, 또한 높은 수준의 상품을 제공해주셔서 감사합니다.
(e) 템플릿: 원어민 화자

CM

인공지능에 관한 영어와 타갈로그어 혼합 문장을 작성하십시오.

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 현대적인 솔루션을 제공하고 일부 자동화된 작업을 처리함으로써 우리가 살고 일하는 방식을 혁신하고 있습니다. (Davinci-002) 인공지능은 우리가 감사해야 할 것입니다. (BLOOMZ) 인공지능 전문가가 동료의 도움으로 양 언어를 구사하는 학생에게 자신의 전문 분야를 설명합니다. (Flan-T5-XXL) 학교에서 차량을 연구하는 학생들을 위해 명예를 위한 작업을 수행하는 남성을 통해 더 많은 파괴력을 조사합니다. (f) CM 문장을 작성하세요.

그림 16: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비 코드 혼용 문장을 포함한 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다.

23
(d) 템플릿: CM을 명확하게 정의하십시오.

그림 15: 다른 언어와 주제 분야를 가진 모든 프롬프트 템플릿 및 코드믹스 / 비코드믹스 문장을 포함하는 다른 LLM의 응답. 설명은 ChatGPT의 원래 생성 부분입니다. "CM"은 코드믹싱 수준을 나타냅니다 (2.2절 참조).

61
61번째
CM
CM

Anggapkan anda seorang penutur dwibahasa Inggeris-Melayu,
bagaimana anda akan menulis ayat campuran kod Inggeris-Melayu
yang semula jadi tentang trafik?

나는 이 도로가 차들로 인해 매우 혼잡하다고 생각합니다. 모든 차선이 막혀 있기 때문입니다.

이 문장에서는 영어와 말레이어 단어를 섞어서 코드믹스 문장을 만들었습니다. 이 문장은 말레이어로 시작해서...

3

(Davinci-003) "오래 걸리는 작업은
긴 도로에서 오래 기다리는 것처럼
지루하게 만들어요!"

0

오늘 교통 정말 혼잡해.

(BLOOMZ) 고속도로에서 교통 체증. 0

(플랜-T5-XXL) 지난 해 동안 도로 상의 차량 수가 32% 감소했습니다. 0

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 음식에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT) 발화자 1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어?
발화자 2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너는 먹어봤니?
발화자 1: 네, 먹어봤어. 맛들의 조합이 정말 좋아. 새테 아얌도 먹어봤어?
발화자 2: 오, 네. 새테 아얌을 정말 좋아해! ..<truncated>

2

(Davinci-003) "영어 사용자: 저는 저녁으로 가장 놀라운 나시 고렝을 먹었어요!
인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요?
영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요.

2

(다빈치-002) "A: 당신이 가장 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식을 좋아해요, 특히 나시 고렝이요.
A: 네, 저도 나시 고렝을 좋아해요!"

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어?
M: 오! 기대했던 대로 정말 재미있었어. W: 다행이야. 다음에 어디 가면 나도 같이 갈 거라고 말했지 않았어?
M: 응... 그래. 그럼 좋아"

0

(Flan-T5-XXL) M: 파티 음식 어때? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어.

0

(b) 템플릿: 두 개의 양언자

CM

가족에 관한 한 문장을 싱글리쉬로 구사할 수 있는 사람의 말투를 모방해 보세요.

(ChatGPT) 응, 알지, 가족은 아주 중요한 거야.
레, 항상 오징어와 고추장처럼 붙어다녀야 해, 되겠니? 3
(Davinci-003) "우리 가족은 응, 너무 친한데, 어디든 함께 갈 수 있어!"

3

(다빈치-002) 우리 가족은 최고야! 0

(BLOOMZ) 0

(Flan-T5-XXL) 나는 가족을 보러 집에 갈 거야.

(c) 템플릿: 말하는 스타일 모방하기

CM

코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹싱된 영어-중국어 문장을 생성할 수 있나요?

(ChatGPT) 그럼, 예를 들어보겠습니다: "점심에 ∏ !(zhá j¯ı) 치킨을 먹는 것을 좋아해요." 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 좋아해요! 0

(다빈치-002) "두부, 두부, 먹기에 좋지 않아요, 좋지 않아요." 0

(BLOOMZ) 플라워 배송 서비스 제로

(Flan-T5-XXL) 한 요리사가 음료를 준비합니다. 0

(d) 템플릿: CM을 명확하게 정의하다.

CM

상상해보세요. 당신이 베트남어를 사용하는 사람이라고 가정해봅시다. 영어와 베트남어를 동시에 사용하여 날씨에 대해 어떻게 이야기할까요?

(ChatGPT) "오늘은 날씨가 꽤 더워서 나는 반바지와 티셔츠를 입을 거 같아."

3

(Davinci-003) 오늘 날씨는 분명히 아름다울 거야.

(Davinci-002) 난 여기 날씨가 좋아. 너무 더우지도 않고 너무 추지도 않아.

0

(BLOOMZ) 한국어를 할 수 있는 사람이라고 말하고, 두 가지 언어를 사용하여 날씨를 설명해주세요: 0

(Flan-T5-XXL) V 고객님께서는 항상 특정한 옷 크기와 디자인을 찾으실 것이므로, 이 템플릿은 0개의 옷을 가지고 있습니다.

CM

인공지능에 관한 영어와 타갈로그어 혼용 문장을 작성하세요.

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 우리가 살고, 일하고, 지금 살아가는 방식을 혁신하고 있습니다. 이는 프로젝트에 현대적인 솔루션을 제공하고 자동화를 기다리는 몇 가지 작업을 수행함으로써 이루어집니다.

3

(다빈치-002) 인공지능은 우리가 감사해야 할 것이다.

0

(BLOOMZ) 인공지능 전문가가 양 언어를 구사하는 동료의 도움을 받아 학생에게 자신의 전문 분야를 설명합니다.

0

(Flan-T5-XXL) 더 많은 머리카락 손상을 분석하는 연구는 차량의 연구를 통해 열가소성을 연구하고, 한 남성의 명예를 유지하기 위해 모임을 개최합니다.
(f) 템플릿: CM 문장을 작성하세요.

그림 16: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비 코드 혼용 문장을 포함한 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다.

23
(e) 템플릿: 원어민

CM

Anggapkan anda seorang penutur dwibahasa Inggeris-Melayu,
bagaimana anda akan menulis ayat campuran kod Inggeris-Melayu
yang semula jadi tentang trafik?

나는 이 도로가 차들로 인해 매우 혼잡하다고 생각합니다. 모든 차선이 막혀 있기 때문입니다.

이 문장에서는 영어와 말레이어 단어를 섞어서 코드믹스 문장을 만들었습니다. 이 문장은 말레이어로 시작해서...

3

(Davinci-003) "오래 걸리는 작업은
긴 도로에서 오래 기다리는 것처럼
지루하게 만들어요!"

0

오늘 교통 정말 혼잡해.

(BLOOMZ) 고속도로에서 교통 체증. 0

(플랜-T5-XXL) 지난 해 동안 도로 상의 차량 수가 32% 감소했습니다. 0

(a) 템플릿: 이중언어 사용자로 가정하다.

CM

상상해보세요. 두 명의 영어-인도네시아어 이중언어 사용자가 서로 대화하고 있다고 상상해보세요. 그들이 음식에 대해 이야기하는 대화를 상상할 수 있나요?

(ChatGPT) 발화자 1: 안녕, 인도네시아 요리인 나시 고렝을 먹어봤어?
발화자 2: 네, 먹어봤어. 내가 좋아하는 음식 중 하나야. 너는 먹어봤니?
발화자 1: 네, 먹어봤어. 맛들의 조합이 정말 좋아. 새테 아얌도 먹어봤어?
발화자 2: 오, 네. 새테 아얌을 정말 좋아해! ..<truncated>

2

(Davinci-003) "영어 사용자: 저는 저녁으로 가장 놀라운 나시 고렝을 먹었어요!
인도네시아어 사용자: 아, 나시 고렝은 인도네시아의 대표적인 음식 중 하나에요. 다른 인도네시아 음식도 좋아하시나요?
영어 사용자: 저는 가도 가도와 아얌 페네트도 정말 좋아해요.
..<중략>

2

(다빈치-002) "A: 당신이 가장 좋아하는 음식은 무엇인가요?
B: 저는 인도네시아 음식을 좋아해요, 특히 나시 고렝이요.
A: 네, 저도 나시 고렝을 좋아해요!"

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(BLOOMZ) "여기 예시가 있어요: W: 안녕 마리암. 어제 여행은 어땠어?
M: 오! 기대했던 대로 정말 재미있었어. W: 다행이야. 다음에 어디 가면 나도 같이 갈 거라고 말했지 않았어?
M: 응... 그래. 그럼 좋아"

0

(Flan-T5-XXL) M: 파티 음식 어때? 맛있어? W: 파티 음식은 괜찮은데, 먹을 필요 없어.

0

(b) 템플릿: 두 명의 양언자

CM

가족에 관한 한 문장을 싱글리쉬로 구사할 수 있는 사람의 말투를 모방해 보세요.

(ChatGPT) 응, 알지, 가족은 아주 중요한 거야.
레, 항상 오징어와 고추장처럼 붙어다녀야 해, 되겠니? 3
(Davinci-003) "우리 가족은 응, 너무 친한데, 어디든 함께 갈 수 있어!"

3

(다빈치-002) 우리 가족은 최고야! 0

(BLOOMZ) 0

(Flan-T5-XXL) 나는 가족을 보러 집에 갈 거야.

(c) 템플릿: 말하는 스타일 모방하기

CM

코드믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 가리킵니다. 음식에 관한 코드믹싱된 영어-중국어 문장을 생성할 수 있나요?

(ChatGPT) 그럼, 예를 들어보겠습니다: "점심에 ∏ !(zhá j¯ı) 치킨을 먹는 것을 좋아해요." 2
(Davinci-003) ⌘Ö1⇤Øa 저는 감자칩을 좋아해요! 0

(다빈치-002) "두부, 두부, 먹기에 좋지 않아요, 좋지 않아요." 0

(BLOOMZ) 플라워 배송 서비스 제로

(Flan-T5-XXL) 한 요리사가 음료를 준비합니다. 0

(d) 템플릿: CM을 명확하게 정의하다.

CM

상상해보세요. 당신이 베트남어를 사용하는 사람이라고 가정해봅시다. 영어와 베트남어를 동시에 사용하여 날씨에 대해 어떻게 이야기할까요?

(ChatGPT) "오늘은 날씨가 꽤 더워서 나는 반바지와 티셔츠를 입을 거 같아."

3

(Davinci-003) 오늘 날씨는 분명히 아름답겠어요.

(Davinci-002) 난 여기 날씨가 좋아. 너무 더우지도 않고 너무 추지도 않아.

0

(BLOOMZ) 한국어를 할 수 있는 사람이라고 말하고, 두 가지 언어로 날씨를 설명해주세요: 0

(Flan-T5-XXL) V khách hàng không hài lòng với chất lượng sản phẩm và muốn đổi hàng, nhưng lượng hàng mới có sẵn là 0.

CM

인공지능에 관한 영어와 타갈로그어 혼용 문장을 작성하세요.

인공지능은 사회에 많은 혜택을 제공할 수 있는 흥미로운 기술입니다.

1. 안녕하세요, 저는 한국어를 배우고 있습니다.

(Davinci-003) AI는 우리가 살고, 일하고, 지금 살아가는 방식을 혁신하고 있습니다. 이는 프로젝트에 현대적인 솔루션을 제공하고 자동화를 기다리는 몇 가지 작업을 수행함으로써 이루어집니다.

3

(다빈치-002) 인공지능은 우리가 감사해야 할 것이다.

0

(BLOOMZ) 인공지능 전문가가 양 언어를 구사하는 동료의 도움을 받아 학생에게 자신의 전문 분야를 설명합니다.

0

(Flan-T5-XXL) 더 많은 머리카락 손상을 분석하는 연구는 차량의 연구를 통해 열가소성을 연구하고, 한 남성의 명예를 유지하기 위해 모임을 개최합니다.
(f) 템플릿: CM 문장을 작성하세요.

그림 16: 다른 언어와 주제 분야를 가진 프롬프트 템플릿 및 코드 혼용 / 비 코드 혼용 문장을 포함한 다른 LLM의 응답. 우리는 또한 화자의 국적을 명시하는 템플릿을 포함시켰습니다. 설명은 ChatGPT의 원래 생성물의 일부입니다.

23
(f) 템플릿: CM 문장을 작성하세요.

그림 15: (계속) 우리는 언어와 주제 분야 외에도 발화자의 국적을 명시하는 템플릿을 포함하였습니다.

62
예시 표준 영어 번역
언어 쌍
문제 설명

내일은 우산을 준비해야 합니다. 날씨가 흐리고 하루 종일 비가 올 가능성이 있기 때문입니다.
Unnatural phrasing "chance of hujan" and "cuacanya bakal cloudy" sound unnatural. Should be "chance of raining" and "cuacanya akan menjadi cloudy".
Saya suka menghabiskan waktu bersama keluarga saya, terutama ketika kita makan makanan yang sedap seperti nasi lemak dan roti canai.
Gerund; Conjunction "sukaspend time" should change to "sukaspending time" as the word "suka" (like. v) should be followed with gerund. "or" should also be changed to "and".

점심에 튀긴 닭고기를 먹는 것을 좋아해요. 점심에 튀긴 닭고기를 먹는 것을 좋아해요.
중국어에서 "炸鸡"는 "튀긴 닭고기"와 같은 의미입니다.

그래서, 워런은 인간적인 감각의 AI 현실성을 주장하는 전문적인 가능성을 가진 성장 지능 기술이라고 믿습니다.

비자역 스크립트 시스템 생성된 텍스트는 핀인 대신에 중국어 문자를 사용해야 합니다. "So, 我认为一个健康的AI是一个具有专业实际可能性的成长智能的技术." 이렇게 써야 합니다. 또한, 이 문장은 전혀 의미가 없습니다.

가족은 이번 주말에 큰 가족 모임을 공원에서 계획하고 있습니다.

소유격 표지자 영어에서 타갈로그어로의 "My family"에서 "ay nagplano"으로의 전환은 부자역입니다. 타갈로그어가 기본 언어인 경우, 타갈로그어 소유한 한정사를 사용하므로 올바른 형태는 "Ang family ko ay nagplano..."입니다.

어제, 나는 내 부모님의 결혼 기념일을 축하하기 위해 가족과 나갔습니다.

동사구 "điout" 대신에 "đi" 또는 "went out"을 사용해야 합니다.

AI는 우리의 삶을 쉽게 만드는 등 여러 가지 일을 할 수 있지만, 제대로 사용하지 않으면 매우 난감할 수도 있습니다.

싱글리시 표현 "pai seh"의 잘못된 사용은 환영어로 수준이 낮거나 미안하거나 당황한 사람을 묘사하는 방언입니다. AI가 당황스러워하는 것을 묘사하기 위해 사용하는 것은 적절하지 않습니다.

가족은 매우 중요하다는 것을 알잖아, 항상 오직 된장과 고추장처럼 함께 있어야 해, 가능하면? 가족이 매우 중요하므로 오직 오징어와 고추장처럼 항상 함께 있어야 한다는 비유는 부자역입니다. 싱가포르에서는 이러한 표현을 사용하지 않습니다.

오늘은 교통이 너무 혼잡해서 목적지에 도달하는 데 영원히 걸리고 있습니다.

형용사구 "Traffic rombakastapattu irukkutoday"는 교통이 고통스러워한다는 의미로, 교통이 혼잡하다는 것과는 다릅니다.

2 5 0
2 5 0 개 중 2 5 0 개가 작성되었습니다! 남은 응답 수: 0개
2 5 0 개 중 2 1 5 개가 작성되었습니다! 남은 응답 수: 3 5개
2 5 0 개 중 1 8 9 개가 작성되었습니다! 남은 응답 수: 6 1개
2 5 0 개 중 1 1 3 개가 작성되었습니다! 남은 응답 수: 1 3 7개
2 5 0 개 중 9 0 개가 작성되었습니다! 남은 응답 수: 1 6 0개

N o
P r o m p t s
C h a t G P T R e s p o n s e s C o d e - s w i t c h n e s s ( 0 / 0 . 5 / 1 / 2 / 3 ) N a t u r a l n e s s ( V , X , ? ) N a t u r a l n e s s e x p l a n a t i o n
자연성 (V, X, ?)
자연성 설명 자연성 (V, X, ?) 자연성 설명

8 8
코드-믹싱은 한 문장에서 두 개 이상의 언어를 결합하는 현상을 말한다. 인공지능에 관한 코드-믹싱된 영어-타밀어 문장을 생성할 수 있을까요?
(인공지능은 새로운 기술로, 컴퓨터 과학과 관련된 개념을 포함합니다.) 0.5V 번역은 타밀어로 되어 있지만 유창함 문제는 없습니다.

1 8 9
당신이 영어-타밀 양언자라고 가정하면, 인공지능에 관한 자연스러운 영어-타밀 혼용 문장을 어떻게 작성하겠습니까?
인공지능을 웹 애플리케이션에서 사용함으로써, 영어와 타밀 양쪽에서 공유되는 콘텐츠를 생성할 수 있습니다. (인공지능에 대한 구체적인 정보는 언급하지 않습니다.)
참고: 이 문장은 영어와 타밀을 혼용하여 작성되었으며, "인공지능"과 "웹 애플리케이션"이라는 용어는 영어로 사용하고, "생성"이라는 동사와 "영어와 타밀 양쪽에서 공유되는"이라는 구는 타밀로 사용합니다. 혼용은 양언자 커뮤니티에서 흔하며, 양 언어의 강점을 결합하여 의사소통을 향상시킬 수 있습니다. 0.5 X 타밀 문장에 문제가 있습니다. "생성할 수 있습니다"는 문법적으로 올바르지 않으며, "I can create content"의 올바른 번역이 아닙니다.

1 9 0
나는 영어와 타밀어를 구사할 수 있는 사람의 말하는 스타일을 모방하여 인공지능에 대한 한 문장을 만들었습니다.
"인공지능은 우리가 기술과 상호작용하는 방식을 혁신하고 그 데이터 식별은 어떤 언어에서든 가능합니다." 1 X "인공지능은 우리가 기술과 상호작용하는 방식을 혁신하고 그 데이터 식별은 어떤 언어에서든 가능합니다."라는 의미로, "인공 웹 애플리케이션에서의 데이터 식별은 어떤 언어에서든 효과적입니다." 영어와 타밀어 절은 독립적이므로 이 문장은 유창성 문제가 있습니다. 인공 웹 애플리케이션에서의 데이터 식별은 어떤 언어에서든 효과적입니다. 인공지능은 우리가 기술과 상호작용하는 방식을 혁신하고 있습니다.
영어 - 타밀어
쉼표 결합 영어와 타밀어 독립절은 쉼표로 결합되어 있으며, 이는 쉼표 결합의 문법적 오류입니다.
표 4 : 챗 GPT의 자연스러움 문제에 대한 설명
코드 혼합 텍스트 생성.

63
언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 제6회 절차, 64-73쪽
2023년 12월 7일 ©2023 협회 for 계산언어학
CONFLATOR: 코드 혼합 언어 모델링을 위한 스위칭 포인트 기반 회전 위치 인코딩 통합

모신 알리1 사이 테자 칸두쿠리2 니하리카 구프타3 파르트 패트와4
아눕합 챠터지3 비니자 제인5 아만 차다5,6* 아미타바 다스7
1샌디에이고 주립대학교, 미국 2샌호세 주립대학교, 미국
3위프로 인공지능 연구소, 인도 4캘리포니아 대학교 로스앤젤레스 캠퍼스, 미국
5스탠포드 대학교, 미국 6아마존 인공지능, 미국 7사우스캐롤라이나 대학교, 미국
1mmohammed5956@sdsu.edu 2saiteja.kandukuri@sjsu.edu

7amitava@mailbox.sc.edu -> 7amitava@mailbox.sc.edu

요약

두 개 이상의 언어가 혼합되는 것을 코드믹싱(CM)이라고 합니다. CM은 다양한 언어를 사용하는 사회에서의 사회적 규범입니다. 트랜스포머와 같은 신경 언어 모델(NLM)은 많은 NLP 작업에서 효과적입니다. 그러나 CM을 위한 NLM은 아직 탐구되지 않은 영역입니다. 트랜스포머는 능력이 있고 강력하지만, 비순환적이기 때문에 항상 위치 정보를 인코딩할 수는 없습니다. 따라서 단어 정보를 풍부하게 하고 위치 정보를 통합하기 위해 위치 인코딩이 정의되었습니다. 우리는 스위칭 포인트(SPs)라고 가정합니다. 즉, 언어가 전환되는 텍스트의 접합점(L1→L2 또는 L2→L1)은 CM 언어 모델(LM)에 대한 도전 과제를 제시하며, 모델링 과정에서 SP에 특별한 강조를 줍니다. 우리는 여러 위치 인코딩 메커니즘을 실험하고, 회전 위치 인코딩과 스위칭 포인트 정보를 결합한 결과가 가장 좋다는 것을 보여줍니다.

우리는 CONFLATOR를 소개합니다: 코드 혼합 언어에 대한 신경망 언어 모델링 접근 방식입니다. CONFLATOR는 더 똑똑한 위치 인코딩을 사용하여 단일어 및 이중어 수준에서 전환 지점을 강조하는 방법을 배우려고 합니다. CONFLATOR는 코드 혼합된 힌디어와 영어 (힌글리쉬)를 기반으로 한 두 가지 작업에서 최신 기술을 능가합니다: (i) 감성 분석 및 (ii) 기계 번역.

1 코드믹싱: 두 언어의 병렬 배치

코드믹싱은 발화 중에 두 개 이상의 언어를 번갈아 사용하는 것으로 정의된다. 최근에는 NLP 분야에서 코드믹싱이 많은 관심을 받고 있는데, 이는 인도, 유럽, 미국, 남아프리카, 멕시코 등 다양한 언어가 혼용되는 다양한 언어사회에서 코드믹싱이 흔하게 일어나기 때문이다. 이러한 사회에서는 특히 비공식적인 대화에서 코드믹싱이 상당히 흔한 현상이다.

일은 아마존의 직책과 관련이 없습니다.

자주 로마자로 표기되며 보조 언어와 혼용되는 경우가 많습니다. 이 효과는 때로는 소셜 미디어 플랫폼인 트위터, 페이스북 등에서 원천이 되는 게시물에서 나타납니다. 힌디어와 영어 혼용의 예로는 다음 구절에서 영어 단어인 "dance"가 힌디어 로마자 단어와 혼합되어 사용됩니다: "Gaaye, aur, kare."

가요하고 춤을 춥니다.

인터넷에서 코드 혼용이 증가함에 따라, 코드 혼용 언어에 대한 언어 처리와 언어 모델링을 연구하는 것이 중요합니다. 신경망을 사용한 언어 모델링은 오랜 시간 동안 발전해 왔으며, 분산 신경망 표현으로 n-gram 언어 모델을 대체하는 것(Bengio et al., 2003)부터 최근의 대형 Transformer 기반 사전 훈련 언어 모델(GPT-x (Radford et al., 2019), BERT (Devlin et al., 2018a) 등)까지 다양한 모델이 등장했습니다. 그러나 최신 Transformer 기반 모델을 사용한 코드 혼용 언어 모델링은 아직 충분히 탐구되지 않았습니다.
코드 혼용에 대한 최신 Transformer 기반 언어 모델의 채택에서 가장 큰 어려움은 데이터 부족으로 설명될 수 있습니다. BERT와 GPT와 같은 Transformer 기반 아키텍처는 언어 모델링 분야에서 새로운 기준을 세웠지만, 샘플 효율성이 낮다는 것으로 악명이 높습니다. 다시 말해, Transformer의 탐식적인 데이터 요구와 커뮤니티에서 충분한 코드 혼용 데이터셋의 부재로 인해, 코드 혼용 언어 모델링 분야에서 기술적인 어려움이 일반적인 언어 모델링에 비해 큽니다.
위에서 언급한 주장을 확인하기 위해, 우리는 GPT-2와 BERT와 같은 Transformer 기반 모델을 코드 혼용에 대해 실험해 보았습니다. 실험 결과, 이러한 모델들이 코드 혼용 데이터를 포함한 작업에서 성능이 좋지 않음을 경험적으로 관찰했습니다. 우리의 가설은 다음과 같습니다: 전환과 관련된 정보가 부족하기 때문에, Transformer 기반 모델은 코드 혼용 데이터에 대해 잘 작동하지 않는 것입니다.

64
인코딩 포인트는 코드 혼합 콘텐츠의 맥락에서 주요 구성 요소이므로 하향식 처리에 통합되어야 합니다. 스위칭 포인트는 모델이 코드 혼합 데이터를 처리하는 데 병목 현상이 되며, SoTA 신경 언어 모델을 사용할 때 성능이 저하되는 이유입니다 (Chatterjere et al., 2020). 스위칭 포인트는 CM 데이터 처리 시 중요한 요소입니다. 다음 몇 섹션에서는 다양한 위치 인코딩 접근 방식, 스위칭 포인트 및 코드 혼합 데이터에 대한 언어 모델링을 위한 접근 방식에 대해 논의합니다. 우리의 주요 기여는 다음과 같습니다:

우리는 스위칭 포인트와 관련된 위치 정보를 통합한 LM 시스템인 CONFLATOR를 제안합니다.

• 우리의 시스템은 기존 모델의 성능을 향상시키고 두 가지 작업에서 새로운 최고 성능을 달성합니다.

우리는 다양한 스위칭 포인트 기반 위치 인코딩 기술을 조사, 실험하고 소개합니다.

우리는 RoPE (Rotary Positional Encoding)를 위한 새로운 스위칭 포인트 기반 회전 매트릭스를 소개합니다.

우리는 코드 혼용 트윗의 새로운 데이터셋을 선별합니다.

2 관련 연구

코드믹싱을 공부하는 것은 매우 중요하다. 이는 대부분의 다중언어 사회에서 일부이며 소셜 미디어에서 흔하다. NLP 작업에서 코드믹싱된 텍스트를 처리하는 것은 단일언어 텍스트보다 복잡하다. Bokamba (1988)와 Singh (1985)은 구문론과 문법을 기반으로 다중언어의 복잡성에 대해 유사한 연구를 수행했다. 소셜 미디어에서 코드믹싱된 언어를 처리하는 어려움은 이상한 철자, 동일한 단어를 작성하는 많은 독특한 방법, 불필요한 대문자 사용 등으로 인해 더욱 악화된다. 소셜 미디어에서 코드믹싱된 데이터에 대해 감정 분석, 번역, 혐오 발언 탐지, POS 태깅 등과 같은 다양한 작업이 수행되고 있다. 텍스트 분류를 위한 코드믹싱 처리 방법에는 CNN (Aroyehun and Gelbukh, 2018; Patwa et al., 2020b), Transformer 또는 BERT와 유사한 방법이 사용된다.

모델 (Samghabadi et al., 2020; Tang et al., 2020),
앙상블 모델 (Tula et al., 2021; Jhanwar and Das, 2018), 포컬 로스 (Tula et al., 2022; Ma et al., 2020) 등.
Vaswani et al. (2017a)은 가려진 언어 모델링 (MLM)과 다음 문장 예측을 사용한 신경 언어 모델링을 위해 트랜스포머를 제안했으며, 이는 많은 NLP 작업에서 SoTA 성능을 달성했습니다. Devlin et al. (2018b)은 104개 언어를 포함한 다국어 말뭉치에서 훈련된 mBERT를 공개했습니다. Lample and Conneau (2019)에서는 단일 언어 및 교차 언어 말뭉치를 활용한 크로스 리잉귤러 언어 모델 XLM이 제안되었습니다. Nayak and Joshi (2022)는 CM 데이터에 사전 훈련된 bert를 제시했습니다. 그러나 그들은 특히 코드믹스 데이터를 처리하기 위해 언어 모델이나 기술을 변경하지 않습니다. Sengupta et al. (2021)은 단어 간의 의미 관계를 포착하고 코드믹스 데이터의 문장 수준 의미를 계층적으로 학습하는 계층적 트랜스포머 기반 아키텍처를 제안합니다. Ali et al. (2022)는 위치 인코딩에 전환 지점 정보를 통합하는 것이 처음인데, 그들은 동적 위치 인코딩을 활용하고 있으며, 우리의 방법인 CONFLATOR는 회전 위치 인코딩에 전환 지점 정보를 주입하고 최종 임베딩을 얻기 위해 유니그램과 바이그램 토큰을 모두 사용합니다.

3 데이터 추출 및 전략

이 섹션에서는 코드 혼합 데이터 추출의 세부 사항에 대해 논의합니다. 우리의 주요 목표는 자연스럽게 분포된 코드 혼합 데이터를 추출하는 것입니다.

3.1 힌글리시 말뭉치의 질적 및 양적 검사점

LM의 성능은 훈련 데이터의 크기와 품질, 그리고 어휘 크기에 의존한다. 코드 혼합 언어 모델링은 다음과 같은 도전에 직면한다: i) 데이터 부족, ii) 한 문장에 2개 이상의 언어로 된 단어, iii) 힌디어는 영어 문자로 쓰여지며 (즉, 영어로 표기), 그 결과 철자 표준화가 없어 단어 형태가 증식된다 (Laddha et al., 2020, 2022), iv) 코드 혼합은 주로 소셜 미디어에서 발견되며 네티즌들은 창의성과 언어유희를 혼합에 도입한다. 우리는 데이터 수집을 안내하기 위해 두 가지 기본적인 질문을 고려한다:

1. 모든 NLP 작업의 성능은 데이터의 복잡성에 따라 달라집니다.

65
경험적 측정: 두 개의 4단어 트윗을 고려해보십시오 - i) Ti : wL1wL1wL2wL2 및 ii) Tj : wL1wL2wL1wL2. 두 트윗 모두 언어 L1과 L2에서 각각 2개의 단어를 가지고 있습니다. 따라서 트윗 Ti와 Tj의 혼합 비율은 (4-2)/4 = 0.50입니다. 그러나 Ti에는 코드 교대점이 1개만 포함되어 있고 Tj에는 3개의 스위치가 포함되어 있습니다. Tj가 처리하기 어려울 가능성이 높습니다. 따라서 우리는 언어 간 혼합 수준을 측정하기 위한 지표가 필요합니다. 우리는 Code-Mixing-Index (Gambäck and Das, 2016) (CMI)를 사용하여 이러한 복잡성을 측정합니다. CMI에 대한 자세한 내용은 섹션 3.2를 참조하십시오.

충분한 데이터는 얼마나 됩니까?

경험적 측정: 두 언어가 혼합될 때, Hinglish 말뭉치에서 고유한 단어 형태의 수가 단일 언어인 영어나 힌디어 말뭉치보다 훨씬 더 많을 것은 당연합니다. 그러므로, 우리는 매우 처음에 중요한 질문을 하게 됩니다. 얼마나 많은 데이터가 충분한가요? 우리는 고유한 단어 대부분을 포함하기 위해 Heaps의 곡선이 수렴하기 시작할 때까지 데이터를 계속 수집하기로 결정합니다.

힙스의 법칙 (Gopalan and Hopkins, 2020)은 n개의 단어로 이루어진 텍스트에서 고유한 단어의 수는 V(n) = Knβ로 근사됨을 말한다. 여기서 K는 양의 상수이고 β는 0과 1 사이에 위치한다. K는 일반적으로 10에서 100 사이에 위치하며 β는 0.4에서 0.6 사이에 위치한다. 힙스의 법칙은 어휘 크기를 계산하는 좋은 추정치로 간주된다. 비교를 위해, 그림 1에서 볼 수 있듯이, 영어 위키의 경우 힙스의 법칙 곡선의 평탄화는 40K-50K에서 시작되지만, 단일 언어인 힌디어의 경우 80K-90K에서 수렴하며, 힌글리시의 경우 800K 어휘와 50M 단어 정도에서 동일한 행동이 시작된다.

3.2 코드 혼용 지수 (CMI)

이전에 언급한 대로, 우리는 코드 혼용 수준이 증가함에 따라 언어 처리 작업의 난이도가 증가할 것으로 예상합니다. 우리의 말뭉치에서 코드 혼용 수준을 측정하기 위해 우리는 Code-mixing Index (Gambäck and Das, 2016)를 사용합니다.

그림 1: 영어, 힌디어 및 힌글 코퍼스의 5천만 단어 형태에 대한 힙스 플롯. β 값은 각각 0.58, 0.61, 0.74입니다.

Cu(x) = wmfm(x)+wpfp(x)

wmN(x) −maxLiϵL(tLi)(x) = wmN(x) - maxLiϵL(tLi)(x)
N(x)
∗100+wpP(x)
N(x)
∗100 = wmN(x) - maxLiϵL(tLi)(x)
N(x)
∗100+wpP(x)
N(x)
∗100

= 100
∗
wm((N(x) −maxLiϵL(tLi)(x))+wpP(x)
N(x)

= 100
∗
wm((N(x) −maxLiϵL(tLi)(x))+wpP(x)
N(x)

(1)
x가 발화를 나타내는 것을 의미하고, N은 언어 Li에 속하는 x의 토큰 수이며, wm과 wn은 가중치입니다. CMI의 자세한 설명은 Gambäck과 Das (2016)를 참조하십시오.

3.3 데이터 수집 파이프라인

우리는 (Chatterjere et al., 2020)와 유사한 파이프라인을 따릅니다. 우리는 Twitter API를 통해 Twitter에서 CM 데이터를 수집합니다. CM 트윗을 얻기 위해 검색에 관련 키워드(힌디어에만 해당하는 단어)를 사용해야 합니다. 힌디어와 영어 사이에 어휘적 중복이 있는 단어는 검색에 사용해서는 안 됩니다. 예를 들어, do라는 단어는 힌디어에서는 two를 의미하기 때문에 혼동됩니다. 우리는 ICON 2017 Hinglish 감성 분석 데이터셋(Patra et al., 2018)을 사용하여 시작합니다. 이 데이터에서 우리는 VHI와 VEN이라는 두 개의 어휘를 생성하고, 고유한 힌디어 단어로 이루어진 어휘 VHI −UNIQ = VHI −I를 생성합니다. 여기서 I = VHI TVEN입니다. VHI −UNIQ 집합은 단어 빈도에 따라 내림차순으로 정렬되며, 이는 Twitter API에서 검색어로 사용됩니다. 트윗을 얻은 후에는 트윗에 단어 수준의 언어 식별기(Barman et al., 2014)를 사용하여 CMI를 계산합니다(정확도 90% 이상). 단어 수준의 언어 레이블을 얻으면 전환 지점을 알 수도 있습니다. CMI = 0인 트윗은 삭제됩니다. 마지막으로, 우리는 87k개의 트윗만 남게 됩니다. 우리 데이터의 CMI 분포는 표 1에 제시되어 있습니다. 이 데이터셋은 우리의 모델 사전 훈련에 사용됩니다.

훈련 및 테스트 데이터: 우리는 모든 CMI 범위에 분포된 87k개의 문장을 수집합니다.

66
CMI    # 트윗 비율

0-10   7,036  8.05%
11-20   16,481 18.9%
21-30   22,617 25.9%
31-40   22,722 26.0%
41-50   11,404 13.1%
50+    7,036  8.05% 

0-10   7,036  8.05%
11-20   16,481 18.9%
21-30   22,617 25.9%
31-40   22,722 26.0%
41-50   11,404 13.1%
50+    7,036  8.05%

평균 CMI: 28 총 트윗 수: 87,296

표 1: 수집된 데이터의 CMI 분포. 추출된 트윗의 총 수는 87K입니다.

CMI 범위 전체에서 동일한 데이터를 수집하여, 이 코퍼스로 훈련된 언어 모델은 실제 데이터를 처리할 수 있도록 합니다. 언어 모델의 훈련 및 테스트 코퍼스에 동일한 분포를 유지합니다 (4:1 비율).

4 코드 혼합 언어 모델링의 병목 현상: 전환 지점

공식적으로, 스위칭 포인트(SPs)는 언어가 전환되는 텍스트에서의 토큰입니다. 코드믹스 언어의 경우, 언어 쌍으로 구성된 경우 두 가지 유형의 스위칭 포인트가 있을 수 있습니다. 코드믹스 언어의 일부인 두 언어를 L1과 L2라고 가정하면, 스위칭 포인트는 텍스트에서 언어가 L1에서 L2로 또는 L2에서 L1로 변경될 때 발생합니다. 더 잘 설명하기 위해, Hinglish에서 다음 샘플을 고려해 봅시다.

노래를 즐기세요.

위의 예에서는 언어가 힌디어에서 영어로 전환될 때 (gaanaHI enjoyEN), HI-EN (힌디어-영어) 전환 지점이 발생합니다. 마찬가지로, EN-HI (영어-힌디어) 전환 지점은 - enjoyEN kareHI에서 발생합니다.
혼합 언어 모델링의 맥락에서 전환 지점은 코퍼스에서 다른 단일 언어의 bigram과 함께 발생하는 일반적인 bigram으로 간주될 수 있습니다. 특정 SP bigram이 주어진 코퍼스에서 상대적으로 드물다는 것을 쉽게 추론할 수 있습니다.
따라서 전환 지점 bigram의 희소한 발생은 어떤 언어 모델도 그들의 확률과 문맥을 학습하기 어렵게 만듭니다. 언어가 전환되는 지점에서 LMs는 이러한 토큰을 처리하기 어려울 것으로 예상됩니다.
이 도전에 대응하기 위해, 우리는 코드 혼합 데이터를 (i) 전환 지점과 (ii) 비전환 지점으로 분할합니다. 그런 다음 전환 지점과 비전환 지점에 대해 특별히 LMs를 구축합니다.

다음 섹션에서 논의된 대로.
CONFLATOR 가설: CONFLATOR는 2가지 가설에 기반을 두고 있습니다. i) 위치 정보는 언어 모델에 있어서 특히 CM 텍스트를 다룰 때 중요합니다. ii) 스위칭 포인트는 코드 혼용 언어 모델(CMLM)에서 병목 현상입니다. 우리는 스위칭 포인트의 위치 정보를 CMLM에 통합합니다.

5 위치 인코딩 기법

상의한 대로, SP는 주요 병목 현상이므로 따로 처리해야 합니다. 언어 모델에서는 토큰 간의 의존성을 학습하기 위해 위치 인코딩이 필요합니다. 위치 임베딩은 처음으로 Vaswani et al. (2017b)에 의해 소개되었습니다. 제안된 사인과 코사인 값을 사용한 사인파 위치 인코딩은 위치 인덱스를 입력으로 사용합니다. 인코딩 기술은 Liu et al. (2020)에 의해 더 개선되었으며, 그들은 동적 함수를 도입하여 기울기 흐름으로 위치를 학습하였고, Shaw et al. (2018)은 학습 가능한 매개변수를 사용하여 상대적 위치의 위치 표현을 학습했습니다. 우리는 다음 소절에서 다양한 위치 인코딩 기술에 대해 자세히 이야기합니다.
우리는 여러 현대적인 기술을 실험해보았고, rotary 위치 인코딩 (Su et al., 2021)이 가장 우수한 성능을 보였습니다.

5.1 사인 함수 위치 인코딩 (SPE)

바스와니 외 (2017b)는 미리 정의된 사인 벡터 pi를 소개했습니다.

각 위치 i에 할당된 Rd 차원의 위치 표시기 pi가 있습니다. 이 pi는 위치 i의 단어 임베딩 xi ∈ Rd에 추가되며, xi + pi는 모델의 입력으로 사용됩니다. 이를 통해 Transformer는 서로 다른 위치에서 오는 단어를 구별할 수 있으며, 이는 각 토큰에 위치에 따라 다른 주의를 할당합니다. - 식 2.

eabs
ij
= 1
√d
(cid:0)(xi + pi)WQ,1 (cid:1)(cid:0)(xj + pj)WK,1 (cid:1)T (2)
W는 가중치 행렬이고, Q는 쿼리이며, K는 키이고, l은 레이어입니다.

5.2 동적 위치 인코딩 (DPE)

미리 정의된 주기 함수(sin과 같은) 대신에, Liu et al. (2020)은 각 인코더 레이어마다 동적 함수 Θ(i)를 도입했습니다. 사인 함수를 개선한 동적 PE는 모델에 동적 행동을 가져오기 위해 미리 정의된 pi 대신에 학습 가능한 함수 Θ(i)를 학습합니다. 각 발화마다 이 학습 가능한 함수 Θ(i)는 기울기 흐름을 통해 위치 정보에 대한 가장 적합한 표현을 학습하려고 시도합니다.

67
식 (3)에서 주어진대로, 단어 임베딩 wi에 Θ(i)가 추가됩니다.
eij = 1 / √d * (xi + Θ(i))WQ,1 * (xj + Θ(j))WK,1 * T
5.3 상대적 위치 인코딩 (RPE)

절대 PE에서는 서로 다른 위치 i에 대해 서로 다른 pi를 사용하여 변압기가 서로 다른 위치의 단어를 구별할 수 있습니다. 그러나, 절대 PE는 상대적인 단어 순서를 포착하는 데 효과적이지 않습니다. Shaw 등 (2018)은 학습 가능한 매개 변수 al을 소개했습니다.

i-j의 상대 위치의 위치 표현을 학습하는 인코더 레이어 l입니다. 이를 통해 우리 모델에서 단어 순서를 명시적으로 포착할 수 있습니다.

에렐
이제
= 1
루트 d
시그마 WQ, 시그마 WK, 더하기 al

나는 −j이다.
T (4)
5.4 스위칭 포인트 기반 동적 및 상대 위치 인코딩 (SPDRPE)

알리 외 (2022)은 새로운 스위칭 포인트 기반 PE를 소개합니다. 설명을 위해 코드믹스된 힌글리시 텍스트를 고려해보겠습니다 - yeHI gaanaHI enjoyEN kareHI. SP 기반 지수 (SPI)는 SP가 발생할 때마다 지수를 0으로 설정합니다. 인덱싱은 일반적으로 Index = (0, 1, 2, 3)이지만, 스위칭 포인트 통합으로 인해 SPI = (0, 1, 0, 0)으로 변경됩니다. 이에 추가로, 그들은 학습 매개변수 al i −j를 사용합니다. 이는 인코더 레이어 l에서 상대 위치 i-j를 인코딩합니다. 이 인코딩 접근 방식은 SP를 기반으로 동적으로 표현을 학습하며, al i −j 임베딩과 함께 상대적인 단어 순서도 포착할 수 있습니다. 다음과 같이 표현됩니다: eij = 1 √d (cid:16)(xi+Θ(S(li)))lWQ,l (cid:17)(cid:16)(xi+Θ(S(lj)))lWK,l+al i−j (cid:17)T (5)
5.5 로터리 위치 인코딩 (RoPE)

전자기파의 개념과 유사하게, (Su et al., 2021)은 Rotary Positional Encoding (RoPE)의 아이디어를 제시했습니다. 이 아이디어는 임베딩 벡터에 회전 행렬을 사용하여 위치 값을 생성하는 것입니다. 회전은 절대적인 위치 정보를 부정하고 시퀀스 내 모든 단어 임베딩 쌍 간의 상대적인 각도에 대한 정보만을 유지합니다. 두 벡터 사이의 내적은 개별 벡터의 크기와 그 사이의 각도의 함수임을 알고 있습니다. 이를 염두에 두고 RoPE의 직관은 임베딩을 복소수로 나타내고 위치를 적용하는 순수한 회전으로 나타내는 것입니다.
수학적으로, 간단한 2차원 경우의 정의는 다음과 같습니다:

fQ(xi,i) = (WQxi)e√ −1iθ
fQ(xj,j) = (WKxj)e√ −1jθ

fQ(xi,i) = (WQxi)e^(-iθ)
fQ(xj,j) = (WKxj)e^(-ijθ)

g(xi,xj,i−j) = Re[(WQxi)(WKxi)*e√−1(i−j)θ]

(6)
Re[]은 복소수의 실수부이고, (W Kx i)*는 (W Kx i)의 켤레 복소수를 나타냅니다. θ ∈ R은 미리 설정된 0이 아닌 상수입니다. 행렬 곱셈으로 f(Q,K)를 정의하면 다음과 같습니다.

fQ(xi,i) = (cid:16)cosmθ1 −sinmθ1 sinmθ1 cosmθ1 (cid:17)(cid:18)W(11) Q,K W(12) Q,K W(21)

fQ(xi,i) = (cid:16)cosmθ1 −sinmθ1 sinmθ1 cosmθ1 (cid:17)(cid:18)W(11) Q,K W(12) Q,K W(21)

Q, K
W(22)
Q, K
(19)(18)x(1) i x(2)
i (19)
(7)
(x i(1),x i(2))이 2D 좌표 형식으로 표현된 x i인 경우. 마찬가지로, 우리는 함수 g를 행렬 형태로 변환할 수 있습니다. 변환된 임베딩 벡터를 위치 인덱스의 배수 각도로 회전시킴으로써 상대적인 위치 정보를 통합할 수 있습니다. 이 특성으로 인해 이를 회전 위치 임베딩이라고 합니다.
2D에서 얻은 결과를 d가 짝수인 R d의 모든 x i에 대해 일반화하기 위해, d차원 공간을 d
2
개의 하위 공간으로 나누고, 내적의 선형성을 이용하여 이들을 결합합니다. 이로써 주의 메커니즘을 다음과 같이 변환합니다.

fQ,K = 에로타리 ij = 1 √d (cid:16)RMd Θ,iWQ,1(xi) (cid:17)T (cid:16)RMd Θ,jWK,1(xj) (cid:17) (8)

RM = 알엠

  
cosmθ1 −sinmθ1 0 0 ... 0 0
sinmθ1 cosmθ1 0 0 ... 0 0
0  0 cosmθ2 −sinmθ2 ... 0 0
0  0 sinmθ2 cosmθ2 ... 0 0 . . . . ... . .
.  .  .  . ... . .
0  0  0  0 ... cosmθd/2 −sinmθd/2 0 0 0 0 ... sinmθd/2 cosmθd/2

아무도 와서 나에게 도움을 주지 않았다.
나는 항상 너를 지지할 것이다.
그는 매우 피곤해 보인다.
나는 너를 사랑해.
이 책은 너무 어렵다.
나는 너를 믿는다.
그녀는 아주 예쁘다.
나는 너를 그리워한다.
이 음식은 맛있다.
나는 너를 이해한다.

(9) 아홉

RM이 직교하고 희소 행렬 사전 정의 매개변수인 경우

Θ = θ i = 10000-2(i-1)/d,i ∈ [1,2,...,d/2]. (10)
다른 작업에서 사용되는 위치 임베딩 방법의 가산성과는 달리, 그들의 접근 방식은 곱셈적입니다. 또한, RoPE는 자기 주의와 함께 적용될 때 가산적 위치 인코딩의 확장된 공식에서 항을 변경하는 대신 회전 행렬 곱을 통해 상대적인 위치 정보를 자연스럽게 통합합니다.

CMLM에 스위칭 포인트 정보 통합

위치 인코딩은 트랜스포머가 입력 시퀀스의 서로 다른 위치에 있는 토큰들 간의 의존성을 학습하는 데 도움이 됩니다. 코드 혼합 텍스트의 위치 인코딩을 강화하기 위해 우리는 회전 위치 인코딩을 수정하여 전환 지점 정보를 통합합니다.

68
그림 2: 스위칭 포인트 통합을 사용한 회전 접근 방식에 대한 시각적 직관. 우리는 선형으로 편광된 전자기파를 고려하고, 스위칭 포인트가 발생할 때마다 회전의 변화를 보여줍니다.

그림 3: 이 다이어그램은 제안된 위치 임베딩의 더 높은 수준의 이해를 보여줍니다.

6.1 스위칭 포인트 기반 회전 매트릭스
스위칭 포인트는 코드 혼용 언어 모델링에 있어 잠재적인 병목 현상입니다. 이 문제를 해결하기 위해 우리는 아키텍처에 스위칭 포인트 기반의 회전 위치 인코딩을 통합합니다. RoPE의 직관은 전자기파입니다. 임베딩은 복소수로 표현되고 위치는 그들에게 적용되는 순수한 회전으로 표현됩니다. 이를 염두에 두고, 우리는 RoPE에 참여하는 각도들의 도움으로 스위칭 포인트(SP) 문제를 해결합니다. 스위칭 포인트를 만나면 우리는 각도를 변경합니다.

회전, 즉, 우리는 이 각도들의 방향을 변경합니다. 회전 변경을 구현하기 위해, 우리는 전환점 행렬을 정의합니다. 전환점 행렬은 우리의 모델이 말뭉치에서 코드 혼용의 패턴을 인식하고 학습하는 데 도움이 됩니다. 우리의 행렬은 1과 -1로 정의됩니다. 언어 전환(L1이 있을 때

L2) 또는 (L2
→
L1), 즉, 전환점을 만났을 때, 우리는 열 값을 -1로 주석 처리하고, L2의 연속된 단어들에 대해서는 전환점이 다시 발생할 때까지 열 값을 1로 주석 처리합니다.

SPM
∈
Rd
n ∗n
if i == SP:

SPMi = -1
그렇지 않으면:

SPMi = 1
SPMi = 1

(11) 
나는 한국 음식을 좋아해요.

우리 접근 방식의 시각적 직관은 그림 2에 나와 있습니다. 1과 -1로 구성된 스위칭 포인트 행렬(SPM)은 회전 행렬을 전치하여 직관적으로 스위칭 포인트를 만날 때마다 회전을 반전시킵니다. 따라서 최종 행렬인 스위칭 포인트 회전 행렬(SPRM)은 정의된 스위칭 포인트 행렬(SPM)과 회전 행렬(RM)의 요소별 곱셈의 결과입니다.

SPRM = SPM
×
RM       (12)

eSPRotary ij = 1 √d (cid:16)SPRMd Θ,iWQ,1(xi) (cid:17)T (cid:16)SPRMd Θ,jWK,1(xi)

eSPRotary ij = 1 / √d (cid:16)SPRMd Θ,iWQ,1(xi) (cid:17)T (cid:16)SPRMd Θ,jWK,1(xi)

(13)

6.2 빅램과 스위칭 포인트 기반 회전 위치 인코딩 (BSPRoPE)

언어는 SP에서 변경되므로, 우리는 서로 다른 언어를 가진 두 개의 연속 토큰을 얻게 됩니다. 따라서 우리는 모델에 바이그램 수준의 정보도 포함시킵니다. 이 위치 인코딩 방법에서는, 우리는 발화 내의 바이그램들 사이의 위치 정보를 얻습니다. 우리는 단어 간 및 바이그램 수준에서의 스위칭 포인트 기반 회전 위치 인코딩 기술을 사용하며, 그림 3, 4에 나와 있는 대로 수학적으로 식 16으로 표현됩니다.

eUniSPRotary ij = 1 √d (cid:16)SPRMd Θ,iWQ,1(xi) (cid:17)T (cid:16)SPRMd Θ,jWK,1(xj)

eUniSPRotary ij = 1 / √d (cid:16)SPRMd Θ,iWQ,1(xi) (cid:17)T (cid:16)SPRMd Θ,jWK,1(xj)

(14) 14번째입니다.

eBiSPRotary ij = 1 √d (cid:16)SPRMd Θ,iWQ,1(xi) (cid:17)T (cid:16)SPRMd Θ,jWK,1(xj)

eBiSPRotary ij = 1 / √d (cid:16)SPRMd Θ,iWQ,1(xi) (cid:17)T (cid:16)SPRMd Θ,jWK,1(xj)

(15) 십오


예측 = a * eUnigramSPRotary ij + b * eBigramSPRotary ij (16)

a와 b는 학습 가능한 계수입니다. 방정식 14에서의 xi와 xi는 유니그램 입력을 나타내며, 방정식 15에서는 바이그램 입력을 나타냅니다.
69
그림 4: 인코더 레이어 내의 CONFLATOR 아키텍처입니다. 이는 입력 문장의 유니그램과 바이그램이 우리의 인코더 디코더 아키텍처에 입력으로 전달되는 방식을 보여줍니다. 이 프레임워크에서 우리는 회전 행렬과 스위칭 포인트 행렬을 생성합니다. 앞서 언급한 행렬들을 원소별 곱셈을 수행하여 우리의 제안된 새로운 스위칭 포인트 기반 회전 행렬을 얻습니다. 우리는 임베딩을 복소수로 표현하고, 위치를 순수 회전으로 나타내며, 이를 스위칭 포인트 기반 회전 행렬의 도움으로 적용합니다. 그런 다음, 유니그램과 바이그램 문장에 대한 출력 레이어를 따로 얻습니다. 우리는 각각의 가중 계수 a와 b를 유니그램 출력과 바이그램 출력에 도입합니다. 이 가중 유니그램과 바이그램 출력을 더하여 최종 출력 레이어를 얻습니다.

(a) 사인파 형태의 잠재 에너지 (b) 회전식 잠재 에너지 (c) 혼합기

그림 5: CONFLATOR는 다른 위치에서 나오는 단어를 구별하고, 다른 모델들은 그렇게 할 수 없는 상황에서 전환점이 발생할 때 (bagEN과 kidarHI에서) 높은 주의를 줄 수 있습니다.

6.3 CONFLATOR 아키텍처

Unigram과 Bigram의 지역 의존성 (처음부터 훈련된 Word2Vec)은 각 인코더 레이어의 6개의 헤드로 구성된 Multi-Head Attention (MHA)에 입력되며, 이로 인해 2개의 어텐션 행렬이 생성됩니다. 우리는 각각 unigram과 bigram 행렬의 가중 계수로 사용되는 학습 가능한 매개 변수인 α와 β를 도입합니다. 최종 행렬은 디코더 레이어로 전달됩니다. 그림 3과 4에 표시된 임베딩과 아키텍처를 사용합니다.

7 실험과 결과
우리의 기본 모델들은 각 훈련 단계마다 약 0.5초가 걸립니다. 우리는 기본 모델들을 총 100,000단계 또는 12시간 동안 훈련시킵니다. bigram과 SPM 기반 모델과 같은 큰 모델들의 경우, 단계 시간은 1.0초입니다. 큰 모델들은 250,000단계 동안 훈련되었습니다.

CMI 범위 변압기 GPT-2 BERT Conflator

0-10  1018.54 823.71 666.48 492.96
11-20 1210.11 967.01 782.19 501.44
21-30 1401.37 1334.72 1007.34 544.71
31-40 2688.00 2334.73 1007.34 800.62
41-50 4421.22 3905.87 4337.02 1095.12
Average 2147.85 1873.20 1701.49 578

표 2: CMI 범위에 따른 다른 모델들 간의 혼란도 비교. 낮은 혼란도가 더 좋습니다.

단계 (2일). 우리는 ADAM 옵티마이저를 사용하며 β1 = 0.9, β2 = 0.98 및 ϵ = 1e-9를 사용합니다. 우리는 Vaswani et al. (2017b)의 학습 과정에서 학습률을 변화시키는 방법을 사용합니다.

batch normalization.

70
모델들

위치 표현 대형 이중음절 F1(%)
Sin/Cos 지수 동적 SPI 상대 RM SPRM

Word2Vec+LSTM ✗ ✗  ✗   ✗  ✗  ✗  ✗  ✗   56
BERT     ✓   ✗  ✗   ✗  ✗  ✗  ✗  ✗   60

Word2Vec+LSTM ✗ ✗  ✗   ✗  ✗  ✗  ✗  ✗   56
BERT     ✓   ✗  ✗   ✗  ✗  ✗  ✗  ✗   60

3HA+사인파PE ✓ ✓ ✗ ✗  ✗  ✗  ✗  ✗  74.34
3HA+동적PE ✗ ✓  ✓   ✗  ✗  ✗  ✗  ✗  75.02
3HA+상대PE ✗ ✗ ✗   ✗  ✓  ✗  ✗  ✗  75.32
3HA+회전PE ✓ ✓  ✗   ✗  ✗  ✓  ✗  ✗  76.04

SOTA(PESTO) ✗  ✗  ✓  ✓   ✓  ✗  ✗  ✗  75.6
UnigramSPRelative(USPR) ✗ ✗ ✗ ✓ ✓ ✗ ✗ ✗  75
BigramSPRelativeBSPR) ✗ ✗ ✓ ✓ ✓ ✗ ✗ ✓   75
UnigramSPRoPE+GoodTuning ✓ ✓ ✗ ✓ ✗ ✓ ✓ ✗ 74.6
UnigramSPRoPE ✓ ✓ ✗  ✓   ✗  ✓  ✓  ✗   75
Conflator(BSPRoPE) ✓ ✓ ✗ ✓ ✗ ✓  ✓  ✓  76.23
ConflatorwithStableLM ✓ ✓ ✗ ✓ ✗ ✓ ✓ ✓  76.11
ConflatorwithAlpaca ✓ ✓ ✗ ✓ ✗ ✓ ✓  ✓  75.69
ConflatorwithLLaMA ✓ ✓ ✗ ✓ ✗  ✓  ✓  ✓  76.45

표 3: CM 텍스트에 대한 감성 분석을 위한 다양한 위치 민감 실험 결과. nHA는 n-헤드 어텐션을 의미합니다.

모델들

위치 표현 대표성 빅램 블루
사인/코사인 지수 동적 SPI 상대 RM SPRM

3HA+사인파PE ✓ ✓  ✗   ✗   ✗   ✗  ✗    ✗  17.2
3HA+동적PE ✗  ✓   ✓   ✗   ✗   ✗  ✗    ✗  17.9
3HA+상대PE ✗ ✗   ✗   ✗   ✓   ✗  ✗    ✗  18.4
3HA+회전PE ✓   ✓   ✗   ✗   ✗   ✓  ✗    ✗  24.9

SOTA(IIITH-mrinaldhar) ✗ ✗ ✓ ✓ ✓   ✗  ✗    ✗  28.4
UnigramSPRelative(USPR) ✗ ✗ ✗ ✓ ✓  ✗  ✗    ✗  9.8
BigramSPRelative(BSPR) ✗ ✗ ✓ ✓ ✓   ✗  ✗   ✓   7.6
UnigramSPRoPE ✓  ✓   ✗   ✓   ✗   ✓  ✓    ✗  29.1
Conflator(BSPRoPE) ✓ ✓ ✗  ✓   ✗   ✓  ✓   ✓   25.16
ConflatorwithStableLM ✓ ✓ ✗ ✓ ✗   ✓  ✓   ✓   29.06
ConflatorwithAlpaca ✓ ✓ ✗ ✓   ✗   ✓  ✓   ✓   29.89
ConflatorwithLLaMA ✓ ✓ ✗  ✓   ✗   ✓  ✓   ✓   30.15

표 4: CM 텍스트에 대한 위치 민감 실험의 결과. 높은 BLEU가 더 좋다.

정규화. 또한, 우리는 인코더와 디코더 레이어의 단어 임베딩과 위치 인코딩의 합에 드롭아웃과 정규화를 적용합니다. 우리는 Pdrop = 0.2의 비율을 사용합니다.
내재적 평가: 혼합 언어 모델링 작업에서 기준 언어 모델의 어려움 점수와 CONFLATOR과 비교한 어려움 점수가 2에 표시됩니다. 우리는 우리의 모델이 다른 모델보다 훨씬 더 잘 수행된다는 것을 알 수 있습니다.

외부 평가: 우리는 두 가지 하위 작업인 (i) 감성 분석과 (ii) 기계 번역에서 모델을 평가합니다. 감성 분석에 대해서는 Patwa et al. (2020a)가 제공한 데이터를 사용합니다. CONFLATOR는 76.23%의 F1 점수를 달성하며 SOTA (Ali et al., 2022)를 능가합니다. 이는 가변 길이 MHA 프레임워크와 함께 회전 위치 인코딩을 통해 SP를 학습하는 것이 주된 이유입니다. 기계 번역에 대해서는 Dhar et al. (2018)가 제공한 데이터를 사용합니다. 우리는 Unigram SPRoPE 모델을 사용하여 29.1의 bleu 점수를 달성하며 SOTA (Dhar et al., 2018)를 능가합니다. 이 모델은 언어 혼합의 패턴을 학습하는 데 도움을 주는 것입니다.

스위칭 포인트 기반 회전 위치 인코딩.
8 결론 및 요약
이 연구에서는 Hinglish 감성 분석 및 기계 번역 문제에 대한 실험 결과를 보고합니다. 이는 언어 모델링의 관점에서 이루어진 것입니다. 우리의 기여는 다음과 같이 볼 수 있습니다:
(i) 스위칭 포인트 기반 회전 위치 인코딩의 아이디어를 소개합니다. 스위칭 포인트가 발견되면 회전 변경을 통해 언어 혼합의 패턴을 학습합니다.
(ii) CONFLATOR라는 코드 혼합 언어를 위한 신경 언어 모델링 접근 방식을 소개합니다. CONFLATOR는 스위칭 포인트 기반 회전 위치 인코딩을 통해 더 나은 표현을 학습하려고 시도합니다. 초기에는 유니그램 수준에서, 그리고 이후에는 바이그램 수준에서 이루어집니다.
(iii) 우리는 CONFLATOR가 코드 혼합의 패턴을 학습한다는 것을 경험적으로 증명합니다. 다른 위치 인코딩을 사용하는 모델들이 실패하는 것을 그림 5에서 확인할 수 있습니다.
(iv) 또한, CONFLATOR는 어떠한 사전 훈련된 언어 모델도 사용하지 않고도 SOTA 결과와 비교 가능한 성능을 달성한다는 것도 주목할 만합니다.

71
9 제한사항

우리의 bigram 모델은 unigram을 사용한 감성 분석에서 SOTA를 달성하지만, 기계 번역에서는 bigram 모델보다 약간 뒤쳐지며, 디코더 수준에서 bigram을 사용하면 성능이 저하되었습니다. 광범위한 실험을 진행했음에도 불구하고, MT에 대한 bigram 기반 접근법이 실패한 이유에 대한 자세한 설명이 부족합니다. 향후 실험은 MT에 대한 bigram의 문제를 탐구하거나 이해하고 동일한 문제에 대한 해결책을 모색하는 데 초점을 맞출 것입니다.

참고문헌

모신 알리, 사이 테자 칸두쿠리, 수만스 만두루, 파르트 팟와, 아미타바 다스. 2022. Pesto: 코드 혼합 언어를 위한 스위칭 포인트 기반 동적 및 상대적 위치 인코딩 (학생 초록). 인공지능 AAAI 학회 논문집, 36권.

세군 타오피크 아로예훈과 알렉산더 겔부크. 2018년.
소셜 미디어에서의 공격 탐지: 딥 뉴럴 네트워크, 데이터 증강 및 가짜 라벨링 활용.
제1회 트롤링, 공격 및 사이버 괴롭힘 워크샵(TRAC-2018) 논문집, 90-97쪽, 뉴멕시코 주 산타페.
계산언어학 협회.

Shubhanker Banerjee, Bharathi Raja Chakravarthi, 그리고 John P McCrae. 2020. 인도어 코드믹스 텍스트에서 혐오 발언을 식별하기 위한 사전 훈련된 임베딩의 비교. 2020년 제2회 국제 컴퓨팅, 통신, 제어 및 네트워킹 (ICACCCN) 학회 논문집, 21-25쪽. IEEE.

우츠압 바르만, 아미타바 다스, 요아킴 바그너, 그리고 제니퍼 포스터. 2014년. 코드 혼용: 소셜 미디어 언어 인식에 대한 도전. 제1회 코드 스위칭에 대한 컴퓨터적 접근 워크샵 논문집, 13-23쪽, 도하, 카타르. 계산언어학 협회.

요슈아 벵지오, 레장 뒤샤르메, 파스칼 빈센트, 그리고 크리스찬 잔빈. 2003년. 신경망 확률 언어 모델. 기계 학습 연구지, 3:1137-1155.

아디티야 보라, 디판슈 비제이, 비네이 싱, 시드 사르파즈 아크타르, 그리고 마니시 스리바스타바. 2018년. 혐오 발언 탐지를 위한 힌디어-영어 코드 혼용 소셜 미디어 텍스트 데이터셋. 사회적 미디어에서 사람들의 의견, 성격, 감정에 대한 계산 모델링을 위한 두 번째 워크샵 논문집, 36-41쪽.

Eyamba G Bokamba. 1988. 코드 혼용, 언어 변이 및 언어 이론: 반투어 언어로부터의 증거. Lingua, 76(1):21–62.

바라티 라자 차크라바르티, 비그네쉬와란 무랄리다란,
루바 프리야다르시니, 그리고 존 P 맥크레이. 2020. 혼합된 타밀어-영어 텍스트에서 감성 분석을 위한 말뭉치 생성. arXiv 사전 인쇄 arXiv:2006.00206.

아린담 차터제레, 비니스 구프타, 파룰 초프라, 아미타바 다스. 2020. 스위칭 포인트를 위한 소수 양성 샘플링 - 코드믹싱 언어 모델링을 위한 일화. 제12회 언어 자원 및 평가 컨퍼런스 논문집, 6230-6238쪽, 프랑스 마르세유. 유럽 언어 자원 협회.

아미타바 다스와 비욘 감백. 2014. 혼합된 인도 소셜 미디어 텍스트에서 단어 수준에서 언어 식별하기.

제이콥 데블린, 민위 창, 켄튼 리, 그리고 크리스티나 투타노바. 2018a. BERT: 언어 이해를 위한 깊은 양방향 트랜스포머의 사전 훈련. arXiv 사전 인쇄 arXiv:1810.04805.

제이콥 데블린, 민위 창, 켄튼 리, 그리고 크리스티나 투타노바. 2018b. BERT: 언어 이해를 위한 깊은 양방향 트랜스포머의 사전 훈련. CoRR, abs/1810.04805.

미리날 다르, 바이브하브 쿠마르, 매니쉬 스리바스타바.
2018년. 코드 혼용 번역을 가능하게 하는: 병렬 말뭉치 생성과 기계 번역 보강 접근법. 제1회 언어 자원에 대한 워크샵 논문집, 131-140쪽, 뉴멕시코 주 산타페. Association for Computational Linguistics.

Björn Gambäck과 Amitava Das. 2016. 말뭉치에서의 코드 스위칭 수준 비교. 제10회 언어 자원 및 평가 국제 학회 논문집 (LREC'16)에서 발표됨, 1850-1855쪽, 슬로베니아 포토로즈. 유럽 언어 자원 협회 (ELRA).

Vinay Gopalan과 Mark Hopkins. 2020년. Reed에서 semeval-2020 task 9: 코드 혼합 트윗에 대한 감성 분석을 수행했습니다. CoRR, abs/2007.13061.

마단 고팔 쟌와르와 아르피타 다스. 2018. 힌디어-영어 코드믹스 데이터의 감성 분석을 위한 앙상블 모델. arXiv 사전 인쇄 arXiv:1806.04450.

아비셋 라다, 모하메드 하누시, 데브둣 무커지, 파르트 팟와, 그리고 안쿠르 나랑. 2020년. 메시징 앱에서 스티커 추천을 위한 채팅 메시지 이해. 인공지능 AAAI 학회 논문집, 34(08):13156-13163.

아비셋 라다, 모하메드 하누시, 데브두트 무커지, 파르트 팟와, 그리고 안쿠르 나랑. 2022년. 메시징 앱에서 대규모 다국어 스티커 추천. AI 매거진, 42(4):16–28.

Guillaume Lample과 Alexis Conneau. 2019. 교차 언어 모델 사전 훈련.

72
Xuanqing Liu et al. 2020. 위치를 연속적인 동역학 모델과 함께 변환기에 인코딩하는 방법 학습. ICML 2020에서.

이리 마, 리앙 조, 그리고 지에 하오. 2020. Xlp at semeval-2020 task 9: 교차 언어 모델과 포컬 로스를 사용한 코드믹싱 언어의 감성 분석. 제14회 시맨틱 평가 워크샵 논문집, 975-980쪽.

라빈드라 나야크와 라비라지 조시. 2022년. L3cube-hingcorpus와 hingbert: 코드 혼합된 힌디어-영어 데이터셋과 BERT 언어 모델.

브라자 고팔 패트라, 디판카르 다스, 아미타바 다스.
2018. 코드 혼합된 인도 언어의 감성 분석: sail_code-mixed 공유 작업 개요
@icon-2017. CoRR, abs/1803.06745.

파르트 팟와, 구스타보 아귈라, 수디타 카르, 수라지 판데이, 스리니바스 PYKL, 비욘 감백, 탄모이 차크라보르티, 타마르 솔로리오, 그리고 아미타바 다스. 2020a. SemEval-2020 작업 9: 코드 혼합 트윗의 감성 분석 개요. 제14회 의미 평가 워크샵 논문집, 774-790쪽, 바르셀로나 (온라인). 국제 계산 언어학 위원회.

파르트 팟와, 스리니바스 피클, 아미타바 다스, 프레라나 무커지, 그리고 비스와나스 풀라바이가리. 2020b. 캡슐 네트워크를 사용한 헤이터-오-지니어스 공격 분류. 제17회 자연어 처리 국제 학회(ICON) 논문집, 149-154쪽, 인도 기술 연구소 팟나, 팟나, 인도. 인도 자연어 처리 협회(NLPAI).

알렉 라드포드, 제프 우, 리원 차일드, 데이비드 루안, 다리오 아모데이, 그리고 일리야 숙스케버. 2019년. 언어 모델은 비지도 다중 작업 학습자입니다.

니루파르 사피 삼가바디, 파르트 팻와, 스리니바스 피클,
프레라나 무커지, 아미타바 다스, 그리고 타마리오.
2020년. BERT를 사용한 공격과 여성혐오 감지:
다중 작업 접근 방식. 트롤링, 공격 및 사이버 괴롭힘
에 관한 두 번째 워크샵 논문집, 126-131쪽.

아얀 센구프타, 소라브 쿠마르 바타차르지, 탄모이 차크라보르티, 그리고 MD 샤드 아크타르. 2021년. Hit: 강건한 코드믹스 언어 표현을 위한 계층적으로 융합된 딥 어텐션 네트워크.

피터 쇼, 야코브 우스코레이트, 그리고 애시시 바스와니. 2018년.
상대적 위치 표현을 사용한 셀프 어텐션.
NAACL 2018에서 발표.

라제드라 싱. 1985. 코드믹싱에 대한 문법적 제약: 힌디어-영어에서의 증거. 캐나다 언어학 잡지, 30(1):33–45.

비벡 스리바스타바와 마양크 싱. 2020. Phinc: 기계 번역을 위한 병렬 힌글리시 소셜 미디어 코드 혼합 말뭉치. arXiv 사전 인쇄 arXiv:2004.09447.

Jianlin Su, Yu Lu, Shengfeng Pan, Bo Wen, and Yunfeng Liu. 2021. Roformer: 회전 위치 임베딩이 강화된 트랜스포머. CoRR, abs/2104.09864.

티안청 탕, 신화이 탕, 그리고 티안이 위안. 2020년.
불균형 코드 스위칭 텍스트에서 다중 레이블 감성 분석을 위한 BERT 세부 조정. IEEE Access,
8:193248–193256.

데바프리야 툴라, 프라티우시 포틀루리, 쉬레야
미스, 수만스 도답아네니, 프란잘 사후,
로한 수쿠마란, 그리고 파르트 팻와. 2021년.
Bitions@DravidianLangTech-EACL2021: 앙상블
다국어 언어 모델과 유사 라벨링을 사용한 드라비다어 언어에서의 모욕 탐지.
드라비다어 언어에 대한 음성 및 언어 기술을 위한 첫 번째 워크샵의 논문,
페이지 291-299, 키예프. 계산 언어학 협회.

Debapriya Tula, MS Shreyas, Viswanatha Reddy, Pranjal Sahu, Sumanth Doddapaneni, Prathyush Potluri, Rohan Sukumaran, and Parth Patwa. 2022. 드라비다어에서 코드믹싱 지수 기반 초점 손실을 사용한 범죄 탐지. SN Computer Science, 3(5):330.

아시쉬 바스와니, 노암 샤지어, 니키 파마르, 야코브 우스코레이트, 리온 존스, 에이단 엔 고메즈, 우카시 카이저, 그리고 일리아 폴로수킨. 2017년. 주의는 당신이 필요한 모든 것이다. 신경 정보 처리 시스템 발전, 30권. Curran Associates, Inc.

아시쉬 바스와니, 노암 샤지어, 니키 파마르, 야코브 우스코레이트, 리온 존스, 에이단 N. 고메즈, 루카시 카이저, 그리고 일리야 폴로수킨. 2017b. 주의력은 당신이 필요한 모든 것이다. CoRR, abs/1706.03762.

S.K. Verma. 1976년. 코드 스위칭: 힌디어-영어. Lin-
gua, 38(2):153–165.

요가르시 비아스, 스판다나 겔라, 자틴 샤르마, 칼리카 바리, 그리고 모노짓 초우드후리. 2014년. 영어-힌디어 코드믹스 소셜 미디어 콘텐츠의 품사 태깅. 2014년 자연어 처리에 대한 경험적인 방법 (EMNLP) 컨퍼런스 논문집, 974-979쪽.

73
언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 제6회 절차, 74-82 페이지
2023년 12월 7일 ©2023 협회 for 계산 언어학
연결된 토크나이저를 기반으로 한 코드 스위칭 음성 인식 및 언어 식별에 대한 통합 모델

쿠날 다완, 디마 레케쉬, 보리스 긴스버그
NVIDIA, 산타클라라, 미국
{kdhawan, drekesh, bginsburg}@nvidia.com

요약

코드 스위칭 (CS) 다중 언어 자동 음성 인식 (ASR) 모델은 대화 중에 두 개 이상의 번갈아가며 사용되는 언어를 포함하는 음성을 전사할 수 있습니다. 본 논문은 (1) 순수한 단일 언어 데이터 소스에서 코드 스위칭 ASR 데이터셋을 생성하기 위한 새로운 방법을 제안하고, (2) 기존의 단일 언어 토크나이저를 재사용하면서 각 발행된 텍스트 토큰에 대한 언어 ID를 생성할 수 있는 새로운 연결 토크나이저를 제안합니다. 이러한 접근 방식의 효과는 영어-힌디어 및 영어-스페인어 두 언어 쌍에 대해 데모니스트레이션되었으며, Miami Bangor CS 평가 코퍼스에서 새로운 최첨단 결과를 달성했습니다. 경쟁력 있는 ASR 성능 외에도, 제안된 연결 토크나이저 모델은 FLEURS 데이터셋에서 98% 이상의 정확도로 말하는 언어 식별에 매우 효과적입니다.

1 소개

자동 음성 인식 (ASR) 시스템은 전문화된 단일 언어 모델에서 동시에 여러 언어를 처리할 수 있는 ASR 아키텍처로 이동하고 있습니다 (Weng et al., 1997; Waibel et al., 2000; Kannan et al., 2019; Li et al., 2022; Pratap et al., 2023). 코드 스위칭 (CS)은 두 개 이상의 언어나 언어 변종이 동일한 발화에서 사용되는 다중 언어 음성의 특수한 범주입니다. 이는 더 구체적으로 두 가지 범주로 나눌 수 있습니다: 문장 간 코드 스위칭은 주로 문장 경계에서 언어 간 전환이 발생하는 것이고, 문장 내 코드 스위칭은 문장 내에서 발생하는 것입니다 (Myers-Scotton, 1989). 코드 스위칭 ASR의 대부분의 작업은 좋은 품질의 코드 스위칭 음성 말뭉치의 가용성에 의존합니다 (Sitaram et al., 2019). 이 논문에서 우리가 탐구하는 질문 중 하나는: 기존의 단일 언어 음성 말뭉치를 어떻게 더 잘 활용하여 코드 스위칭 ASR 시스템을 훈련시킬 수 있는지입니다.

실제 세계의 코드 스위칭 상황에서 잘 수행할 수 있는 것.

ASR 이후의 텍스트 후처리, 예를 들어 구두 및 대문자화 (Guerreiro et al., 2021) 및 역 텍스트 정규화 (Sunkara et al., 2021)는 다국어 및 CS 음성 시스템에 대한 또 다른 중요한 문제입니다. 이러한 후처리는 텍스트 생성에 정확한 언어 식별 능력이 필요하기 때문에 단일 언어 시나리오보다 어렵습니다. 전통적으로, 별도의 언어 식별 (LID) 및 ASR 모델이 공통 음향 인코더와 함께 훈련되었습니다. Li et al. (Li et al., 2019)은 문장 내 CS ASR을 위한 엔드 투 엔드 아키텍처를 제안한 최초의 몇 가지 연구 중 하나였습니다. 그들은 두 개의 별도의 단일 언어 ASR 시스템과 프레임 수준의 LID 모델을 훈련시켰습니다. ASR 모델의 사후 확률은 LID 점수로 조정되었으며, 언어 모델 재점수화 없이 탐욕적 디코딩이 사용되었습니다. (Ali et al., 2021)에서 저자들은 문장 내 CS에 대해 Transformer 기반 시스템보다 효과적인 다중 그래프 가중 유한 상태 변환기를 사용하기를 제안했습니다. 최근의 연구들 (Seki et al., 2019), (Radford et al., 2022)은 이 문제를 다르게 접근하여 언어 식별을 위해 [EN] [ES]와 같은 특수한 LID 기호를 도입했습니다. 이러한 기호들은 디코딩된 텍스트가 어떤 언어에 속하는지 식별하기 위해 발화의 시작 부분에서 예측되거나, 각 언어에 속하는 디코딩된 토큰 범위를 표시하기 위해 발화 중에 예측됩니다.

이 논문에서는 우리가 제안하는 토큰 레벨 언어 식별을 위한 간소화된 기술인 Concatenated Tokenizer에 대해 설명합니다. 이전 접근 방식과는 달리, 우리는 언어별 토크나이저 어휘의 합집합을 취하는 "통합" 토크나이저(Li et al., 2021)나 언어 간에 공유된 서브워드 토큰 세트를 생성하는 방식(Pratap et al., 2020a)과는 달리, Concatenated Tokenizer 방법에서는 단일 언어 토크나이저를 재사용하고 상호 매핑합니다.

74
각 언어에 대한 독점 레이블 공간을 생성합니다. 이는 훈련 중 ASR 모델에 명시적인 언어 정보를 제공하고, 디코딩 시 토큰 수준의 LID를 저렴하게 예측하는 데 도움이 됩니다.
이 논문의 주요 기여는 다음과 같습니다:

1. 크기 조절 가능하고 확장 가능한 합성 코드 스위칭 ASR 데이터 생성 파이프라인은 엄격한 단일 언어 데이터 소스로부터 온라인(예: 훈련 중) 또는 오프라인에서 어떤 크기의 말뭉치도 생성할 수 있게 해줍니다.

2. 이어붙인 토크나이저 방법은 기존의 단일 언어 토크나이저를 효과적으로 활용하며, 다중 언어 및 CS ASR 모델을 학습하는 동안 토큰 수준의 LID 정보를 제공할 수 있습니다.

3. 우리는 제안된 통합 ASR 모델의 CS 음성 인식 능력을 실제 세계 데이터로 두 개의 언어 쌍에 대해 증명하며, 분포 범위를 벗어난 FLEURS 평가 데이터셋에서의 말하기 언어 식별 능력을 보여줍니다.

2 다국어 및 코드 스위칭 ASR

현대 자연어 처리(NLP) 및 ASR 모델은 텍스트를 표현하기 위해 토크나이저를 사용합니다 (Kudo 및 Richardson, 2018). 전통적인 접근 방식은 각 언어와 도메인마다 새로운 토크나이저를 학습해야 합니다. ASR에서는 이 토크나이저를 사용하여 원본 오디오 길이에 대한 공격적인 다운샘플링 아래 CTC 요구 사항을 충족하기 위해 대상 시퀀스 길이를 줄입니다 (Graves 등, 2006). 이 섹션에서는 제안된 연결된 토크나이저와 합성 코드 스위칭 데이터 생성 파이프라인에 대해 논의합니다.

2.1 연결된 토크나이저

다중 언어 ASR 모델을 훈련시킬 때, 단일 언어 훈련 세트는 일반적으로 크기, 품질, 잡음 수준 등이 크게 다른 특성을 가지므로 최적 결과를 얻기 위해 다른 비율로 결합하여 실험해야 합니다. 각 실험마다 결합된 데이터 세트에 대해 다른 토크나이저를 훈련하는 것은 논리적인 도전이 되는데, 결과적으로 생성된 모델은 항상 동일한 토크나이저를 사용해야 합니다. 합성 코드 스위칭 훈련 데이터 세트는 인접한 토큰들의 순수한 합성 동시 발생을 토크나이저가 학습하기 때문에 추가적인 도전을 제시합니다.

그림 1: 양언어 영어-스페인어 예시에 대한 집계된 vs 연결된 (제안된) 토큰화 접근 방식. 스페인어 텍스트와 토크나이저는 빨간색으로, 영어 텍스트와 토크나이저는 파란색으로 표시됩니다.

다른 언어로 작성된 코드 스위칭 데이터에서는 실제로 발생하기 어려운 현상이다. 마지막으로, 다국어 데이터에서 단일 토크나이저를 훈련시킬 때, 각 토큰의 LID 정보를 무시해야 하며, LID 정보를 유지하려면 외부 기술에 의존해야 한다.

우리는 위의 문제를 완화하기 위해 연결된 토크나이저 기술을 제안합니다. 그림 1은 어휘 크기가 2K인 이중 언어 영어-스페인어 모델을 훈련할 때 이 접근 방식을 보여줍니다. 기존의 방식에서는 텍스트 대본이 일정 비율로 혼합되고 토크나이저가 공동 텍스트 말뭉치에서 훈련됩니다. LID 정보는 손실되며 필요한 경우 다시 제공해야 합니다. CS 사용 사례의 경우, 합성 코드 스위칭 데이터셋에서 직접 토크나이저를 훈련하면 언어 샘플 간 임의의 전환을 학습하게 되어 피하는 것이 좋습니다.

연결된 토크나이저 방법에서는 영어와 스페인어 토크나이저를 각각 해당 단일 언어 데이터셋에 대해 1K 어휘 크기로 훈련합니다. 우리는 0부터 1023까지의 ID 범위를 영어에 할당하고, 1024부터 2047까지의 ID 범위를 스페인어에 할당합니다. 이를 위해 토크나이즈 후에는 각 스페인어 토큰을 1024만큼 이동하여 할당된 범위에 놓이도록 합니다. 따라서 연결된 토크나이저는 2K개의 토큰을 가지게 됩니다. 훈련 중에는 영어 토크나이저(파란색으로 표시)를 사용하여 각 영어 샘플 세그먼트를 토크나이즈하고, 스페인어 토크나이저(빨간색)를 사용하여 각 스페인어 세그먼트를 토크나이즈합니다. 추론 시에는 모델이 토큰 ID 시퀀스를 예측합니다. 만약 토큰 ID가 0부터 1023까지의 범위에 있다면, 해당 토큰이 영어 토큰임을 알고, 영어 토크나이저를 사용하여 텍스트로 변환합니다. 마찬가지로, 1024부터의 범위에 있는 토큰은 스페인어 토크나이저를 사용하여 변환합니다.

75
2047년까지 스페인어로 된 문장들은 스페인어 토크나이저로 보내져서 디토큰화됩니다. 각 토큰의 ID에는 언어 식별 정보가 포함되어 있으며, 결과 텍스트 세그먼트의 하향 처리에서 사용할 수 있습니다. 우리는 이 방법을 연결된 토크나이저라고 이름 지었는데, 이러한 토크나이저는 사실상 분리된 단일 언어 토크나이저보다 더 많은 토큰 공간을 보유하고 있습니다. 위의 예시에서는 영어와 스페인어에 동일한 토큰 수를 할당하기로 선택했지만, 데이터셋 크기가 매우 다를 때는 반드시 그렇게 할 필요는 없습니다.
연결된 토크나이저 방법은 표준 기술인 혼합 트랜스크립트로 토크나이저를 학습한 다음 언어 정보를 토큰화된 시퀀스에 특수한 LID 토큰을 통해 다시 주입하는 기술과는 크게 다릅니다 (Seki et al., 2019), (Radford et al., 2022). 후자의 접근 방식에서는 특수한 LID 토큰은 텍스트의 단일 언어 구간의 시작과 끝만을 나타냅니다.
연결된 토크나이저의 설계는 알려진 오디오에 특정 언어가 포함되지 않을 때 해당 언어를 추론에서 쉽게 제외할 수 있도록 해줍니다. 우리는 단순히 억제된 언어에 해당하는 토큰 ID에 대한 확률을 계산할 필요가 없으므로 동시에 성능을 향상시킬 수 있습니다. 그림 2는 CTC 디코더에서 이 작업이 어떻게 작동하는지를 보여줍니다. 반대로, 디코더에 언어를 추가할 때는 가중치 수술을 통해 기존의 토큰 가중치를 전달할 수 있으며, 증분 언어의 가중치를 처음부터 초기화할 수 있습니다. 동일한 아이디어는 Transducer 디코더에서도 작동합니다. 이는 단일 언어 체크포인트에서 다국어 모델을 훈련하는 동안 더 나은 디코더 초기화를 가능하게 하며, 수렴 시간을 개선합니다.

2.2 코드 스위칭 ASR을 위한 합성 데이터 생성

gether without considering the linguistic and cultural context, the generated data may not accurately represent natural code-switching patterns. Therefore, we developed a data generation pipeline that incorporated linguistic rules and cultural knowledge to create realistic code-switching samples. This allowed our model to learn the intricacies of code-switching and perform well on real-world data.

그림 2: 다국어 ASR 모델에서 언어의 추가/제거를 위한 연결된 토크나이저의 이점을 보여주는 다이어그램. 간단하게 설명하기 위해, CTC 디코더를 가진 이중 언어 ASR 모델의 단일 출력 단계를 보여줍니다. 이 디코더는 하나의 전방향 완전 연결 레이어(FC)로 구성되어 있으며, 이 레이어는 인코더 표현 (차원 denc)을 토큰 로짓 (차원 dvocab, 빈 심볼 제외)으로 매핑하는 가중치 W를 가지고 있습니다. 연결된 토크나이저에는 빨간색과 파란색으로 표시된 두 가지 언어가 있습니다. 연결된 토크나이저에서 서로 다른 언어에 대해 겹치지 않는 토큰 매핑 때문에, FC 가중치를 쉽게 분리하고 독립적으로 수정할 수 있습니다.

같이하면 일관성이 무너지고 다른 진폭과 배경 조건은 모델이 생성된 데이터를 학습하기 쉽게 만들어줄 수 있습니다. 이러한 불일치는 실제 예제에서 찾을 수 없으며, 따라서 모델은 성능을 일반화할 수 없습니다. 또한, 우리는 생성된 샘플을 특정 언어로 시작하거나 끝내는 것에 편향을 주고 싶지 않았습니다. 예를 들어, 영어.

우리는 모노링구언어 음성 말뭉치에서 두 개 이상의 언어에 대한 합성 CS 음성 데이터를 생성하기 위해 그림 3에 설명된 알고리즘을 사용했습니다. 각 언어에는 샘플링 주파수가 할당되었습니다. 각 합성 CS 샘플마다 최대 및 최소 지속 시간을 정의합니다. 이는 특정 지속 시간 분포로 샘플을 생성할 수 있도록 하며, 또한 샘플이 유사한 길이를 가지도록 보장하여 배치 중 패딩을 줄이고 데이터의 효과적인 활용을 높입니다. 합성 샘플의 선행 및 후행 침묵뿐만 아니라 연결된 샘플 사이의 간격을 제어하기 위해 세 가지 매개변수를 도입합니다: 시작 침묵 지속 시간, 끝 침묵 지속 시간, 연결 침묵 지속 시간. 현재 구현에서는 침묵을 사용하지만, 이는 원하는 SNR과 함께 노이즈를 추가하는 것으로 쉽게 확장할 수 있습니다. 알고리즘의 다음 단계는 선행 및 후행 침묵의 제거입니다.

76
그림 3: 두 언어에 대한 합성 CS 샘플 생성 프로세스의 플로우차트입니다. 조절 가능한 하이퍼파라미터는 밑줄로 표시되었습니다. 이 프로세스는 데이터로더에서 온라인 합성 데이터 생성 또는 섹션 2.2에서 논의된 합성 음성 말뭉치의 오프라인 생성에 모두 사용될 수 있습니다.

이는 개별 발화에서 음성 부분만 추출하고 발화의 시작 또는 끝에있는 모든 침묵을 제거함을 보장합니다.
이를 통해 우리는 앞서 설명한 조절 가능한 지속 시간 매개 변수를 사용하여 생성된 샘플에서 선행, 결합 및 후행 침묵을 완전히 제어할 수 있습니다.
현재 구현에서는 침묵 제거를 위해 진폭 기반 임계값을 사용하지만, 향후 반복에서 음성 활동 감지 (VAD)로 확장될 것입니다.
알고리즘에서 또 다른 중요한 단계는 오디오 진폭 정규화와 스케일링입니다.
연결하기 전에 각 샘플에 대해 피크 진폭 정규화를 수행하고 정규화 된 샘플에 조절 가능한 스케일링 매개 변수를 곱하여 모든 샘플이 유사한 진폭 범위에 있도록 보장합니다.
이를 통해 단일 언어 샘플을 제공하는 개별 데이터 세트에서 진폭 편향을 제거합니다.
비슷한 합성 음성 데이터 생성 아이디어가 (Seki et al., 2018)에서 제안되었지만, 우리의 접근 방식은 더 많은 사용자 정의가 가능합니다.

일반적으로 제어 가능한 매개변수의 수가 많기 때문에 이 기술은 훈련을 가속화하는 데 도움이 되는 길이가 더 길고 유사한 합성 샘플을 생성하는 데 유용하게 사용될 수 있다는 것을 발견했습니다. 합성 CS 데이터 생성 접근 방식은 또한 다국어 언어 모델 (Winata et al., 2019) 및 번역 모델 (Gupta et al., 2020; Tarunesh et al., 2021)을 훈련시키기 위해 텍스트 도메인에서도 탐구되었습니다.
우리의 구현에서는 합성 데이터 생성 파이프라인의 오프라인 및 온라인 버전을 모두 제공합니다. 오프라인 버전에서는 제안된 알고리즘을 사용하여 생성된 합성 말뭉치가 명시적으로 저장되어 ASR 모델을 훈련하는 데 사용될 수 있습니다. 온라인 버전에서는 합성 샘플 생성 프로세스가 데이터로더에서 발생하며, ASR 모델에 샘플을 공급하여 훈련에 사용됩니다. 온라인 데이터 생성 접근 방식은 생성된 합성 말뭉치를 저장할 필요가 없으므로 다양한 언어 비율 및 기타 매개변수 조합을 빠르게 실험할 수 있는 장점을 제공하며, 디스크 공간을 절약하면서 대량의 합성 훈련 CS ASR 말뭉치를 생성할 수 있습니다. 데이터 생성 프로세스의 코드는 오픈 소스로 제공되며 NeMo 툴킷에서 사용할 수 있습니다.

2.3 말하는 언어 식별

구어 언어 식별은 오디오에서 직접 주어진 발화의 언어를 식별하는 작업을 의미합니다 (Li et al., 2006). 이 작업은 CS ASR에 있어서 중요한 역할을 합니다. 왜냐하면 우리가 말할 때 어떤 언어가 사용되었는지 예측할 수 있다면, 단일 언어 모델을 재사용하여 CS 디코딩 결과를 다시 점수화할 수 있기 때문입니다. 제안된 연결된 토크나이저는 각 예측된 토큰이 속한 언어의 정보도 포함하고 있기 때문에 여기에 완벽하게 적합합니다. 발화 수준의 구어 언어 식별에 대한 연결된 토크나이저의 효과를 계산하기 위해, 문장의 각 토큰에 대한 예측된 언어 중 최대값을 취합니다. 공정한 비교를 위해, 우리는 3.1절에서 설명한 데이터셋으로 모델을 훈련시키고 FLEURS [26] 데이터셋의 블라인드 테스트 세트에서 구어 언어 식별 성능을 평가했습니다.

3 실험 설정

3.1 데이터셋

우리는 LibriSpeech (Panayotov et al., 2015)를 사용했습니다.

영어 말뭉치로 960시간을 사용했습니다. 스페인어의 경우,

1. https://github.com/NVIDIA/NeMo/scripts/speech_recognition/code_switching

우리는 데이터셋을 편집했습니다.

기본 청소 후 1300시) Mozilla Common Voice 7.0 (Ardila et al., 2020), Multilingual LibriSpeech (Pratap et al., 2020b), Voxpopuli (et al, 2021) 및 Fisher (Graff et al., 2010) (모두 스페인어)로 구성된 데이터를 사용했습니다. 힌디어 훈련에는 ULCA 데이터셋 (Dhuriya et al., 2022) (기본 청소 후 약 2,250시간)을 사용했습니다.
영어-스페인어 (en-es) 및 영어-힌디어 (en-hi) 합성 CS 데이터 생성에는 섹션 2.2에서 설명한 방법을 따라 10K 시간의 훈련 말뭉치를 생성했습니다. 다음 매개변수를 사용했습니다: 최대 샘플 지속 시간 19초, 최소 샘플 지속 시간 17초, 공백 지속 시간 0.02초, 끝 공백 지속 시간 0.02초, 결합 공백 지속 시간 0.1초. 동일한 매개변수를 사용하여 양 언어 쌍의 단일 언어 테스트 세트를 사용하여 10시간의 합성 이중 언어 CS 테스트 세트를 생성했습니다. 언어 샘플링 확률은 매개변수이며, 실험 과정에서 여러 비율을 실험했습니다.
스페인어 외부 분포 CS 테스트 세트로는 Miami Bangor corpus (Deuchar et al., 2014)를 선택했습니다. 이는 전체 대화로 구성되어 있으며, 제공된 타임스탬프를 사용하여 개별 상호작용을 추출했습니다. 2초 미만의 발화문은 제거되었습니다. 최종 평가 세트는 16시간에 16620개의 발화문과 35개의 고유한 문자가 포함되어 있습니다. 힌디어 CS 테스트 세트로는 MUCS 2021 corpus (Diwan et al., 2021)를 사용했습니다. 기본 청소를 수행하여 5시간에 3136개의 샘플과 89개의 고유한 문자가 포함된 세트를 얻었습니다.

3.2 모델과 실험

우리는 Conformer-RNNT Large 모델 (Gu-
lati et al., 2020) (
∼
120 M 파라미터, 외부 LM 없음)을 사용하였으며, AdamW 옵티마이저와 Noam 스케줄러를 사용하여 200 에포크 동안 훈련하였습니다. 워머업 단계는 20k 스텝이며, 최대 학습률은 0.0015이고 최소 학습률은 10−6입니다. 우리는 다음과 같은 실험을 수행하였습니다:

• 단일 언어: 우리는 단일 언어로 영어, 스페인어, 힌디어 ASR 모델을 훈련시켰습니다 (3.1절 참조). 각 언어에 대해 우리는 SPE 유니그램 토크나이저 (Sennrich et al., 2016)를 1024의 어휘 크기로 훈련시켰습니다.

bilingual models: English-Spanish and English-Hindi. We used various combinations of monolingual datasets, aiming to give more weight to the smaller dataset. We conducted training for two categories.

모델, 하나는 연결된 토크나이저(2.1절)를 사용하고 다른 하나는 1:1 비율로 결합된 텍스트 말뭉치에서 훈련된 일반 (종합) 토크나이저를 사용합니다. 또한, 양쪽 언어 쌍에 대해 단일 언어 체크포인트에서 처음부터 훈련하거나 시작점으로부터 초기화 연구를 수행했습니다.

• 코드 스위칭 (CS): 우리는 CS 영어-스페인어 및 영어-힌디어 모델을 합성 코드 스위칭 데이터로 훈련시켰습니다. 이는 섹션 3.1에서 강조된 내용입니다. 우리는 처음부터 훈련하는 것과 해당 양언어 (비 CS) 모델을 실험했습니다. 또한 모든 시나리오에서 연결 및 집계 토크나이저를 사용하는 것을 조사했습니다.

• 언어 식별: 우리는 이중 언어 CS 실험을 통해 훈련된 영어-스페인어 및 영어-힌디어 연결 토크나이저를 사용하여 FLEURS 세트(Conneau et al., 2023)의 영어(en_us_test, 647개 샘플), 스페인어(es_419_test, 908개 샘플) 및 힌디어(hi_in_test, 418개 샘플) 음성 샘플에서 문장 수준의 언어 식별을 수행했습니다.

4 결과 및 토론

이 섹션에서는 섹션 3.2에서 설명한 실험 결과를 제시합니다. 표 1a는 영어 Librispeech와 스페인어 Fisher 테스트 세트에서 단일 언어, 이중 언어 및 CS 영어-스페인어 모델의 성능을 보여줍니다. 영어와 스페인어 토큰 분석기에 대한 다른 토크나이저를 사용했습니다. 훈련 세트를 균형있게 맞추기 위해 이중 언어 모델의 데이터 세트 혼합 비율 (영어 대 스페인어)은 2:1로 설정했습니다. Fisher 테스트 세트는 섹션 3.1에서 언급된 네 개의 스페인어 데이터 세트 중 가장 어려웠기 때문에 스페인어 모델의 성능을 대표하기 위해 선택되었습니다. 마찬가지로, 표 1b는 영어-힌디어 언어 쌍에 대한 다른 모델의 결과를 제시합니다. 이중 언어 모델의 데이터 세트 혼합 비율 (영어 대 힌디어)도 훈련 세트를 균형있게 맞추기 위해 2:1로 설정했습니다. 결과는 세 번의 실행에서 평균화되었으며, 다섯 개의 최상의 모델 체크포인트에서 평균화되었습니다.
영어-스페인어 CS 실험 결과는 표 2a에 강조되어 있으며, 영어-힌디어는 표 2b에 나와 있습니다. 단일 언어 모델의 숫자는 코드 스위칭 평가 데이터 세트에 보고되지 않았으며, 예상대로 비교적 낮은 성능을 보입니다.

78
표 1: 영어-스페인어 및 영어-힌디어 모델에 대한 단일 언어 평가 세트 결과. 우리는 다국어 (ml) 및 코드 스위칭 (cs) 모델에 대해 연결 (con) 및 집계 (agg) 토크나이저로 훈련된 모델과 단일 언어 기준선에 대한 WER(%) (낮을수록 좋음)를 제시합니다. 우리는 연결된 토크나이저의 사용이 모델 성능에 해를 끼치지 않으면서 각 토큰에 대한 LID 예측 능력을 추가하는 것을 관찰합니다.

(a) 영어-스페인어 결과는 영어 단일 언어 Librispeech 테스트-기타 및 스페인어 Fisher 테스트 세트에 있습니다.

모델 토크나이저 LS 테스트-다른 Fisher-테스트

en   모노     5.29     98.37
es   모노     85.68    16.14
ml    어그     5.00     16.37
ml    콘     5.14     16.72
cs    어그     5.38     16.35
cs    콘     5.28     16.42

(b) 영어-힌디어 결과는 영어 단일 언어 Librispeech 테스트-기타 및 힌디어 ULCA 평가 세트에 있습니다.

모델 토크나이저 LS 테스트-기타 ULCA

en   mono     5.29    100
안녕하세요. 모노입니다. 5.29 100

hi   mono     100    10.53
안녕하세요. 모노입니다. 100 10.53

ml     agg     5.00   10.78
안녕하세요. 애그입니다. 5.00 10.78

ml     con     5.14   10.73
안녕하세요. 콘입니다. 5.14 10.73

cs    agg     5.42   11.35
안녕하세요. 애그입니다. 5.42 11.35

cs    con     5.29   11.64
안녕하세요. 콘입니다. 5.29 11.64

표 2: 합성 (con) 및 집계 (agg) 토크나이저로 훈련된 코드 스위칭 (cs) 영어-스페인어 및 영어-힌디어 모델의 성능 비교, 합성 및 실제 세계 블라인드 CS 평가 데이터셋에서. 다중 언어 (ml) 모델의 성능도 벤치마크로 보고되었습니다. 우리는 제안된 합성 CS 데이터를 사용하는 장점을 강조하여 cs 모델이 ml 모델보다 훨씬 우수한 성능을 보인다는 것을 관찰했습니다.

(a) 코드 스위치된 영어-스페인어 모델: 합성 및 마이애미-방고르 코드 스위치 평가 세트에서의 WER(%).

모델 토크나이저 신스 마이애미

cs    agg   5.51 50.0
cs    con   5.50 53.3

ml    agg   16.52 58.78
ml    con   24.08 63.54

(b) 코드 스위칭된 영어-힌디어 모델: 합성 및 MUCS CS 평가 세트에서의 WER(%).

모델 토크나이저 신스 MUCS

cs    agg   6.55 30.3
cs    con   6.57 28.78

ml    agg   35.70 62.18
ml    con   53.01 100

다중 언어 모델을 사용하여 코드 스위칭된 음성을 디코딩할 때, 우리는 그들이 발화가 시작된 언어에 고수되고 발화 내에서 언어를 전환할 수 없다는 것을 관찰합니다. 이는 표 2a와 2b의 대응하는 높은 WER과 일치하며, 모델이 훈련 중에 코드 스위칭된 데이터를 만나지 않았다는 사실과 일치합니다. 설명하기 위해, 다음은 영어-스페인어 코드 스위칭된 오디오의 샘플 대본입니다:
ML 모델 출력: con qué departamento puedo dejar fitbax sobre mi experiencia de compra en la tienda que estaba ubicada en one tú threforme ave
CS 모델 출력: con qué departamento puedo dejar feedbacks sobre mi experiencia de compra en la tienda que estaba ubicada en one two three fourth avenue
우리는 ML 모델이 스페인어(주 언어)에서 영어(시각적 비교를 위해 밑줄로 표시)로 전환할 수 없다는 것을 볼 수 있습니다. 반면, CS 모델의 출력은 100% 정확합니다. 마지막으로, 언어 식별 결과는 다음과 같습니다.

세 가지 언어에 대한 실험 결과는 표 3에 제시되었습니다. 이어서, 우리는 결과를 자세히 분석하고 발견을 논의하겠습니다.

4.1 이중 언어 모델, 모델 초기화 및 토크나이저의 효과

표 1a와 1b에서는 양언어 및 CS 모델이 각각의 단일 언어 평가 세트에서 단일 언어 모델과 비교 가능한 성능을 보여준다는 것을 관찰할 수 있습니다. 이는 영어-힌디어 및 영어-스페인어 언어 쌍에 대해 관찰되었습니다. 이는 한 언어에 대해 두 개의 별도의 단일 언어 모델을 생성하는 대신 단일 양언어 코드 스위치 모델을 사용할 수 있도록 해주는 흥미로운 결과입니다. 단일 언어 체크포인트에서 훈련을 초기화하면 훈련을 가속화하지만 최종 WER에는 개선이 없었습니다. 연결된 또는 집계된 토크나이저를 사용하더라도 유사한 성능을 보였습니다. 그러나 연결된 토크나이저는 언어 식별 및 다중 언어 LM 재점수화와 같은 추가적인 이점을 제공합니다.

79
표 3: FLEURS 데이터셋에서 영어-스페인어 및 영어-힌디어 연결 토크나이저를 사용한 구어 언어 식별.

언어 샘플 수 LID 정확도

영어    647      98%
(en_us_test)       (632/647)
스페인어    908      100%
(es_419_test)       (908/908)
힌디어     418      99%
(hi_in_test)       (414/418)

4.3절에서 논의된 대로.

4.2 코드 스위칭 모델, 모델 초기화 및 토크나이저의 효과

표 1a는 영어-스페인어 CS ASR 모델의 성능을 단일 언어 테스트 세트인 Librispeech와 Fisher에서 보여줍니다. 표 2a는 코드 스위칭 세트인 합성 및 Miami Bangor 말뭉치에 대한 해당 결과를 보여줍니다. 마찬가지로, 영어-힌디어 코드 스위칭 ASR 모델의 경우, 표 1b는 단일 언어 테스트 세트인 Librispeech와 ULCA에서의 성능을 보여주며, 표 2b는 코드 스위칭 테스트 세트인 합성 및 MUCS의 결과를 요약합니다. 양쪽 언어 쌍에 대해, 코드 스위칭 모델을 다중 언어 체크포인트에서 초기화하는 것이 처음부터 모델을 초기화하거나 단일 언어 체크포인트에서 초기화하는 것보다 더 나은 결과와 빠른 수렴을 이끌어냄을 관찰했습니다. 또한, 다른 언어 데이터셋 혼합 비율을 실험해본 결과, 코드 스위칭 데이터셋이 대략 균형을 이룰 때 가장 좋은 결과를 얻을 수 있음을 확인했습니다. 이는 작은 언어의 오버샘플링을 필요로 할 수 있습니다.

(Weller et al., 2022)에서 저자들은 마이애미 방고르 말뭉치에서 53%의 성능을 보고했으며, 이는 우리의 코드 스위치 모델이 실제 세계 샘플에서 최첨단 기술과 경쟁력을 갖추고 있으며, 순수한 합성 코드 스위치 데이터로만 훈련되었음을 보여줍니다. 또 다른 중요한 관찰은 연결된 토크나이저가 CS 모델에 대해 집계 토크나이저만큼 잘 수행되므로, 추가적인 이점을 제공하기 때문에 선호되어야 한다는 것입니다. 토론을 마치며, 우리는 이제 단일 모델이 단일 언어, 양언어 및 코드 스위치 데이터에서 잘 수행되는 것을 가지고 있습니다.

4.3 연결된 토크나이저와 언어 식별

표 3은 FLEURS 데이터셋의 테스트 세트에서 연결된 토크나이저로 훈련된 영어-스페인어 및 영어-힌디어 모델의 발화 수준의 구어 언어 식별 성능을 보여줍니다. 우리는 이러한 모델이 음성 샘플에서 직접 발화의 언어를 매우 정확하게 예측하는 것을 관찰합니다. 이는 훈련 중 모델이 보지 못한 분포 밖의 샘플이기 때문에 중요하다고 생각합니다.

5 결론

이 논문에서는 순수한 단일 언어 데이터셋을 사용하여 이중언어 및 코드 스위칭 모델의 훈련을 조사합니다. 우리는 두 가지 새로운 기술을 제안합니다: (1) 실시간 및 오프라인 합성 코드 스위칭 데이터 생성 파이프라인 및 (2) 연결된 토크나이저 방법을 통해 모델이 개별 토큰 수준에서 언어 ID를 직접 예측할 수 있도록 합니다. 우리는 이 두 가지 기술을 사용하여 CS ASR 모델을 훈련시키고, 단일 언어 평가 기준에서 단일 언어 모델의 성능과 유사한 성능을 보이면서 코드 스위칭 데이터에서 훨씬 우수한 성능을 발휘한다는 것을 발견했습니다. 우리는 실제 세계의 Engish-Spanish Miami Bangor 및 English-Hindi MUCS 코퍼스뿐만 아니라 합성 CS 테스트 세트를 사용하여 모델의 성능을 평가했습니다. 또한, 우리는 FLEURS 데이터셋을 사용하여 측정한 LID 감지에서 모델의 강력한 성능을 발견했습니다. 연결된 토크나이저로 훈련된 모델의 성능은 일반적인 집계 토크나이저로 훈련된 모델과 유사하며, LID 감지의 추가적인 이점을 제공합니다. 이 결과들은 이러한 접근 방식이 모델 아키텍처 복잡성을 증가시키지 않고 다른 언어로 확장될 수 있음을 시사합니다. 더 나아가, 연결된 토크나이저 모델의 우수한 LID 기능은 단일 언어 모델을 사용하여 코드 스위칭 모델 예측을 재점수화하고 개선하는 데 도움이 될 수 있습니다. 이 모든 것은 추가 연구에 대한 함의를 가지고 있습니다. 코드와 모델 가중치는 NeMo2에서 공개적으로 공개되었습니다.

제한사항

conducted experiments on a code-switching speech
recognition task using a large-scale dataset. The
results demonstrate that our approach outperforms
existing methods and achieves state-of-the-art
performance.

2https://github.com/NVIDIA/NeMo
2https://github.com/NVIDIA/NeMo

80
두 가지 언어 쌍으로 실험을 진행했습니다: 영어-스페인어 (en-es)와 영어-힌디어 (en-hi). 우리는 영어와 스페인어의 양언어적 특성으로 인해 en-es를 선택했고, 힌디어와 영어는 서로 다른 문자 집합을 가지고 있기 때문에 en-hi를 선택했습니다. 이를 통해 우리의 접근 방식의 견고성을 평가할 수 있었습니다. 그러나 일반적으로 이 방법이 작동하는지 확인하기 위해 더 다양한 언어 쌍으로 실험을 수행해야 합니다. 또한, 연결된 토크나이저가 한 번에 두 개 이상의 언어로 확장되는지 확인하기 위해 더 많은 실험이 필요합니다. 연결된 토크나이저는 각 언어에 대해 상호 배타적인 토큰 공간을 할당하므로, 추가 언어를 포함할수록 크기가 증가합니다. 이 확장성의 도전은 대규모 다국어 모델의 구축을 방해할 수 있습니다. 이러한 제한 사항을 향후 연구 노력을 통해 해결함으로써, 코드 스위칭 음성 인식 분야에서 우리의 연구 결과의 포괄성과 적용 가능성을 향상시킬 수 있습니다.

윤리 성명

우리는 ACL 윤리 정책에 기술된 원칙을 준수하고 지지합니다. 우리의 합성 코드 스위치 ASR 연구는 널리 사용되는 언어부터 드물게 사용되는 언어까지 다양한 언어 범위에서 광범위한 이점을 제공할 수 있는 잠재력을 가지고 있습니다. 데이터 수집과 관련된 도전을 완화함으로써, 우리의 연구는 다양하고 공정한 언어적 환경의 진보에 기여합니다. 또한, 우리의 다국어 모델 탐색은 훈련 및 배포의 계산 요구를 간소화하는데만 그치는 것이 아니라, 다양한 단일 언어 모델의 유틸리티를 통합함으로써 자원 효율성을 촉진합니다. 마지막으로, 우리는 이 연구에서 사용된 모든 코드와 모델을 공개적으로 이용 가능한 데이터셋에서 독점적으로 훈련시키고, 이를 온라인에서 접근 가능하게 함으로써 투명성과 개방성에 대한 약속을 확인합니다.

참고문헌

아메드 알리, 샴무르 압사르 초우드리, 아미르 후세인, 그리고 야서 히프니. 2021년. 단일 언어 데이터를 사용한 아랍어 코드 스위칭 음성 인식. Interspeech에서.

R. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler, J. Meyer, R. Morais, L. Saunders, F. M. Tyers, and G. Weber. 2020. Common voice: A massively-multilingual speech corpus. In LREC.

R. 아르딜라, M. 브랜슨, K. 데이비스, M. 헨레티, M. 코러, J. 메이어, R. 모라이스, L. 산더스, F. M. 타이어스, 그리고 G. 웨버. 2020. Common voice: 대규모 다국어 음성 말뭉치. LREC에서.

알렉시스 코너, 민 마, 심란 칸주자, 유 장,
베라 악셀로드, 시다르트 달미아, 제이슨 리에사, 클라라
리베라, 그리고 안쿠르 바프나. 2023년. FLEURS: 페우샷
러닝에서의 유니버설 음성 표현 평가. SLT에서.

마가렛 듀차, 페레더 데이비스, 존 러셀 헤링, M 카르멘 파라피타 쿠토, 그리고 다이애나 카터. 2014년. 이중언어 말뭉치 구축. 이중언어 연구의 진전, 93-110쪽. 멀티링구얼 매터스.

앙쿠르 듀리야, 리샤브 고어 외. 2022. Ulca-asr-dataset-corpus. https://github.com/Open-Speech-EkStep/ULCA-asr-dataset-corpus.

아누지 디완, 라케시 바이디스와란, 산케트 샤,
안키타 싱, 스리니바사 라가반, 쉬레야 카레,
비닛 우니, 사우라브 비아스, 아카시 라즈푸리아, 치-
란지비 야라 등. 2021. 저자 미상. 저자 미상. 다국어 및 코드-
스위칭 asr 저해결책: 인도의 저자원 언어를 위한 도전. arXiv 사전인쇄 arXiv:2104.00235.

창한 왕 외. 2021. VoxPopuli: 표현 학습, 준지도 학습 및 해석을 위한 대규모 다국어 음성 말뭉치. ACL에서.

데이비드 그래프, 슈동 황, 인그리드 카르타게나, 케빈 워커, 그리고 크리스토퍼 시에리. 2010년. 피셔 스페인어 음성. https://catalog.ldc.upenn.edu/LDC2010S01.

A. Graves, S. Fernández, F. Gomez, and J. Schmid-huber. 2006. 연결주의 시간 분류: 순환 신경망을 사용하여 세분화되지 않은 순서 데이터에 레이블 지정. ICML에서.

누노 미구엘 게레이루, 리카르도 레이, 그리고 페르난도 바티스타. 2021년. 더 나은 자막을 향하여: 말문장 복원을 위한 다국어 접근 방식. 응용 전문 시스템, 186:115740.

안몰 구라티, 제임스 친, 정청 치우, 니키 파마르, 유 장, 지아희 유, 웨이 한, 시보 왕, 정동 장, 용희 우 등. 2020년. 콘포머: 음성 인식을 위한 합성곱 보강 트랜스포머. 인터스피치, 페이지 5036-5040.

딥악 구프타, 아시프 에크발, 푸시팍 바타차리야.
2020년. 사전 훈련된 인코더와 전이 학습을 사용한 반지도 학습 방법을 통한 코드 혼합 텍스트 생성. 연구 결과: 협회를 위한 계산 언어학: EMNLP 2020, 페이지 2267-2280.

안주리 칸난, 아린드리마 다타, 타라 N 세이네스, 유진 와인스타인, 부바나 라마바드란, 용희 우, 안쿠르 바프나, 지펑 천, 그리고 승지 리. 2019년. 스트리밍 엔드 투 엔드 모델을 사용한 대규모 다국어 음성 인식. 인터스피치.

타쿠 쿠도와 존 리처드슨. 2018. Sentencepiece: 신경망 텍스트 처리를 위한 간단하고 언어 독립적인 서브워드 토크나이저와 디토크나이저. EMNLP: 시스템 데모.

81
Bo Li, Ruoming Pang, Tara N Sainath, Anmol Gulati,
Yu Zhang, James Qin, Parisa Haghani, W Ronny
Huang, Min Ma, and Junwen Bai. 2021. 대규모 다국어 음성인식을 위한 엔드 투 엔드 모델 확장. ASRU에서 발표.

하이저우 리, 빈 마, 그리고 친휘 리. 2006년. 말하는 언어 식별에 대한 벡터 공간 모델링 접근 방식. IEEE Transactions on Audio, Speech, and Language Processing.

Ke Li, Jinyu Li, Guoli Ye, Rui Zhao, and Yifan Gong.
2019년. 엔드 투 엔드 CTC 모델을 위한 코드 스위칭 ASR을 향해. ICASSP에서.

신장 리, 플로리안 메체, 데이비드 R 모르텐슨, 앨런 W 블랙, 그리고 신지 와타나베. 2022. ASR2K: 오디오 없이 약 2000개 언어에 대한 음성 인식. arXiv:2209.02842.

유첸 리우, 롱 조우, 이닝 왕, 양 조우,
지아준 장, 그리고 청칭 존. 2018년. NMT에서 모델 평균화, 앙상블 및 재순위에 대한 비교 연구. NLPCC에서, 페이지 299-308.

Carol Myers-Scotton. 1989년. 영어와 함께하는 코드스위칭: 스위칭의 유형, 커뮤니티의 유형. 월드 잉글리시, 8(3):333–346.

바실 파나요토프, 구오구오 천, 다니엘 포비, 산지브 쿠다푸르. 2015년. Librispeech: 공공 도메인 오디오북을 기반으로 한 ASR 말뭉치. ICASSP에서.

Vineel Pratap, Anuroop Sriram, Paden Tomasello, Awni Hannun, Vitaliy Liptchinsky, Gabriel Synnaeve, and Ronan Collobert. 2020a. 대규모 다국어 음성인식: 50개 언어, 1개 모델, 10억 개의 매개변수. Interspeech.

Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi 등. 2023년. 1,000개 이상의 언어로 음성 기술 확장. arXiv:2305.13516.

Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, and Ronan Collobert. 2020b. MLS: A large-scale multilingual dataset for speech research. In Interspeech. 

빈일 프라탑, 첸토우 쉬, 아누루프 스리람, 가브리엘 시네브, 그리고 로난 콜로베르. 2020b. MLS: 음성 연구를 위한 대규모 다국어 데이터셋. Interspeech에서.

알렉 라드포드, 김종욱, 터오 쉬, 그렉 브록먼, 크리스틴 맥리비, 그리고 일리야 숫크에버. 2022년. 대규모 약한 감독을 통한 견고한 음성 인식. arXiv:2212.04356.

히로시 세키, 타카아키 호리, 신지 와타나베, 조나단 르 루, 그리고 존 R 허시. 2019년. 종단 간 다국어 다화자 음성 인식. INTERSPEECH에서, 페이지 3755-3759.

히로시 세키, 신지 와타나베, 타카아키 호리, 조나단 르 루, 그리고 존 R 허시. 2018년. 혼합 언어 음성을 위한 종단 간 언어 추적 음성 인식기. ICASSP에서.

리코 센릭, 배리 하도우, 알렉산드라 버치.
2016년. 서브워드 단위를 사용한 희귀 단어의 신경 기계 번역. ACL에서.

Sunayana Sitaram, Khyathi Raghavi Chandu, Sai Krishna Rallabandi, 그리고 Alan W Black. 2019. 코드 스위칭된 음성 및 언어 처리에 대한 조사. arXiv:1904.00784.

모니카 순카라, 차이타냐 시바데, 스라반 보다파티, 그리고 카트린 키르훌. 2021년. 신경망 역 텍스트 정규화. ICASSP에서.

이샨 타루네시, 샴안탁 쿠마르, 그리고 프리티 조티.
2021년. 기계 번역에서 코드 스위칭으로:
고품질의 코드 스위칭 텍스트 생성. arXiv
사전 인쇄물 arXiv:2107.06483.

알렉스 와이벨, 하겐 솔타우, 탄야 슐츠, 토마스 샤프, 그리고 플로리안 메체. 2000년. 다국어 음성 인식. Verbmobil: 음성 대 음성 번역의 기초, 33-45쪽. 스프링거.

오리온 웰러, 마티아스 스페버, 텔모 피레스, 헨드라 세티아완, 크리스티안 골란, 도미닉 텔라르, 그리고 마티아스 파울릭. 2022년. 코드 스위치된 음성에 대한 엔드 투 엔드 음성 번역. ACL에서.

풀리앙 웽, 해리 브랫, 레오나르도 뉴마이어, 그리고 안드레아스 스톨케. 1997년. 다국어 음성 인식에 대한 연구. 제5회 유럽 음성 통신 및 기술 컨퍼런스에서 발표.

Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, 그리고 Pascale Fung. 2019. 병렬 문장으로부터 신경망 기반 합성 데이터를 사용한 코드 스위칭 언어 모델. arXiv 사전 인쇄 arXiv:1909.08582.

82
언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 제6회 절차, 83-88 페이지
2023년 12월 7일 ©2023 협회 for 계산 언어학
다국어 자기 지도 음성 표현은 코드 스위칭이 있는 저자원 아프리카 언어의 음성 인식을 개선시킵니다.

톨룰로.페. 오구느.미 크리스토퍼 D. 매닝 단 주라프스키

스탠포드 대학교
tolulope@cs.stanford.edu

요약




1 소개

전 세계 인구의 절반 이상이 적어도 두 개의 언어를 정기적으로 사용합니다 (Ansaldo et al., 2008). 이러한 일반적인 상황에도 불구하고, 자동 음성 인식 (ASR) 모델은 코드 스위칭이 포함된 음성과 잘 작동하지 않습니다: 화자가 발화 내에서 두 개 이상의 언어나 변형을 번갈아 사용하는 경우 (Myers-Scotton, 2017). 저자들은 이 문제를 해결하려고 할 때, 저자들은 저자들은 저자들은 두 가지 문제를 마주하게 됩니다: 엔드 투 엔드 훈련을 위한 충분한 데이터 부족과 언어 모델링을 위한 충분한 데이터 부족.
최근에는 wav2vec 2.0 (Baevski et al., 2020)와 같은 음성의 자기 지도 학습이 영어 ASR의 오류율을 매우 낮게 유지하는 것으로 입증되었습니다. 사전 훈련 비용이 매우 비싸지만, 영어 모델과 교차 언어 (XLSR) 표현 (Conneau et al., 2020)은 많은 언어에 대한 효율적인 음성 인식기를 만들기 위해 세밀 조정을 위해 사용할 수 있습니다.
이 연구에서 우리는 다음과 같은 질문을 제기합니다: XLSR의 세밀 조정은 코드 스위칭 데이터의 인식을 개선시킬 수 있을까요?

코드 스위칭된 데이터에 대한 전통적인 훈련? 이 현상을 테스트하기 위해 우리는 네 개의 아프리카 언어 (isiZulu, isiXhosa, Sesotho, Setswana)를 영어와 함께 코드 스위칭하여 조사합니다. 또한 이 fine-tuning 과정을 진행하는 방법에 대해 세 가지 질문을 탐구합니다. 먼저 ASR 성능을 향상시키기 위해 코드 스위칭 데이터셋에 추가할 다양한 유형의 데이터를 실험해보며 다음과 같은 질문을 제기합니다. 1. 단일 언어 데이터를 추가해야 할까요? 다른 많은 방법들은 모델에 언어 식별 (language ID)을 통합하기 때문에 우리는 다음과 같이 묻습니다. 2. 우리의 파이프라인에 언어 식별을 추가하는 것이 도움이 될까요 (명시적으로든 암시적으로든)? 이를 테스트하기 위해 언어를 암시적으로 식별하고 프레임 수준의 언어 ID와 ASR을 동시에 학습하기 위해 발화를 보강하는 방법을 사용합니다. 마지막으로 우리는 다음과 같이 묻습니다. 3. 코드 스위칭된 데이터로 훈련된 간단한 n-gram 언어 모델은 데이터의 양이 적더라도 성능을 향상시킬까요? 우리는 코드 스위칭된 말뭉치를 사용하여 bigram과 trigram 모델을 훈련시키고 모델을 디코딩할 때 사용합니다. 우리는 사전 훈련된 다중 언어 모델을 세밀하게 조정하고 간단한 trigram 언어 모델로 보강하는 것이 저자원 언어에서 코드 스위칭된 데이터를 인식하는 데에 잘 작동한다는 것을 발견했습니다. 이는 처음부터 훈련하는 전용 모델 (CNN-TDNN-F 음향 모델 + LSTM 언어 모델)의 이전 방법보다 훨씬 우수한 성능을 보입니다. 우리는 언어 ID나 단일 언어 데이터 추가가 추가적인 성능 향상을 가져오지 않으며, 놀랍게도 단일 언어 데이터 추가가 모델 성능을 악화시킨다는 것을 발견했습니다. 우리의 연구 결과는 훈련 데이터가 제한적인 상황에서는 자기 지도 학습 표현을 세밀하게 조정하는 것이 성능이 더 우수하고 실용적인 해결책일 수 있다는 것을 시사합니다.

2 관련 연구

어구 처리에서 코드 스위칭에 대한 연구는 코드 스위칭 감지 (Ralla-bandi et al., 2018; Yılmaz et al., 2016; Wang et al., 2019)로 언어 식별 (Choud-을 사용하여 나눌 수 있습니다.

83
휴리 등(2017)과 엔드 투 엔드 인식(인드라 위나타 등, 2018)을 통해 두 가지 방법을 살펴봅니다. 이 연구에서는 wav2vec 2.0(Baevski 등, 2020)라는 자기 지도 표현을 세밀 조정하는 방법을 사용합니다. 언어 식별 방법은 음성에 대한 ASR을 수행하기 전에 언어를 식별하거나 음향 모델과 언어 ID를 병렬로 훈련합니다. 엔드 투 엔드 인식은 크로스 리규얼 표현을 사용한 다국어 모델링(Li 등, 2019a; Luo 등, 2018; Zhang 등, 2022)과 여러 전사를 생성하는 병렬 모델링으로 나눌 수 있으며, 이를 보간하여 가장 높은 가능성을 가진 하나의 전사로 결합합니다(Ahmed와 Tan, 2012; Lyu 등, 2006).
저희는 이러한 방법을 적용할 때 저자원 언어에 대한 충분한 데이터 부족과 저자원 언어나 코드스위치 언어 쌍에 대한 신경 언어 모델링을 위한 충분한 데이터 부족이라는 두 가지 문제를 마주칩니다. 코드스위치 쌍에 대한 언어 모델의 부재로 인해 이전에 계산 비용이 적은 방법이 실패하고 모델의 일반화에 충분한 데이터 부족으로 인해 모델의 성능이 저하됩니다.
저희 연구에서는 선택한 언어 쌍을 위해 사전 훈련된 자기 지도 음향 모델 wav2vec 2.0(Baevski 등, 2020)를 활용하여 기존의 다국어 음향 모델을 세밀 조정하는 데 초점을 맞추고 있습니다. 작은 데이터셋에서 성능을 향상시킬 수 있는 추가 신호로 언어 식별을 통합합니다.

3 배경

3.1 언어

이 작품에서 사용된 언어는 네 개의 남아프리카 언어와 영어입니다. 남아프리카 언어는 모두 남부 반투어 (SB) 언어로, 응니어와 소토-츠와나 언어로 구성되어 있습니다. 이 작품에서 사용된 영어는 남아프리카 사투리로 말하는 영어입니다.

3.2 데이터

우리는 남아프리카의 다국어 코드 스위칭된 연속극 대사 코퍼스를 사용합니다(Niesler et al., 2018). 이 코퍼스는 626개의 남아프리카 연속극 에피소드에서 수집된 대사로 구성되어 있으며, 이사주루, 이시코사, 세소토, 세츠와나 언어로 이루어진 대사가 영어와 코드 스위칭되어 있습니다.

언어 번호 화자
(백만 명)
언어 가족

isiXhosa 11.6      SB: Nguni
isiZulu  8.2       SB: Nguni
Sesotho  4.0     SB: Sotho-Tswana
Tswana   3.8     SB: Sotho-Tswana
English  380    IE: Western Germanic

표 1: 이 작업에서 사용된 언어에 대한 개요입니다. 남아프리카 언어는 남부 반투족 (SB) 언어 가족의 응니와 소토-츠와나 분파에 속하며, 영어는 인도유럽어 (IE) 언어 가족의 서부 게르만어 분파에 속합니다.

추가적인 단일 언어 데이터로는 isiZulu, isiXhosa, Sesotho, Setswana 및 영어 부분을 사용하여 NCHLT Speech Corpus (Barnard et al., 2014)를 단일 언어 보강 세부 조정 데이터로 추가합니다. 우리는 데이터셋의 NCHLT-clean 파티션을 사용합니다. 이 작업에서 사용된 데이터셋은 표 2에 요약되어 있습니다.

언어 번호 문장 수 지속 시간 (시간)

비누
오페라
말뭉치
Eng-Zul 9347    5.45
Eng-Xho  7941    3.14
Eng-Sot 6303    2.86
Eng-Tsn 6563    2.83

NCHLT
코퍼스
isiZulu 44673   56.2
isiXhosa 46651  56.3
Sesotho 57539   56.3
Setswana 58414   56.3
English 77412   56.4

표 2: 남아프리카 다국어 코드 스위치된 연속극 대화(Soap Opera Corpus)와 NCHLT-청정 음성 말뭉치(NCHLT Corpus)에서 실험에 사용된 데이터 요약.

3.3 기준 모델

우리는 Biswas et al. (2022)의 이 데이터로부터 처음부터 훈련된 모델과 비교합니다. 그들의 가장 우수한 성능을 보이는 음향 모델은 Kaldi 기반의 CNN-TDNN-F로, 5개 언어를 모두 학습하고 각 언어 쌍에 대해 fine-tuning을 거칩니다. 언어 모델 디코딩에는 저자들은 양방향 LSTM 아키텍처를 사용하며 임베딩은 256차원, 매트릭스는 256차원입니다. LSTM은 언어 쌍에 대해 훈련되어 총 네 개의 별도 언어 모델이 생성됩니다. 우리는 이 작업에서 각 언어 쌍에 대해 가장 우수한 성능을 보이는 모델과 우리의 방법을 비교합니다.

4 어떤 추가 데이터가 도움이 될까요?

코드스위칭된 말 데이터의 자원이 부족한 상황에서, 어떤 유형의 데이터가 가장 적합한지 알아보기 위해 질문합니다.

84
코드스위치 데이터셋을 보완하여 하위 결과를 향상시킵니다. 이를 테스트하기 위해 우리는 각 언어 쌍에 대해 Soap Opera Corpus 데이터 이외의 추가 데이터로 모델을 "사전 세부 조정"합니다. 도메인 내 데이터가 가장 유용한지 테스트하기 위해 우리는 4개의 언어 쌍에 대한 Soap Opera Corpus 데이터로 모델을 42000 단계 동안 사전 세부 조정합니다. 그런 다음 이 모델은 각 개별 언어 쌍에 대한 Soap Opera Corpus 데이터로 12000 단계 동안 추가적으로 사전 세부 조정되어 +all 4 쌍 모델이 생성됩니다. 단일 언어 데이터를 추가하는 것이 성능을 향상시키는지 테스트하기 위해 우리는 각 언어 쌍의 NCHLT 단일 언어 데이터와 해당 언어 쌍의 Soap Opera Corpus 데이터를 사용하여 모델을 42000 단계 동안 사전 세부 조정합니다. 그런 다음 이러한 모델을 해당 언어 쌍의 Soap Opera Corpus 데이터로 추가적으로 사전 세부 조정하여 +monolingual 모델을 생성합니다. 제안된 방법을 원하는 언어 쌍의 Soap Opera Corpus 데이터만을 사용하여 사전 세부 조정하는 것과 비교하기 위해 우리는 해당 언어 쌍의 Soap Opera Corpus 데이터로 모델을 15000 단계 동안 사전 세부 조정하여 One pair 모델을 생성합니다. 표 3은 이러한 실험의 결과를 탐욕적 디코딩으로 보여줍니다.

언어 쌍 모델 유형 WER

한 쌍 72.2
+모든 4 쌍 59.0
+단일 언어 77.5

한 쌍 60.8
+ 모든 4 쌍 50.8
+ 단일 언어 67.6

한 쌍 59.4
+ 모든 4 쌍 50.2
+ 단일 언어 63.3

한 쌍 51.4
+ 모든 4 쌍 42.7
+ 단일 언어 60.4

표 3: "사전 세부 조정"에 사용된 추가 데이터의 ASR 성능에 대한 영향. WER은 모델의 단어 오류율입니다. +모든 4개 언어 쌍은 Soap Opera Corpus의 도메인 내 코드스위칭 데이터로 "사전 세부 조정"되었으며, +단일 언어는 해당 언어 쌍의 Soap Opera Corpus 데이터와 각 언어의 단일 언어 데이터로 "사전 세부 조정"되었습니다.

우리는 모든 네 가지 언어에서 코드스위칭된 데이터를 사용하는 것을 볼 수 있습니다.




5. 암시적 또는 명시적 언어 식별 정보를 추가하는 것이 도움이 됩니까?

이전 연구에서는 코드스위치 ASR에 대해
언어 식별 (language ID) 및 ASR을 동시에 학습하는 것이 ASR 성능을 향상시킨다는 것을 보였다 (Luo et al., 2018; Li et al., 2019b; Zeng et al., 2019). 여기서는 데이터를 보강하고 분류기를 훈련시켜 언어 식별 정보를 추가해보려고 한다.
우리는 Soap Opera Corpus 문장을 보강하여 명시적인 언어 레이블이나 타임스탬프 대신 문장의 이중언어성을 포착하는 실험을 진행한다. 각 언어 쌍에 대해 두 가지 방법을 사용한다: 언어별 대소문자와 언어별 태그. 언어별 대소문자의 경우, 각 언어에 특정한 대소문자를 부여하여 어휘 크기를 두 배로 늘린다. 예를 들어, 영어는 대문자로, isiZulu는 소문자로 한다. 그런 다음 이 데이터로 wav2vec 2.0 XLSR 300M을 12000 단계 동안 fine-tune하여 각 언어 쌍에 대한 +casingID 모델을 얻는다. 언어별 태그의 경우, 특정 언어의 텍스트 양쪽에 여는 태그와 닫는 태그를 넣는다. 그런 다음 이 데이터로 wav2vec 2.0 XLSR 300M을 12000 단계 동안 fine-tune하여 각 언어 쌍에 대한 +tagsID 모델을 얻는다.

케이싱: 만약 경찰이 먼저 도착한다면

<kor> 만약 </kor> <zul> etholwa
amaphoyisa kuqala </zul>

암시적 덧셈의 시연

우리의 모델에 언어 정보의 85%를 언어별 대소문자와 언어별 태그를 통해 제공합니다.
우리의 데이터를 기반으로 언어 식별 분류기를 훈련시키기 위해 wav2vec 2.0 XLSR 인코더에 프레임 수준의 분류 헤드를 추가합니다. 우리는 말뭉치의 타임스탬프를 사용하여 프레임을 영어 또는 남아프리카 언어로 레이블링하고 교차 엔트로피 손실로 모델을 훈련시킵니다. 언어 식별 모델의 결과는 표 4에 있습니다.

영어-한국어 99%

표 4: 네 개의 남아프리카 언어와 영어의 프레임 수준 언어 식별 결과

프레임 수준 언어 식별 모델은 잘 작동합니다.
그래서 우리는 모델 성능을 향상시키기 위해 멀티태스크 설정을 시도합니다. 
언어 식별과 ASR을 동시에 학습하며, 두 작업의 가중 손실을 합산합니다. 
손실 계산은 식 1에 요약되어 있습니다. 
ASR이 우선이므로 언어 식별 가중치를 항상 CTC 가중치보다 높게 유지합니다. 
결과적으로 언어 쌍별로 12,000 단계 동안 세밀하게 조정된 +멀티태스크ID 모델이 됩니다. 
모델 아키텍처는 그림 1에 시각화되어 있습니다.

손실CTC+LID = λCTCLCTC+(1 −λCTC)LLID

(1) 저는 한국에 살고 있어요.

그림 1: 손실의 가중 합으로 CTC와 프레임 수준 언어 식별을 결합하기 위한 우리의 다중 작업 학습 설정.

언어 쌍 모델 유형 WER

한 쌍 72.2
+태그 ID 83.4
+케이싱 ID 87.9
+멀티태스크 ID 75.2

한 쌍 60.8
+태그 ID 80.8
+케이싱 ID 80.9
+멀티태스크 ID 64.2

한 쌍 59.4
+태그 ID 76.3
+케이싱 ID 89.4
+멀티태스크 ID 65.6

한 쌍 51.4
+태그 ID 72.6
+케이싱 ID 86.6
+멀티태스크 ID 64.5

표 5: 언어 식별 기능이 ASR 성능에 미치는 영향. WER은 모델의 단어 오류율입니다.
+tagsID는 데이터셋의 발화 주변에 언어별 태그를 사용하며, +casingID는 각 언어에 대해 하나의 대소문자를 사용합니다 (예: 영어는 대문자, isiZulu는 소문자). 언어 식별 및 ASR을 동시에 학습하는 모델은 +multitaskID 모델로 지칭됩니다. +multitaskID 모델은 +tagsID 및 +casingID보다 더 좋은 성능을 보입니다. 그러나 언어 식별 모델 중 어느 것도 전혀 언어 식별을 사용하지 않는 기준선("One pair" 행)만큼 잘 작동하지는 않습니다.

우리 실험의 결과는 표 5에 있습니다.
다중 작업 설정에서는 최상의 언어 식별 및 CTC 가중치 결과가 보고됩니다.
다중 작업 학습 설정은 언어별 대소문자 및 태그보다 하류 성능을 향상시킵니다. 그러나 더 세밀한 조정보다는 모델이 두 가지 작업을 동시에 배우려고 하면 방해받는 것으로 추정됩니다.
언어별 대소문자는 모델 성능을 향상시키지 않고, 실제로 기준선과 비교하여 모델을 악화시킵니다. 이는 어휘가 불필요하게 두 배로 늘어나기 때문일 가능성이 높습니다.
언어 식별 태그는 언어별 대소문자보다 더 잘 작동하지만, 태그 없이 세밀 조정보다 우수한 성능을 내지 않습니다. 이는 태그가 어떤 음성에 해당하지 않기 때문에 도입되면 초기 혼란을 야기하기 때문일 가능성이 높습니다.
요약하면, 코드 스위칭 데이터셋에서 언어 식별 정보를 추가해도 ASR 성능이 향상되지 않습니다. 이는 훈련에 사용 가능한 데이터의 부족 또는 실제 음성에 대응하지 않는 태그의 도입 때문일 수 있습니다.

86
우리 5개 언어의 문자 집합이 모두 겹치는 것이거나, 우리의 실험이 세밀 조정(finetuning)을 포함하고 있으며, end-to-end 사전 훈련이 아니라는 사실에 대해 생각해 볼 수 있습니다.
다른 연구에서는 코드 스위칭 음성 인식을 위해 다중 작업 학습을 사용한 결과 (Li et al., 2019b; Zeng et al., 2019; Song et al., 2022; Winata et al., 2018), 문자 집합이 겹치지 않는 영어와 중국어의 언어 쌍에서 성공을 보였습니다. 해당 영어/중국어 모델은 처음부터 끝까지 처음부터 훈련되었으므로, 언어 식별 기능의 통합이 훈련 중에 더 유용하고 세밀 조정과 같은 후기 단계에서는 덜 유용할 수 있습니다.

언어 모델은 성능을 향상시킬까요?

지금까지 우리의 실험에서는 wav2vec 2.0 모델에 CTC 헤드로 finetuned하여 탐욕적 디코딩을 수행했습니다. 언어 모델 정보를 추가하면 성능이 향상될 수 있을까요? 비교 대상인 기준 시스템은 LSTM 언어 모델을 사용했으며, 이 정보가 유용할 수 있다는 것을 시사합니다.
이 섹션에서는 Soap Opera Corpus의 대본을 훈련 데이터로 사용하여 작은 n-gram 언어 모델의 정확도를 향상시킬 수 있는지 연구합니다. 우리는 KenLM (Heafield, 2011)을 사용하여 4개의 언어 쌍 데이터셋마다 별도의 bigram과 trigram (단어) 언어 모델을 훈련시키고, 이 언어 모델을 디코딩에 사용합니다.
각 언어 쌍에 대해 가장 잘 finetuned된 모델의 언어 모델 결과는 표 6에 제시되었습니다.

기준선 48.7 43.3 48.5 43.5
탐욕적 59.0 50.8 50.2 42.7
2-gram 26.7 25.5 30.6 28.9
3-gram 22.1 22.3 23.4 21.7

표 6: 언어 모델링이 ASR 성능에 미치는 영향 (WER로 측정). 기준선의 숫자는 (Biswas et al., 2022)에서 가져온 것이며, 그들의 시스템(이 LSTM 언어 모델을 포함)은 Soap Opera Corpus 데이터로 finetuning된 wave2vec 2.0과 비교되며, 그리디 디코딩(언어 모델 없음)뿐만 아니라 Soap Opera Corpus 데이터로 훈련된 바이그램 및 트라이그램 n-gram 모델과도 비교됩니다. n-gram 언어 모델 없이는 기준선 모델이 finetuning된 wav2vec 2.0보다 우수한 성능을 보입니다. 그러나 ASR 데이터로 n-gram 언어 모델을 훈련하면 기준선보다 성능이 향상됩니다.

라인(CNN-TDNN-F 음향 모델과 양방향 LSTM 모델)보다 욕심 많은 디코딩이 더 나은 결과를 보여주지 않습니다.

라인에는 언어 모델이 있으며, 우리는 단순한 n-gram 언어 모델을 장착한 세밀하게 조정된 모델이 기준 모델을 일관되게 이기는 것을 발견했습니다. 이러한 결과는 사전 훈련된 대형 모델을 단순한 언어 모델 지원만으로 세밀하게 조정하는 것이 저자원 상황에서 더 나은 해결책일 수 있다는 것을 시사합니다.

7 결론

이 작업에서는 남아프리카 언어와 영어의 코드스위칭 데이터로 wav2vec 2.0 XLSR을 세밀하게 조정했습니다. 우리는 이 시스템이 간단한 바이그램 또는 트라이그램 언어 모델과 함께 사용될 때 LSTM 언어 모델로 훈련된 기준 모델을 능가한다는 것을 발견했습니다. 또한, 매우 관련된 언어와 동일한 장르/도메인의 데이터를 추가하는 것이 도움이 된다는 것을 발견했습니다. 우리는 다양한 종류의 언어 ID 정보로 모델을 개선할 수 없었습니다. 이러한 방법은 문자 집합이 겹치지 않는 언어나 충분한 데이터가 있는 경우에 더 성공적일 수 있습니다. 이 작업은 상대적으로 적은 계산과 매우 기본적인 n-gram 언어 모델을 사용하여 코드스위칭 데이터로 ASR 모델을 훈련하는 방법을 보여주며, 세계의 많은 언어에서 특징이 되는 저자원 설정에서 중요한 작업에 대한 방향을 제시합니다.

8. 감사의 말씀

리뷰어들께서 제공해주신 의견과 제안에 감사드립니다. 이 연구는 NSF (국립과학재단)의 IIS-2128145 번호로 일부 지원받았으며, Stanford 공학부 장학금으로 TO에게 일부 지원되었습니다. CM은 CIFAR Learning in Machines and Brains 프로그램의 펠로우입니다.

참고문헌

Basem H.A. Ahmed와 Tien-Ping Tan. 2012. 1-best 재점수화를 사용한 코드 스위칭 음성의 자동 음성 인식. 2012년 아시아 언어 처리 국제 컨퍼런스에서 발표된 논문, 137-140쪽.

아나 이네스 안살도, 카린 마르코트, 릴리안 쉐러, 그리고 가엘 라보아. 2008년. 언어 치료와 이중언어 아피지아: 심리언어학과 신경영상 연구의 임상적 함의. 신경언어학 저널, 21(6):539–557. L2의 습득, 처리 및 상실: 기능적, 인지적 및 신경적 관점.

87
알렉세이 바예프스키, 유하오 조우, 압델라만 모하메드, 그리고 마이클 아울리. 2020. wav2vec 2.0: 음성 표현의 자기 지도 학습을 위한 프레임워크. Advances in Neural Information Processing Systems, 33권, 12449-12460쪽. Curran Associates, Inc.

에티엔 바르나르, 마렐리 H 다벨, 찰 바른 헤르덴, 페베 데 벳, 그리고 자코 바덴호스트. 2014년. 남아프리카 언어의 NCHLT 음성 말뭉치. 4차 언어 부족 언어를 위한 구어 언어 기술 워크샵 (SLTU 2014)에서, 194-200쪽.

Astik Biswas, Emre Yılmaz, Ewald van der Westhuizen, Febe de Wet, and Thomas Niesler. 2022. 다섯 가지 남아프리카 언어에서의 코드 스위칭 자동 음성 인식. 컴퓨터 음성 및 언어, 71:101262.

모노짓 초우드후리, 칼리카 발리, 수나야나 시타람, 그리고 아슈토시 바헤티. 2017년. 코드 스위칭을 위한 커리큘럼 디자인: 딥 뉴럴 네트워크를 이용한 언어 식별 및 언어 모델링 실험. 제14회 국제 자연어 처리 학회 (ICON-2017) 논문집, 65-74쪽.

알렉시스 코너, 알렉세이 바에프스키, 로낭 콜로베르, 압델라만 모하메드, 그리고 마이클 아울리. 2020년. 음성 인식을 위한 비지도형 교차언어 표현 학습.

케네스 힐필드. 2011. KenLM: 더 빠르고 작은 언어 모델 쿼리. 제6회 통계 기계 번역 워크샵 논문집, 187-197쪽, 에든버러, 스코틀랜드. Association for Computational Linguistics.

Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, 그리고 Pascale Fung. 2018. 엔드 투 엔드 자동 코드 스위칭 음성 인식을 향하여. arXiv 전자 출판물, 페이지 arXiv-1810.

Ke Li, Jinyu Li, Guoli Ye, Rui Zhao, and Yifan Gong.
2019a. Towards code-switching asr for end-to-end
ctc models. In ICASSP 2019 - 2019 IEEE Interna-
tional Conference on Acoustics, Speech and Signal
Processing (ICASSP), pages 6076–6080.

케 리, 진유 리, 구올리 예, 루이 조, 이판 공.
2019a. 엔드 투 엔드 CTC 모델을 위한 코드 스위칭 ASR을 향하여. ICASSP 2019 - 2019 IEEE 국제 음향, 음성 및 신호 처리 컨퍼런스(ICASSP), 페이지 6076-6080.

Ke Li, Jinyu Li, Guoli Ye, Rui Zhao, and Yifan Gong.
2019b. Towards code-switching asr for end-to-end
ctc models. In ICASSP 2019 - 2019 IEEE Interna-
tional Conference on Acoustics, Speech and Signal
Processing (ICASSP), pages 6076–6080.

케 리, 진유 리, 구올리 예, 루이 조, 이판 공.
2019b. 엔드 투 엔드 CTC 모델을 위한 코드 스위칭 ASR을 향하여. ICASSP 2019 - 2019 IEEE 국제 음향, 음성 및 신호 처리 컨퍼런스(ICASSP)에서, 페이지 6076-6080.

네 루오, 동웨이 장, 쇼지앙 조, 카이샤 공,
웨이 조우, 그리고 샹강 리. 2018년. 엔드-투-엔드 코드 스위칭 음성 인식을 향하여. arXiv 사전 인쇄 arXiv:1810.13091.

다우청 류, 렌 유안 류, 유앙 친 치앙, 그리고
춘 난 슈. 2006. 중국어 방언 간의 코드 스위칭에 대한 음성 인식. 2006 IEEE 국제 음향, 음성 및 신호 처리 학회 논문집, 1권, I-I 페이지.

Carol Myers-Scotton. 2017. 코드 스위칭. 사회언어학 핸드북, 217-237쪽.

토마스 니슬러 외. 2018. 다국어 코드 스위칭된 남아프리카의 첫 번째 연속극 말뭉치. 언어 자원 및 평가에 관한 제11회 국제 학회 (LREC 2018) 논문집에서 발표됨.

다니엘 포비, 아르납 고샬, 질 불리안, 루카스 부르겟, 온드레이 글렘베크, 나겐드라 고엘, 미르코 한네만, 페트르 모틀리체크, 얀민 치안, 페트르 슈바르츠 등. 2011년. Kaldi 음성 인식 도구. IEEE 2011 자동 음성 인식 및 이해 워크샵, CONF. IEEE 신호처리 학회.

SaiKrishna Rallabandi, Sunayana Sitaram, 그리고 Alan W Black. 2018. 음향으로부터의 코드 스위칭 스타일의 자동 감지. 제3회 언어 코드 스위칭에 대한 계산적 접근 방식 워크샵 논문집, 76-81쪽, 멜버른, 호주. Association for Computational Linguistics.

통통 송, 척 쉬, 멍 게, 롱비아오 왕,
하오 시, 용지 루, 유친 린, 그리고 지안우 당.
2022년. 코드 스위칭 음성 인식을 위한
언어별 특성 지원. 인터스피치
2022년.

Qinyi Wang, Emre Yılmaz, Adem Derinel, and Haizhou Li. 2019. Code-switching detection using asr-generated language posteriors. Proc. Interspeech 2019, pages 3740–3744.

Qinyi Wang, Emre Yılmaz, Adem Derinel, 그리고 Haizhou Li. 2019. ASR 생성 언어 후보를 사용한 코드 스위칭 감지. Interspeech 2019, 페이지 3740-3744.

Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, 그리고 Pascale Fung. 2018. 엔드 투 엔드 자동 코드 스위칭 음성 인식을 향하여. arXiv 사전 인쇄 arXiv:1810.12620.

엠레 윌마즈, 헨크 반 덴 허벨, 그리고 다비드 반 리우언. 2016. 다중 언어 DNN을 사용한 코드 스위칭 감지. 2016 IEEE 음성 언어 기술 워크샵 (SLT) 논문집, 610-616쪽. IEEE.

징 지핑, 예르볼라트 하산노프, 하이화 쉬우 반
풍 펌, 엥 셩 청, 하이저우 리. 2019.
중영 코드 스위칭 음성 인식에 대한 엔드 투 엔드 솔루션에 관하여. 인터스피치 2019.

Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Yu Ting Yeung, and Liqun Deng. 2022. 다중 언어적 맥락 혼동을 줄이는 엔드 투 엔드 코드 스위칭 자동 음성 인식을 위한 연구. InProc. Interspeech, 페이지 3894-3898.

88
저자 색인

아가르왈, 아시쉬, 14세
아지, 알함 피크리, 43세
알라스트루이, 벨렌, 14세

카히야위자야, 사무엘, 43
차다, 아만, 64
차터지, 아누밥, 64
크루즈, 잔 크리스찬 블레이즈, 43

다스, 아미타바, 64
다완, 쿠날, 74

포드, 제시카 조사, 43세

가르시아, 로우에나, 43세
긴즈버그, 보리스, 74세
골란, 크리스천, 14세
구프타, 니하리카, 64세

제인, 비니자, 64
주라프스키, 댄, 83

칸두쿠리, 사이 테자, 64세

리, 하이저우, 33세
러베니아, 홀리, 43세

매닝, 크리스토퍼, 83세
모하메드, 모신 알리, 64세

Ng, 팀, 14세

오군레미, 톨루로페, 83세

파하리, 니라지, 23
팟와, 파르트, 64
판, 롱, 43, 43

레케시, KDimating, 74

심다, 카즈타카, 23
솔로리오, 타마르, 43
스퍼버, 마티아스, 14
스터너, 이고르, 1
수브라모니안, 아르준, 43
수타위카, 린탕, 43

탄, 인린, 43세
텔라르, 도미닉, 14세
토이펠, 시몬, 1세

왕, 친이, 33세
왕, 스카일러, 43세
위나타, 겐타 인드라, 43세

용, 정신신, 43세

장, 루첸, 43세

89

